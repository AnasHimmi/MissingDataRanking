{
    "submission_name": "mT5_small",
    "param_count": "-",
    "schema_guided_dialog_val": {
        "predictions_file": "mT5_small/schema_guided_dialog_val",
        "N": 10000,
        "total_length": 119963,
        "mean_pred_length": 11.9963,
        "std_pred_length": 6.857527711209048,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.03298517042754849,
        "vocab_size-1": 3957,
        "unique-1": 1700,
        "entropy-1": 8.002474259542447,
        "distinct-2": 0.11522966816110873,
        "vocab_size-2": 12671,
        "unique-2": 6526,
        "entropy-2": 11.017533211002986,
        "cond_entropy-2": 2.7433340211918176,
        "distinct-3": 0.21751047887718455,
        "vocab_size-3": 21743,
        "unique-3": 13078,
        "entropy-3": 12.309760020741422,
        "cond_entropy-3": 1.3286125790018315,
        "total_length-nopunct": 105423,
        "mean_pred_length-nopunct": 10.5423,
        "std_pred_length-nopunct": 6.314207053146104,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.03738273431793821,
        "vocab_size-1-nopunct": 3941,
        "unique-1-nopunct": 1696,
        "entropy-1-nopunct": 8.22442451148219,
        "distinct-2-nopunct": 0.1249174727267011,
        "vocab_size-2-nopunct": 11920,
        "unique-2-nopunct": 6380,
        "entropy-2-nopunct": 10.891260101257107,
        "cond_entropy-2-nopunct": 2.81766268787799,
        "distinct-3-nopunct": 0.2352831005864519,
        "vocab_size-3-nopunct": 20100,
        "unique-3-nopunct": 12532,
        "entropy-3-nopunct": 12.206217758162799,
        "cond_entropy-3-nopunct": 1.3584269285887765,
        "msttr-100": 0.69107,
        "msttr-100_nopunct": 0.71889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_val.json",
        "local_recall": {
            "1": 0.6015793585832279
        },
        "rouge1": {
            "precision": 0.62225,
            "recall": 0.59859,
            "fmeasure": 0.59605
        },
        "rouge2": {
            "precision": 0.39901,
            "recall": 0.38524,
            "fmeasure": 0.38192
        },
        "rougeL": {
            "precision": 0.56271,
            "recall": 0.54176,
            "fmeasure": 0.53928
        },
        "rougeLsum": {
            "precision": 0.56271,
            "recall": 0.54176,
            "fmeasure": 0.53928
        },
        "nist": 7.359432005081272,
        "bleu": 34.4962,
        "bertscore": {
            "precision": 0.88333,
            "recall": 0.87582,
            "f1": 0.87896
        },
        "bleurt": 0.02437,
        "meteor": 0.338604001956967,
        "nubia": {
            "semantic_relation": 3.8227,
            "contradiction": 4.89678,
            "irrelevancy": 17.95911,
            "logical_agreement": 77.14411,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.58617,
            "nubia_score": 0.7059
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 10000,
        "total_length": 125695,
        "mean_pred_length": 12.5695,
        "std_pred_length": 7.423191345371611,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 87,
        "distinct-1": 0.032236763594415054,
        "vocab_size-1": 4052,
        "unique-1": 1781,
        "entropy-1": 7.926999895971281,
        "distinct-2": 0.1182159989627901,
        "vocab_size-2": 13677,
        "unique-2": 7206,
        "entropy-2": 11.05902264204335,
        "cond_entropy-2": 2.8697628997653304,
        "distinct-3": 0.2262621102028459,
        "vocab_size-3": 23915,
        "unique-3": 14511,
        "entropy-3": 12.43441478719614,
        "cond_entropy-3": 1.4197853890244387,
        "total_length-nopunct": 110479,
        "mean_pred_length-nopunct": 11.0479,
        "std_pred_length-nopunct": 6.772503642671593,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.036531829578471925,
        "vocab_size-1-nopunct": 4036,
        "unique-1-nopunct": 1779,
        "entropy-1-nopunct": 8.132945330966844,
        "distinct-2-nopunct": 0.12829546472397219,
        "vocab_size-2-nopunct": 12891,
        "unique-2-nopunct": 7020,
        "entropy-2-nopunct": 10.938804478992635,
        "cond_entropy-2-nopunct": 2.965103979651184,
        "distinct-3-nopunct": 0.24535537847724936,
        "vocab_size-3-nopunct": 22200,
        "unique-3-nopunct": 13915,
        "entropy-3-nopunct": 12.334555769144455,
        "cond_entropy-3-nopunct": 1.4602500732828958,
        "msttr-100": 0.672,
        "msttr-100_nopunct": 0.69676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5479307188496982
        },
        "rouge1": {
            "precision": 0.57305,
            "recall": 0.53927,
            "fmeasure": 0.54369
        },
        "rouge2": {
            "precision": 0.35152,
            "recall": 0.33129,
            "fmeasure": 0.33313
        },
        "rougeL": {
            "precision": 0.51533,
            "recall": 0.48453,
            "fmeasure": 0.48874
        },
        "rougeLsum": {
            "precision": 0.51533,
            "recall": 0.48453,
            "fmeasure": 0.48874
        },
        "nist": 6.674012425361793,
        "bleu": 30.42991,
        "bertscore": {
            "precision": 0.8728,
            "recall": 0.86221,
            "f1": 0.86699
        },
        "bleurt": -0.09119,
        "meteor": 0.3063605206249328,
        "nubia": {
            "semantic_relation": 3.55556,
            "contradiction": 9.43825,
            "irrelevancy": 21.5783,
            "logical_agreement": 68.98345,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.50376,
            "nubia_score": 0.63508
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "mT5_small/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "total_length": 6639,
        "mean_pred_length": 13.278,
        "std_pred_length": 7.955169137108275,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 51,
        "distinct-1": 0.1602651001656876,
        "vocab_size-1": 1064,
        "unique-1": 601,
        "entropy-1": 7.880611793002743,
        "distinct-2": 0.5197914969864799,
        "vocab_size-2": 3191,
        "unique-2": 2294,
        "entropy-2": 10.937504630962184,
        "cond_entropy-2": 2.80934734878119,
        "distinct-3": 0.7618372051782231,
        "vocab_size-3": 4296,
        "unique-3": 3654,
        "entropy-3": 11.795472912599017,
        "cond_entropy-3": 0.8750760668702964,
        "total_length-nopunct": 5794,
        "mean_pred_length-nopunct": 11.588,
        "std_pred_length-nopunct": 7.258805411360742,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.1815671384190542,
        "vocab_size-1-nopunct": 1052,
        "unique-1-nopunct": 598,
        "entropy-1-nopunct": 8.089574092463284,
        "distinct-2-nopunct": 0.5402342274272761,
        "vocab_size-2-nopunct": 2860,
        "unique-2-nopunct": 2125,
        "entropy-2-nopunct": 10.775821956383087,
        "cond_entropy-2-nopunct": 2.813669111874865,
        "distinct-3-nopunct": 0.7778936392075079,
        "vocab_size-3-nopunct": 3730,
        "unique-3-nopunct": 3231,
        "entropy-3-nopunct": 11.594732426663965,
        "cond_entropy-3-nopunct": 0.8500970904042701,
        "msttr-100": 0.69106,
        "msttr-100_nopunct": 0.72228,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.4981454005934718
        },
        "rouge1": {
            "precision": 0.48128,
            "recall": 0.48145,
            "fmeasure": 0.46716
        },
        "rouge2": {
            "precision": 0.25817,
            "recall": 0.26171,
            "fmeasure": 0.25103
        },
        "rougeL": {
            "precision": 0.42084,
            "recall": 0.42085,
            "fmeasure": 0.40824
        },
        "rougeLsum": {
            "precision": 0.42084,
            "recall": 0.42085,
            "fmeasure": 0.40824
        },
        "nist": 4.928478940731826,
        "bleu": 23.97164,
        "bertscore": {
            "precision": 0.84421,
            "recall": 0.84475,
            "f1": 0.84393
        },
        "bleurt": -0.26901,
        "meteor": 0.2759969040666043,
        "nubia": {
            "semantic_relation": 3.2834,
            "contradiction": 10.73308,
            "irrelevancy": 28.65542,
            "logical_agreement": 60.6115,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.70452,
            "nubia_score": 0.54637
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "mT5_small/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "total_length": 6632,
        "mean_pred_length": 13.264,
        "std_pred_length": 8.637957165904448,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 91,
        "distinct-1": 0.16043425814234016,
        "vocab_size-1": 1064,
        "unique-1": 583,
        "entropy-1": 7.946706121233607,
        "distinct-2": 0.5244618395303327,
        "vocab_size-2": 3216,
        "unique-2": 2274,
        "entropy-2": 10.995676821200068,
        "cond_entropy-2": 2.818182160227196,
        "distinct-3": 0.7741477272727273,
        "vocab_size-3": 4360,
        "unique-3": 3701,
        "entropy-3": 11.853046984013563,
        "cond_entropy-3": 0.8751205548546135,
        "total_length-nopunct": 5825,
        "mean_pred_length-nopunct": 11.65,
        "std_pred_length-nopunct": 7.923603977988804,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.18042918454935622,
        "vocab_size-1-nopunct": 1051,
        "unique-1-nopunct": 579,
        "entropy-1-nopunct": 8.139107976552145,
        "distinct-2-nopunct": 0.543661971830986,
        "vocab_size-2-nopunct": 2895,
        "unique-2-nopunct": 2115,
        "entropy-2-nopunct": 10.839753322778343,
        "cond_entropy-2-nopunct": 2.828412545028065,
        "distinct-3-nopunct": 0.7881110190555095,
        "vocab_size-3-nopunct": 3805,
        "unique-3-nopunct": 3283,
        "entropy-3-nopunct": 11.663017181031242,
        "cond_entropy-3-nopunct": 0.8560823016872037,
        "msttr-100": 0.69788,
        "msttr-100_nopunct": 0.7231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "local_recall": {
            "1": 0.4929405612689559
        },
        "rouge1": {
            "precision": 0.50385,
            "recall": 0.48133,
            "fmeasure": 0.47808
        },
        "rouge2": {
            "precision": 0.28701,
            "recall": 0.27162,
            "fmeasure": 0.27094
        },
        "rougeL": {
            "precision": 0.44648,
            "recall": 0.42565,
            "fmeasure": 0.42333
        },
        "rougeLsum": {
            "precision": 0.44648,
            "recall": 0.42565,
            "fmeasure": 0.42333
        },
        "nist": 5.243195204691079,
        "bleu": 24.87986,
        "bertscore": {
            "precision": 0.84837,
            "recall": 0.84227,
            "f1": 0.84476
        },
        "bleurt": -0.30384,
        "meteor": 0.2762634220540829,
        "nubia": {
            "semantic_relation": 3.26619,
            "contradiction": 10.92877,
            "irrelevancy": 27.90272,
            "logical_agreement": 61.1685,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.92814,
            "nubia_score": 0.52813
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "mT5_small/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "total_length": 6256,
        "mean_pred_length": 12.512,
        "std_pred_length": 7.729803102278868,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 48,
        "distinct-1": 0.1656010230179028,
        "vocab_size-1": 1036,
        "unique-1": 603,
        "entropy-1": 7.858644384959474,
        "distinct-2": 0.5262334954829743,
        "vocab_size-2": 3029,
        "unique-2": 2179,
        "entropy-2": 10.85675149346029,
        "cond_entropy-2": 2.75821530229204,
        "distinct-3": 0.7682648401826484,
        "vocab_size-3": 4038,
        "unique-3": 3443,
        "entropy-3": 11.703740472905277,
        "cond_entropy-3": 0.8630835549952167,
        "total_length-nopunct": 5496,
        "mean_pred_length-nopunct": 10.992,
        "std_pred_length-nopunct": 7.046696814820402,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.18631732168850074,
        "vocab_size-1-nopunct": 1024,
        "unique-1-nopunct": 599,
        "entropy-1-nopunct": 8.057245399453018,
        "distinct-2-nopunct": 0.5422337870296237,
        "vocab_size-2-nopunct": 2709,
        "unique-2-nopunct": 2000,
        "entropy-2-nopunct": 10.68508964448912,
        "cond_entropy-2-nopunct": 2.7515779719992945,
        "distinct-3-nopunct": 0.7784697508896797,
        "vocab_size-3-nopunct": 3500,
        "unique-3-nopunct": 3027,
        "entropy-3-nopunct": 11.496028940952081,
        "cond_entropy-3-nopunct": 0.8322493986737065,
        "msttr-100": 0.69113,
        "msttr-100_nopunct": 0.71704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "local_recall": {
            "1": 0.4869915720043972
        },
        "rouge1": {
            "precision": 0.49645,
            "recall": 0.47195,
            "fmeasure": 0.47103
        },
        "rouge2": {
            "precision": 0.27067,
            "recall": 0.25731,
            "fmeasure": 0.25686
        },
        "rougeL": {
            "precision": 0.44081,
            "recall": 0.41883,
            "fmeasure": 0.41842
        },
        "rougeLsum": {
            "precision": 0.44081,
            "recall": 0.41883,
            "fmeasure": 0.41842
        },
        "nist": 5.047245742465562,
        "bleu": 24.68689,
        "bertscore": {
            "precision": 0.8482,
            "recall": 0.84214,
            "f1": 0.84462
        },
        "bleurt": -0.28954,
        "meteor": 0.27334592009937675,
        "nubia": {
            "semantic_relation": 3.24333,
            "contradiction": 11.35023,
            "irrelevancy": 27.0318,
            "logical_agreement": 61.61797,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.84754,
            "nubia_score": 0.52415
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "mT5_small/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "total_length": 6601,
        "mean_pred_length": 13.202,
        "std_pred_length": 8.100197281548148,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 54,
        "distinct-1": 0.17133767610968034,
        "vocab_size-1": 1131,
        "unique-1": 652,
        "entropy-1": 8.084642972472068,
        "distinct-2": 0.5400753974758237,
        "vocab_size-2": 3295,
        "unique-2": 2457,
        "entropy-2": 10.990753343284023,
        "cond_entropy-2": 2.8476629542216343,
        "distinct-3": 0.7734333154793787,
        "vocab_size-3": 4332,
        "unique-3": 3753,
        "entropy-3": 11.802375795328967,
        "cond_entropy-3": 0.8501864218054741,
        "total_length-nopunct": 5982,
        "mean_pred_length-nopunct": 11.964,
        "std_pred_length-nopunct": 7.450819015383477,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.18706118355065196,
        "vocab_size-1-nopunct": 1119,
        "unique-1-nopunct": 650,
        "entropy-1-nopunct": 8.183505666577258,
        "distinct-2-nopunct": 0.5545421379058738,
        "vocab_size-2-nopunct": 3040,
        "unique-2-nopunct": 2313,
        "entropy-2-nopunct": 10.867038046714253,
        "cond_entropy-2-nopunct": 2.8008650945047853,
        "distinct-3-nopunct": 0.7808109193095143,
        "vocab_size-3-nopunct": 3890,
        "unique-3-nopunct": 3407,
        "entropy-3-nopunct": 11.644560371844303,
        "cond_entropy-3-nopunct": 0.8086116066592415,
        "msttr-100": 0.71591,
        "msttr-100_nopunct": 0.73136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.49265797723147997
        },
        "rouge1": {
            "precision": 0.50881,
            "recall": 0.47258,
            "fmeasure": 0.47631
        },
        "rouge2": {
            "precision": 0.29591,
            "recall": 0.26934,
            "fmeasure": 0.27332
        },
        "rougeL": {
            "precision": 0.4457,
            "recall": 0.41253,
            "fmeasure": 0.41662
        },
        "rougeLsum": {
            "precision": 0.4457,
            "recall": 0.41253,
            "fmeasure": 0.41662
        },
        "nist": 5.298663468847307,
        "bleu": 23.98676,
        "bertscore": {
            "precision": 0.84783,
            "recall": 0.834,
            "f1": 0.8403
        },
        "bleurt": -0.30868,
        "meteor": 0.2730738161489726,
        "nubia": {
            "semantic_relation": 3.32933,
            "contradiction": 9.67289,
            "irrelevancy": 27.65496,
            "logical_agreement": 62.67215,
            "grammar_ref": 4.79983,
            "grammar_hyp": 5.05524,
            "nubia_score": 0.52818
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "mT5_small/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "total_length": 6566,
        "mean_pred_length": 13.132,
        "std_pred_length": 7.689380729291534,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 52,
        "distinct-1": 0.15686871763630825,
        "vocab_size-1": 1030,
        "unique-1": 565,
        "entropy-1": 7.8572521925217,
        "distinct-2": 0.5133531157270029,
        "vocab_size-2": 3114,
        "unique-2": 2189,
        "entropy-2": 10.916602928670821,
        "cond_entropy-2": 2.825485714847246,
        "distinct-3": 0.7601509162773985,
        "vocab_size-3": 4231,
        "unique-3": 3558,
        "entropy-3": 11.78625609979401,
        "cond_entropy-3": 0.8875918679002914,
        "total_length-nopunct": 5789,
        "mean_pred_length-nopunct": 11.578,
        "std_pred_length-nopunct": 7.057188958785219,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.17602349283123164,
        "vocab_size-1-nopunct": 1019,
        "unique-1-nopunct": 563,
        "entropy-1-nopunct": 8.040904525301878,
        "distinct-2-nopunct": 0.5297787861599547,
        "vocab_size-2-nopunct": 2802,
        "unique-2-nopunct": 2015,
        "entropy-2-nopunct": 10.756762471189903,
        "cond_entropy-2-nopunct": 2.844161790905173,
        "distinct-3-nopunct": 0.7713987473903967,
        "vocab_size-3-nopunct": 3695,
        "unique-3-nopunct": 3161,
        "entropy-3-nopunct": 11.587177649841488,
        "cond_entropy-3-nopunct": 0.8708432244429493,
        "msttr-100": 0.69277,
        "msttr-100_nopunct": 0.71526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.47823094131818966
        },
        "rouge1": {
            "precision": 0.48546,
            "recall": 0.45424,
            "fmeasure": 0.45651
        },
        "rouge2": {
            "precision": 0.25165,
            "recall": 0.23428,
            "fmeasure": 0.23596
        },
        "rougeL": {
            "precision": 0.41632,
            "recall": 0.38899,
            "fmeasure": 0.39101
        },
        "rougeLsum": {
            "precision": 0.41632,
            "recall": 0.38899,
            "fmeasure": 0.39101
        },
        "nist": 5.047574514893082,
        "bleu": 22.86943,
        "bertscore": {
            "precision": 0.84275,
            "recall": 0.8344,
            "f1": 0.83804
        },
        "bleurt": -0.34742,
        "meteor": 0.26307656784639266,
        "nubia": {
            "semantic_relation": 3.17012,
            "contradiction": 11.86688,
            "irrelevancy": 26.86496,
            "logical_agreement": 61.26817,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.83051,
            "nubia_score": 0.51389
        }
    },
    "xsum_val": {
        "predictions_file": "mT5_small/xsum_val",
        "N": 1117,
        "total_length": 21612,
        "mean_pred_length": 19.348254252461953,
        "std_pred_length": 4.090683028751066,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.17499537294095874,
        "vocab_size-1": 3782,
        "unique-1": 2087,
        "entropy-1": 8.74455438586923,
        "distinct-2": 0.5422298121493047,
        "vocab_size-2": 11113,
        "unique-2": 8835,
        "entropy-2": 12.370403529970421,
        "cond_entropy-2": 3.382206188852073,
        "distinct-3": 0.7709257921354112,
        "vocab_size-3": 14939,
        "unique-3": 13370,
        "entropy-3": 13.464474801948509,
        "cond_entropy-3": 1.128271336342719,
        "total_length-nopunct": 20074,
        "mean_pred_length-nopunct": 17.971351835273055,
        "std_pred_length-nopunct": 3.8628088335829394,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.18795456809803726,
        "vocab_size-1-nopunct": 3773,
        "unique-1-nopunct": 2087,
        "entropy-1-nopunct": 8.919024552379732,
        "distinct-2-nopunct": 0.5461834678482882,
        "vocab_size-2-nopunct": 10354,
        "unique-2-nopunct": 8272,
        "entropy-2-nopunct": 12.270688401942904,
        "cond_entropy-2-nopunct": 3.5135749991826586,
        "distinct-3-nopunct": 0.7790919282511211,
        "vocab_size-3-nopunct": 13899,
        "unique-3-nopunct": 12460,
        "entropy-3-nopunct": 13.394756057115492,
        "cond_entropy-3-nopunct": 1.1659077401882034,
        "msttr-100": 0.67144,
        "msttr-100_nopunct": 0.6907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_val.json",
        "local_recall": {
            "1": 0.2797705095771594
        },
        "rouge1": {
            "precision": 0.35586,
            "recall": 0.30294,
            "fmeasure": 0.3203
        },
        "rouge2": {
            "precision": 0.1138,
            "recall": 0.09672,
            "fmeasure": 0.10222
        },
        "rougeL": {
            "precision": 0.27584,
            "recall": 0.23552,
            "fmeasure": 0.24856
        },
        "rougeLsum": {
            "precision": 0.27584,
            "recall": 0.23552,
            "fmeasure": 0.24856
        },
        "nist": 2.8566265775929107,
        "bleu": 5.9307,
        "bertscore": {
            "precision": 0.81643,
            "recall": 0.79355,
            "f1": 0.80454
        },
        "bleurt": -0.4996,
        "meteor": 0.1308898016347364,
        "nubia": {
            "semantic_relation": 2.19439,
            "contradiction": 35.54491,
            "irrelevancy": 56.61903,
            "logical_agreement": 7.83606,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.82372,
            "nubia_score": 0.25103
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 460,
        "total_length": 10950,
        "mean_pred_length": 23.804347826086957,
        "std_pred_length": 7.61040353502845,
        "median_pred_length": 24.0,
        "min_pred_length": 6,
        "max_pred_length": 48,
        "distinct-1": 0.12757990867579908,
        "vocab_size-1": 1397,
        "unique-1": 381,
        "entropy-1": 8.256297762331931,
        "distinct-2": 0.2913250714966635,
        "vocab_size-2": 3056,
        "unique-2": 1283,
        "entropy-2": 10.67257665165797,
        "cond_entropy-2": 2.2180426086342795,
        "distinct-3": 0.4135593220338983,
        "vocab_size-3": 4148,
        "unique-3": 2171,
        "entropy-3": 11.45615884524178,
        "cond_entropy-3": 0.8133324303325887,
        "total_length-nopunct": 8956,
        "mean_pred_length-nopunct": 19.469565217391306,
        "std_pred_length-nopunct": 6.886750655684637,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.15520321572130416,
        "vocab_size-1-nopunct": 1390,
        "unique-1-nopunct": 381,
        "entropy-1-nopunct": 8.871677603786045,
        "distinct-2-nopunct": 0.3303907721280603,
        "vocab_size-2-nopunct": 2807,
        "unique-2-nopunct": 1283,
        "entropy-2-nopunct": 10.707738705445712,
        "cond_entropy-2-nopunct": 1.903547968394141,
        "distinct-3-nopunct": 0.45818815331010454,
        "vocab_size-3-nopunct": 3682,
        "unique-3-nopunct": 2084,
        "entropy-3-nopunct": 11.346495831453076,
        "cond_entropy-3-nopunct": 0.6709402734675497,
        "msttr-100": 0.54092,
        "msttr-100_nopunct": 0.58517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.24965229485396384,
            "2": 0.589936057825966,
            "3": 0.8036785285885646,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.32305,
            "recall": 0.31942,
            "fmeasure": 0.31453
        },
        "rouge2": {
            "precision": 0.13464,
            "recall": 0.13082,
            "fmeasure": 0.12854
        },
        "rougeL": {
            "precision": 0.32095,
            "recall": 0.31756,
            "fmeasure": 0.31258
        },
        "rougeLsum": {
            "precision": 0.32095,
            "recall": 0.31756,
            "fmeasure": 0.31258
        },
        "nist": 7.991530810761576,
        "bleu": 43.53096,
        "bertscore": {
            "precision": 0.95166,
            "recall": 0.94092,
            "f1": 0.94552
        },
        "bleurt": 0.13418,
        "meteor": 0.5706095552516527,
        "nubia": {
            "semantic_relation": 3.93171,
            "contradiction": 19.12032,
            "irrelevancy": 21.98099,
            "logical_agreement": 58.89868,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.35497,
            "nubia_score": 0.82608
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 253,
        "total_length": 2160,
        "mean_pred_length": 8.537549407114625,
        "std_pred_length": 2.836028287092249,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.4041666666666667,
        "vocab_size-1": 873,
        "unique-1": 565,
        "entropy-1": 8.29338776176102,
        "distinct-2": 0.7435762978500262,
        "vocab_size-2": 1418,
        "unique-2": 1137,
        "entropy-2": 10.22322111328396,
        "cond_entropy-2": 1.2400115727766874,
        "distinct-3": 0.8651753325272068,
        "vocab_size-3": 1431,
        "unique-3": 1262,
        "entropy-3": 10.386395319735774,
        "cond_entropy-3": 0.17028821461180818,
        "total_length-nopunct": 1724,
        "mean_pred_length-nopunct": 6.8142292490118574,
        "std_pred_length-nopunct": 2.4318934657726716,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5034802784222738,
        "vocab_size-1-nopunct": 868,
        "unique-1-nopunct": 565,
        "entropy-1-nopunct": 9.035094702516806,
        "distinct-2-nopunct": 0.7627464309993202,
        "vocab_size-2-nopunct": 1122,
        "unique-2-nopunct": 925,
        "entropy-2-nopunct": 9.894878803196425,
        "cond_entropy-2-nopunct": 0.9946326021069588,
        "distinct-3-nopunct": 0.8719211822660099,
        "vocab_size-3-nopunct": 1062,
        "unique-3-nopunct": 951,
        "entropy-3-nopunct": 9.954424126114075,
        "cond_entropy-3-nopunct": 0.14431126682029768,
        "msttr-100": 0.75286,
        "msttr-100_nopunct": 0.87294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3699658703071672,
            "2": 0.6471408647140865,
            "3": 0.8054607508532423,
            "4": 0.7428571428571429,
            "5": 0.8181818181818182,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.32543,
            "recall": 0.32987,
            "fmeasure": 0.32446
        },
        "rouge2": {
            "precision": 0.17935,
            "recall": 0.18204,
            "fmeasure": 0.17763
        },
        "rougeL": {
            "precision": 0.32477,
            "recall": 0.32938,
            "fmeasure": 0.3239
        },
        "rougeLsum": {
            "precision": 0.32477,
            "recall": 0.32938,
            "fmeasure": 0.3239
        },
        "nist": 8.024497689674533,
        "bleu": 55.73962,
        "bertscore": {
            "precision": 0.96278,
            "recall": 0.95927,
            "f1": 0.96047
        },
        "bleurt": 0.35141,
        "meteor": 0.7199436486349332,
        "nubia": {
            "semantic_relation": 4.11578,
            "contradiction": 22.97725,
            "irrelevancy": 19.66125,
            "logical_agreement": 57.3615,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.90333,
            "nubia_score": 0.82486
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2105,
        "mean_pred_length": 19.858490566037737,
        "std_pred_length": 3.7878621422118264,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.36152019002375296,
        "vocab_size-1": 761,
        "unique-1": 528,
        "entropy-1": 7.923600645063321,
        "distinct-2": 0.7678839419709855,
        "vocab_size-2": 1535,
        "unique-2": 1325,
        "entropy-2": 10.26525225181814,
        "cond_entropy-2": 2.1501242642550515,
        "distinct-3": 0.9286846275752774,
        "vocab_size-3": 1758,
        "unique-3": 1669,
        "entropy-3": 10.711689590470268,
        "cond_entropy-3": 0.47254670263540377,
        "total_length-nopunct": 1968,
        "mean_pred_length-nopunct": 18.566037735849058,
        "std_pred_length-nopunct": 3.660134207057215,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.38414634146341464,
        "vocab_size-1-nopunct": 756,
        "unique-1-nopunct": 527,
        "entropy-1-nopunct": 8.031753825061317,
        "distinct-2-nopunct": 0.765843179377014,
        "vocab_size-2-nopunct": 1426,
        "unique-2-nopunct": 1233,
        "entropy-2-nopunct": 10.151918949106028,
        "cond_entropy-2-nopunct": 2.2362727319791227,
        "distinct-3-nopunct": 0.933371298405467,
        "vocab_size-3-nopunct": 1639,
        "unique-3-nopunct": 1559,
        "entropy-3-nopunct": 10.620455165753107,
        "cond_entropy-3-nopunct": 0.49220169832124333,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.69,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2907834101382488
        },
        "rouge1": {
            "precision": 0.3606,
            "recall": 0.31218,
            "fmeasure": 0.32723
        },
        "rouge2": {
            "precision": 0.11718,
            "recall": 0.10085,
            "fmeasure": 0.10585
        },
        "rougeL": {
            "precision": 0.27385,
            "recall": 0.23649,
            "fmeasure": 0.24825
        },
        "rougeLsum": {
            "precision": 0.27385,
            "recall": 0.23649,
            "fmeasure": 0.24825
        },
        "nist": 2.6293244632189294,
        "bleu": 6.68857,
        "bertscore": {
            "precision": 0.82018,
            "recall": 0.79562,
            "f1": 0.80746
        },
        "bleurt": -0.47557,
        "meteor": 0.1391618135887116,
        "nubia": {
            "semantic_relation": 2.19183,
            "contradiction": 36.61538,
            "irrelevancy": 54.45142,
            "logical_agreement": 8.9332,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.70672,
            "nubia_score": 0.26207
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 369,
        "total_length": 4124,
        "mean_pred_length": 11.176151761517616,
        "std_pred_length": 3.539000722304221,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.19907856450048497,
        "vocab_size-1": 821,
        "unique-1": 447,
        "entropy-1": 7.2182500721138965,
        "distinct-2": 0.5075898801597869,
        "vocab_size-2": 1906,
        "unique-2": 1337,
        "entropy-2": 10.20856091230677,
        "cond_entropy-2": 2.621279795586187,
        "distinct-3": 0.710277613703485,
        "vocab_size-3": 2405,
        "unique-3": 1930,
        "entropy-3": 10.941532393350151,
        "cond_entropy-3": 0.8416245719805527,
        "total_length-nopunct": 3536,
        "mean_pred_length-nopunct": 9.582655826558266,
        "std_pred_length-nopunct": 2.926252075978409,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.229920814479638,
        "vocab_size-1-nopunct": 813,
        "unique-1-nopunct": 446,
        "entropy-1-nopunct": 7.489854321729309,
        "distinct-2-nopunct": 0.49384275339437955,
        "vocab_size-2-nopunct": 1564,
        "unique-2-nopunct": 1061,
        "entropy-2-nopunct": 9.92336929663998,
        "cond_entropy-2-nopunct": 2.7758522185049674,
        "distinct-3-nopunct": 0.7008577555396712,
        "vocab_size-3-nopunct": 1961,
        "unique-3-nopunct": 1551,
        "entropy-3-nopunct": 10.647179896683927,
        "cond_entropy-3-nopunct": 0.8790939902661254,
        "msttr-100": 0.58512,
        "msttr-100_nopunct": 0.63686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2399364406779661,
            "2": 0.6011419249592169,
            "3": 0.7257636122177955,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.67354,
            "recall": 0.68497,
            "fmeasure": 0.67007
        },
        "rouge2": {
            "precision": 0.43314,
            "recall": 0.44003,
            "fmeasure": 0.42982
        },
        "rougeL": {
            "precision": 0.59896,
            "recall": 0.61445,
            "fmeasure": 0.59809
        },
        "rougeLsum": {
            "precision": 0.59896,
            "recall": 0.61445,
            "fmeasure": 0.59809
        },
        "nist": 6.753326165043678,
        "bleu": 38.55539,
        "bertscore": {
            "precision": 0.90077,
            "recall": 0.90646,
            "f1": 0.90244
        },
        "bleurt": -0.03985,
        "meteor": 0.36420324320527353,
        "nubia": {
            "semantic_relation": 3.88154,
            "contradiction": 25.92502,
            "irrelevancy": 13.27342,
            "logical_agreement": 60.80156,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.3045,
            "nubia_score": 0.60234
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 5049,
        "total_length": 36426,
        "mean_pred_length": 7.214497920380273,
        "std_pred_length": 2.4962915157084384,
        "median_pred_length": 7.0,
        "min_pred_length": 1,
        "max_pred_length": 29,
        "distinct-1": 0.027480371163454677,
        "vocab_size-1": 1001,
        "unique-1": 441,
        "entropy-1": 6.620144271287531,
        "distinct-2": 0.08691079453102592,
        "vocab_size-2": 2727,
        "unique-2": 1324,
        "entropy-2": 8.695040195982031,
        "cond_entropy-2": 1.6970146397650603,
        "distinct-3": 0.14011166394469976,
        "vocab_size-3": 3689,
        "unique-3": 2023,
        "entropy-3": 9.283318642252691,
        "cond_entropy-3": 0.655328538230744,
        "total_length-nopunct": 31022,
        "mean_pred_length-nopunct": 6.144186967716379,
        "std_pred_length-nopunct": 2.3010254539511577,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.03197730642769647,
        "vocab_size-1-nopunct": 992,
        "unique-1-nopunct": 441,
        "entropy-1-nopunct": 6.774876233750194,
        "distinct-2-nopunct": 0.08701343703076271,
        "vocab_size-2-nopunct": 2260,
        "unique-2-nopunct": 1120,
        "entropy-2-nopunct": 8.336060037719482,
        "cond_entropy-2-nopunct": 1.784328182650299,
        "distinct-3-nopunct": 0.1398260537130842,
        "vocab_size-3-nopunct": 2926,
        "unique-3-nopunct": 1649,
        "entropy-3-nopunct": 8.847695166933233,
        "cond_entropy-3-nopunct": 0.6622694201390948,
        "msttr-100": 0.54104,
        "msttr-100_nopunct": 0.5611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.44600925221057564
        },
        "rouge1": {
            "precision": 0.50397,
            "recall": 0.46834,
            "fmeasure": 0.47278
        },
        "rouge2": {
            "precision": 0.29214,
            "recall": 0.27165,
            "fmeasure": 0.27305
        },
        "rougeL": {
            "precision": 0.47853,
            "recall": 0.44305,
            "fmeasure": 0.44832
        },
        "rougeLsum": {
            "precision": 0.47853,
            "recall": 0.44305,
            "fmeasure": 0.44832
        },
        "nist": 4.490765522550951,
        "bleu": 24.63331,
        "bertscore": {
            "precision": 0.8583,
            "recall": 0.84783,
            "f1": 0.85244
        },
        "bleurt": -0.11377,
        "meteor": 0.25329441772738825,
        "nubia": {
            "semantic_relation": 3.08692,
            "contradiction": 9.42071,
            "irrelevancy": 23.0567,
            "logical_agreement": 67.52259,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.4389,
            "nubia_score": 0.57126
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 1,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 1.904753988810935,
        "bleu": 19.494,
        "bertscore": {
            "precision": 0.89366,
            "recall": 0.90014,
            "f1": 0.89689
        },
        "bleurt": 0.09528,
        "meteor": 0.3358855318220253,
        "nubia": {
            "semantic_relation": 3.26649,
            "contradiction": 63.10029,
            "irrelevancy": 11.75981,
            "logical_agreement": 25.1399,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.81175,
            "nubia_score": 0.57758
        }
    },
    "xsum_test": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 1166,
        "total_length": 22812,
        "mean_pred_length": 19.564322469982848,
        "std_pred_length": 4.578332500601563,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 85,
        "distinct-1": 0.17332982640715414,
        "vocab_size-1": 3954,
        "unique-1": 2187,
        "entropy-1": 8.777220122696722,
        "distinct-2": 0.5402383812251687,
        "vocab_size-2": 11694,
        "unique-2": 9245,
        "entropy-2": 12.42218277776913,
        "cond_entropy-2": 3.404422652361793,
        "distinct-3": 0.771240234375,
        "vocab_size-3": 15795,
        "unique-3": 14119,
        "entropy-3": 13.535209138777812,
        "cond_entropy-3": 1.147714287019343,
        "total_length-nopunct": 21139,
        "mean_pred_length-nopunct": 18.1295025728988,
        "std_pred_length-nopunct": 3.897204556425618,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.18652727186716495,
        "vocab_size-1-nopunct": 3943,
        "unique-1-nopunct": 2186,
        "entropy-1-nopunct": 8.95326044576094,
        "distinct-2-nopunct": 0.5442847844590196,
        "vocab_size-2-nopunct": 10871,
        "unique-2-nopunct": 8627,
        "entropy-2-nopunct": 12.317614989412162,
        "cond_entropy-2-nopunct": 3.5254267907410433,
        "distinct-3-nopunct": 0.781358004998139,
        "vocab_size-3-nopunct": 14695,
        "unique-3-nopunct": 13158,
        "entropy-3-nopunct": 13.470527253639162,
        "cond_entropy-3-nopunct": 1.1937280661581975,
        "msttr-100": 0.66763,
        "msttr-100_nopunct": 0.68654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.27882357963034105
        },
        "rouge1": {
            "precision": 0.36057,
            "recall": 0.30744,
            "fmeasure": 0.32471
        },
        "rouge2": {
            "precision": 0.11561,
            "recall": 0.09838,
            "fmeasure": 0.10376
        },
        "rougeL": {
            "precision": 0.278,
            "recall": 0.23773,
            "fmeasure": 0.25068
        },
        "rougeLsum": {
            "precision": 0.278,
            "recall": 0.23773,
            "fmeasure": 0.25068
        },
        "nist": 2.8828482919735534,
        "bleu": 6.17052,
        "bertscore": {
            "precision": 0.81671,
            "recall": 0.79339,
            "f1": 0.80457
        },
        "bleurt": -0.50689,
        "meteor": 0.13265884025802732,
        "nubia": {
            "semantic_relation": 2.22598,
            "contradiction": 35.03794,
            "irrelevancy": 56.70194,
            "logical_agreement": 8.26012,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.75414,
            "nubia_score": 0.26081
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 350,
        "total_length": 10433,
        "mean_pred_length": 29.80857142857143,
        "std_pred_length": 10.362594033447458,
        "median_pred_length": 29.0,
        "min_pred_length": 10,
        "max_pred_length": 94,
        "distinct-1": 0.10687242403910668,
        "vocab_size-1": 1115,
        "unique-1": 365,
        "entropy-1": 7.593010795580963,
        "distinct-2": 0.3047704056332441,
        "vocab_size-2": 3073,
        "unique-2": 1549,
        "entropy-2": 10.539288905552642,
        "cond_entropy-2": 2.829020045171924,
        "distinct-3": 0.4933730607212576,
        "vocab_size-3": 4802,
        "unique-3": 3072,
        "entropy-3": 11.664258686036542,
        "cond_entropy-3": 1.175762765009062,
        "total_length-nopunct": 9297,
        "mean_pred_length-nopunct": 26.562857142857144,
        "std_pred_length-nopunct": 9.50490356798714,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.11907066795740562,
        "vocab_size-1-nopunct": 1107,
        "unique-1-nopunct": 365,
        "entropy-1-nopunct": 7.7804607434836175,
        "distinct-2-nopunct": 0.31820722029730636,
        "vocab_size-2-nopunct": 2847,
        "unique-2-nopunct": 1507,
        "entropy-2-nopunct": 10.445767424632983,
        "cond_entropy-2-nopunct": 2.7828159718153143,
        "distinct-3-nopunct": 0.5093637315342562,
        "vocab_size-3-nopunct": 4379,
        "unique-3-nopunct": 2898,
        "entropy-3-nopunct": 11.545790709949612,
        "cond_entropy-3-nopunct": 1.1461473661903763,
        "msttr-100": 0.5724,
        "msttr-100_nopunct": 0.60457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23245484157536275,
            "2": 0.5591858596679165,
            "3": 0.744288681204569,
            "4": 0.4,
            "5": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.57435,
            "recall": 0.68193,
            "fmeasure": 0.61126
        },
        "rouge2": {
            "precision": 0.35169,
            "recall": 0.41705,
            "fmeasure": 0.37344
        },
        "rougeL": {
            "precision": 0.46167,
            "recall": 0.54874,
            "fmeasure": 0.49068
        },
        "rougeLsum": {
            "precision": 0.46167,
            "recall": 0.54874,
            "fmeasure": 0.49068
        },
        "nist": 5.926087264069255,
        "bleu": 30.70461,
        "bertscore": {
            "precision": 0.87423,
            "recall": 0.88487,
            "f1": 0.8779
        },
        "bleurt": -0.17511,
        "meteor": 0.32620509518381413,
        "nubia": {
            "semantic_relation": 3.74886,
            "contradiction": 31.09191,
            "irrelevancy": 15.74091,
            "logical_agreement": 53.16718,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.29555,
            "nubia_score": 0.57981
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 494,
        "total_length": 10984,
        "mean_pred_length": 22.234817813765183,
        "std_pred_length": 7.8715344708844635,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 58,
        "distinct-1": 0.14147851420247634,
        "vocab_size-1": 1554,
        "unique-1": 509,
        "entropy-1": 8.438158320175356,
        "distinct-2": 0.33336510962821736,
        "vocab_size-2": 3497,
        "unique-2": 1651,
        "entropy-2": 10.943644829392781,
        "cond_entropy-2": 2.282853593223353,
        "distinct-3": 0.4755902360944378,
        "vocab_size-3": 4754,
        "unique-3": 2783,
        "entropy-3": 11.706633408843791,
        "cond_entropy-3": 0.7898734199198015,
        "total_length-nopunct": 8948,
        "mean_pred_length-nopunct": 18.11336032388664,
        "std_pred_length-nopunct": 6.706944226245836,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.1728877961555655,
        "vocab_size-1-nopunct": 1547,
        "unique-1-nopunct": 507,
        "entropy-1-nopunct": 9.086357800670763,
        "distinct-2-nopunct": 0.3713035249585995,
        "vocab_size-2-nopunct": 3139,
        "unique-2-nopunct": 1586,
        "entropy-2-nopunct": 10.889131062916823,
        "cond_entropy-2-nopunct": 1.8744432099070922,
        "distinct-3-nopunct": 0.5160804020100502,
        "vocab_size-3-nopunct": 4108,
        "unique-3-nopunct": 2553,
        "entropy-3-nopunct": 11.542024429293638,
        "cond_entropy-3-nopunct": 0.6958557296732851,
        "msttr-100": 0.66294,
        "msttr-100_nopunct": 0.74652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.24625831485587582,
            "2": 0.5731850117096019,
            "3": 0.8234207609900258,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.36133,
            "recall": 0.36925,
            "fmeasure": 0.35684
        },
        "rouge2": {
            "precision": 0.18183,
            "recall": 0.20119,
            "fmeasure": 0.18526
        },
        "rougeL": {
            "precision": 0.34261,
            "recall": 0.35116,
            "fmeasure": 0.33858
        },
        "rougeLsum": {
            "precision": 0.34261,
            "recall": 0.35116,
            "fmeasure": 0.33858
        },
        "nist": 8.144704419451868,
        "bleu": 44.63396,
        "bertscore": {
            "precision": 0.95015,
            "recall": 0.94154,
            "f1": 0.94496
        },
        "bleurt": 0.11052,
        "meteor": 0.5784978619292626,
        "nubia": {
            "semantic_relation": 3.92324,
            "contradiction": 19.16966,
            "irrelevancy": 22.28895,
            "logical_agreement": 58.54139,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.42398,
            "nubia_score": 0.81732
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 114,
        "total_length": 5024,
        "mean_pred_length": 44.07017543859649,
        "std_pred_length": 11.595310076004651,
        "median_pred_length": 43.0,
        "min_pred_length": 26,
        "max_pred_length": 80,
        "distinct-1": 0.1409235668789809,
        "vocab_size-1": 708,
        "unique-1": 248,
        "entropy-1": 7.424650698430147,
        "distinct-2": 0.3439918533604888,
        "vocab_size-2": 1689,
        "unique-2": 872,
        "entropy-2": 9.951588856533826,
        "cond_entropy-2": 2.449743515404732,
        "distinct-3": 0.4989574645537948,
        "vocab_size-3": 2393,
        "unique-3": 1516,
        "entropy-3": 10.75481364477171,
        "cond_entropy-3": 0.8330498397792687,
        "total_length-nopunct": 4493,
        "mean_pred_length-nopunct": 39.41228070175438,
        "std_pred_length-nopunct": 10.673636486738298,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.15557533941687068,
        "vocab_size-1-nopunct": 699,
        "unique-1-nopunct": 246,
        "entropy-1-nopunct": 7.585633059850489,
        "distinct-2-nopunct": 0.35693080612011874,
        "vocab_size-2-nopunct": 1563,
        "unique-2-nopunct": 832,
        "entropy-2-nopunct": 9.870553763336186,
        "cond_entropy-2-nopunct": 2.3540233030122484,
        "distinct-3-nopunct": 0.5116060961313013,
        "vocab_size-3-nopunct": 2182,
        "unique-3-nopunct": 1408,
        "entropy-3-nopunct": 10.62663661098765,
        "cond_entropy-3-nopunct": 0.7740344808569277,
        "msttr-100": 0.5828,
        "msttr-100_nopunct": 0.60545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20328425821064552,
            "2": 0.5985663082437276,
            "3": 0.7288220551378446
        },
        "rouge1": {
            "precision": 0.65876,
            "recall": 0.6322,
            "fmeasure": 0.63772
        },
        "rouge2": {
            "precision": 0.37655,
            "recall": 0.36024,
            "fmeasure": 0.36384
        },
        "rougeL": {
            "precision": 0.46051,
            "recall": 0.44841,
            "fmeasure": 0.44904
        },
        "rougeLsum": {
            "precision": 0.46051,
            "recall": 0.44841,
            "fmeasure": 0.44904
        },
        "nist": 7.092166851045034,
        "bleu": 39.87614,
        "bertscore": {
            "precision": 0.8825,
            "recall": 0.87239,
            "f1": 0.87594
        },
        "bleurt": -0.18927,
        "meteor": 0.30906389977119414,
        "nubia": {
            "semantic_relation": 3.67814,
            "contradiction": 27.30946,
            "irrelevancy": 11.8549,
            "logical_agreement": 60.83564,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.03339,
            "nubia_score": 0.60387
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 354,
        "total_length": 9288,
        "mean_pred_length": 26.23728813559322,
        "std_pred_length": 7.508576602079403,
        "median_pred_length": 26.0,
        "min_pred_length": 8,
        "max_pred_length": 60,
        "distinct-1": 0.14071920757967268,
        "vocab_size-1": 1307,
        "unique-1": 448,
        "entropy-1": 8.238692520438518,
        "distinct-2": 0.3074770539511977,
        "vocab_size-2": 2747,
        "unique-2": 1314,
        "entropy-2": 10.51875123288173,
        "cond_entropy-2": 2.1024759813542224,
        "distinct-3": 0.429020979020979,
        "vocab_size-3": 3681,
        "unique-3": 2118,
        "entropy-3": 11.231177087846994,
        "cond_entropy-3": 0.7348680524571827,
        "total_length-nopunct": 7743,
        "mean_pred_length-nopunct": 21.872881355932204,
        "std_pred_length-nopunct": 6.874434678558331,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.167893581299238,
        "vocab_size-1-nopunct": 1300,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 8.772678844932939,
        "distinct-2-nopunct": 0.3414535119772635,
        "vocab_size-2-nopunct": 2523,
        "unique-2-nopunct": 1293,
        "entropy-2-nopunct": 10.51182979276085,
        "cond_entropy-2-nopunct": 1.7940263889112957,
        "distinct-3-nopunct": 0.46439232409381664,
        "vocab_size-3-nopunct": 3267,
        "unique-3-nopunct": 2018,
        "entropy-3-nopunct": 11.085976809204464,
        "cond_entropy-3-nopunct": 0.6010549533287277,
        "msttr-100": 0.65859,
        "msttr-100_nopunct": 0.73104,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26000375727972946,
            "2": 0.6188498402555911,
            "3": 0.8134802882577363,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.50556,
            "recall": 0.53128,
            "fmeasure": 0.50512
        },
        "rouge2": {
            "precision": 0.26615,
            "recall": 0.28561,
            "fmeasure": 0.26498
        },
        "rougeL": {
            "precision": 0.49238,
            "recall": 0.5181,
            "fmeasure": 0.49188
        },
        "rougeLsum": {
            "precision": 0.49238,
            "recall": 0.5181,
            "fmeasure": 0.49188
        },
        "nist": 8.185756105999861,
        "bleu": 47.4046,
        "bertscore": {
            "precision": 0.95161,
            "recall": 0.94175,
            "f1": 0.94602
        },
        "bleurt": 0.13525,
        "meteor": 0.597994267464681,
        "nubia": {
            "semantic_relation": 3.88665,
            "contradiction": 19.63689,
            "irrelevancy": 22.38232,
            "logical_agreement": 57.98079,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.37409,
            "nubia_score": 0.82042
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 305,
        "total_length": 11053,
        "mean_pred_length": 36.239344262295084,
        "std_pred_length": 10.877187418049994,
        "median_pred_length": 34.0,
        "min_pred_length": 15,
        "max_pred_length": 96,
        "distinct-1": 0.10883922916855153,
        "vocab_size-1": 1203,
        "unique-1": 445,
        "entropy-1": 7.598663848288907,
        "distinct-2": 0.309080759211016,
        "vocab_size-2": 3322,
        "unique-2": 1783,
        "entropy-2": 10.580149671127316,
        "cond_entropy-2": 2.8839336012122465,
        "distinct-3": 0.49937757349420664,
        "vocab_size-3": 5215,
        "unique-3": 3471,
        "entropy-3": 11.74202580022264,
        "cond_entropy-3": 1.201215271777864,
        "total_length-nopunct": 9910,
        "mean_pred_length-nopunct": 32.49180327868852,
        "std_pred_length-nopunct": 10.265049648646109,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.12048435923309789,
        "vocab_size-1-nopunct": 1194,
        "unique-1-nopunct": 444,
        "entropy-1-nopunct": 7.775080835212315,
        "distinct-2-nopunct": 0.3260801665799063,
        "vocab_size-2-nopunct": 3132,
        "unique-2-nopunct": 1775,
        "entropy-2-nopunct": 10.508990947668732,
        "cond_entropy-2-nopunct": 2.832542974803539,
        "distinct-3-nopunct": 0.5169892473118279,
        "vocab_size-3-nopunct": 4808,
        "unique-3-nopunct": 3293,
        "entropy-3-nopunct": 11.639462394483678,
        "cond_entropy-3-nopunct": 1.1666879301137598,
        "msttr-100": 0.56855,
        "msttr-100_nopunct": 0.59525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22327923894795748,
            "2": 0.54516711833785,
            "3": 0.7401948538596053
        },
        "rouge1": {
            "precision": 0.57521,
            "recall": 0.65587,
            "fmeasure": 0.60371
        },
        "rouge2": {
            "precision": 0.33544,
            "recall": 0.37936,
            "fmeasure": 0.35064
        },
        "rougeL": {
            "precision": 0.4369,
            "recall": 0.50303,
            "fmeasure": 0.46016
        },
        "rougeLsum": {
            "precision": 0.4369,
            "recall": 0.50303,
            "fmeasure": 0.46016
        },
        "nist": 6.273162688266159,
        "bleu": 32.21384,
        "bertscore": {
            "precision": 0.86727,
            "recall": 0.87416,
            "f1": 0.86932
        },
        "bleurt": -0.22736,
        "meteor": 0.3136442266027949,
        "nubia": {
            "semantic_relation": 3.59881,
            "contradiction": 34.39835,
            "irrelevancy": 15.72127,
            "logical_agreement": 49.88037,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.1648,
            "nubia_score": 0.55096
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 79,
        "total_length": 3924,
        "mean_pred_length": 49.67088607594937,
        "std_pred_length": 12.749506338407667,
        "median_pred_length": 48.0,
        "min_pred_length": 31,
        "max_pred_length": 89,
        "distinct-1": 0.15112130479102956,
        "vocab_size-1": 593,
        "unique-1": 230,
        "entropy-1": 7.325461108585865,
        "distinct-2": 0.3500650195058518,
        "vocab_size-2": 1346,
        "unique-2": 698,
        "entropy-2": 9.693955896448191,
        "cond_entropy-2": 2.304664819296227,
        "distinct-3": 0.4917684545937334,
        "vocab_size-3": 1852,
        "unique-3": 1168,
        "entropy-3": 10.398995780654863,
        "cond_entropy-3": 0.7244085015058535,
        "total_length-nopunct": 3503,
        "mean_pred_length-nopunct": 44.34177215189873,
        "std_pred_length-nopunct": 12.009369839757838,
        "median_pred_length-nopunct": 44.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.16699971453040252,
        "vocab_size-1-nopunct": 585,
        "unique-1-nopunct": 229,
        "entropy-1-nopunct": 7.492070108959488,
        "distinct-2-nopunct": 0.3676985981308411,
        "vocab_size-2-nopunct": 1259,
        "unique-2-nopunct": 672,
        "entropy-2-nopunct": 9.64802067336972,
        "cond_entropy-2-nopunct": 2.209326636297912,
        "distinct-3-nopunct": 0.5112107623318386,
        "vocab_size-3-nopunct": 1710,
        "unique-3-nopunct": 1110,
        "entropy-3-nopunct": 10.294884958319965,
        "cond_entropy-3-nopunct": 0.6591540411601571,
        "msttr-100": 0.59256,
        "msttr-100_nopunct": 0.628,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23109243697478993,
            "2": 0.4610303830911493,
            "3": 0.7535734705546027
        },
        "rouge1": {
            "precision": 0.68025,
            "recall": 0.62921,
            "fmeasure": 0.64633
        },
        "rouge2": {
            "precision": 0.39799,
            "recall": 0.36496,
            "fmeasure": 0.37609
        },
        "rougeL": {
            "precision": 0.46776,
            "recall": 0.43438,
            "fmeasure": 0.44488
        },
        "rougeLsum": {
            "precision": 0.46776,
            "recall": 0.43438,
            "fmeasure": 0.44488
        },
        "nist": 7.220670729337461,
        "bleu": 42.90841,
        "bertscore": {
            "precision": 0.88981,
            "recall": 0.87284,
            "f1": 0.87985
        },
        "bleurt": -0.22697,
        "meteor": 0.3153327713883918,
        "nubia": {
            "semantic_relation": 3.57242,
            "contradiction": 24.44011,
            "irrelevancy": 9.13266,
            "logical_agreement": 66.42723,
            "grammar_ref": 3.96506,
            "grammar_hyp": 3.89726,
            "nubia_score": 0.62037
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 297,
        "total_length": 3204,
        "mean_pred_length": 10.787878787878787,
        "std_pred_length": 3.350278325860181,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.2194132334581773,
        "vocab_size-1": 703,
        "unique-1": 376,
        "entropy-1": 7.141737958014515,
        "distinct-2": 0.5366357069143447,
        "vocab_size-2": 1560,
        "unique-2": 1100,
        "entropy-2": 9.988664545706662,
        "cond_entropy-2": 2.4653848516465877,
        "distinct-3": 0.7310344827586207,
        "vocab_size-3": 1908,
        "unique-3": 1555,
        "entropy-3": 10.626925864605026,
        "cond_entropy-3": 0.7387412336127486,
        "total_length-nopunct": 2761,
        "mean_pred_length-nopunct": 9.296296296296296,
        "std_pred_length-nopunct": 2.7912356374174103,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.25172039116262224,
        "vocab_size-1-nopunct": 695,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 7.411292554876944,
        "distinct-2-nopunct": 0.5190746753246753,
        "vocab_size-2-nopunct": 1279,
        "unique-2-nopunct": 874,
        "entropy-2-nopunct": 9.688210832530745,
        "cond_entropy-2-nopunct": 2.6043072557844456,
        "distinct-3-nopunct": 0.7189663128749423,
        "vocab_size-3-nopunct": 1558,
        "unique-3-nopunct": 1251,
        "entropy-3-nopunct": 10.330378445168435,
        "cond_entropy-3-nopunct": 0.7887505340283796,
        "msttr-100": 0.58406,
        "msttr-100_nopunct": 0.63333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.24623803009575923,
            "2": 0.6310880829015544,
            "3": 0.7595581988105352,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.70039,
            "recall": 0.71214,
            "fmeasure": 0.69708
        },
        "rouge2": {
            "precision": 0.46767,
            "recall": 0.47385,
            "fmeasure": 0.46374
        },
        "rougeL": {
            "precision": 0.62522,
            "recall": 0.64094,
            "fmeasure": 0.62446
        },
        "rougeLsum": {
            "precision": 0.62522,
            "recall": 0.64094,
            "fmeasure": 0.62446
        },
        "nist": 7.084810457425239,
        "bleu": 43.1213,
        "bertscore": {
            "precision": 0.91261,
            "recall": 0.91896,
            "f1": 0.9147
        },
        "bleurt": 0.0603,
        "meteor": 0.39040738229226074,
        "nubia": {
            "semantic_relation": 4.0524,
            "contradiction": 23.30382,
            "irrelevancy": 11.6189,
            "logical_agreement": 65.07728,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.27136,
            "nubia_score": 0.65121
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7229,
        "mean_pred_length": 20.13649025069638,
        "std_pred_length": 9.1858423186049,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.36644072485821,
        "vocab_size-1": 2649,
        "unique-1": 1933,
        "entropy-1": 9.204601060334188,
        "distinct-2": 0.845414847161572,
        "vocab_size-2": 5808,
        "unique-2": 5386,
        "entropy-2": 12.214450573848323,
        "cond_entropy-2": 2.748968289552871,
        "distinct-3": 0.9688219935493779,
        "vocab_size-3": 6308,
        "unique-3": 6196,
        "entropy-3": 12.57353139728536,
        "cond_entropy-3": 0.3748342848513119,
        "total_length-nopunct": 6456,
        "mean_pred_length-nopunct": 17.983286908077993,
        "std_pred_length-nopunct": 8.15960218755718,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4083023543990087,
        "vocab_size-1-nopunct": 2636,
        "unique-1-nopunct": 1930,
        "entropy-1-nopunct": 9.521398318728968,
        "distinct-2-nopunct": 0.8651795965228801,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.12066793495952,
        "cond_entropy-2-nopunct": 2.7348537281635985,
        "distinct-3-nopunct": 0.9811781108400139,
        "vocab_size-3-nopunct": 5630,
        "unique-3-nopunct": 5542,
        "entropy-3-nopunct": 12.445366994834446,
        "cond_entropy-3-nopunct": 0.34460054672478496,
        "msttr-100": 0.73264,
        "msttr-100_nopunct": 0.77109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04265704584040747,
            "2": 0.18773946360153257,
            "3": 0.40919037199124725,
            "4": 0.5816164817749604,
            "5": 0.6915887850467289,
            "6": 0.7783816425120773,
            "7": 0.8736158839251623
        },
        "rouge1": {
            "precision": 0.85348,
            "recall": 0.80789,
            "fmeasure": 0.81987
        },
        "rouge2": {
            "precision": 0.70936,
            "recall": 0.67588,
            "fmeasure": 0.68255
        },
        "rougeL": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "rougeLsum": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "nist": 11.348324337318253,
        "bleu": 68.4974,
        "bertscore": {
            "precision": 0.95485,
            "recall": 0.94662,
            "f1": 0.94865
        },
        "bleurt": 0.21243,
        "meteor": 0.4688629598902241,
        "nubia": {
            "semantic_relation": 4.33162,
            "contradiction": 4.00834,
            "irrelevancy": 17.09194,
            "logical_agreement": 78.89971,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.98215,
            "nubia_score": 0.69949
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 2517,
        "total_length": 36884,
        "mean_pred_length": 14.653953118792213,
        "std_pred_length": 4.285296217720157,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.06395727144561328,
        "vocab_size-1": 2359,
        "unique-1": 1129,
        "entropy-1": 7.9422007669940395,
        "distinct-2": 0.20513865044955917,
        "vocab_size-2": 7050,
        "unique-2": 3994,
        "entropy-2": 10.880348072501835,
        "cond_entropy-2": 2.712677189327787,
        "distinct-3": 0.33971742543171113,
        "vocab_size-3": 10820,
        "unique-3": 7070,
        "entropy-3": 12.02233233925269,
        "cond_entropy-3": 1.2237905670851177,
        "total_length-nopunct": 32602,
        "mean_pred_length-nopunct": 12.952721493841874,
        "std_pred_length-nopunct": 3.8653012531263866,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.07192810257039445,
        "vocab_size-1-nopunct": 2345,
        "unique-1-nopunct": 1127,
        "entropy-1-nopunct": 8.128094974727663,
        "distinct-2-nopunct": 0.21429283696194118,
        "vocab_size-2-nopunct": 6447,
        "unique-2-nopunct": 3753,
        "entropy-2-nopunct": 10.723774416619811,
        "cond_entropy-2-nopunct": 2.7866603875994573,
        "distinct-3-nopunct": 0.3533081834010447,
        "vocab_size-3-nopunct": 9740,
        "unique-3-nopunct": 6521,
        "entropy-3-nopunct": 11.857075964895888,
        "cond_entropy-3-nopunct": 1.2506591556425413,
        "msttr-100": 0.67394,
        "msttr-100_nopunct": 0.69896,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5775805493921685
        },
        "rouge1": {
            "precision": 0.62724,
            "recall": 0.60493,
            "fmeasure": 0.60495
        },
        "rouge2": {
            "precision": 0.39791,
            "recall": 0.38388,
            "fmeasure": 0.38341
        },
        "rougeL": {
            "precision": 0.54661,
            "recall": 0.52817,
            "fmeasure": 0.52761
        },
        "rougeLsum": {
            "precision": 0.54661,
            "recall": 0.52817,
            "fmeasure": 0.52761
        },
        "nist": 6.713484878124628,
        "bleu": 32.28433,
        "bertscore": {
            "precision": 0.88371,
            "recall": 0.87485,
            "f1": 0.87886
        },
        "bleurt": -0.06606,
        "meteor": 0.3229249553407203,
        "nubia": {
            "semantic_relation": 3.93569,
            "contradiction": 9.3677,
            "irrelevancy": 22.53965,
            "logical_agreement": 68.09265,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.58002,
            "nubia_score": 0.68878
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "mT5_small/xsum_challenge_test_backtranslation",
        "N": 500,
        "total_length": 11323,
        "mean_pred_length": 22.646,
        "std_pred_length": 5.2979886749595835,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.2563808178044688,
        "vocab_size-1": 2903,
        "unique-1": 1807,
        "entropy-1": 9.051646827828472,
        "distinct-2": 0.7415688810865749,
        "vocab_size-2": 8026,
        "unique-2": 7014,
        "entropy-2": 12.496429298427506,
        "cond_entropy-2": 3.2355221724160734,
        "distinct-3": 0.936646323743098,
        "vocab_size-3": 9669,
        "unique-3": 9296,
        "entropy-3": 13.165464696799827,
        "cond_entropy-3": 0.6806474531951153,
        "total_length-nopunct": 10555,
        "mean_pred_length-nopunct": 21.11,
        "std_pred_length-nopunct": 5.071281889226825,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.27408810990052107,
        "vocab_size-1-nopunct": 2893,
        "unique-1-nopunct": 1806,
        "entropy-1-nopunct": 9.217911734529295,
        "distinct-2-nopunct": 0.7467926404773745,
        "vocab_size-2-nopunct": 7509,
        "unique-2-nopunct": 6594,
        "entropy-2-nopunct": 12.400232844662273,
        "cond_entropy-2-nopunct": 3.2944620168397525,
        "distinct-3-nopunct": 0.9411826268969126,
        "vocab_size-3-nopunct": 8993,
        "unique-3-nopunct": 8664,
        "entropy-3-nopunct": 13.07117307136023,
        "cond_entropy-3-nopunct": 0.6897039086009543,
        "msttr-100": 0.73124,
        "msttr-100_nopunct": 0.74981,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.2306681491964015
        },
        "rouge1": {
            "precision": 0.25143,
            "recall": 0.24922,
            "fmeasure": 0.24339
        },
        "rouge2": {
            "precision": 0.04901,
            "recall": 0.04787,
            "fmeasure": 0.04709
        },
        "rougeL": {
            "precision": 0.18405,
            "recall": 0.18315,
            "fmeasure": 0.17837
        },
        "rougeLsum": {
            "precision": 0.18405,
            "recall": 0.18315,
            "fmeasure": 0.17837
        },
        "nist": 1.9893660475109294,
        "bleu": 2.61062,
        "bertscore": {
            "precision": 0.78106,
            "recall": 0.77471,
            "f1": 0.77762
        },
        "bleurt": -0.78723,
        "meteor": 0.10140648177057277,
        "nubia": {
            "semantic_relation": 1.55325,
            "contradiction": 39.19783,
            "irrelevancy": 57.68552,
            "logical_agreement": 3.11665,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.68806,
            "nubia_score": 0.13701
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 1328,
        "total_length": 24594,
        "mean_pred_length": 18.51957831325301,
        "std_pred_length": 5.417195052037433,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 86,
        "distinct-1": 0.07762055785964056,
        "vocab_size-1": 1909,
        "unique-1": 937,
        "entropy-1": 7.878131368534183,
        "distinct-2": 0.22934754577495056,
        "vocab_size-2": 5336,
        "unique-2": 3064,
        "entropy-2": 10.61724421761625,
        "cond_entropy-2": 2.562588543556222,
        "distinct-3": 0.3705898441061172,
        "vocab_size-3": 8130,
        "unique-3": 5322,
        "entropy-3": 11.780942095606413,
        "cond_entropy-3": 1.2306569269451817,
        "total_length-nopunct": 21706,
        "mean_pred_length-nopunct": 16.34487951807229,
        "std_pred_length-nopunct": 4.705646216066961,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.08734912005896987,
        "vocab_size-1-nopunct": 1896,
        "unique-1-nopunct": 934,
        "entropy-1-nopunct": 8.081983080969758,
        "distinct-2-nopunct": 0.2441358327608205,
        "vocab_size-2-nopunct": 4975,
        "unique-2-nopunct": 2911,
        "entropy-2-nopunct": 10.543812458556225,
        "cond_entropy-2-nopunct": 2.6035562685006375,
        "distinct-3-nopunct": 0.3919685039370079,
        "vocab_size-3-nopunct": 7467,
        "unique-3-nopunct": 5017,
        "entropy-3-nopunct": 11.711036413856974,
        "cond_entropy-3-nopunct": 1.2638706465166183,
        "msttr-100": 0.6669,
        "msttr-100_nopunct": 0.69571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5798687089715536
        },
        "rouge1": {
            "precision": 0.64511,
            "recall": 0.60134,
            "fmeasure": 0.61047
        },
        "rouge2": {
            "precision": 0.41087,
            "recall": 0.38539,
            "fmeasure": 0.38987
        },
        "rougeL": {
            "precision": 0.54638,
            "recall": 0.51121,
            "fmeasure": 0.51819
        },
        "rougeLsum": {
            "precision": 0.54638,
            "recall": 0.51121,
            "fmeasure": 0.51819
        },
        "nist": 6.60955964657208,
        "bleu": 30.96515,
        "bertscore": {
            "precision": 0.8889,
            "recall": 0.87519,
            "f1": 0.88161
        },
        "bleurt": -0.07643,
        "meteor": 0.3211192031416504,
        "nubia": {
            "semantic_relation": 4.09463,
            "contradiction": 9.19329,
            "irrelevancy": 17.69677,
            "logical_agreement": 73.10994,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.65976,
            "nubia_score": 0.70483
        }
    },
    "cs_restaurants_val": {
        "predictions_file": "mT5_small/cs_restaurants_val",
        "N": 781,
        "total_length": 7989,
        "mean_pred_length": 10.229193341869399,
        "std_pred_length": 3.670133183187939,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.03592439604456127,
        "vocab_size-1": 287,
        "unique-1": 86,
        "entropy-1": 6.168645697090385,
        "distinct-2": 0.09877913429522753,
        "vocab_size-2": 712,
        "unique-2": 278,
        "entropy-2": 7.752447705228884,
        "cond_entropy-2": 1.3454395222817548,
        "distinct-3": 0.17535397541621286,
        "vocab_size-3": 1127,
        "unique-3": 520,
        "entropy-3": 8.511147539359468,
        "cond_entropy-3": 0.8119836097994986,
        "total_length-nopunct": 6729,
        "mean_pred_length-nopunct": 8.615877080665813,
        "std_pred_length-nopunct": 3.2863281613172033,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.042056769207906075,
        "vocab_size-1-nopunct": 283,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.298309220500406,
        "distinct-2-nopunct": 0.10238735709482179,
        "vocab_size-2-nopunct": 609,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.610454276818369,
        "cond_entropy-2-nopunct": 1.383035202478148,
        "distinct-3-nopunct": 0.19218114960325142,
        "vocab_size-3-nopunct": 993,
        "unique-3-nopunct": 475,
        "entropy-3-nopunct": 8.44734418060427,
        "cond_entropy-3-nopunct": 0.8775168505399378,
        "msttr-100": 0.50975,
        "msttr-100_nopunct": 0.53209,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_val.json",
        "local_recall": {
            "1": 0.4378698224852071
        },
        "rouge1": {
            "precision": 0.49144,
            "recall": 0.48307,
            "fmeasure": 0.47327
        },
        "rouge2": {
            "precision": 0.29715,
            "recall": 0.29517,
            "fmeasure": 0.28669
        },
        "rougeL": {
            "precision": 0.44473,
            "recall": 0.4404,
            "fmeasure": 0.42999
        },
        "rougeLsum": {
            "precision": 0.44473,
            "recall": 0.4404,
            "fmeasure": 0.42999
        },
        "nist": 3.7877733834848093,
        "bleu": 17.94383,
        "bertscore": {
            "precision": 0.89636,
            "recall": 0.89371,
            "f1": 0.89476
        },
        "bleurt": -0.16472,
        "meteor": 0.22910726536698878,
        "nubia": {
            "semantic_relation": 3.161,
            "contradiction": 27.09208,
            "irrelevancy": 26.86194,
            "logical_agreement": 46.04598,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.65118,
            "nubia_score": 0.42124
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 469,
        "total_length": 10297,
        "mean_pred_length": 21.955223880597014,
        "std_pred_length": 6.5556596264228615,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 87,
        "distinct-1": 0.10925512285131592,
        "vocab_size-1": 1125,
        "unique-1": 571,
        "entropy-1": 7.639928388111685,
        "distinct-2": 0.2793040293040293,
        "vocab_size-2": 2745,
        "unique-2": 1650,
        "entropy-2": 9.981243138420746,
        "cond_entropy-2": 2.211302645347583,
        "distinct-3": 0.4322042953306977,
        "vocab_size-3": 4045,
        "unique-3": 2760,
        "entropy-3": 11.047323868026991,
        "cond_entropy-3": 1.1068136175191698,
        "total_length-nopunct": 9187,
        "mean_pred_length-nopunct": 19.588486140724946,
        "std_pred_length-nopunct": 5.6932192910394175,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.12147599869380647,
        "vocab_size-1-nopunct": 1116,
        "unique-1-nopunct": 570,
        "entropy-1-nopunct": 7.78857203001212,
        "distinct-2-nopunct": 0.2973158981417756,
        "vocab_size-2-nopunct": 2592,
        "unique-2-nopunct": 1591,
        "entropy-2-nopunct": 9.933648699505506,
        "cond_entropy-2-nopunct": 2.2387128942970187,
        "distinct-3-nopunct": 0.45872226936598376,
        "vocab_size-3-nopunct": 3784,
        "unique-3-nopunct": 2631,
        "entropy-3-nopunct": 11.014902162086836,
        "cond_entropy-3-nopunct": 1.1211489397449916,
        "msttr-100": 0.65794,
        "msttr-100_nopunct": 0.67813,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6253618992472496
        },
        "rouge1": {
            "precision": 0.65094,
            "recall": 0.64355,
            "fmeasure": 0.63586
        },
        "rouge2": {
            "precision": 0.4249,
            "recall": 0.41828,
            "fmeasure": 0.41413
        },
        "rougeL": {
            "precision": 0.56067,
            "recall": 0.55463,
            "fmeasure": 0.54817
        },
        "rougeLsum": {
            "precision": 0.56067,
            "recall": 0.55463,
            "fmeasure": 0.54817
        },
        "nist": 6.322411972173444,
        "bleu": 33.3082,
        "bertscore": {
            "precision": 0.88949,
            "recall": 0.88353,
            "f1": 0.88613
        },
        "bleurt": -0.06892,
        "meteor": 0.33848085584989723,
        "nubia": {
            "semantic_relation": 4.25157,
            "contradiction": 11.83588,
            "irrelevancy": 17.0787,
            "logical_agreement": 71.08542,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.7033,
            "nubia_score": 0.73535
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "mT5_small/xsum_challenge_test_bfp_02",
        "N": 500,
        "total_length": 11261,
        "mean_pred_length": 22.522,
        "std_pred_length": 5.387533387367544,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 51,
        "distinct-1": 0.2822129473403783,
        "vocab_size-1": 3178,
        "unique-1": 2143,
        "entropy-1": 9.132609783483193,
        "distinct-2": 0.7515100827060682,
        "vocab_size-2": 8087,
        "unique-2": 7147,
        "entropy-2": 12.50357072296463,
        "cond_entropy-2": 3.1578565969091197,
        "distinct-3": 0.935873696520807,
        "vocab_size-3": 9603,
        "unique-3": 9269,
        "entropy-3": 13.143719958251525,
        "cond_entropy-3": 0.6464461867862645,
        "total_length-nopunct": 10518,
        "mean_pred_length-nopunct": 21.036,
        "std_pred_length-nopunct": 5.156617495994832,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.30119794637763836,
        "vocab_size-1-nopunct": 3168,
        "unique-1-nopunct": 2143,
        "entropy-1-nopunct": 9.300507465829018,
        "distinct-2-nopunct": 0.7580355360351367,
        "vocab_size-2-nopunct": 7594,
        "unique-2-nopunct": 6753,
        "entropy-2-nopunct": 12.415129324588431,
        "cond_entropy-2-nopunct": 3.2279927062749154,
        "distinct-3-nopunct": 0.9409539819289767,
        "vocab_size-3-nopunct": 8956,
        "unique-3-nopunct": 8664,
        "entropy-3-nopunct": 13.053412597324115,
        "cond_entropy-3-nopunct": 0.6550308724300482,
        "msttr-100": 0.72893,
        "msttr-100_nopunct": 0.74924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "local_recall": {
            "1": 0.23989698890649763
        },
        "rouge1": {
            "precision": 0.26452,
            "recall": 0.25882,
            "fmeasure": 0.25573
        },
        "rouge2": {
            "precision": 0.05658,
            "recall": 0.05611,
            "fmeasure": 0.05503
        },
        "rougeL": {
            "precision": 0.19454,
            "recall": 0.19169,
            "fmeasure": 0.18854
        },
        "rougeLsum": {
            "precision": 0.19454,
            "recall": 0.19169,
            "fmeasure": 0.18854
        },
        "nist": 2.173533553885026,
        "bleu": 3.2926,
        "bertscore": {
            "precision": 0.78054,
            "recall": 0.77731,
            "f1": 0.77867
        },
        "bleurt": -0.88282,
        "meteor": 0.10539741430669437,
        "nubia": {
            "semantic_relation": 1.58637,
            "contradiction": 40.72119,
            "irrelevancy": 55.35954,
            "logical_agreement": 3.91926,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.96787,
            "nubia_score": 0.13117
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 72,
        "total_length": 920,
        "mean_pred_length": 12.777777777777779,
        "std_pred_length": 3.8341384017730262,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.30217391304347824,
        "vocab_size-1": 278,
        "unique-1": 184,
        "entropy-1": 6.467743210363834,
        "distinct-2": 0.6367924528301887,
        "vocab_size-2": 540,
        "unique-2": 411,
        "entropy-2": 8.697367308485918,
        "cond_entropy-2": 1.992552367482751,
        "distinct-3": 0.8118556701030928,
        "vocab_size-3": 630,
        "unique-3": 532,
        "entropy-3": 9.166933972299377,
        "cond_entropy-3": 0.5276599770079199,
        "total_length-nopunct": 775,
        "mean_pred_length-nopunct": 10.76388888888889,
        "std_pred_length-nopunct": 3.164442444990005,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.3496774193548387,
        "vocab_size-1-nopunct": 271,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 6.589340660024372,
        "distinct-2-nopunct": 0.647226173541963,
        "vocab_size-2-nopunct": 455,
        "unique-2-nopunct": 346,
        "entropy-2-nopunct": 8.45915315509652,
        "cond_entropy-2-nopunct": 2.109401430227251,
        "distinct-3-nopunct": 0.8066561014263075,
        "vocab_size-3-nopunct": 509,
        "unique-3-nopunct": 427,
        "entropy-3-nopunct": 8.856992505555386,
        "cond_entropy-3-nopunct": 0.48201923734342583,
        "msttr-100": 0.56333,
        "msttr-100_nopunct": 0.6,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21830985915492956,
            "2": 0.4904214559386973,
            "3": 0.6048632218844985
        },
        "rouge1": {
            "precision": 0.5628,
            "recall": 0.5729,
            "fmeasure": 0.55865
        },
        "rouge2": {
            "precision": 0.29071,
            "recall": 0.30054,
            "fmeasure": 0.28986
        },
        "rougeL": {
            "precision": 0.49063,
            "recall": 0.50514,
            "fmeasure": 0.48931
        },
        "rougeLsum": {
            "precision": 0.49063,
            "recall": 0.50514,
            "fmeasure": 0.48931
        },
        "nist": 4.501415546754889,
        "bleu": 21.69554,
        "bertscore": {
            "precision": 0.85193,
            "recall": 0.85491,
            "f1": 0.85186
        },
        "bleurt": -0.45299,
        "meteor": 0.27552808757461367,
        "nubia": {
            "semantic_relation": 3.17673,
            "contradiction": 36.73744,
            "irrelevancy": 20.09835,
            "logical_agreement": 43.16421,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.44121,
            "nubia_score": 0.40073
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 1075,
        "total_length": 21977,
        "mean_pred_length": 20.44372093023256,
        "std_pred_length": 9.623196061275483,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.10256176912226418,
        "vocab_size-1": 2254,
        "unique-1": 626,
        "entropy-1": 8.719105265607723,
        "distinct-2": 0.26059707205052146,
        "vocab_size-2": 5447,
        "unique-2": 2309,
        "entropy-2": 11.413286918381752,
        "cond_entropy-2": 2.4338442744430373,
        "distinct-3": 0.3924950824633076,
        "vocab_size-3": 7782,
        "unique-3": 4193,
        "entropy-3": 12.278116761415163,
        "cond_entropy-3": 0.8980775283829353,
        "total_length-nopunct": 18044,
        "mean_pred_length-nopunct": 16.78511627906977,
        "std_pred_length-nopunct": 8.289716906012412,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.12447350919973399,
        "vocab_size-1-nopunct": 2246,
        "unique-1-nopunct": 625,
        "entropy-1-nopunct": 9.402254336422903,
        "distinct-2-nopunct": 0.293888856149449,
        "vocab_size-2-nopunct": 4987,
        "unique-2-nopunct": 2292,
        "entropy-2-nopunct": 11.407694717172841,
        "cond_entropy-2-nopunct": 2.093526784949647,
        "distinct-3-nopunct": 0.43079149364540076,
        "vocab_size-3-nopunct": 6847,
        "unique-3-nopunct": 3942,
        "entropy-3-nopunct": 12.142195607361081,
        "cond_entropy-3-nopunct": 0.7883437864515355,
        "msttr-100": 0.68128,
        "msttr-100_nopunct": 0.75833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2640046380172476,
            "2": 0.6011196641007698,
            "3": 0.8197097020626433,
            "4": 0.8831168831168831,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.40179,
            "recall": 0.41412,
            "fmeasure": 0.39916
        },
        "rouge2": {
            "precision": 0.20878,
            "recall": 0.22455,
            "fmeasure": 0.20966
        },
        "rougeL": {
            "precision": 0.38909,
            "recall": 0.40164,
            "fmeasure": 0.38662
        },
        "rougeLsum": {
            "precision": 0.38909,
            "recall": 0.40164,
            "fmeasure": 0.38662
        },
        "nist": 8.697799274662675,
        "bleu": 46.84858,
        "bertscore": {
            "precision": 0.95385,
            "recall": 0.94576,
            "f1": 0.94908
        },
        "bleurt": 0.17508,
        "meteor": 0.6008308289698534,
        "nubia": {
            "semantic_relation": 3.96296,
            "contradiction": 19.82943,
            "irrelevancy": 21.70986,
            "logical_agreement": 58.46071,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.51055,
            "nubia_score": 0.8234
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 335,
        "total_length": 8162,
        "mean_pred_length": 24.36417910447761,
        "std_pred_length": 4.321266449678337,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 42,
        "distinct-1": 0.10291595197255575,
        "vocab_size-1": 840,
        "unique-1": 426,
        "entropy-1": 7.305698096185742,
        "distinct-2": 0.24875431199693368,
        "vocab_size-2": 1947,
        "unique-2": 1142,
        "entropy-2": 9.413990410922992,
        "cond_entropy-2": 2.0175842116630087,
        "distinct-3": 0.3862786972770956,
        "vocab_size-3": 2894,
        "unique-3": 1926,
        "entropy-3": 10.445357238204803,
        "cond_entropy-3": 1.0060083894738523,
        "total_length-nopunct": 7455,
        "mean_pred_length-nopunct": 22.253731343283583,
        "std_pred_length-nopunct": 3.7541749240890985,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.11106639839034205,
        "vocab_size-1-nopunct": 828,
        "unique-1-nopunct": 424,
        "entropy-1-nopunct": 7.350100494265422,
        "distinct-2-nopunct": 0.26053370786516855,
        "vocab_size-2-nopunct": 1855,
        "unique-2-nopunct": 1095,
        "entropy-2-nopunct": 9.400165550559684,
        "cond_entropy-2-nopunct": 2.049087401000725,
        "distinct-3-nopunct": 0.40456890198968315,
        "vocab_size-3-nopunct": 2745,
        "unique-3-nopunct": 1863,
        "entropy-3-nopunct": 10.38386479940648,
        "cond_entropy-3-nopunct": 1.0203792147101496,
        "msttr-100": 0.62889,
        "msttr-100_nopunct": 0.6327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6477707006369426
        },
        "rouge1": {
            "precision": 0.75361,
            "recall": 0.66224,
            "fmeasure": 0.69701
        },
        "rouge2": {
            "precision": 0.5176,
            "recall": 0.45438,
            "fmeasure": 0.47821
        },
        "rougeL": {
            "precision": 0.63665,
            "recall": 0.56113,
            "fmeasure": 0.58973
        },
        "rougeLsum": {
            "precision": 0.63665,
            "recall": 0.56113,
            "fmeasure": 0.58973
        },
        "nist": 6.639627390008886,
        "bleu": 37.51344,
        "bertscore": {
            "precision": 0.90987,
            "recall": 0.88966,
            "f1": 0.89938
        },
        "bleurt": 0.02083,
        "meteor": 0.3651530751607695,
        "nubia": {
            "semantic_relation": 4.43605,
            "contradiction": 4.02819,
            "irrelevancy": 6.00426,
            "logical_agreement": 89.96755,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.43983,
            "nubia_score": 0.79254
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1295,
        "total_length": 43692,
        "mean_pred_length": 33.738996138996136,
        "std_pred_length": 13.46896276873695,
        "median_pred_length": 32.0,
        "min_pred_length": 8,
        "max_pred_length": 96,
        "distinct-1": 0.04167811040922823,
        "vocab_size-1": 1821,
        "unique-1": 537,
        "entropy-1": 7.747174072857052,
        "distinct-2": 0.1457886171191358,
        "vocab_size-2": 6181,
        "unique-2": 2633,
        "entropy-2": 10.947322432358522,
        "cond_entropy-2": 3.0909589290850303,
        "distinct-3": 0.2786725706778259,
        "vocab_size-3": 11454,
        "unique-3": 6223,
        "entropy-3": 12.347428122143072,
        "cond_entropy-3": 1.4535458444043319,
        "total_length-nopunct": 38991,
        "mean_pred_length-nopunct": 30.10888030888031,
        "std_pred_length-nopunct": 12.36615282987918,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.04647226282988382,
        "vocab_size-1-nopunct": 1812,
        "unique-1-nopunct": 537,
        "entropy-1-nopunct": 7.953479804638621,
        "distinct-2-nopunct": 0.1586640492359932,
        "vocab_size-2-nopunct": 5981,
        "unique-2-nopunct": 2732,
        "entropy-2-nopunct": 10.896124829569244,
        "cond_entropy-2-nopunct": 3.055698088408151,
        "distinct-3-nopunct": 0.2973544682838384,
        "vocab_size-3-nopunct": 10824,
        "unique-3-nopunct": 6159,
        "entropy-3-nopunct": 12.271427693500275,
        "cond_entropy-3-nopunct": 1.423841949642339,
        "msttr-100": 0.58023,
        "msttr-100_nopunct": 0.60648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22250935056103366,
            "2": 0.536625321787971,
            "3": 0.7408669094326324,
            "4": 0.6470588235294118,
            "5": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.60053,
            "recall": 0.65954,
            "fmeasure": 0.61816
        },
        "rouge2": {
            "precision": 0.35911,
            "recall": 0.39284,
            "fmeasure": 0.36854
        },
        "rougeL": {
            "precision": 0.45786,
            "recall": 0.50799,
            "fmeasure": 0.4729
        },
        "rougeLsum": {
            "precision": 0.45786,
            "recall": 0.50799,
            "fmeasure": 0.4729
        },
        "nist": 6.764101374399729,
        "bleu": 34.49316,
        "bertscore": {
            "precision": 0.87449,
            "recall": 0.87833,
            "f1": 0.87495
        },
        "bleurt": -0.20144,
        "meteor": 0.3167418231769581,
        "nubia": {
            "semantic_relation": 3.67868,
            "contradiction": 30.91585,
            "irrelevancy": 14.6322,
            "logical_agreement": 54.45195,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.25532,
            "nubia_score": 0.58255
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2141,
        "mean_pred_length": 20.19811320754717,
        "std_pred_length": 7.458589845121535,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 85,
        "distinct-1": 0.36057916861279776,
        "vocab_size-1": 772,
        "unique-1": 537,
        "entropy-1": 7.897766876409134,
        "distinct-2": 0.745945945945946,
        "vocab_size-2": 1518,
        "unique-2": 1321,
        "entropy-2": 10.13685517323417,
        "cond_entropy-2": 2.055040301377861,
        "distinct-3": 0.8843960601347849,
        "vocab_size-3": 1706,
        "unique-3": 1610,
        "entropy-3": 10.528128087916793,
        "cond_entropy-3": 0.4177555225205933,
        "total_length-nopunct": 1960,
        "mean_pred_length-nopunct": 18.49056603773585,
        "std_pred_length-nopunct": 4.786469299895964,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3903061224489796,
        "vocab_size-1-nopunct": 765,
        "unique-1-nopunct": 536,
        "entropy-1-nopunct": 8.035993698309415,
        "distinct-2-nopunct": 0.7588996763754046,
        "vocab_size-2-nopunct": 1407,
        "unique-2-nopunct": 1228,
        "entropy-2-nopunct": 10.06973268989928,
        "cond_entropy-2-nopunct": 2.152049264477758,
        "distinct-3-nopunct": 0.9044622425629291,
        "vocab_size-3-nopunct": 1581,
        "unique-3-nopunct": 1493,
        "entropy-3-nopunct": 10.487572289856956,
        "cond_entropy-3-nopunct": 0.4373943563595653,
        "msttr-100": 0.66333,
        "msttr-100_nopunct": 0.68421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3011709601873536
        },
        "rouge1": {
            "precision": 0.3768,
            "recall": 0.32056,
            "fmeasure": 0.34066
        },
        "rouge2": {
            "precision": 0.1355,
            "recall": 0.11704,
            "fmeasure": 0.12336
        },
        "rougeL": {
            "precision": 0.29078,
            "recall": 0.24555,
            "fmeasure": 0.2619
        },
        "rougeLsum": {
            "precision": 0.29078,
            "recall": 0.24555,
            "fmeasure": 0.2619
        },
        "nist": 2.8250415200317707,
        "bleu": 6.90042,
        "bertscore": {
            "precision": 0.81803,
            "recall": 0.79704,
            "f1": 0.80708
        },
        "bleurt": -0.48887,
        "meteor": 0.14576477979288666,
        "nubia": {
            "semantic_relation": 2.28095,
            "contradiction": 30.84976,
            "irrelevancy": 60.64508,
            "logical_agreement": 8.50516,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.69035,
            "nubia_score": 0.26286
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2128,
        "mean_pred_length": 20.07547169811321,
        "std_pred_length": 4.2751985790964655,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.38298872180451127,
        "vocab_size-1": 815,
        "unique-1": 580,
        "entropy-1": 8.01184951974875,
        "distinct-2": 0.7863501483679525,
        "vocab_size-2": 1590,
        "unique-2": 1403,
        "entropy-2": 10.331098967716944,
        "cond_entropy-2": 2.1260962931142813,
        "distinct-3": 0.9311064718162839,
        "vocab_size-3": 1784,
        "unique-3": 1694,
        "entropy-3": 10.738281425157925,
        "cond_entropy-3": 0.4288107801443538,
        "total_length-nopunct": 1970,
        "mean_pred_length-nopunct": 18.58490566037736,
        "std_pred_length-nopunct": 4.023206091570625,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.40913705583756343,
        "vocab_size-1-nopunct": 806,
        "unique-1-nopunct": 578,
        "entropy-1-nopunct": 8.114372619283982,
        "distinct-2-nopunct": 0.7832618025751072,
        "vocab_size-2-nopunct": 1460,
        "unique-2-nopunct": 1285,
        "entropy-2-nopunct": 10.200555189542907,
        "cond_entropy-2-nopunct": 2.1948248986785597,
        "distinct-3-nopunct": 0.934584755403868,
        "vocab_size-3-nopunct": 1643,
        "unique-3-nopunct": 1560,
        "entropy-3-nopunct": 10.628370592413447,
        "cond_entropy-3-nopunct": 0.4403845226328914,
        "msttr-100": 0.68571,
        "msttr-100_nopunct": 0.69579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2928603910868577
        },
        "rouge1": {
            "precision": 0.38933,
            "recall": 0.32535,
            "fmeasure": 0.34945
        },
        "rouge2": {
            "precision": 0.1168,
            "recall": 0.09538,
            "fmeasure": 0.10347
        },
        "rougeL": {
            "precision": 0.28848,
            "recall": 0.24362,
            "fmeasure": 0.2604
        },
        "rougeLsum": {
            "precision": 0.28848,
            "recall": 0.24362,
            "fmeasure": 0.2604
        },
        "nist": 2.7009699264455325,
        "bleu": 6.2936,
        "bertscore": {
            "precision": 0.81903,
            "recall": 0.79649,
            "f1": 0.80734
        },
        "bleurt": -0.45893,
        "meteor": 0.14164235014890247,
        "nubia": {
            "semantic_relation": 2.39982,
            "contradiction": 31.75066,
            "irrelevancy": 59.72153,
            "logical_agreement": 8.52781,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.76243,
            "nubia_score": 0.30362
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "mT5_small/xsum_challenge_test_bfp_05",
        "N": 500,
        "total_length": 11539,
        "mean_pred_length": 23.078,
        "std_pred_length": 5.665325762919552,
        "median_pred_length": 23.0,
        "min_pred_length": 4,
        "max_pred_length": 56,
        "distinct-1": 0.2905797729439293,
        "vocab_size-1": 3353,
        "unique-1": 2284,
        "entropy-1": 9.198073989981495,
        "distinct-2": 0.7639278920192046,
        "vocab_size-2": 8433,
        "unique-2": 7525,
        "entropy-2": 12.56756006804159,
        "cond_entropy-2": 3.1589229101039815,
        "distinct-3": 0.9411708890786602,
        "vocab_size-3": 9919,
        "unique-3": 9593,
        "entropy-3": 13.195133342846086,
        "cond_entropy-3": 0.6338190370999668,
        "total_length-nopunct": 10786,
        "mean_pred_length-nopunct": 21.572,
        "std_pred_length-nopunct": 5.370364605871747,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 53,
        "distinct-1-nopunct": 0.309846096792138,
        "vocab_size-1-nopunct": 3342,
        "unique-1-nopunct": 2283,
        "entropy-1-nopunct": 9.36507924344617,
        "distinct-2-nopunct": 0.7692980750534707,
        "vocab_size-2-nopunct": 7913,
        "unique-2-nopunct": 7094,
        "entropy-2-nopunct": 12.475626034224907,
        "cond_entropy-2-nopunct": 3.2156648528496903,
        "distinct-3-nopunct": 0.9445125689760883,
        "vocab_size-3-nopunct": 9243,
        "unique-3-nopunct": 8954,
        "entropy-3-nopunct": 13.098224289768872,
        "cond_entropy-3-nopunct": 0.643379294349073,
        "msttr-100": 0.73243,
        "msttr-100_nopunct": 0.75402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "local_recall": {
            "1": 0.22550776583034648
        },
        "rouge1": {
            "precision": 0.24014,
            "recall": 0.24206,
            "fmeasure": 0.23513
        },
        "rouge2": {
            "precision": 0.04454,
            "recall": 0.04472,
            "fmeasure": 0.04344
        },
        "rougeL": {
            "precision": 0.17401,
            "recall": 0.17564,
            "fmeasure": 0.17035
        },
        "rougeLsum": {
            "precision": 0.17401,
            "recall": 0.17564,
            "fmeasure": 0.17035
        },
        "nist": 1.9512623543004728,
        "bleu": 2.35429,
        "bertscore": {
            "precision": 0.77148,
            "recall": 0.77196,
            "f1": 0.77149
        },
        "bleurt": -0.98316,
        "meteor": 0.09654662328920223,
        "nubia": {
            "semantic_relation": 1.38243,
            "contradiction": 43.76791,
            "irrelevancy": 52.90434,
            "logical_agreement": 3.32775,
            "grammar_ref": 3.79385,
            "grammar_hyp": 5.2539,
            "nubia_score": 0.10948
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "mT5_small/xsum_challenge_test_nopunc",
        "N": 500,
        "total_length": 11024,
        "mean_pred_length": 22.048,
        "std_pred_length": 5.173943950218247,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.26242743105950656,
        "vocab_size-1": 2893,
        "unique-1": 1794,
        "entropy-1": 9.04626710303277,
        "distinct-2": 0.7411630558722919,
        "vocab_size-2": 7800,
        "unique-2": 6817,
        "entropy-2": 12.43615062264274,
        "cond_entropy-2": 3.173099162727583,
        "distinct-3": 0.9336592178770949,
        "vocab_size-3": 9359,
        "unique-3": 9011,
        "entropy-3": 13.103816680074857,
        "cond_entropy-3": 0.6781533604403344,
        "total_length-nopunct": 10295,
        "mean_pred_length-nopunct": 20.59,
        "std_pred_length-nopunct": 4.991382573996908,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.28003885381253035,
        "vocab_size-1-nopunct": 2883,
        "unique-1-nopunct": 1791,
        "entropy-1-nopunct": 9.216782568245623,
        "distinct-2-nopunct": 0.747524247064829,
        "vocab_size-2-nopunct": 7322,
        "unique-2-nopunct": 6437,
        "entropy-2-nopunct": 12.349898387910116,
        "cond_entropy-2-nopunct": 3.2468147423288327,
        "distinct-3-nopunct": 0.9388918773534158,
        "vocab_size-3-nopunct": 8727,
        "unique-3-nopunct": 8421,
        "entropy-3-nopunct": 13.016291101549164,
        "cond_entropy-3-nopunct": 0.6831780938872906,
        "msttr-100": 0.72636,
        "msttr-100_nopunct": 0.7452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.25703093611892325
        },
        "rouge1": {
            "precision": 0.28742,
            "recall": 0.27771,
            "fmeasure": 0.27563
        },
        "rouge2": {
            "precision": 0.07002,
            "recall": 0.06793,
            "fmeasure": 0.06711
        },
        "rougeL": {
            "precision": 0.21354,
            "recall": 0.20669,
            "fmeasure": 0.20478
        },
        "rougeLsum": {
            "precision": 0.21354,
            "recall": 0.20669,
            "fmeasure": 0.20478
        },
        "nist": 2.397360417171582,
        "bleu": 3.56812,
        "bertscore": {
            "precision": 0.79323,
            "recall": 0.78448,
            "f1": 0.78856
        },
        "bleurt": -0.73023,
        "meteor": 0.11663810695573316,
        "nubia": {
            "semantic_relation": 1.81125,
            "contradiction": 35.52806,
            "irrelevancy": 60.72263,
            "logical_agreement": 3.74932,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.58806,
            "nubia_score": 0.1657
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "mT5_small/xsum_challenge_test_covid",
        "N": 401,
        "total_length": 9782,
        "mean_pred_length": 24.394014962593516,
        "std_pred_length": 5.727334300902108,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 49,
        "distinct-1": 0.21570231036597834,
        "vocab_size-1": 2110,
        "unique-1": 1258,
        "entropy-1": 8.634353331149708,
        "distinct-2": 0.6726361795117791,
        "vocab_size-2": 6310,
        "unique-2": 5312,
        "entropy-2": 12.02627952993808,
        "cond_entropy-2": 3.221772483635501,
        "distinct-3": 0.8989977728285078,
        "vocab_size-3": 8073,
        "unique-3": 7625,
        "entropy-3": 12.844182190065741,
        "cond_entropy-3": 0.8157729307788624,
        "total_length-nopunct": 9083,
        "mean_pred_length-nopunct": 22.65087281795511,
        "std_pred_length-nopunct": 5.420732849414596,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.23131124077947815,
        "vocab_size-1-nopunct": 2101,
        "unique-1-nopunct": 1257,
        "entropy-1-nopunct": 8.780210799626127,
        "distinct-2-nopunct": 0.6877447592720571,
        "vocab_size-2-nopunct": 5971,
        "unique-2-nopunct": 5067,
        "entropy-2-nopunct": 11.969962558263314,
        "cond_entropy-2-nopunct": 3.2666344482647,
        "distinct-3-nopunct": 0.9097935032000966,
        "vocab_size-3-nopunct": 7534,
        "unique-3-nopunct": 7155,
        "entropy-3-nopunct": 12.765438697718372,
        "cond_entropy-3-nopunct": 0.7960123758165736,
        "msttr-100": 0.71887,
        "msttr-100_nopunct": 0.73878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "local_recall": {
            "1": 0.21600192215281114
        },
        "rouge1": {
            "precision": 0.22565,
            "recall": 0.22889,
            "fmeasure": 0.22044
        },
        "rouge2": {
            "precision": 0.04542,
            "recall": 0.04803,
            "fmeasure": 0.04524
        },
        "rougeL": {
            "precision": 0.16272,
            "recall": 0.16661,
            "fmeasure": 0.15951
        },
        "rougeLsum": {
            "precision": 0.16272,
            "recall": 0.16661,
            "fmeasure": 0.15951
        },
        "nist": 1.7747649102659455,
        "bleu": 2.82184,
        "bertscore": {
            "precision": 0.76592,
            "recall": 0.75953,
            "f1": 0.76248
        },
        "bleurt": -0.86954,
        "meteor": 0.09355842662469731,
        "nubia": {
            "semantic_relation": 1.30659,
            "contradiction": 32.876,
            "irrelevancy": 63.97775,
            "logical_agreement": 3.14625,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.70067,
            "nubia_score": 0.11838
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 4,
        "total_length": 35,
        "mean_pred_length": 8.75,
        "std_pred_length": 2.48746859276655,
        "median_pred_length": 7.5,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.8,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.672140159802106,
        "distinct-2": 0.9032258064516129,
        "vocab_size-2": 28,
        "unique-2": 25,
        "entropy-2": 4.760647923290102,
        "cond_entropy-2": -0.11057057752583337,
        "distinct-3": 0.9259259259259259,
        "vocab_size-3": 25,
        "unique-3": 23,
        "entropy-3": 4.606739354015323,
        "cond_entropy-3": -0.19930880822340663,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 7.25,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.582118926162054,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": -0.1341248053528476,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": -0.2515387669959643,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.5384615384615384,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "nist": 4.293312475992189,
        "bleu": 64.68168,
        "bertscore": {
            "precision": 0.96553,
            "recall": 0.96872,
            "f1": 0.96702
        },
        "bleurt": 0.43581,
        "meteor": 0.7990826286317544,
        "nubia": {
            "semantic_relation": 3.97929,
            "contradiction": 46.08819,
            "irrelevancy": 21.51382,
            "logical_agreement": 32.39798,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.04748,
            "nubia_score": 0.74782
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 842,
        "total_length": 9205,
        "mean_pred_length": 10.93230403800475,
        "std_pred_length": 2.45315767479276,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.0534492123845736,
        "vocab_size-1": 492,
        "unique-1": 190,
        "entropy-1": 6.530818594464185,
        "distinct-2": 0.14384790147076407,
        "vocab_size-2": 1203,
        "unique-2": 619,
        "entropy-2": 8.17740694627687,
        "cond_entropy-2": 1.4107902459038648,
        "distinct-3": 0.23108629171652706,
        "vocab_size-3": 1738,
        "unique-3": 1024,
        "entropy-3": 8.860267605084573,
        "cond_entropy-3": 0.8221178627738942,
        "total_length-nopunct": 7711,
        "mean_pred_length-nopunct": 9.157957244655583,
        "std_pred_length-nopunct": 2.3210263943162297,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.06328621449876799,
        "vocab_size-1-nopunct": 488,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 6.73202908983492,
        "distinct-2-nopunct": 0.13772019216771,
        "vocab_size-2-nopunct": 946,
        "unique-2-nopunct": 472,
        "entropy-2-nopunct": 7.978476892058161,
        "cond_entropy-2-nopunct": 1.5023289690510355,
        "distinct-3-nopunct": 0.23145843703334992,
        "vocab_size-3-nopunct": 1395,
        "unique-3-nopunct": 779,
        "entropy-3-nopunct": 8.699292428091113,
        "cond_entropy-3-nopunct": 0.9529883665232025,
        "msttr-100": 0.53826,
        "msttr-100_nopunct": 0.57312,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.41909116098642285
        },
        "rouge1": {
            "precision": 0.41538,
            "recall": 0.43895,
            "fmeasure": 0.41451
        },
        "rouge2": {
            "precision": 0.23404,
            "recall": 0.25002,
            "fmeasure": 0.23353
        },
        "rougeL": {
            "precision": 0.37368,
            "recall": 0.39525,
            "fmeasure": 0.3731
        },
        "rougeLsum": {
            "precision": 0.37368,
            "recall": 0.39525,
            "fmeasure": 0.3731
        },
        "nist": 3.5480755344237127,
        "bleu": 15.74218,
        "bertscore": {
            "precision": 0.88189,
            "recall": 0.89538,
            "f1": 0.88833
        },
        "bleurt": -0.26773,
        "meteor": 0.21268704341036682,
        "nubia": {
            "semantic_relation": 3.02557,
            "contradiction": 28.96585,
            "irrelevancy": 30.17513,
            "logical_agreement": 40.85902,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.7817,
            "nubia_score": 0.43208
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 256,
        "total_length": 7875,
        "mean_pred_length": 30.76171875,
        "std_pred_length": 7.040747708581699,
        "median_pred_length": 32.0,
        "min_pred_length": 16,
        "max_pred_length": 56,
        "distinct-1": 0.06742857142857143,
        "vocab_size-1": 531,
        "unique-1": 221,
        "entropy-1": 6.830924388361969,
        "distinct-2": 0.17968237301483134,
        "vocab_size-2": 1369,
        "unique-2": 664,
        "entropy-2": 8.86397580487752,
        "cond_entropy-2": 1.9675023471951205,
        "distinct-3": 0.30789080537824254,
        "vocab_size-3": 2267,
        "unique-3": 1372,
        "entropy-3": 9.888317333616557,
        "cond_entropy-3": 1.0792789244636556,
        "total_length-nopunct": 7166,
        "mean_pred_length-nopunct": 27.9921875,
        "std_pred_length-nopunct": 6.199793461466579,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.07312308121685739,
        "vocab_size-1-nopunct": 524,
        "unique-1-nopunct": 221,
        "entropy-1-nopunct": 6.870516209536498,
        "distinct-2-nopunct": 0.1861070911722142,
        "vocab_size-2-nopunct": 1286,
        "unique-2-nopunct": 626,
        "entropy-2-nopunct": 8.789548824237025,
        "cond_entropy-2-nopunct": 1.986957001129984,
        "distinct-3-nopunct": 0.3208596333032762,
        "vocab_size-3-nopunct": 2135,
        "unique-3-nopunct": 1303,
        "entropy-3-nopunct": 9.824358521733382,
        "cond_entropy-3-nopunct": 1.0770803655359953,
        "msttr-100": 0.59051,
        "msttr-100_nopunct": 0.59479,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5986354197567487
        },
        "rouge1": {
            "precision": 0.6481,
            "recall": 0.6091,
            "fmeasure": 0.61899
        },
        "rouge2": {
            "precision": 0.40617,
            "recall": 0.38297,
            "fmeasure": 0.38803
        },
        "rougeL": {
            "precision": 0.54004,
            "recall": 0.50775,
            "fmeasure": 0.51575
        },
        "rougeLsum": {
            "precision": 0.54004,
            "recall": 0.50775,
            "fmeasure": 0.51575
        },
        "nist": 5.799403226701553,
        "bleu": 31.72727,
        "bertscore": {
            "precision": 0.89085,
            "recall": 0.8789,
            "f1": 0.88455
        },
        "bleurt": -0.11528,
        "meteor": 0.32383512245809803,
        "nubia": {
            "semantic_relation": 3.85959,
            "contradiction": 11.30578,
            "irrelevancy": 30.06329,
            "logical_agreement": 58.63092,
            "grammar_ref": 4.19274,
            "grammar_hyp": 3.99276,
            "nubia_score": 0.64641
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7229,
        "mean_pred_length": 20.13649025069638,
        "std_pred_length": 9.1858423186049,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.36644072485821,
        "vocab_size-1": 2649,
        "unique-1": 1933,
        "entropy-1": 9.204601060334188,
        "distinct-2": 0.845414847161572,
        "vocab_size-2": 5808,
        "unique-2": 5386,
        "entropy-2": 12.214450573848323,
        "cond_entropy-2": 2.748968289552871,
        "distinct-3": 0.9688219935493779,
        "vocab_size-3": 6308,
        "unique-3": 6196,
        "entropy-3": 12.57353139728536,
        "cond_entropy-3": 0.3748342848513119,
        "total_length-nopunct": 6456,
        "mean_pred_length-nopunct": 17.983286908077993,
        "std_pred_length-nopunct": 8.15960218755718,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4083023543990087,
        "vocab_size-1-nopunct": 2636,
        "unique-1-nopunct": 1930,
        "entropy-1-nopunct": 9.521398318728968,
        "distinct-2-nopunct": 0.8651795965228801,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.12066793495952,
        "cond_entropy-2-nopunct": 2.7348537281635985,
        "distinct-3-nopunct": 0.9811781108400139,
        "vocab_size-3-nopunct": 5630,
        "unique-3-nopunct": 5542,
        "entropy-3-nopunct": 12.445366994834446,
        "cond_entropy-3-nopunct": 0.34460054672478496,
        "msttr-100": 0.73264,
        "msttr-100_nopunct": 0.77109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04265704584040747,
            "2": 0.18773946360153257,
            "3": 0.40919037199124725,
            "4": 0.5816164817749604,
            "5": 0.6915887850467289,
            "6": 0.7783816425120773,
            "7": 0.8736158839251623
        },
        "rouge1": {
            "precision": 0.85348,
            "recall": 0.80789,
            "fmeasure": 0.81987
        },
        "rouge2": {
            "precision": 0.70936,
            "recall": 0.67588,
            "fmeasure": 0.68255
        },
        "rougeL": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "rougeLsum": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "nist": 11.348324337318253,
        "bleu": 68.4974,
        "bertscore": {
            "precision": 0.95485,
            "recall": 0.94662,
            "f1": 0.94865
        },
        "bleurt": 0.21243,
        "meteor": 0.4688629598902241,
        "nubia": {
            "semantic_relation": 4.33162,
            "contradiction": 4.00834,
            "irrelevancy": 17.09194,
            "logical_agreement": 78.89971,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.98215,
            "nubia_score": 0.69949
        }
    },
    "e2e_nlg_val": {
        "predictions_file": "mT5_small/e2e_nlg_val",
        "N": 4299,
        "total_length": 107472,
        "mean_pred_length": 24.999302163293788,
        "std_pred_length": 7.163413380176351,
        "median_pred_length": 25.0,
        "min_pred_length": 5,
        "max_pred_length": 48,
        "distinct-1": 0.0012282268870031263,
        "vocab_size-1": 132,
        "unique-1": 4,
        "entropy-1": 5.571768694111885,
        "distinct-2": 0.003702519069911702,
        "vocab_size-2": 382,
        "unique-2": 29,
        "entropy-2": 6.867088210923669,
        "cond_entropy-2": 1.2107871249092554,
        "distinct-3": 0.007251653619758481,
        "vocab_size-3": 717,
        "unique-3": 94,
        "entropy-3": 7.6522077091452,
        "cond_entropy-3": 0.8158072914117487,
        "total_length-nopunct": 98040,
        "mean_pred_length-nopunct": 22.8053035589672,
        "std_pred_length-nopunct": 6.6052070340388145,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.0013259893920848633,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.6226553280869265,
        "distinct-2-nopunct": 0.003979048655337579,
        "vocab_size-2-nopunct": 373,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 6.8271791217733835,
        "cond_entropy-2-nopunct": 1.2404204226109063,
        "distinct-3-nopunct": 0.007960466000313053,
        "vocab_size-3-nopunct": 712,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 7.6764510162002235,
        "cond_entropy-3-nopunct": 0.841658695100948,
        "msttr-100": 0.26864,
        "msttr-100_nopunct": 0.2602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_val.json",
        "local_recall": {
            "1": 0.7381618485131074
        },
        "rouge1": {
            "precision": 0.74276,
            "recall": 0.75771,
            "fmeasure": 0.74089
        },
        "rouge2": {
            "precision": 0.47581,
            "recall": 0.48402,
            "fmeasure": 0.47397
        },
        "rougeL": {
            "precision": 0.55227,
            "recall": 0.56213,
            "fmeasure": 0.55025
        },
        "rougeLsum": {
            "precision": 0.55227,
            "recall": 0.56213,
            "fmeasure": 0.55025
        },
        "nist": 5.387936273210175,
        "bleu": 36.6993,
        "bertscore": {
            "precision": 0.92135,
            "recall": 0.91356,
            "f1": 0.91718
        },
        "bleurt": 0.32175,
        "meteor": 0.3898643918329525,
        "nubia": {
            "semantic_relation": 4.44856,
            "contradiction": 2.12601,
            "irrelevancy": 10.84124,
            "logical_agreement": 87.03275,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.26129,
            "nubia_score": 0.85102
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1654,
        "total_length": 45368,
        "mean_pred_length": 27.429262394195888,
        "std_pred_length": 14.800430230439893,
        "median_pred_length": 26.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.04326838300123435,
        "vocab_size-1": 1963,
        "unique-1": 548,
        "entropy-1": 7.805834358837509,
        "distinct-2": 0.15487029326989066,
        "vocab_size-2": 6770,
        "unique-2": 2944,
        "entropy-2": 11.077319587715804,
        "cond_entropy-2": 3.130100109081418,
        "distinct-3": 0.292867332382311,
        "vocab_size-3": 12318,
        "unique-3": 6886,
        "entropy-3": 12.453876315954952,
        "cond_entropy-3": 1.443508531036756,
        "total_length-nopunct": 40318,
        "mean_pred_length-nopunct": 24.376058041112454,
        "std_pred_length-nopunct": 13.528779210546213,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.04846470559055509,
        "vocab_size-1-nopunct": 1954,
        "unique-1-nopunct": 548,
        "entropy-1-nopunct": 8.032140500939468,
        "distinct-2-nopunct": 0.16529588247465343,
        "vocab_size-2-nopunct": 6391,
        "unique-2-nopunct": 2943,
        "entropy-2-nopunct": 10.990922565966578,
        "cond_entropy-2-nopunct": 3.1018941313895976,
        "distinct-3-nopunct": 0.30740340448527426,
        "vocab_size-3-nopunct": 11377,
        "unique-3-nopunct": 6606,
        "entropy-3-nopunct": 12.343370699515562,
        "cond_entropy-3-nopunct": 1.4217949014023519,
        "msttr-100": 0.48234,
        "msttr-100_nopunct": 0.49429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22792775785035554,
            "2": 0.5558129738837405,
            "3": 0.754769921436588,
            "4": 0.8909090909090909,
            "5": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.63061,
            "recall": 0.67549,
            "fmeasure": 0.64213
        },
        "rouge2": {
            "precision": 0.39036,
            "recall": 0.4164,
            "fmeasure": 0.39629
        },
        "rougeL": {
            "precision": 0.50412,
            "recall": 0.5437,
            "fmeasure": 0.51445
        },
        "rougeLsum": {
            "precision": 0.50412,
            "recall": 0.5437,
            "fmeasure": 0.51445
        },
        "nist": 7.104130315540987,
        "bleu": 36.55229,
        "bertscore": {
            "precision": 0.88454,
            "recall": 0.88895,
            "f1": 0.88537
        },
        "bleurt": -0.12651,
        "meteor": 0.3308274540961698,
        "nubia": {
            "semantic_relation": 3.79667,
            "contradiction": 27.95102,
            "irrelevancy": 13.79408,
            "logical_agreement": 58.25489,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.50739,
            "nubia_score": 0.60526
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 46,
        "total_length": 1457,
        "mean_pred_length": 31.67391304347826,
        "std_pred_length": 8.22259439600022,
        "median_pred_length": 31.0,
        "min_pred_length": 19,
        "max_pred_length": 50,
        "distinct-1": 0.12834591626630062,
        "vocab_size-1": 187,
        "unique-1": 79,
        "entropy-1": 6.198851581923578,
        "distinct-2": 0.30900070871722185,
        "vocab_size-2": 436,
        "unique-2": 222,
        "entropy-2": 7.910230212149325,
        "cond_entropy-2": 1.663061022890008,
        "distinct-3": 0.46007326007326005,
        "vocab_size-3": 628,
        "unique-3": 401,
        "entropy-3": 8.68863669514523,
        "cond_entropy-3": 0.7950174614799128,
        "total_length-nopunct": 1341,
        "mean_pred_length-nopunct": 29.152173913043477,
        "std_pred_length-nopunct": 7.377897047216061,
        "median_pred_length-nopunct": 28.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.13571961222967935,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.18413171447131,
        "distinct-2-nopunct": 0.3196911196911197,
        "vocab_size-2-nopunct": 414,
        "unique-2-nopunct": 215,
        "entropy-2-nopunct": 7.856693133754173,
        "cond_entropy-2-nopunct": 1.70021639465226,
        "distinct-3-nopunct": 0.4755804643714972,
        "vocab_size-3-nopunct": 594,
        "unique-3-nopunct": 386,
        "entropy-3-nopunct": 8.618749399095465,
        "cond_entropy-3-nopunct": 0.7957180995331418,
        "msttr-100": 0.52,
        "msttr-100_nopunct": 0.52154,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.578860445912469
        },
        "rouge1": {
            "precision": 0.58377,
            "recall": 0.59266,
            "fmeasure": 0.57158
        },
        "rouge2": {
            "precision": 0.35522,
            "recall": 0.3665,
            "fmeasure": 0.35023
        },
        "rougeL": {
            "precision": 0.46329,
            "recall": 0.47762,
            "fmeasure": 0.45673
        },
        "rougeLsum": {
            "precision": 0.46329,
            "recall": 0.47762,
            "fmeasure": 0.45673
        },
        "nist": 4.62204662991497,
        "bleu": 30.61339,
        "bertscore": {
            "precision": 0.86256,
            "recall": 0.86431,
            "f1": 0.86303
        },
        "bleurt": -0.32165,
        "meteor": 0.2840718975676017,
        "nubia": {
            "semantic_relation": 3.43118,
            "contradiction": 26.85669,
            "irrelevancy": 30.83746,
            "logical_agreement": 42.30584,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.22074,
            "nubia_score": 0.45677
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 1397,
        "total_length": 28225,
        "mean_pred_length": 20.20400858983536,
        "std_pred_length": 7.102423671734245,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 50,
        "distinct-1": 0.05842338352524358,
        "vocab_size-1": 1649,
        "unique-1": 781,
        "entropy-1": 7.159672701477161,
        "distinct-2": 0.16803339794244818,
        "vocab_size-2": 4508,
        "unique-2": 2624,
        "entropy-2": 9.635521514592831,
        "cond_entropy-2": 2.353305397397949,
        "distinct-3": 0.29739294561755336,
        "vocab_size-3": 7563,
        "unique-3": 5080,
        "entropy-3": 11.003325225377733,
        "cond_entropy-3": 1.4125592636483304,
        "total_length-nopunct": 25533,
        "mean_pred_length-nopunct": 18.27702219040802,
        "std_pred_length-nopunct": 6.633777928209239,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.06411310852622097,
        "vocab_size-1-nopunct": 1637,
        "unique-1-nopunct": 779,
        "entropy-1-nopunct": 7.239895362785974,
        "distinct-2-nopunct": 0.17836426914153133,
        "vocab_size-2-nopunct": 4305,
        "unique-2-nopunct": 2556,
        "entropy-2-nopunct": 9.595086052161246,
        "cond_entropy-2-nopunct": 2.456041646734268,
        "distinct-3-nopunct": 0.31518536435199435,
        "vocab_size-3-nopunct": 7167,
        "unique-3-nopunct": 4895,
        "entropy-3-nopunct": 10.975891793642026,
        "cond_entropy-3-nopunct": 1.4604626019257032,
        "msttr-100": 0.57496,
        "msttr-100_nopunct": 0.58498,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6137047580317202
        },
        "rouge1": {
            "precision": 0.64627,
            "recall": 0.62741,
            "fmeasure": 0.62499
        },
        "rouge2": {
            "precision": 0.424,
            "recall": 0.41198,
            "fmeasure": 0.40996
        },
        "rougeL": {
            "precision": 0.55937,
            "recall": 0.54553,
            "fmeasure": 0.54218
        },
        "rougeLsum": {
            "precision": 0.55937,
            "recall": 0.54553,
            "fmeasure": 0.54218
        },
        "nist": 6.330692261533665,
        "bleu": 33.59737,
        "bertscore": {
            "precision": 0.87958,
            "recall": 0.87235,
            "f1": 0.87559
        },
        "bleurt": -0.10325,
        "meteor": 0.3278008048711175,
        "nubia": {
            "semantic_relation": 4.00174,
            "contradiction": 8.79908,
            "irrelevancy": 23.90456,
            "logical_agreement": 67.29637,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.89086,
            "nubia_score": 0.6653
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 983,
        "total_length": 5126,
        "mean_pred_length": 5.214649033570702,
        "std_pred_length": 1.3628216547224548,
        "median_pred_length": 5.0,
        "min_pred_length": 4,
        "max_pred_length": 12,
        "distinct-1": 0.00721810378462739,
        "vocab_size-1": 37,
        "unique-1": 3,
        "entropy-1": 3.2707272070517392,
        "distinct-2": 0.012792662321988897,
        "vocab_size-2": 53,
        "unique-2": 5,
        "entropy-2": 3.663598248784875,
        "cond_entropy-2": 0.40048444048518206,
        "distinct-3": 0.01930379746835443,
        "vocab_size-3": 61,
        "unique-3": 6,
        "entropy-3": 4.05836289703812,
        "cond_entropy-3": 0.38165900348460946,
        "total_length-nopunct": 4180,
        "mean_pred_length-nopunct": 4.252288911495422,
        "std_pred_length-nopunct": 1.0879121042814306,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.008133971291866028,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.9244867713625404,
        "distinct-2-nopunct": 0.013137316233969347,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.262112303476453,
        "cond_entropy-2-nopunct": 0.22774790972861003,
        "distinct-3-nopunct": 0.018066847335140017,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.365858008101469,
        "cond_entropy-3-nopunct": 0.2231902141318058,
        "msttr-100": 0.14804,
        "msttr-100_nopunct": 0.13463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.49282808820381074
        },
        "rouge1": {
            "precision": 0.55174,
            "recall": 0.51075,
            "fmeasure": 0.52208
        },
        "rouge2": {
            "precision": 0.3661,
            "recall": 0.33434,
            "fmeasure": 0.34332
        },
        "rougeL": {
            "precision": 0.55072,
            "recall": 0.50994,
            "fmeasure": 0.52118
        },
        "rougeLsum": {
            "precision": 0.55072,
            "recall": 0.50994,
            "fmeasure": 0.52118
        },
        "nist": 2.6369613480102143,
        "bleu": 28.58702,
        "bertscore": {
            "precision": 0.85992,
            "recall": 0.85122,
            "f1": 0.85511
        },
        "bleurt": 0.14611,
        "meteor": 0.2639942858980559,
        "nubia": {
            "semantic_relation": 3.11833,
            "contradiction": 2.38326,
            "irrelevancy": 22.53308,
            "logical_agreement": 75.08366,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.47653,
            "nubia_score": 0.60049
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 1027,
        "total_length": 10493,
        "mean_pred_length": 10.21713729308666,
        "std_pred_length": 4.317101968865565,
        "median_pred_length": 9.0,
        "min_pred_length": 1,
        "max_pred_length": 30,
        "distinct-1": 0.103306966549128,
        "vocab_size-1": 1084,
        "unique-1": 582,
        "entropy-1": 7.167899321845763,
        "distinct-2": 0.2701246566659624,
        "vocab_size-2": 2557,
        "unique-2": 1547,
        "entropy-2": 9.808727316260878,
        "cond_entropy-2": 2.2676238226878334,
        "distinct-3": 0.42808056872037914,
        "vocab_size-3": 3613,
        "unique-3": 2458,
        "entropy-3": 10.837565495922826,
        "cond_entropy-3": 1.1075287912185505,
        "total_length-nopunct": 9025,
        "mean_pred_length-nopunct": 8.787731256085687,
        "std_pred_length-nopunct": 4.05820905978941,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.11944598337950138,
        "vocab_size-1-nopunct": 1078,
        "unique-1-nopunct": 582,
        "entropy-1-nopunct": 7.4482792335273915,
        "distinct-2-nopunct": 0.2786946736684171,
        "vocab_size-2-nopunct": 2229,
        "unique-2-nopunct": 1350,
        "entropy-2-nopunct": 9.637355986174926,
        "cond_entropy-2-nopunct": 2.4648101020036193,
        "distinct-3-nopunct": 0.44299440699842246,
        "vocab_size-3-nopunct": 3089,
        "unique-3-nopunct": 2132,
        "entropy-3-nopunct": 10.625993495227286,
        "cond_entropy-3-nopunct": 1.167606369074558,
        "msttr-100": 0.60308,
        "msttr-100_nopunct": 0.63644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6138821452218053
        },
        "rouge1": {
            "precision": 0.67314,
            "recall": 0.64687,
            "fmeasure": 0.64873
        },
        "rouge2": {
            "precision": 0.46963,
            "recall": 0.45231,
            "fmeasure": 0.45132
        },
        "rougeL": {
            "precision": 0.61679,
            "recall": 0.59201,
            "fmeasure": 0.59374
        },
        "rougeLsum": {
            "precision": 0.61679,
            "recall": 0.59201,
            "fmeasure": 0.59374
        },
        "nist": 7.224474653145458,
        "bleu": 43.52362,
        "bertscore": {
            "precision": 0.90533,
            "recall": 0.89657,
            "f1": 0.90059
        },
        "bleurt": 0.18648,
        "meteor": 0.3675292734357709,
        "nubia": {
            "semantic_relation": 3.93887,
            "contradiction": 11.04497,
            "irrelevancy": 16.08239,
            "logical_agreement": 72.87264,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.71676,
            "nubia_score": 0.71207
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 125,
        "total_length": 4811,
        "mean_pred_length": 38.488,
        "std_pred_length": 13.589770270317302,
        "median_pred_length": 35.0,
        "min_pred_length": 15,
        "max_pred_length": 86,
        "distinct-1": 0.11141134899189357,
        "vocab_size-1": 536,
        "unique-1": 183,
        "entropy-1": 6.7980658609067826,
        "distinct-2": 0.29236022193768674,
        "vocab_size-2": 1370,
        "unique-2": 662,
        "entropy-2": 9.453162527301767,
        "cond_entropy-2": 2.5898273399916736,
        "distinct-3": 0.475553606665205,
        "vocab_size-3": 2169,
        "unique-3": 1350,
        "entropy-3": 10.535753121726351,
        "cond_entropy-3": 1.1152255852132218,
        "total_length-nopunct": 4276,
        "mean_pred_length-nopunct": 34.208,
        "std_pred_length-nopunct": 12.472880020267974,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.12371375116931711,
        "vocab_size-1-nopunct": 529,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 6.922545045874439,
        "distinct-2-nopunct": 0.3141411708022163,
        "vocab_size-2-nopunct": 1304,
        "unique-2-nopunct": 677,
        "entropy-2-nopunct": 9.39280089335098,
        "cond_entropy-2-nopunct": 2.5514793020592577,
        "distinct-3-nopunct": 0.5004967709885743,
        "vocab_size-3-nopunct": 2015,
        "unique-3-nopunct": 1306,
        "entropy-3-nopunct": 10.44731449552209,
        "cond_entropy-3-nopunct": 1.0736862982565765,
        "msttr-100": 0.45625,
        "msttr-100_nopunct": 0.47143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20091027308192458,
            "2": 0.44569288389513106,
            "3": 0.6214285714285714
        },
        "rouge1": {
            "precision": 0.47559,
            "recall": 0.57833,
            "fmeasure": 0.5109
        },
        "rouge2": {
            "precision": 0.23231,
            "recall": 0.28887,
            "fmeasure": 0.25123
        },
        "rougeL": {
            "precision": 0.34939,
            "recall": 0.43529,
            "fmeasure": 0.37923
        },
        "rougeLsum": {
            "precision": 0.34939,
            "recall": 0.43529,
            "fmeasure": 0.37923
        },
        "nist": 4.521768329513098,
        "bleu": 21.58342,
        "bertscore": {
            "precision": 0.83838,
            "recall": 0.84832,
            "f1": 0.84135
        },
        "bleurt": -0.51207,
        "meteor": 0.2519926040315332,
        "nubia": {
            "semantic_relation": 3.10773,
            "contradiction": 44.40221,
            "irrelevancy": 19.3269,
            "logical_agreement": 36.27089,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.29864,
            "nubia_score": 0.43502
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 958,
        "total_length": 19872,
        "mean_pred_length": 20.74321503131524,
        "std_pred_length": 6.567207623364387,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 87,
        "distinct-1": 0.0792572463768116,
        "vocab_size-1": 1575,
        "unique-1": 755,
        "entropy-1": 7.496785861237514,
        "distinct-2": 0.21502590673575128,
        "vocab_size-2": 4067,
        "unique-2": 2326,
        "entropy-2": 9.985973784876322,
        "cond_entropy-2": 2.354977085345519,
        "distinct-3": 0.3431721987079528,
        "vocab_size-3": 6162,
        "unique-3": 3965,
        "entropy-3": 11.202018185024771,
        "cond_entropy-3": 1.3047576831987042,
        "total_length-nopunct": 17423,
        "mean_pred_length-nopunct": 18.186847599164928,
        "std_pred_length-nopunct": 5.918157393213277,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.08970900533777192,
        "vocab_size-1-nopunct": 1563,
        "unique-1-nopunct": 754,
        "entropy-1-nopunct": 7.7078840858357935,
        "distinct-2-nopunct": 0.22963862739143637,
        "vocab_size-2-nopunct": 3781,
        "unique-2-nopunct": 2211,
        "entropy-2-nopunct": 9.95957487946884,
        "cond_entropy-2-nopunct": 2.4061522137780815,
        "distinct-3-nopunct": 0.3682208035080931,
        "vocab_size-3-nopunct": 5710,
        "unique-3-nopunct": 3734,
        "entropy-3-nopunct": 11.237280930126264,
        "cond_entropy-3-nopunct": 1.3836599858230485,
        "msttr-100": 0.62753,
        "msttr-100_nopunct": 0.65609,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5903088693680929
        },
        "rouge1": {
            "precision": 0.65182,
            "recall": 0.60246,
            "fmeasure": 0.61512
        },
        "rouge2": {
            "precision": 0.40804,
            "recall": 0.3756,
            "fmeasure": 0.38383
        },
        "rougeL": {
            "precision": 0.56457,
            "recall": 0.52272,
            "fmeasure": 0.53343
        },
        "rougeLsum": {
            "precision": 0.56457,
            "recall": 0.52272,
            "fmeasure": 0.53343
        },
        "nist": 6.480218527669436,
        "bleu": 30.81218,
        "bertscore": {
            "precision": 0.88649,
            "recall": 0.87573,
            "f1": 0.8807
        },
        "bleurt": -0.08769,
        "meteor": 0.33256601159762184,
        "nubia": {
            "semantic_relation": 4.27859,
            "contradiction": 8.26858,
            "irrelevancy": 15.53263,
            "logical_agreement": 76.19879,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.80995,
            "nubia_score": 0.73318
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1510,
        "total_length": 40036,
        "mean_pred_length": 26.513907284768212,
        "std_pred_length": 14.700434916011183,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.046383255070436606,
        "vocab_size-1": 1857,
        "unique-1": 548,
        "entropy-1": 7.8087889085525415,
        "distinct-2": 0.1595545865130042,
        "vocab_size-2": 6147,
        "unique-2": 2701,
        "entropy-2": 11.007701543414655,
        "cond_entropy-2": 3.050734964562827,
        "distinct-3": 0.2929814134428355,
        "vocab_size-3": 10845,
        "unique-3": 6058,
        "entropy-3": 12.296228915848571,
        "cond_entropy-3": 1.358694244407995,
        "total_length-nopunct": 35646,
        "mean_pred_length-nopunct": 23.606622516556293,
        "std_pred_length-nopunct": 13.453336910338237,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.0518431240531897,
        "vocab_size-1-nopunct": 1848,
        "unique-1-nopunct": 548,
        "entropy-1-nopunct": 8.037894865603322,
        "distinct-2-nopunct": 0.16806304194984767,
        "vocab_size-2-nopunct": 5737,
        "unique-2-nopunct": 2642,
        "entropy-2-nopunct": 10.907653678178674,
        "cond_entropy-2-nopunct": 3.0175423618693116,
        "distinct-3-nopunct": 0.30445043830074175,
        "vocab_size-3-nopunct": 9933,
        "unique-3-nopunct": 5715,
        "entropy-3-nopunct": 12.17006907670796,
        "cond_entropy-3-nopunct": 1.3330470084165715,
        "msttr-100": 0.47812,
        "msttr-100_nopunct": 0.48902,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23512667235980644,
            "2": 0.5763151686718566,
            "3": 0.7797850009541378,
            "4": 0.9411764705882353,
            "5": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.64326,
            "recall": 0.69064,
            "fmeasure": 0.656
        },
        "rouge2": {
            "precision": 0.40619,
            "recall": 0.43361,
            "fmeasure": 0.41263
        },
        "rougeL": {
            "precision": 0.5177,
            "recall": 0.55953,
            "fmeasure": 0.52912
        },
        "rougeLsum": {
            "precision": 0.5177,
            "recall": 0.55953,
            "fmeasure": 0.52912
        },
        "nist": 7.324338862549115,
        "bleu": 38.96077,
        "bertscore": {
            "precision": 0.89018,
            "recall": 0.89466,
            "f1": 0.89101
        },
        "bleurt": -0.08204,
        "meteor": 0.3443573982597444,
        "nubia": {
            "semantic_relation": 3.87514,
            "contradiction": 26.85287,
            "irrelevancy": 12.78732,
            "logical_agreement": 60.35981,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.52716,
            "nubia_score": 0.62737
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 500,
        "total_length": 5453,
        "mean_pred_length": 10.906,
        "std_pred_length": 2.486194682642532,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.07243719053731891,
        "vocab_size-1": 395,
        "unique-1": 168,
        "entropy-1": 6.52921243752286,
        "distinct-2": 0.18433272763981426,
        "vocab_size-2": 913,
        "unique-2": 497,
        "entropy-2": 8.10631120984948,
        "cond_entropy-2": 1.3402173468897165,
        "distinct-3": 0.28565012351223895,
        "vocab_size-3": 1272,
        "unique-3": 778,
        "entropy-3": 8.726630951504623,
        "cond_entropy-3": 0.7361656429053771,
        "total_length-nopunct": 4579,
        "mean_pred_length-nopunct": 9.158,
        "std_pred_length-nopunct": 2.3573366327277063,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.08538982310548154,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 168,
        "entropy-1-nopunct": 6.722948872260174,
        "distinct-2-nopunct": 0.17896543270409415,
        "vocab_size-2-nopunct": 730,
        "unique-2-nopunct": 373,
        "entropy-2-nopunct": 7.91868279600256,
        "cond_entropy-2-nopunct": 1.4190083248283252,
        "distinct-3-nopunct": 0.2900251466890193,
        "vocab_size-3-nopunct": 1038,
        "unique-3-nopunct": 601,
        "entropy-3-nopunct": 8.569294260734521,
        "cond_entropy-3-nopunct": 0.8444380244379627,
        "msttr-100": 0.55019,
        "msttr-100_nopunct": 0.57933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.42697414395527605
        },
        "rouge1": {
            "precision": 0.42276,
            "recall": 0.44501,
            "fmeasure": 0.42077
        },
        "rouge2": {
            "precision": 0.24112,
            "recall": 0.25695,
            "fmeasure": 0.24003
        },
        "rougeL": {
            "precision": 0.37945,
            "recall": 0.3999,
            "fmeasure": 0.37787
        },
        "rougeLsum": {
            "precision": 0.37945,
            "recall": 0.3999,
            "fmeasure": 0.37787
        },
        "nist": 3.5359820884230184,
        "bleu": 16.07412,
        "bertscore": {
            "precision": 0.88247,
            "recall": 0.89499,
            "f1": 0.88843
        },
        "bleurt": -0.26608,
        "meteor": 0.21682425277322318,
        "nubia": {
            "semantic_relation": 3.02526,
            "contradiction": 30.33198,
            "irrelevancy": 28.71735,
            "logical_agreement": 40.95068,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.79054,
            "nubia_score": 0.43149
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 269,
        "total_length": 10143,
        "mean_pred_length": 37.70631970260223,
        "std_pred_length": 12.889839123372129,
        "median_pred_length": 35.0,
        "min_pred_length": 12,
        "max_pred_length": 92,
        "distinct-1": 0.09109730848861283,
        "vocab_size-1": 924,
        "unique-1": 367,
        "entropy-1": 7.102421136811252,
        "distinct-2": 0.272635203564918,
        "vocab_size-2": 2692,
        "unique-2": 1463,
        "entropy-2": 10.091628814351038,
        "cond_entropy-2": 2.915342821636602,
        "distinct-3": 0.46881832378969285,
        "vocab_size-3": 4503,
        "unique-3": 2977,
        "entropy-3": 11.421172143532875,
        "cond_entropy-3": 1.372592921818121,
        "total_length-nopunct": 8948,
        "mean_pred_length-nopunct": 33.2639405204461,
        "std_pred_length-nopunct": 12.012425447903667,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.1024810013410818,
        "vocab_size-1-nopunct": 917,
        "unique-1-nopunct": 367,
        "entropy-1-nopunct": 7.243553534970078,
        "distinct-2-nopunct": 0.2915082382762991,
        "vocab_size-2-nopunct": 2530,
        "unique-2-nopunct": 1437,
        "entropy-2-nopunct": 10.022327844549457,
        "cond_entropy-2-nopunct": 2.875242079029022,
        "distinct-3-nopunct": 0.4958382877526754,
        "vocab_size-3-nopunct": 4170,
        "unique-3-nopunct": 2865,
        "entropy-3-nopunct": 11.340789065977265,
        "cond_entropy-3-nopunct": 1.3574072611089287,
        "msttr-100": 0.49218,
        "msttr-100_nopunct": 0.50034,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18566775244299674,
            "2": 0.4117647058823529,
            "3": 0.5914263032548294,
            "4": 0.25,
            "5": 0.75
        },
        "rouge1": {
            "precision": 0.48757,
            "recall": 0.54533,
            "fmeasure": 0.50329
        },
        "rouge2": {
            "precision": 0.22802,
            "recall": 0.26053,
            "fmeasure": 0.23719
        },
        "rougeL": {
            "precision": 0.35604,
            "recall": 0.40445,
            "fmeasure": 0.36932
        },
        "rougeLsum": {
            "precision": 0.35604,
            "recall": 0.40445,
            "fmeasure": 0.36932
        },
        "nist": 4.70201035233657,
        "bleu": 19.26071,
        "bertscore": {
            "precision": 0.83141,
            "recall": 0.83802,
            "f1": 0.83327
        },
        "bleurt": -0.55533,
        "meteor": 0.23987819369241484,
        "nubia": {
            "semantic_relation": 3.03606,
            "contradiction": 41.75997,
            "irrelevancy": 22.01644,
            "logical_agreement": 36.22359,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.29938,
            "nubia_score": 0.40204
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 149,
        "total_length": 1639,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.006101281269066504,
        "vocab_size-1": 10,
        "unique-1": 0,
        "entropy-1": 3.277613436819116,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 10,
        "unique-2": 0,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 9,
        "unique-3": 0,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 1192,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "msttr-100": 0.1,
        "msttr-100_nopunct": 0.08,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.04155495978552279
        },
        "rouge1": {
            "precision": 0.05513,
            "recall": 0.11267,
            "fmeasure": 0.07251
        },
        "rouge2": {
            "precision": 0.016,
            "recall": 0.04259,
            "fmeasure": 0.02279
        },
        "rougeL": {
            "precision": 0.05465,
            "recall": 0.11219,
            "fmeasure": 0.07203
        },
        "rougeLsum": {
            "precision": 0.05465,
            "recall": 0.11219,
            "fmeasure": 0.07203
        },
        "nist": 0.36107033693505836,
        "bleu": 0.09301,
        "bertscore": {
            "precision": 0.80629,
            "recall": 0.85036,
            "f1": 0.82769
        },
        "bleurt": -0.8703,
        "meteor": 0.03513013445170839,
        "nubia": {
            "semantic_relation": 1.02714,
            "contradiction": 55.49188,
            "irrelevancy": 36.34971,
            "logical_agreement": 8.15842,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.65081,
            "nubia_score": 0.07914
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 500,
        "total_length": 9950,
        "mean_pred_length": 19.9,
        "std_pred_length": 9.935491935480599,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.17045226130653265,
        "vocab_size-1": 1696,
        "unique-1": 660,
        "entropy-1": 8.590669815410136,
        "distinct-2": 0.38751322751322753,
        "vocab_size-2": 3662,
        "unique-2": 1951,
        "entropy-2": 11.085426608458535,
        "cond_entropy-2": 2.2332126553635168,
        "distinct-3": 0.5360893854748603,
        "vocab_size-3": 4798,
        "unique-3": 3068,
        "entropy-3": 11.790928441785294,
        "cond_entropy-3": 0.7303223649434312,
        "total_length-nopunct": 8177,
        "mean_pred_length-nopunct": 16.354,
        "std_pred_length-nopunct": 8.478247696310836,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.2064326770209123,
        "vocab_size-1-nopunct": 1688,
        "unique-1-nopunct": 657,
        "entropy-1-nopunct": 9.248861555134507,
        "distinct-2-nopunct": 0.4252963397160349,
        "vocab_size-2-nopunct": 3265,
        "unique-2-nopunct": 1832,
        "entropy-2-nopunct": 11.036788522768848,
        "cond_entropy-2-nopunct": 1.8682653653165942,
        "distinct-3-nopunct": 0.5707119966559844,
        "vocab_size-3-nopunct": 4096,
        "unique-3-nopunct": 2743,
        "entropy-3-nopunct": 11.60147094653354,
        "cond_entropy-3-nopunct": 0.6063552585783206,
        "msttr-100": 0.57869,
        "msttr-100_nopunct": 0.63519,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2667861799217731,
            "2": 0.5942424242424242,
            "3": 0.812341504649197,
            "4": 0.8444444444444444,
            "5": 0.6,
            "6": 1.0
        },
        "rouge1": {
            "precision": 0.39832,
            "recall": 0.41114,
            "fmeasure": 0.39627
        },
        "rouge2": {
            "precision": 0.20469,
            "recall": 0.22065,
            "fmeasure": 0.2063
        },
        "rougeL": {
            "precision": 0.38587,
            "recall": 0.40021,
            "fmeasure": 0.38464
        },
        "rougeLsum": {
            "precision": 0.38587,
            "recall": 0.40021,
            "fmeasure": 0.38464
        },
        "nist": 8.374224371619379,
        "bleu": 46.12611,
        "bertscore": {
            "precision": 0.95437,
            "recall": 0.94562,
            "f1": 0.94931
        },
        "bleurt": 0.18807,
        "meteor": 0.5977265394775108,
        "nubia": {
            "semantic_relation": 3.94912,
            "contradiction": 20.05998,
            "irrelevancy": 21.32612,
            "logical_agreement": 58.6139,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.54371,
            "nubia_score": 0.82037
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1322,
        "total_length": 34240,
        "mean_pred_length": 25.90015128593041,
        "std_pred_length": 14.532003910242704,
        "median_pred_length": 23.5,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.04953271028037383,
        "vocab_size-1": 1696,
        "unique-1": 535,
        "entropy-1": 7.636987273323492,
        "distinct-2": 0.16987666322376815,
        "vocab_size-2": 5592,
        "unique-2": 2511,
        "entropy-2": 10.885317472261034,
        "cond_entropy-2": 3.104587385639226,
        "distinct-3": 0.31560957083175084,
        "vocab_size-3": 9972,
        "unique-3": 5577,
        "entropy-3": 12.252873295789351,
        "cond_entropy-3": 1.4372224852245792,
        "total_length-nopunct": 30363,
        "mean_pred_length-nopunct": 22.967473524962177,
        "std_pred_length-nopunct": 13.268882339852336,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.055561044692553435,
        "vocab_size-1-nopunct": 1687,
        "unique-1-nopunct": 535,
        "entropy-1-nopunct": 7.8501402120535255,
        "distinct-2-nopunct": 0.1798491787472883,
        "vocab_size-2-nopunct": 5223,
        "unique-2-nopunct": 2437,
        "entropy-2-nopunct": 10.791211118368796,
        "cond_entropy-2-nopunct": 3.095453976802606,
        "distinct-3-nopunct": 0.3294491143259136,
        "vocab_size-3-nopunct": 9132,
        "unique-3-nopunct": 5236,
        "entropy-3-nopunct": 12.138203440103599,
        "cond_entropy-3-nopunct": 1.4218728400757472,
        "msttr-100": 0.48427,
        "msttr-100_nopunct": 0.50129,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22339795140946414,
            "2": 0.5308503162333099,
            "3": 0.7221555988607405,
            "4": 0.9411764705882353,
            "5": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.61352,
            "recall": 0.66769,
            "fmeasure": 0.62895
        },
        "rouge2": {
            "precision": 0.37433,
            "recall": 0.40524,
            "fmeasure": 0.38233
        },
        "rougeL": {
            "precision": 0.49925,
            "recall": 0.54523,
            "fmeasure": 0.51212
        },
        "rougeLsum": {
            "precision": 0.49925,
            "recall": 0.54523,
            "fmeasure": 0.51212
        },
        "nist": 6.473105720466745,
        "bleu": 32.43275,
        "bertscore": {
            "precision": 0.87918,
            "recall": 0.88599,
            "f1": 0.88114
        },
        "bleurt": -0.15263,
        "meteor": 0.3136838433765128,
        "nubia": {
            "semantic_relation": 3.71987,
            "contradiction": 30.9207,
            "irrelevancy": 14.43028,
            "logical_agreement": 54.64902,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.60248,
            "nubia_score": 0.58014
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 457,
        "total_length": 15939,
        "mean_pred_length": 34.87746170678337,
        "std_pred_length": 14.270222539439253,
        "median_pred_length": 32.0,
        "min_pred_length": 8,
        "max_pred_length": 96,
        "distinct-1": 0.0779848171152519,
        "vocab_size-1": 1243,
        "unique-1": 469,
        "entropy-1": 7.571330415458831,
        "distinct-2": 0.2264565301640615,
        "vocab_size-2": 3506,
        "unique-2": 1841,
        "entropy-2": 10.384978779851533,
        "cond_entropy-2": 2.713542643397456,
        "distinct-3": 0.37051580698835274,
        "vocab_size-3": 5567,
        "unique-3": 3571,
        "entropy-3": 11.46350262719137,
        "cond_entropy-3": 1.1270159590223858,
        "total_length-nopunct": 14231,
        "mean_pred_length-nopunct": 31.14004376367615,
        "std_pred_length-nopunct": 13.061966201472616,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 92,
        "distinct-1-nopunct": 0.08671210737123182,
        "vocab_size-1-nopunct": 1234,
        "unique-1-nopunct": 467,
        "entropy-1-nopunct": 7.759188185265099,
        "distinct-2-nopunct": 0.23602439378539278,
        "vocab_size-2-nopunct": 3251,
        "unique-2-nopunct": 1758,
        "entropy-2-nopunct": 10.297704983931538,
        "cond_entropy-2-nopunct": 2.634392256110382,
        "distinct-3-nopunct": 0.38259367725463694,
        "vocab_size-3-nopunct": 5095,
        "unique-3-nopunct": 3341,
        "entropy-3-nopunct": 11.347204519800732,
        "cond_entropy-3-nopunct": 1.0878669618119083,
        "msttr-100": 0.45289,
        "msttr-100_nopunct": 0.45648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23005698005698005,
            "2": 0.5839094908862351,
            "3": 0.7890548879506333,
            "4": 0.25,
            "5": 0.75
        },
        "rouge1": {
            "precision": 0.63766,
            "recall": 0.67148,
            "fmeasure": 0.64437
        },
        "rouge2": {
            "precision": 0.39348,
            "recall": 0.41379,
            "fmeasure": 0.39699
        },
        "rougeL": {
            "precision": 0.47589,
            "recall": 0.50965,
            "fmeasure": 0.48423
        },
        "rougeLsum": {
            "precision": 0.47589,
            "recall": 0.50965,
            "fmeasure": 0.48423
        },
        "nist": 7.218630582210802,
        "bleu": 40.79443,
        "bertscore": {
            "precision": 0.8874,
            "recall": 0.8864,
            "f1": 0.88559
        },
        "bleurt": -0.15641,
        "meteor": 0.3445047845405412,
        "nubia": {
            "semantic_relation": 3.83038,
            "contradiction": 23.8602,
            "irrelevancy": 13.46704,
            "logical_agreement": 62.67276,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.17519,
            "nubia_score": 0.63136
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 72,
        "total_length": 2169,
        "mean_pred_length": 30.125,
        "std_pred_length": 7.641148655652354,
        "median_pred_length": 29.0,
        "min_pred_length": 14,
        "max_pred_length": 56,
        "distinct-1": 0.17012448132780084,
        "vocab_size-1": 369,
        "unique-1": 203,
        "entropy-1": 6.774601094816229,
        "distinct-2": 0.35097758702908916,
        "vocab_size-2": 736,
        "unique-2": 474,
        "entropy-2": 8.357917907459944,
        "cond_entropy-2": 1.528164153351205,
        "distinct-3": 0.48641975308641977,
        "vocab_size-3": 985,
        "unique-3": 725,
        "entropy-3": 9.07249676203505,
        "cond_entropy-3": 0.6853995920956126,
        "total_length-nopunct": 1932,
        "mean_pred_length-nopunct": 26.833333333333332,
        "std_pred_length-nopunct": 7.104380495315705,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.1873706004140787,
        "vocab_size-1-nopunct": 362,
        "unique-1-nopunct": 202,
        "entropy-1-nopunct": 6.817544635122573,
        "distinct-2-nopunct": 0.3763440860215054,
        "vocab_size-2-nopunct": 700,
        "unique-2-nopunct": 454,
        "entropy-2-nopunct": 8.370750615993504,
        "cond_entropy-2-nopunct": 1.5534759548366708,
        "distinct-3-nopunct": 0.5100671140939598,
        "vocab_size-3-nopunct": 912,
        "unique-3-nopunct": 684,
        "entropy-3-nopunct": 9.022880661204596,
        "cond_entropy-3-nopunct": 0.7019359487288717,
        "msttr-100": 0.60143,
        "msttr-100_nopunct": 0.60474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5993031358885017
        },
        "rouge1": {
            "precision": 0.67105,
            "recall": 0.58305,
            "fmeasure": 0.61715
        },
        "rouge2": {
            "precision": 0.43895,
            "recall": 0.38332,
            "fmeasure": 0.40464
        },
        "rougeL": {
            "precision": 0.53104,
            "recall": 0.45988,
            "fmeasure": 0.48767
        },
        "rougeLsum": {
            "precision": 0.53104,
            "recall": 0.45988,
            "fmeasure": 0.48767
        },
        "nist": 5.555012768850059,
        "bleu": 32.97704,
        "bertscore": {
            "precision": 0.89891,
            "recall": 0.87655,
            "f1": 0.88736
        },
        "bleurt": -0.06605,
        "meteor": 0.3304892100389304,
        "nubia": {
            "semantic_relation": 4.14933,
            "contradiction": 2.85192,
            "irrelevancy": 7.70661,
            "logical_agreement": 89.44147,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.06196,
            "nubia_score": 0.73209
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 4693,
        "total_length": 112763,
        "mean_pred_length": 24.027913914340505,
        "std_pred_length": 6.576976923982816,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 43,
        "distinct-1": 0.0012149375238331723,
        "vocab_size-1": 137,
        "unique-1": 2,
        "entropy-1": 5.707526737554282,
        "distinct-2": 0.004062181919126492,
        "vocab_size-2": 439,
        "unique-2": 32,
        "entropy-2": 7.141316820172465,
        "cond_entropy-2": 1.3444527296018838,
        "distinct-3": 0.008715671764512416,
        "vocab_size-3": 901,
        "unique-3": 94,
        "entropy-3": 7.9744726170546265,
        "cond_entropy-3": 0.8746065207083239,
        "total_length-nopunct": 103601,
        "mean_pred_length-nopunct": 22.075644577029617,
        "std_pred_length-nopunct": 6.1625496468105085,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.001303076225132962,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 5.757363944110729,
        "distinct-2-nopunct": 0.004286811986896915,
        "vocab_size-2-nopunct": 424,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 7.08964725216821,
        "cond_entropy-2-nopunct": 1.3822330074859308,
        "distinct-3-nopunct": 0.009499548904102319,
        "vocab_size-3-nopunct": 895,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 7.977299466598727,
        "cond_entropy-3-nopunct": 0.9062851831179337,
        "msttr-100": 0.27524,
        "msttr-100_nopunct": 0.26952,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7042167125076676
        },
        "rouge1": {
            "precision": 0.77926,
            "recall": 0.71532,
            "fmeasure": 0.73558
        },
        "rouge2": {
            "precision": 0.48278,
            "recall": 0.44104,
            "fmeasure": 0.4542
        },
        "rougeL": {
            "precision": 0.5598,
            "recall": 0.51355,
            "fmeasure": 0.52809
        },
        "rougeLsum": {
            "precision": 0.5598,
            "recall": 0.51355,
            "fmeasure": 0.52809
        },
        "nist": 5.4314127182026,
        "bleu": 32.735,
        "bertscore": {
            "precision": 0.92562,
            "recall": 0.90623,
            "f1": 0.9155
        },
        "bleurt": 0.24122,
        "meteor": 0.36522539829072737,
        "nubia": {
            "semantic_relation": 4.31841,
            "contradiction": 2.27297,
            "irrelevancy": 12.963,
            "logical_agreement": 84.76402,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.42433,
            "nubia_score": 0.7998
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 115,
        "total_length": 2363,
        "mean_pred_length": 20.547826086956523,
        "std_pred_length": 7.60691159208218,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 51,
        "distinct-1": 0.23275497249259416,
        "vocab_size-1": 550,
        "unique-1": 274,
        "entropy-1": 7.152950901095541,
        "distinct-2": 0.5031138790035588,
        "vocab_size-2": 1131,
        "unique-2": 737,
        "entropy-2": 9.547611508963453,
        "cond_entropy-2": 2.238910344051146,
        "distinct-3": 0.6694796061884669,
        "vocab_size-3": 1428,
        "unique-3": 1083,
        "entropy-3": 10.178105331481502,
        "cond_entropy-3": 0.6770517049360942,
        "total_length-nopunct": 2067,
        "mean_pred_length-nopunct": 17.973913043478262,
        "std_pred_length-nopunct": 6.6181054291012495,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.26318335752298017,
        "vocab_size-1-nopunct": 544,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.371320997387529,
        "distinct-2-nopunct": 0.5035860655737705,
        "vocab_size-2-nopunct": 983,
        "unique-2-nopunct": 641,
        "entropy-2-nopunct": 9.344040038465469,
        "cond_entropy-2-nopunct": 2.113412999210112,
        "distinct-3-nopunct": 0.6646706586826348,
        "vocab_size-3-nopunct": 1221,
        "unique-3-nopunct": 924,
        "entropy-3-nopunct": 9.944925952435993,
        "cond_entropy-3-nopunct": 0.652442161768499,
        "msttr-100": 0.59609,
        "msttr-100_nopunct": 0.64,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.24641148325358853,
            "2": 0.5942857142857143,
            "3": 0.8130165289256198
        },
        "rouge1": {
            "precision": 0.6631,
            "recall": 0.71902,
            "fmeasure": 0.67983
        },
        "rouge2": {
            "precision": 0.43311,
            "recall": 0.46721,
            "fmeasure": 0.44357
        },
        "rougeL": {
            "precision": 0.55262,
            "recall": 0.601,
            "fmeasure": 0.56711
        },
        "rougeLsum": {
            "precision": 0.55262,
            "recall": 0.601,
            "fmeasure": 0.56711
        },
        "nist": 6.7727754382585985,
        "bleu": 41.93898,
        "bertscore": {
            "precision": 0.89535,
            "recall": 0.90815,
            "f1": 0.90016
        },
        "bleurt": 0.02008,
        "meteor": 0.38416003006156135,
        "nubia": {
            "semantic_relation": 4.10423,
            "contradiction": 18.94704,
            "irrelevancy": 12.04069,
            "logical_agreement": 69.01227,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.56124,
            "nubia_score": 0.68541
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6180,
        "mean_pred_length": 12.36,
        "std_pred_length": 7.072934327420268,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.14433656957928803,
        "vocab_size-1": 892,
        "unique-1": 507,
        "entropy-1": 7.638006821111831,
        "distinct-2": 0.40299295774647886,
        "vocab_size-2": 2289,
        "unique-2": 1510,
        "entropy-2": 10.143831205487754,
        "cond_entropy-2": 2.2438962043047037,
        "distinct-3": 0.581081081081081,
        "vocab_size-3": 3010,
        "unique-3": 2290,
        "entropy-3": 10.893054817722383,
        "cond_entropy-3": 0.7829195209105797,
        "total_length-nopunct": 5405,
        "mean_pred_length-nopunct": 10.81,
        "std_pred_length-nopunct": 6.472549729434297,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.16281221091581868,
        "vocab_size-1-nopunct": 880,
        "unique-1-nopunct": 504,
        "entropy-1-nopunct": 7.820213227003545,
        "distinct-2-nopunct": 0.41590214067278286,
        "vocab_size-2-nopunct": 2040,
        "unique-2-nopunct": 1381,
        "entropy-2-nopunct": 9.963710241738744,
        "cond_entropy-2-nopunct": 2.2853369562102723,
        "distinct-3-nopunct": 0.5975028376844495,
        "vocab_size-3-nopunct": 2632,
        "unique-3-nopunct": 2051,
        "entropy-3-nopunct": 10.696330398679457,
        "cond_entropy-3-nopunct": 0.7775411503366659,
        "msttr-100": 0.66738,
        "msttr-100_nopunct": 0.69259,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5650964391691394
        },
        "rouge1": {
            "precision": 0.5789,
            "recall": 0.55292,
            "fmeasure": 0.55338
        },
        "rouge2": {
            "precision": 0.36168,
            "recall": 0.34702,
            "fmeasure": 0.34648
        },
        "rougeL": {
            "precision": 0.52102,
            "recall": 0.49835,
            "fmeasure": 0.49868
        },
        "rougeLsum": {
            "precision": 0.52102,
            "recall": 0.49835,
            "fmeasure": 0.49868
        },
        "nist": 6.036108304984923,
        "bleu": 32.31762,
        "bertscore": {
            "precision": 0.87493,
            "recall": 0.86689,
            "f1": 0.87035
        },
        "bleurt": -0.05166,
        "meteor": 0.3185100207571178,
        "nubia": {
            "semantic_relation": 3.604,
            "contradiction": 9.51187,
            "irrelevancy": 20.26223,
            "logical_agreement": 70.2259,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.45733,
            "nubia_score": 0.65631
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 518,
        "total_length": 15692,
        "mean_pred_length": 30.293436293436294,
        "std_pred_length": 14.416541716530851,
        "median_pred_length": 29.0,
        "min_pred_length": 5,
        "max_pred_length": 89,
        "distinct-1": 0.05302064746367576,
        "vocab_size-1": 832,
        "unique-1": 213,
        "entropy-1": 7.575512854554543,
        "distinct-2": 0.14478713589033873,
        "vocab_size-2": 2197,
        "unique-2": 834,
        "entropy-2": 9.880775823904749,
        "cond_entropy-2": 2.1815155163254656,
        "distinct-3": 0.2263919213973799,
        "vocab_size-3": 3318,
        "unique-3": 1574,
        "entropy-3": 10.637183724803993,
        "cond_entropy-3": 0.8001228897648562,
        "total_length-nopunct": 14101,
        "mean_pred_length-nopunct": 27.22200772200772,
        "std_pred_length-nopunct": 12.963080118633169,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.05843557194525211,
        "vocab_size-1-nopunct": 824,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 7.772817720392035,
        "distinct-2-nopunct": 0.1501141132297725,
        "vocab_size-2-nopunct": 2039,
        "unique-2-nopunct": 795,
        "entropy-2-nopunct": 9.783933029599881,
        "cond_entropy-2-nopunct": 2.09319180142893,
        "distinct-3-nopunct": 0.2361270570225794,
        "vocab_size-3-nopunct": 3085,
        "unique-3-nopunct": 1498,
        "entropy-3-nopunct": 10.51869624341536,
        "cond_entropy-3-nopunct": 0.7614125781218473,
        "msttr-100": 0.6291,
        "msttr-100_nopunct": 0.65738,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2587082093471031,
            "2": 0.6600231080300404,
            "3": 0.9211203200914547,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.79675,
            "recall": 0.79743,
            "fmeasure": 0.78999
        },
        "rouge2": {
            "precision": 0.57498,
            "recall": 0.57802,
            "fmeasure": 0.57076
        },
        "rougeL": {
            "precision": 0.63531,
            "recall": 0.63996,
            "fmeasure": 0.63147
        },
        "rougeLsum": {
            "precision": 0.63531,
            "recall": 0.63996,
            "fmeasure": 0.63147
        },
        "nist": 9.124001575955042,
        "bleu": 59.17321,
        "bertscore": {
            "precision": 0.94385,
            "recall": 0.93584,
            "f1": 0.93878
        },
        "bleurt": 0.31495,
        "meteor": 0.42020178912366124,
        "nubia": {
            "semantic_relation": 4.61013,
            "contradiction": 5.16585,
            "irrelevancy": 5.46081,
            "logical_agreement": 89.37334,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.10274,
            "nubia_score": 0.85909
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6331,
        "mean_pred_length": 12.662,
        "std_pred_length": 8.087011561757532,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 87,
        "distinct-1": 0.14326330753435476,
        "vocab_size-1": 907,
        "unique-1": 498,
        "entropy-1": 7.715454103908117,
        "distinct-2": 0.4037043388784085,
        "vocab_size-2": 2354,
        "unique-2": 1534,
        "entropy-2": 10.248027272323128,
        "cond_entropy-2": 2.3010449873260144,
        "distinct-3": 0.5807540799099606,
        "vocab_size-3": 3096,
        "unique-3": 2328,
        "entropy-3": 11.011312497203951,
        "cond_entropy-3": 0.796096719979605,
        "total_length-nopunct": 5570,
        "mean_pred_length-nopunct": 11.14,
        "std_pred_length-nopunct": 7.334057539997898,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.16050269299820466,
        "vocab_size-1-nopunct": 894,
        "unique-1-nopunct": 494,
        "entropy-1-nopunct": 7.880972125428564,
        "distinct-2-nopunct": 0.4175542406311637,
        "vocab_size-2-nopunct": 2117,
        "unique-2-nopunct": 1407,
        "entropy-2-nopunct": 10.085213105635727,
        "cond_entropy-2-nopunct": 2.332730886270144,
        "distinct-3-nopunct": 0.6010940919037199,
        "vocab_size-3-nopunct": 2747,
        "unique-3-nopunct": 2113,
        "entropy-3-nopunct": 10.849703540359373,
        "cond_entropy-3-nopunct": 0.8124487252209297,
        "msttr-100": 0.67032,
        "msttr-100_nopunct": 0.69436,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5433153215966533
        },
        "rouge1": {
            "precision": 0.58701,
            "recall": 0.54348,
            "fmeasure": 0.55278
        },
        "rouge2": {
            "precision": 0.36641,
            "recall": 0.33953,
            "fmeasure": 0.34433
        },
        "rougeL": {
            "precision": 0.52916,
            "recall": 0.48888,
            "fmeasure": 0.49774
        },
        "rougeLsum": {
            "precision": 0.52916,
            "recall": 0.48888,
            "fmeasure": 0.49774
        },
        "nist": 5.958481681171194,
        "bleu": 30.63649,
        "bertscore": {
            "precision": 0.87489,
            "recall": 0.86001,
            "f1": 0.86692
        },
        "bleurt": -0.09137,
        "meteor": 0.30523141481385974,
        "nubia": {
            "semantic_relation": 3.57611,
            "contradiction": 9.79417,
            "irrelevancy": 19.32259,
            "logical_agreement": 70.88324,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.57365,
            "nubia_score": 0.63156
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 1024,
        "total_length": 9529,
        "mean_pred_length": 9.3056640625,
        "std_pred_length": 5.6581770843970585,
        "median_pred_length": 6.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.07366984993178717,
        "vocab_size-1": 702,
        "unique-1": 412,
        "entropy-1": 6.0259256510979915,
        "distinct-2": 0.18718400940623162,
        "vocab_size-2": 1592,
        "unique-2": 1001,
        "entropy-2": 8.23272901170647,
        "cond_entropy-2": 1.8807664574244187,
        "distinct-3": 0.3012966180991846,
        "vocab_size-3": 2254,
        "unique-3": 1565,
        "entropy-3": 9.152292429014592,
        "cond_entropy-3": 0.8818357900464717,
        "total_length-nopunct": 8070,
        "mean_pred_length-nopunct": 7.880859375,
        "std_pred_length-nopunct": 4.95482175627687,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.08599752168525403,
        "vocab_size-1-nopunct": 694,
        "unique-1-nopunct": 411,
        "entropy-1-nopunct": 6.256055595581106,
        "distinct-2-nopunct": 0.2055066704513199,
        "vocab_size-2-nopunct": 1448,
        "unique-2-nopunct": 923,
        "entropy-2-nopunct": 8.156725587139121,
        "cond_entropy-2-nopunct": 2.0511317292146525,
        "distinct-3-nopunct": 0.3375954832281634,
        "vocab_size-3-nopunct": 2033,
        "unique-3-nopunct": 1438,
        "entropy-3-nopunct": 9.135277624197919,
        "cond_entropy-3-nopunct": 0.9338852528389321,
        "msttr-100": 0.44916,
        "msttr-100_nopunct": 0.47788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.3985308628439864
        },
        "rouge1": {
            "precision": 0.42252,
            "recall": 0.37555,
            "fmeasure": 0.38857
        },
        "rouge2": {
            "precision": 0.20349,
            "recall": 0.18289,
            "fmeasure": 0.18809
        },
        "rougeL": {
            "precision": 0.38099,
            "recall": 0.33689,
            "fmeasure": 0.34915
        },
        "rougeLsum": {
            "precision": 0.38099,
            "recall": 0.33689,
            "fmeasure": 0.34915
        },
        "nist": 4.139386065412019,
        "bleu": 22.44336,
        "bertscore": {
            "precision": 0.85552,
            "recall": 0.83735,
            "f1": 0.84598
        },
        "bleurt": -0.54632,
        "meteor": 0.23250572809508221,
        "nubia": {
            "semantic_relation": 2.47026,
            "contradiction": 9.66073,
            "irrelevancy": 28.75449,
            "logical_agreement": 61.58479,
            "grammar_ref": 5.2128,
            "grammar_hyp": 4.99471,
            "nubia_score": 0.41262
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2022,
        "mean_pred_length": 19.07547169811321,
        "std_pred_length": 3.894112908421971,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.3743818001978239,
        "vocab_size-1": 757,
        "unique-1": 524,
        "entropy-1": 7.87706140254896,
        "distinct-2": 0.7729645093945721,
        "vocab_size-2": 1481,
        "unique-2": 1289,
        "entropy-2": 10.195998601537058,
        "cond_entropy-2": 2.1184768936790563,
        "distinct-3": 0.918232044198895,
        "vocab_size-3": 1662,
        "unique-3": 1570,
        "entropy-3": 10.622108546936682,
        "cond_entropy-3": 0.45236732047173506,
        "total_length-nopunct": 1884,
        "mean_pred_length-nopunct": 17.77358490566038,
        "std_pred_length-nopunct": 3.7145380343763827,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.398619957537155,
        "vocab_size-1-nopunct": 751,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 7.984725153014127,
        "distinct-2-nopunct": 0.7705286839145107,
        "vocab_size-2-nopunct": 1370,
        "unique-2-nopunct": 1189,
        "entropy-2-nopunct": 10.076129297602359,
        "cond_entropy-2-nopunct": 2.2227381446083916,
        "distinct-3-nopunct": 0.9222488038277512,
        "vocab_size-3-nopunct": 1542,
        "unique-3-nopunct": 1458,
        "entropy-3-nopunct": 10.521593312767248,
        "cond_entropy-3-nopunct": 0.46509141456247727,
        "msttr-100": 0.669,
        "msttr-100_nopunct": 0.67778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.28689275893675525
        },
        "rouge1": {
            "precision": 0.38329,
            "recall": 0.30877,
            "fmeasure": 0.33428
        },
        "rouge2": {
            "precision": 0.12259,
            "recall": 0.0963,
            "fmeasure": 0.10528
        },
        "rougeL": {
            "precision": 0.2989,
            "recall": 0.24068,
            "fmeasure": 0.26053
        },
        "rougeLsum": {
            "precision": 0.2989,
            "recall": 0.24068,
            "fmeasure": 0.26053
        },
        "nist": 2.4736368318540327,
        "bleu": 6.09814,
        "bertscore": {
            "precision": 0.82491,
            "recall": 0.79637,
            "f1": 0.81008
        },
        "bleurt": -0.4974,
        "meteor": 0.13087497226284317,
        "nubia": {
            "semantic_relation": 2.27181,
            "contradiction": 32.43462,
            "irrelevancy": 56.56613,
            "logical_agreement": 10.99925,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.73242,
            "nubia_score": 0.26447
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2031,
        "mean_pred_length": 19.160377358490567,
        "std_pred_length": 4.08664828401261,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.36681437715411125,
        "vocab_size-1": 745,
        "unique-1": 532,
        "entropy-1": 7.795396722794138,
        "distinct-2": 0.7646753246753247,
        "vocab_size-2": 1472,
        "unique-2": 1290,
        "entropy-2": 10.129429712659205,
        "cond_entropy-2": 2.139359576241595,
        "distinct-3": 0.9147883452446399,
        "vocab_size-3": 1664,
        "unique-3": 1575,
        "entropy-3": 10.594893660244919,
        "cond_entropy-3": 0.4880225745111365,
        "total_length-nopunct": 1894,
        "mean_pred_length-nopunct": 17.867924528301888,
        "std_pred_length-nopunct": 3.882897847280718,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.3901795142555438,
        "vocab_size-1-nopunct": 739,
        "unique-1-nopunct": 532,
        "entropy-1-nopunct": 7.89772559775196,
        "distinct-2-nopunct": 0.7628635346756152,
        "vocab_size-2-nopunct": 1364,
        "unique-2-nopunct": 1192,
        "entropy-2-nopunct": 10.011439988844334,
        "cond_entropy-2-nopunct": 2.241486064327484,
        "distinct-3-nopunct": 0.9197384066587396,
        "vocab_size-3-nopunct": 1547,
        "unique-3-nopunct": 1464,
        "entropy-3-nopunct": 10.49986629610816,
        "cond_entropy-3-nopunct": 0.5140508238653244,
        "msttr-100": 0.6635,
        "msttr-100_nopunct": 0.68,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.27201112140871175
        },
        "rouge1": {
            "precision": 0.37232,
            "recall": 0.30912,
            "fmeasure": 0.33028
        },
        "rouge2": {
            "precision": 0.11767,
            "recall": 0.09962,
            "fmeasure": 0.10449
        },
        "rougeL": {
            "precision": 0.29396,
            "recall": 0.2448,
            "fmeasure": 0.26076
        },
        "rougeLsum": {
            "precision": 0.29396,
            "recall": 0.2448,
            "fmeasure": 0.26076
        },
        "nist": 2.392111380409208,
        "bleu": 5.77236,
        "bertscore": {
            "precision": 0.82069,
            "recall": 0.79459,
            "f1": 0.80713
        },
        "bleurt": -0.5092,
        "meteor": 0.12794360157148219,
        "nubia": {
            "semantic_relation": 2.18399,
            "contradiction": 33.18006,
            "irrelevancy": 56.96461,
            "logical_agreement": 9.85533,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.71497,
            "nubia_score": 0.25604
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1177,
        "total_length": 33441,
        "mean_pred_length": 28.412064570943077,
        "std_pred_length": 15.016251425290479,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.04464579408510511,
        "vocab_size-1": 1493,
        "unique-1": 467,
        "entropy-1": 7.32996863173009,
        "distinct-2": 0.16318497396479048,
        "vocab_size-2": 5265,
        "unique-2": 2424,
        "entropy-2": 10.637096602408974,
        "cond_entropy-2": 3.1924869329328116,
        "distinct-3": 0.3200694824203043,
        "vocab_size-3": 9950,
        "unique-3": 5744,
        "entropy-3": 12.166587272703877,
        "cond_entropy-3": 1.5985842078234678,
        "total_length-nopunct": 29581,
        "mean_pred_length-nopunct": 25.13254035683942,
        "std_pred_length-nopunct": 13.80102946747887,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.05016733714208445,
        "vocab_size-1-nopunct": 1484,
        "unique-1-nopunct": 467,
        "entropy-1-nopunct": 7.501043833041242,
        "distinct-2-nopunct": 0.17631319532460216,
        "vocab_size-2-nopunct": 5008,
        "unique-2-nopunct": 2447,
        "entropy-2-nopunct": 10.554442023922542,
        "cond_entropy-2-nopunct": 3.2021182871817278,
        "distinct-3-nopunct": 0.33911191097072757,
        "vocab_size-3-nopunct": 9233,
        "unique-3-nopunct": 5560,
        "entropy-3-nopunct": 12.072075646241599,
        "cond_entropy-3-nopunct": 1.5920853078863113,
        "msttr-100": 0.54898,
        "msttr-100_nopunct": 0.57807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21019335293593513,
            "2": 0.48541762101084135,
            "3": 0.6392357952195848,
            "4": 0.4,
            "5": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.53529,
            "recall": 0.60892,
            "fmeasure": 0.5589
        },
        "rouge2": {
            "precision": 0.28662,
            "recall": 0.32742,
            "fmeasure": 0.29913
        },
        "rougeL": {
            "precision": 0.42244,
            "recall": 0.48485,
            "fmeasure": 0.4423
        },
        "rougeLsum": {
            "precision": 0.42244,
            "recall": 0.48485,
            "fmeasure": 0.4423
        },
        "nist": 5.157857887045632,
        "bleu": 22.30878,
        "bertscore": {
            "precision": 0.85168,
            "recall": 0.86271,
            "f1": 0.85561
        },
        "bleurt": -0.37529,
        "meteor": 0.2689542976283453,
        "nubia": {
            "semantic_relation": 3.34925,
            "contradiction": 40.63841,
            "irrelevancy": 18.23404,
            "logical_agreement": 41.12755,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.62198,
            "nubia_score": 0.47148
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 1246,
        "total_length": 18602,
        "mean_pred_length": 14.929373996789726,
        "std_pred_length": 5.8317628720310575,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 86,
        "distinct-1": 0.09611869691431028,
        "vocab_size-1": 1788,
        "unique-1": 860,
        "entropy-1": 7.696140544391174,
        "distinct-2": 0.24066605208573405,
        "vocab_size-2": 4177,
        "unique-2": 2416,
        "entropy-2": 10.01618833800014,
        "cond_entropy-2": 2.129093246959483,
        "distinct-3": 0.35747982619491,
        "vocab_size-3": 5759,
        "unique-3": 3703,
        "entropy-3": 11.067205600774706,
        "cond_entropy-3": 1.1425205750664156,
        "total_length-nopunct": 16701,
        "mean_pred_length-nopunct": 13.403691813804173,
        "std_pred_length-nopunct": 5.173083117322698,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.10616130770612538,
        "vocab_size-1-nopunct": 1773,
        "unique-1-nopunct": 857,
        "entropy-1-nopunct": 7.823984530691799,
        "distinct-2-nopunct": 0.24231640245875122,
        "vocab_size-2-nopunct": 3745,
        "unique-2-nopunct": 2203,
        "entropy-2-nopunct": 9.81729570687238,
        "cond_entropy-2-nopunct": 2.1746764828125946,
        "distinct-3-nopunct": 0.363009360264621,
        "vocab_size-3-nopunct": 5158,
        "unique-3-nopunct": 3372,
        "entropy-3-nopunct": 10.870777202235063,
        "cond_entropy-3-nopunct": 1.1821220519206344,
        "msttr-100": 0.63054,
        "msttr-100_nopunct": 0.64904,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6326810643121346
        },
        "rouge1": {
            "precision": 0.69722,
            "recall": 0.65987,
            "fmeasure": 0.66637
        },
        "rouge2": {
            "precision": 0.49541,
            "recall": 0.46777,
            "fmeasure": 0.47211
        },
        "rougeL": {
            "precision": 0.60974,
            "recall": 0.57834,
            "fmeasure": 0.58343
        },
        "rougeLsum": {
            "precision": 0.60974,
            "recall": 0.57834,
            "fmeasure": 0.58343
        },
        "nist": 7.239386816132161,
        "bleu": 38.81621,
        "bertscore": {
            "precision": 0.90277,
            "recall": 0.88862,
            "f1": 0.89519
        },
        "bleurt": -0.01283,
        "meteor": 0.3669175230991299,
        "nubia": {
            "semantic_relation": 4.286,
            "contradiction": 11.4742,
            "irrelevancy": 18.78022,
            "logical_agreement": 69.74558,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.76444,
            "nubia_score": 0.76651
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 56,
        "total_length": 746,
        "mean_pred_length": 13.321428571428571,
        "std_pred_length": 7.194013242315602,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 37,
        "distinct-1": 0.2613941018766756,
        "vocab_size-1": 195,
        "unique-1": 115,
        "entropy-1": 5.98737868683679,
        "distinct-2": 0.527536231884058,
        "vocab_size-2": 364,
        "unique-2": 255,
        "entropy-2": 7.956976483639855,
        "cond_entropy-2": 1.7827422022296044,
        "distinct-3": 0.668769716088328,
        "vocab_size-3": 424,
        "unique-3": 330,
        "entropy-3": 8.414584944621751,
        "cond_entropy-3": 0.5360939062615054,
        "total_length-nopunct": 646,
        "mean_pred_length-nopunct": 11.535714285714286,
        "std_pred_length-nopunct": 6.619679226459882,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.29566563467492263,
        "vocab_size-1-nopunct": 191,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.070168846486632,
        "distinct-2-nopunct": 0.5135593220338983,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 212,
        "entropy-2-nopunct": 7.660249768120358,
        "cond_entropy-2-nopunct": 1.770416813804366,
        "distinct-3-nopunct": 0.6573033707865169,
        "vocab_size-3-nopunct": 351,
        "unique-3-nopunct": 273,
        "entropy-3-nopunct": 8.121283250491953,
        "cond_entropy-3-nopunct": 0.5341301606912224,
        "msttr-100": 0.51143,
        "msttr-100_nopunct": 0.55167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20520231213872833,
            "2": 0.5729166666666666,
            "3": 0.7572463768115942
        },
        "rouge1": {
            "precision": 0.677,
            "recall": 0.69645,
            "fmeasure": 0.67592
        },
        "rouge2": {
            "precision": 0.43951,
            "recall": 0.46268,
            "fmeasure": 0.44308
        },
        "rougeL": {
            "precision": 0.58311,
            "recall": 0.60584,
            "fmeasure": 0.58469
        },
        "rougeLsum": {
            "precision": 0.58311,
            "recall": 0.60584,
            "fmeasure": 0.58469
        },
        "nist": 5.487069672024892,
        "bleu": 36.81259,
        "bertscore": {
            "precision": 0.90533,
            "recall": 0.90771,
            "f1": 0.90532
        },
        "bleurt": 0.0156,
        "meteor": 0.37300290256614066,
        "nubia": {
            "semantic_relation": 4.12408,
            "contradiction": 9.31889,
            "irrelevancy": 11.03329,
            "logical_agreement": 79.64782,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.17849,
            "nubia_score": 0.70118
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 4049,
        "mean_pred_length": 8.098,
        "std_pred_length": 1.290114723580814,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 11,
        "distinct-1": 0.012842677204247963,
        "vocab_size-1": 52,
        "unique-1": 2,
        "entropy-1": 4.510370665517419,
        "distinct-2": 0.03663003663003663,
        "vocab_size-2": 130,
        "unique-2": 17,
        "entropy-2": 5.609420941555807,
        "cond_entropy-2": 0.8911056506273443,
        "distinct-3": 0.06133158412594293,
        "vocab_size-3": 187,
        "unique-3": 39,
        "entropy-3": 5.983142768899358,
        "cond_entropy-3": 0.49636298991123,
        "total_length-nopunct": 3550,
        "mean_pred_length-nopunct": 7.1,
        "std_pred_length-nopunct": 1.2891857895586656,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.01436619718309859,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 4.530051780879787,
        "distinct-2-nopunct": 0.03639344262295082,
        "vocab_size-2-nopunct": 111,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 5.269588387291046,
        "cond_entropy-2-nopunct": 0.9764421136209858,
        "distinct-3-nopunct": 0.0603921568627451,
        "vocab_size-3-nopunct": 154,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.587191242921576,
        "cond_entropy-3-nopunct": 0.5666735779961737,
        "msttr-100": 0.27725,
        "msttr-100_nopunct": 0.28429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4961507831165384
        },
        "rouge1": {
            "precision": 0.55533,
            "recall": 0.50979,
            "fmeasure": 0.5228
        },
        "rouge2": {
            "precision": 0.31395,
            "recall": 0.28191,
            "fmeasure": 0.29133
        },
        "rougeL": {
            "precision": 0.53398,
            "recall": 0.49117,
            "fmeasure": 0.50327
        },
        "rougeLsum": {
            "precision": 0.53398,
            "recall": 0.49117,
            "fmeasure": 0.50327
        },
        "nist": 3.376126279959564,
        "bleu": 25.30473,
        "bertscore": {
            "precision": 0.88872,
            "recall": 0.88004,
            "f1": 0.88403
        },
        "bleurt": 0.08982,
        "meteor": 0.2772436794851981,
        "nubia": {
            "semantic_relation": 3.63545,
            "contradiction": 6.34984,
            "irrelevancy": 17.37145,
            "logical_agreement": 76.27872,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.78003,
            "nubia_score": 0.72624
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 2078,
        "total_length": 20584,
        "mean_pred_length": 9.905678537054861,
        "std_pred_length": 5.208248113203937,
        "median_pred_length": 8.0,
        "min_pred_length": 3,
        "max_pred_length": 43,
        "distinct-1": 0.01729498639720171,
        "vocab_size-1": 356,
        "unique-1": 97,
        "entropy-1": 5.9412964447541965,
        "distinct-2": 0.06570841889117043,
        "vocab_size-2": 1216,
        "unique-2": 423,
        "entropy-2": 8.166238632112305,
        "cond_entropy-2": 1.9276573121090868,
        "distinct-3": 0.13105673240808377,
        "vocab_size-3": 2153,
        "unique-3": 1008,
        "entropy-3": 9.186434817355284,
        "cond_entropy-3": 1.1196120575872737,
        "total_length-nopunct": 17825,
        "mean_pred_length-nopunct": 8.57795957651588,
        "std_pred_length-nopunct": 4.656273286490113,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.019691444600280505,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.0958901340040255,
        "distinct-2-nopunct": 0.07226773353654664,
        "vocab_size-2-nopunct": 1138,
        "unique-2-nopunct": 453,
        "entropy-2-nopunct": 7.877353381572881,
        "cond_entropy-2-nopunct": 2.006589508689621,
        "distinct-3-nopunct": 0.14243909576413782,
        "vocab_size-3-nopunct": 1947,
        "unique-3-nopunct": 992,
        "entropy-3-nopunct": 8.903050668298143,
        "cond_entropy-3-nopunct": 1.1564028201191896,
        "msttr-100": 0.47024,
        "msttr-100_nopunct": 0.48944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.3980441868888084
        },
        "rouge1": {
            "precision": 0.46344,
            "recall": 0.40798,
            "fmeasure": 0.41884
        },
        "rouge2": {
            "precision": 0.23018,
            "recall": 0.20719,
            "fmeasure": 0.20873
        },
        "rougeL": {
            "precision": 0.42541,
            "recall": 0.37587,
            "fmeasure": 0.38548
        },
        "rougeLsum": {
            "precision": 0.42541,
            "recall": 0.37587,
            "fmeasure": 0.38548
        },
        "nist": 3.3386005100806795,
        "bleu": 15.60513,
        "bertscore": {
            "precision": 0.84506,
            "recall": 0.82835,
            "f1": 0.83588
        },
        "bleurt": -0.31068,
        "meteor": 0.22099409188293678,
        "nubia": {
            "semantic_relation": 2.96415,
            "contradiction": 15.24944,
            "irrelevancy": 23.50348,
            "logical_agreement": 61.24708,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.2744,
            "nubia_score": 0.50806
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 715,
        "total_length": 7046,
        "mean_pred_length": 9.854545454545455,
        "std_pred_length": 3.2137973372409405,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 23,
        "distinct-1": 0.0080896962815782,
        "vocab_size-1": 57,
        "unique-1": 7,
        "entropy-1": 4.109363724450241,
        "distinct-2": 0.018796398673195387,
        "vocab_size-2": 119,
        "unique-2": 28,
        "entropy-2": 4.615306997118874,
        "cond_entropy-2": 0.41647207287306565,
        "distinct-3": 0.027243589743589744,
        "vocab_size-3": 153,
        "unique-3": 44,
        "entropy-3": 4.696715324711225,
        "cond_entropy-3": 0.09072595933193875,
        "total_length-nopunct": 6240,
        "mean_pred_length-nopunct": 8.727272727272727,
        "std_pred_length-nopunct": 2.8080349702507807,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.008653846153846154,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.9758501717366657,
        "distinct-2-nopunct": 0.019004524886877826,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.362328227282018,
        "cond_entropy-2-nopunct": 0.3555686116688096,
        "distinct-3-nopunct": 0.027650727650727652,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 4.431792825149649,
        "cond_entropy-3-nopunct": 0.04540569757081005,
        "msttr-100": 0.21029,
        "msttr-100_nopunct": 0.19694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5883725103176027
        },
        "rouge1": {
            "precision": 0.53026,
            "recall": 0.5891,
            "fmeasure": 0.54633
        },
        "rouge2": {
            "precision": 0.27585,
            "recall": 0.30088,
            "fmeasure": 0.28039
        },
        "rougeL": {
            "precision": 0.44346,
            "recall": 0.48654,
            "fmeasure": 0.45404
        },
        "rougeLsum": {
            "precision": 0.44346,
            "recall": 0.48654,
            "fmeasure": 0.45404
        },
        "nist": 2.85618557097707,
        "bleu": 25.73833,
        "bertscore": {
            "precision": 0.85158,
            "recall": 0.86411,
            "f1": 0.85727
        },
        "bleurt": 0.22676,
        "meteor": 0.2942485278452671,
        "nubia": {
            "semantic_relation": 3.65018,
            "contradiction": 1.71321,
            "irrelevancy": 25.05713,
            "logical_agreement": 73.22967,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.12837,
            "nubia_score": 0.76679
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 28,
        "total_length": 300,
        "mean_pred_length": 10.714285714285714,
        "std_pred_length": 3.65334624358412,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.36,
        "vocab_size-1": 108,
        "unique-1": 68,
        "entropy-1": 5.574108103339004,
        "distinct-2": 0.6654411764705882,
        "vocab_size-2": 181,
        "unique-2": 140,
        "entropy-2": 7.188956190971121,
        "cond_entropy-2": 1.3880408397527897,
        "distinct-3": 0.8114754098360656,
        "vocab_size-3": 198,
        "unique-3": 171,
        "entropy-3": 7.468466896909284,
        "cond_entropy-3": 0.3580278625276189,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.1566256848549075,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.39097744360902253,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.60875296262074,
        "distinct-2-nopunct": 0.634453781512605,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.9015664655098625,
        "cond_entropy-2-nopunct": 1.508250505200696,
        "distinct-3-nopunct": 0.7904761904761904,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.196178910430535,
        "cond_entropy-3-nopunct": 0.3868020888564894,
        "msttr-100": 0.50333,
        "msttr-100_nopunct": 0.535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1564625850340136,
            "2": 0.648936170212766,
            "3": 0.8148148148148148,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.7791,
            "recall": 0.74242,
            "fmeasure": 0.75213
        },
        "rouge2": {
            "precision": 0.53175,
            "recall": 0.505,
            "fmeasure": 0.51143
        },
        "rougeL": {
            "precision": 0.6622,
            "recall": 0.6286,
            "fmeasure": 0.63844
        },
        "rougeLsum": {
            "precision": 0.6622,
            "recall": 0.6286,
            "fmeasure": 0.63844
        },
        "nist": 6.360428745667614,
        "bleu": 51.49644,
        "bertscore": {
            "precision": 0.92089,
            "recall": 0.90547,
            "f1": 0.91198
        },
        "bleurt": 0.15888,
        "meteor": 0.3877377304909475,
        "nubia": {
            "semantic_relation": 3.82481,
            "contradiction": 26.86069,
            "irrelevancy": 11.5444,
            "logical_agreement": 61.59492,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.90191,
            "nubia_score": 0.58124
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2104,
        "mean_pred_length": 19.849056603773583,
        "std_pred_length": 4.159082928737628,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.3873574144486692,
        "vocab_size-1": 815,
        "unique-1": 598,
        "entropy-1": 8.030517790727766,
        "distinct-2": 0.7917917917917918,
        "vocab_size-2": 1582,
        "unique-2": 1393,
        "entropy-2": 10.350356545029866,
        "cond_entropy-2": 2.122506901881547,
        "distinct-3": 0.9265327695560254,
        "vocab_size-3": 1753,
        "unique-3": 1673,
        "entropy-3": 10.691469668367324,
        "cond_entropy-3": 0.3531204226166766,
        "total_length-nopunct": 1938,
        "mean_pred_length-nopunct": 18.28301886792453,
        "std_pred_length-nopunct": 3.576006830069065,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.41589267285861714,
        "vocab_size-1-nopunct": 806,
        "unique-1-nopunct": 595,
        "entropy-1-nopunct": 8.159587316584942,
        "distinct-2-nopunct": 0.7991266375545851,
        "vocab_size-2-nopunct": 1464,
        "unique-2-nopunct": 1293,
        "entropy-2-nopunct": 10.251748314831335,
        "cond_entropy-2-nopunct": 2.1937598857704645,
        "distinct-3-nopunct": 0.9403244495944381,
        "vocab_size-3-nopunct": 1623,
        "unique-3-nopunct": 1555,
        "entropy-3-nopunct": 10.60877171512839,
        "cond_entropy-3-nopunct": 0.36616372357127036,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.70789,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3446528129751647
        },
        "rouge1": {
            "precision": 0.39857,
            "recall": 0.37342,
            "fmeasure": 0.37691
        },
        "rouge2": {
            "precision": 0.16032,
            "recall": 0.15204,
            "fmeasure": 0.1519
        },
        "rougeL": {
            "precision": 0.31328,
            "recall": 0.29559,
            "fmeasure": 0.29748
        },
        "rougeLsum": {
            "precision": 0.31328,
            "recall": 0.29559,
            "fmeasure": 0.29748
        },
        "nist": 3.2975557320035684,
        "bleu": 10.56888,
        "bertscore": {
            "precision": 0.82869,
            "recall": 0.81504,
            "f1": 0.82152
        },
        "bleurt": -0.42247,
        "meteor": 0.17044316543687132,
        "nubia": {
            "semantic_relation": 2.50138,
            "contradiction": 29.34993,
            "irrelevancy": 61.99109,
            "logical_agreement": 8.65899,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.81964,
            "nubia_score": 0.31028
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2038,
        "mean_pred_length": 19.22641509433962,
        "std_pred_length": 3.767495086117977,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 33,
        "distinct-1": 0.37438665358194306,
        "vocab_size-1": 763,
        "unique-1": 545,
        "entropy-1": 7.879680070699341,
        "distinct-2": 0.7644927536231884,
        "vocab_size-2": 1477,
        "unique-2": 1270,
        "entropy-2": 10.20169183583105,
        "cond_entropy-2": 2.1236917899535492,
        "distinct-3": 0.9184008762322016,
        "vocab_size-3": 1677,
        "unique-3": 1576,
        "entropy-3": 10.636187568629687,
        "cond_entropy-3": 0.45231754008163333,
        "total_length-nopunct": 1893,
        "mean_pred_length-nopunct": 17.858490566037737,
        "std_pred_length-nopunct": 3.606698901612406,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.3993660855784469,
        "vocab_size-1-nopunct": 756,
        "unique-1-nopunct": 545,
        "entropy-1-nopunct": 7.986384895550314,
        "distinct-2-nopunct": 0.7632904308897593,
        "vocab_size-2-nopunct": 1364,
        "unique-2-nopunct": 1175,
        "entropy-2-nopunct": 10.076589221125735,
        "cond_entropy-2-nopunct": 2.205207429934104,
        "distinct-3-nopunct": 0.9208804283164783,
        "vocab_size-3-nopunct": 1548,
        "unique-3-nopunct": 1457,
        "entropy-3-nopunct": 10.522539399493143,
        "cond_entropy-3-nopunct": 0.4729306530690484,
        "msttr-100": 0.666,
        "msttr-100_nopunct": 0.68611,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2547830144657023
        },
        "rouge1": {
            "precision": 0.32873,
            "recall": 0.27561,
            "fmeasure": 0.29295
        },
        "rouge2": {
            "precision": 0.09553,
            "recall": 0.08118,
            "fmeasure": 0.08547
        },
        "rougeL": {
            "precision": 0.25331,
            "recall": 0.21446,
            "fmeasure": 0.22673
        },
        "rougeLsum": {
            "precision": 0.25331,
            "recall": 0.21446,
            "fmeasure": 0.22673
        },
        "nist": 2.274256328763145,
        "bleu": 4.41168,
        "bertscore": {
            "precision": 0.81113,
            "recall": 0.78547,
            "f1": 0.79774
        },
        "bleurt": -0.53921,
        "meteor": 0.11977270564541533,
        "nubia": {
            "semantic_relation": 2.11043,
            "contradiction": 37.66556,
            "irrelevancy": 58.17722,
            "logical_agreement": 4.15722,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.73743,
            "nubia_score": 0.22634
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2105,
        "mean_pred_length": 19.858490566037737,
        "std_pred_length": 3.8348911554878975,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.3524940617577197,
        "vocab_size-1": 742,
        "unique-1": 514,
        "entropy-1": 7.7853447527243205,
        "distinct-2": 0.7413706853426714,
        "vocab_size-2": 1482,
        "unique-2": 1267,
        "entropy-2": 10.150122750211821,
        "cond_entropy-2": 2.1846658192782082,
        "distinct-3": 0.8991019545694665,
        "vocab_size-3": 1702,
        "unique-3": 1587,
        "entropy-3": 10.62926779848423,
        "cond_entropy-3": 0.5072825153690966,
        "total_length-nopunct": 1951,
        "mean_pred_length-nopunct": 18.40566037735849,
        "std_pred_length-nopunct": 3.530936862921721,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.37570476678626347,
        "vocab_size-1-nopunct": 733,
        "unique-1-nopunct": 511,
        "entropy-1-nopunct": 7.871304748323308,
        "distinct-2-nopunct": 0.7409214092140921,
        "vocab_size-2-nopunct": 1367,
        "unique-2-nopunct": 1168,
        "entropy-2-nopunct": 10.032287957530961,
        "cond_entropy-2-nopunct": 2.2799999873239023,
        "distinct-3-nopunct": 0.9056929269695227,
        "vocab_size-3-nopunct": 1575,
        "unique-3-nopunct": 1470,
        "entropy-3-nopunct": 10.535981431838197,
        "cond_entropy-3-nopunct": 0.5310219090793227,
        "msttr-100": 0.66333,
        "msttr-100_nopunct": 0.67684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2511520737327189
        },
        "rouge1": {
            "precision": 0.33177,
            "recall": 0.28579,
            "fmeasure": 0.30058
        },
        "rouge2": {
            "precision": 0.07881,
            "recall": 0.06967,
            "fmeasure": 0.07214
        },
        "rougeL": {
            "precision": 0.25759,
            "recall": 0.22225,
            "fmeasure": 0.23351
        },
        "rougeLsum": {
            "precision": 0.25759,
            "recall": 0.22225,
            "fmeasure": 0.23351
        },
        "nist": 2.2398765833688206,
        "bleu": 3.5626,
        "bertscore": {
            "precision": 0.80531,
            "recall": 0.78643,
            "f1": 0.79542
        },
        "bleurt": -0.57839,
        "meteor": 0.11354267682507486,
        "nubia": {
            "semantic_relation": 2.02944,
            "contradiction": 39.03464,
            "irrelevancy": 55.76895,
            "logical_agreement": 5.19641,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.77275,
            "nubia_score": 0.2246
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 453,
        "total_length": 6060,
        "mean_pred_length": 13.37748344370861,
        "std_pred_length": 6.540154511937226,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.15544554455445544,
        "vocab_size-1": 942,
        "unique-1": 468,
        "entropy-1": 7.190005166708642,
        "distinct-2": 0.41608703406456216,
        "vocab_size-2": 2333,
        "unique-2": 1522,
        "entropy-2": 10.254216001141424,
        "cond_entropy-2": 2.7815728315805504,
        "distinct-3": 0.6169965075669382,
        "vocab_size-3": 3180,
        "unique-3": 2413,
        "entropy-3": 11.18471841575477,
        "cond_entropy-3": 1.0457140566987793,
        "total_length-nopunct": 5236,
        "mean_pred_length-nopunct": 11.55849889624724,
        "std_pred_length-nopunct": 5.746618120402879,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.17838044308632545,
        "vocab_size-1-nopunct": 934,
        "unique-1-nopunct": 468,
        "entropy-1-nopunct": 7.433535883524225,
        "distinct-2-nopunct": 0.4064394731340163,
        "vocab_size-2-nopunct": 1944,
        "unique-2-nopunct": 1247,
        "entropy-2-nopunct": 9.984482961325154,
        "cond_entropy-2-nopunct": 2.850808407678671,
        "distinct-3-nopunct": 0.607852193995381,
        "vocab_size-3-nopunct": 2632,
        "unique-3-nopunct": 1982,
        "entropy-3-nopunct": 10.909247345578947,
        "cond_entropy-3-nopunct": 1.0711455132965142,
        "msttr-100": 0.50067,
        "msttr-100_nopunct": 0.52865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.235,
            "2": 0.577455919395466,
            "3": 0.7166138524219103,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.64945,
            "recall": 0.6767,
            "fmeasure": 0.65282
        },
        "rouge2": {
            "precision": 0.41146,
            "recall": 0.42757,
            "fmeasure": 0.41238
        },
        "rougeL": {
            "precision": 0.56741,
            "recall": 0.59458,
            "fmeasure": 0.57158
        },
        "rougeLsum": {
            "precision": 0.56741,
            "recall": 0.59458,
            "fmeasure": 0.57158
        },
        "nist": 6.4459688061949505,
        "bleu": 34.70553,
        "bertscore": {
            "precision": 0.8934,
            "recall": 0.89914,
            "f1": 0.89505
        },
        "bleurt": -0.09794,
        "meteor": 0.3490854488808873,
        "nubia": {
            "semantic_relation": 3.82358,
            "contradiction": 26.75254,
            "irrelevancy": 13.28866,
            "logical_agreement": 59.9588,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.16367,
            "nubia_score": 0.58959
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6020,
        "mean_pred_length": 12.04,
        "std_pred_length": 7.104815268534433,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 43,
        "distinct-1": 0.14883720930232558,
        "vocab_size-1": 896,
        "unique-1": 506,
        "entropy-1": 7.641992398227764,
        "distinct-2": 0.4152173913043478,
        "vocab_size-2": 2292,
        "unique-2": 1545,
        "entropy-2": 10.143163551221663,
        "cond_entropy-2": 2.2475059333991894,
        "distinct-3": 0.5896414342629482,
        "vocab_size-3": 2960,
        "unique-3": 2297,
        "entropy-3": 10.86917140437202,
        "cond_entropy-3": 0.7576804760563774,
        "total_length-nopunct": 5300,
        "mean_pred_length-nopunct": 10.6,
        "std_pred_length-nopunct": 6.545838372584523,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.1669811320754717,
        "vocab_size-1-nopunct": 885,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.809439502023525,
        "distinct-2-nopunct": 0.42520833333333335,
        "vocab_size-2-nopunct": 2041,
        "unique-2-nopunct": 1402,
        "entropy-2-nopunct": 9.953109531159598,
        "cond_entropy-2-nopunct": 2.28035134065288,
        "distinct-3-nopunct": 0.6048837209302326,
        "vocab_size-3-nopunct": 2601,
        "unique-3-nopunct": 2053,
        "entropy-3-nopunct": 10.690095711490276,
        "cond_entropy-3-nopunct": 0.7731762506219602,
        "msttr-100": 0.669,
        "msttr-100_nopunct": 0.69604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.551484060095273
        },
        "rouge1": {
            "precision": 0.57958,
            "recall": 0.54107,
            "fmeasure": 0.54876
        },
        "rouge2": {
            "precision": 0.35685,
            "recall": 0.33236,
            "fmeasure": 0.33748
        },
        "rougeL": {
            "precision": 0.5236,
            "recall": 0.48803,
            "fmeasure": 0.49564
        },
        "rougeLsum": {
            "precision": 0.5236,
            "recall": 0.48803,
            "fmeasure": 0.49564
        },
        "nist": 5.92433887631347,
        "bleu": 31.48436,
        "bertscore": {
            "precision": 0.87533,
            "recall": 0.86382,
            "f1": 0.86912
        },
        "bleurt": -0.072,
        "meteor": 0.3097196769564043,
        "nubia": {
            "semantic_relation": 3.53847,
            "contradiction": 10.32864,
            "irrelevancy": 20.9957,
            "logical_agreement": 68.67566,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.53207,
            "nubia_score": 0.62807
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2093,
        "mean_pred_length": 19.745283018867923,
        "std_pred_length": 5.572949019052383,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 54,
        "distinct-1": 0.3506927854753942,
        "vocab_size-1": 734,
        "unique-1": 516,
        "entropy-1": 7.762307127790886,
        "distinct-2": 0.7242073477604429,
        "vocab_size-2": 1439,
        "unique-2": 1244,
        "entropy-2": 10.054038547819534,
        "cond_entropy-2": 2.109043902336532,
        "distinct-3": 0.8729399255715046,
        "vocab_size-3": 1642,
        "unique-3": 1535,
        "entropy-3": 10.500711818519777,
        "cond_entropy-3": 0.47120067830184637,
        "total_length-nopunct": 1932,
        "mean_pred_length-nopunct": 18.22641509433962,
        "std_pred_length-nopunct": 4.419687982814232,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.37681159420289856,
        "vocab_size-1-nopunct": 728,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 7.87313813000512,
        "distinct-2-nopunct": 0.7289156626506024,
        "vocab_size-2-nopunct": 1331,
        "unique-2-nopunct": 1150,
        "entropy-2-nopunct": 9.953010125250758,
        "cond_entropy-2-nopunct": 2.1996521443768,
        "distinct-3-nopunct": 0.8848837209302326,
        "vocab_size-3-nopunct": 1522,
        "unique-3-nopunct": 1423,
        "entropy-3-nopunct": 10.425841036711208,
        "cond_entropy-3-nopunct": 0.493032174746301,
        "msttr-100": 0.651,
        "msttr-100_nopunct": 0.66316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2375586854460094
        },
        "rouge1": {
            "precision": 0.31788,
            "recall": 0.27373,
            "fmeasure": 0.28592
        },
        "rouge2": {
            "precision": 0.09047,
            "recall": 0.07415,
            "fmeasure": 0.07935
        },
        "rougeL": {
            "precision": 0.23592,
            "recall": 0.20343,
            "fmeasure": 0.21214
        },
        "rougeLsum": {
            "precision": 0.23592,
            "recall": 0.20343,
            "fmeasure": 0.21214
        },
        "nist": 2.1516384994590028,
        "bleu": 4.20847,
        "bertscore": {
            "precision": 0.80179,
            "recall": 0.77602,
            "f1": 0.78836
        },
        "bleurt": -0.58752,
        "meteor": 0.1119620095467431,
        "nubia": {
            "semantic_relation": 2.01652,
            "contradiction": 39.41744,
            "irrelevancy": 50.82855,
            "logical_agreement": 9.75401,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.76247,
            "nubia_score": 0.22086
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6581,
        "mean_pred_length": 13.162,
        "std_pred_length": 7.422382097413202,
        "median_pred_length": 11.0,
        "min_pred_length": 1,
        "max_pred_length": 43,
        "distinct-1": 0.14982525452058956,
        "vocab_size-1": 986,
        "unique-1": 567,
        "entropy-1": 7.775104884630541,
        "distinct-2": 0.4145699720440717,
        "vocab_size-2": 2521,
        "unique-2": 1706,
        "entropy-2": 10.323294114718342,
        "cond_entropy-2": 2.325653051707266,
        "distinct-3": 0.5970978144034397,
        "vocab_size-3": 3333,
        "unique-3": 2571,
        "entropy-3": 11.120740672809424,
        "cond_entropy-3": 0.8281743303313354,
        "total_length-nopunct": 5794,
        "mean_pred_length-nopunct": 11.588,
        "std_pred_length-nopunct": 6.761527638041569,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.16827752847773558,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 566,
        "entropy-1-nopunct": 7.946973243024335,
        "distinct-2-nopunct": 0.42916509255761237,
        "vocab_size-2-nopunct": 2272,
        "unique-2-nopunct": 1573,
        "entropy-2-nopunct": 10.166391735582833,
        "cond_entropy-2-nopunct": 2.356073854116636,
        "distinct-3-nopunct": 0.6148070907194995,
        "vocab_size-3-nopunct": 2948,
        "unique-3-nopunct": 2330,
        "entropy-3-nopunct": 10.947477469377992,
        "cond_entropy-3-nopunct": 0.8267078171837915,
        "msttr-100": 0.68108,
        "msttr-100_nopunct": 0.7107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.552714073585217
        },
        "rouge1": {
            "precision": 0.59071,
            "recall": 0.53924,
            "fmeasure": 0.55207
        },
        "rouge2": {
            "precision": 0.36594,
            "recall": 0.33197,
            "fmeasure": 0.34073
        },
        "rougeL": {
            "precision": 0.53022,
            "recall": 0.48188,
            "fmeasure": 0.4945
        },
        "rougeLsum": {
            "precision": 0.53022,
            "recall": 0.48188,
            "fmeasure": 0.4945
        },
        "nist": 6.142876717688282,
        "bleu": 31.06873,
        "bertscore": {
            "precision": 0.87862,
            "recall": 0.86247,
            "f1": 0.87005
        },
        "bleurt": -0.07306,
        "meteor": 0.31134120970542734,
        "nubia": {
            "semantic_relation": 3.58964,
            "contradiction": 10.55987,
            "irrelevancy": 20.67174,
            "logical_agreement": 68.76839,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.5261,
            "nubia_score": 0.64144
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "mT5_small/schema_guided_dialog_test",
        "N": 500,
        "total_length": 6499,
        "mean_pred_length": 12.998,
        "std_pred_length": 7.574826466659154,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 59,
        "distinct-1": 0.14125250038467457,
        "vocab_size-1": 918,
        "unique-1": 505,
        "entropy-1": 7.67038117507293,
        "distinct-2": 0.4067344557426238,
        "vocab_size-2": 2440,
        "unique-2": 1643,
        "entropy-2": 10.270343019555535,
        "cond_entropy-2": 2.3682319081265137,
        "distinct-3": 0.5926532096744863,
        "vocab_size-3": 3259,
        "unique-3": 2529,
        "entropy-3": 11.083953263378017,
        "cond_entropy-3": 0.8667600474742574,
        "total_length-nopunct": 5742,
        "mean_pred_length-nopunct": 11.484,
        "std_pred_length-nopunct": 7.003266666349354,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.1581330546847788,
        "vocab_size-1-nopunct": 908,
        "unique-1-nopunct": 503,
        "entropy-1-nopunct": 7.832442675987206,
        "distinct-2-nopunct": 0.41587180465471196,
        "vocab_size-2-nopunct": 2180,
        "unique-2-nopunct": 1486,
        "entropy-2-nopunct": 10.095889123297733,
        "cond_entropy-2-nopunct": 2.4200524302872766,
        "distinct-3-nopunct": 0.6033319274567693,
        "vocab_size-3-nopunct": 2861,
        "unique-3-nopunct": 2266,
        "entropy-3-nopunct": 10.88383547456708,
        "cond_entropy-3-nopunct": 0.8591675891997925,
        "msttr-100": 0.66828,
        "msttr-100_nopunct": 0.69018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5412149371880915
        },
        "rouge1": {
            "precision": 0.56204,
            "recall": 0.52389,
            "fmeasure": 0.53145
        },
        "rouge2": {
            "precision": 0.3379,
            "recall": 0.31337,
            "fmeasure": 0.31748
        },
        "rougeL": {
            "precision": 0.5032,
            "recall": 0.4676,
            "fmeasure": 0.47486
        },
        "rougeLsum": {
            "precision": 0.5032,
            "recall": 0.4676,
            "fmeasure": 0.47486
        },
        "nist": 5.824424813534434,
        "bleu": 29.16988,
        "bertscore": {
            "precision": 0.867,
            "recall": 0.85539,
            "f1": 0.8607
        },
        "bleurt": -0.15344,
        "meteor": 0.2969083322001667,
        "nubia": {
            "semantic_relation": 3.42532,
            "contradiction": 10.65055,
            "irrelevancy": 23.26499,
            "logical_agreement": 66.08446,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.50467,
            "nubia_score": 0.60288
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 500,
        "total_length": 9762,
        "mean_pred_length": 19.524,
        "std_pred_length": 4.407882031089307,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 54,
        "distinct-1": 0.239500102438025,
        "vocab_size-1": 2338,
        "unique-1": 1427,
        "entropy-1": 8.54488115223943,
        "distinct-2": 0.6290218095443748,
        "vocab_size-2": 5826,
        "unique-2": 4800,
        "entropy-2": 11.764810235299333,
        "cond_entropy-2": 2.99071630757371,
        "distinct-3": 0.8389637069162291,
        "vocab_size-3": 7351,
        "unique-3": 6712,
        "entropy-3": 12.617809418870614,
        "cond_entropy-3": 0.8863059494445341,
        "total_length-nopunct": 9024,
        "mean_pred_length-nopunct": 18.048,
        "std_pred_length-nopunct": 3.874751088779768,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.2580895390070922,
        "vocab_size-1-nopunct": 2329,
        "unique-1-nopunct": 1427,
        "entropy-1-nopunct": 8.714186721240877,
        "distinct-2-nopunct": 0.6325668700140779,
        "vocab_size-2-nopunct": 5392,
        "unique-2-nopunct": 4450,
        "entropy-2-nopunct": 11.65780812391985,
        "cond_entropy-2-nopunct": 3.0974254051871632,
        "distinct-3-nopunct": 0.8505732801595214,
        "vocab_size-3-nopunct": 6825,
        "unique-3-nopunct": 6247,
        "entropy-3-nopunct": 12.546849908659798,
        "cond_entropy-3-nopunct": 0.9193172029889535,
        "msttr-100": 0.66701,
        "msttr-100_nopunct": 0.68667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2806024461740625
        },
        "rouge1": {
            "precision": 0.36018,
            "recall": 0.3063,
            "fmeasure": 0.32381
        },
        "rouge2": {
            "precision": 0.11621,
            "recall": 0.09804,
            "fmeasure": 0.10377
        },
        "rougeL": {
            "precision": 0.27909,
            "recall": 0.23847,
            "fmeasure": 0.25143
        },
        "rougeLsum": {
            "precision": 0.27909,
            "recall": 0.23847,
            "fmeasure": 0.25143
        },
        "nist": 2.816545218486924,
        "bleu": 6.31844,
        "bertscore": {
            "precision": 0.81723,
            "recall": 0.79429,
            "f1": 0.8053
        },
        "bleurt": -0.50129,
        "meteor": 0.1320633817867563,
        "nubia": {
            "semantic_relation": 2.25083,
            "contradiction": 33.33461,
            "irrelevancy": 58.6799,
            "logical_agreement": 7.98549,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.75958,
            "nubia_score": 0.26591
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 1973,
        "mean_pred_length": 18.61320754716981,
        "std_pred_length": 3.8986469707075546,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.37252914343639126,
        "vocab_size-1": 735,
        "unique-1": 526,
        "entropy-1": 7.769203992420871,
        "distinct-2": 0.7509373326191752,
        "vocab_size-2": 1402,
        "unique-2": 1216,
        "entropy-2": 10.060489744431793,
        "cond_entropy-2": 2.0896785662245425,
        "distinct-3": 0.9068710959681999,
        "vocab_size-3": 1597,
        "unique-3": 1493,
        "entropy-3": 10.550953061777564,
        "cond_entropy-3": 0.5104366751422484,
        "total_length-nopunct": 1824,
        "mean_pred_length-nopunct": 17.20754716981132,
        "std_pred_length-nopunct": 3.517388024077803,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3985745614035088,
        "vocab_size-1-nopunct": 727,
        "unique-1-nopunct": 525,
        "entropy-1-nopunct": 7.873241567399316,
        "distinct-2-nopunct": 0.7537834691501746,
        "vocab_size-2-nopunct": 1295,
        "unique-2-nopunct": 1126,
        "entropy-2-nopunct": 9.940391304622711,
        "cond_entropy-2-nopunct": 2.1886166620623615,
        "distinct-3-nopunct": 0.913151364764268,
        "vocab_size-3-nopunct": 1472,
        "unique-3-nopunct": 1380,
        "entropy-3-nopunct": 10.441927929258412,
        "cond_entropy-3-nopunct": 0.5319537301879925,
        "msttr-100": 0.64895,
        "msttr-100_nopunct": 0.66667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.22130350194552528
        },
        "rouge1": {
            "precision": 0.30374,
            "recall": 0.25376,
            "fmeasure": 0.2694
        },
        "rouge2": {
            "precision": 0.08688,
            "recall": 0.07054,
            "fmeasure": 0.07624
        },
        "rougeL": {
            "precision": 0.24107,
            "recall": 0.20186,
            "fmeasure": 0.21417
        },
        "rougeLsum": {
            "precision": 0.24107,
            "recall": 0.20186,
            "fmeasure": 0.21417
        },
        "nist": 1.9637543225547798,
        "bleu": 4.75943,
        "bertscore": {
            "precision": 0.80142,
            "recall": 0.77679,
            "f1": 0.7886
        },
        "bleurt": -0.60339,
        "meteor": 0.10647870492884608,
        "nubia": {
            "semantic_relation": 1.96428,
            "contradiction": 39.55259,
            "irrelevancy": 52.66099,
            "logical_agreement": 7.78642,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.83971,
            "nubia_score": 0.22386
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 5,
        "total_length": 44,
        "mean_pred_length": 8.8,
        "std_pred_length": 0.7483314773547883,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.4318181818181818,
        "vocab_size-1": 19,
        "unique-1": 5,
        "entropy-1": 4.073210744553411,
        "distinct-2": 0.5641025641025641,
        "vocab_size-2": 22,
        "unique-2": 9,
        "entropy-2": 4.3361829878711236,
        "cond_entropy-2": 0.14300977911213772,
        "distinct-3": 0.6470588235294118,
        "vocab_size-3": 22,
        "unique-3": 12,
        "entropy-3": 4.337175341123076,
        "cond_entropy-3": -0.05808974519533622,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 7.8,
        "std_pred_length-nopunct": 0.7483314773547882,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.46153846153846156,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 4.019143808983936,
        "distinct-2-nopunct": 0.5882352941176471,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 4.1973257087065035,
        "cond_entropy-2-nopunct": 0.16572320993515824,
        "distinct-3-nopunct": 0.6896551724137931,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 4.211260736432281,
        "cond_entropy-3-nopunct": -0.0655202081171303,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.65397,
            "recall": 0.48477,
            "fmeasure": 0.50424
        },
        "rouge2": {
            "precision": 0.37381,
            "recall": 0.21818,
            "fmeasure": 0.24768
        },
        "rougeL": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "rougeLsum": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "nist": 1.1584778190719272,
        "bleu": 12.15204,
        "bertscore": {
            "precision": 0.89285,
            "recall": 0.82928,
            "f1": 0.85844
        },
        "bleurt": -0.39693,
        "meteor": 0.22250577795179702,
        "nubia": {
            "semantic_relation": 2.89259,
            "contradiction": 18.10595,
            "irrelevancy": 42.12701,
            "logical_agreement": 39.76705,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.71656,
            "nubia_score": 0.31537
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 120,
        "total_length": 1547,
        "mean_pred_length": 12.891666666666667,
        "std_pred_length": 3.919599965415972,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.049773755656108594,
        "vocab_size-1": 77,
        "unique-1": 6,
        "entropy-1": 4.9835713887956,
        "distinct-2": 0.07988787666433077,
        "vocab_size-2": 114,
        "unique-2": 11,
        "entropy-2": 5.896018336774494,
        "cond_entropy-2": 0.7627092047307868,
        "distinct-3": 0.11400153022188217,
        "vocab_size-3": 149,
        "unique-3": 28,
        "entropy-3": 6.371160877813296,
        "cond_entropy-3": 0.5310849916798362,
        "total_length-nopunct": 1379,
        "mean_pred_length-nopunct": 11.491666666666667,
        "std_pred_length-nopunct": 3.485675050195522,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.05511240029006526,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 5.034650354053485,
        "distinct-2-nopunct": 0.0857823669579031,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 5.722431773857013,
        "cond_entropy-2-nopunct": 0.7838100257194816,
        "distinct-3-nopunct": 0.12554872695346794,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 6.269314473086348,
        "cond_entropy-3-nopunct": 0.5722951607036576,
        "msttr-100": 0.222,
        "msttr-100_nopunct": 0.23231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.620253164556962
        },
        "rouge1": {
            "precision": 0.72743,
            "recall": 0.64743,
            "fmeasure": 0.65946
        },
        "rouge2": {
            "precision": 0.47934,
            "recall": 0.42526,
            "fmeasure": 0.43121
        },
        "rougeL": {
            "precision": 0.61483,
            "recall": 0.54876,
            "fmeasure": 0.55761
        },
        "rougeLsum": {
            "precision": 0.61483,
            "recall": 0.54876,
            "fmeasure": 0.55761
        },
        "nist": 4.514417802599446,
        "bleu": 28.77698,
        "bertscore": {
            "precision": 0.92358,
            "recall": 0.88884,
            "f1": 0.90531
        },
        "bleurt": 0.04391,
        "meteor": 0.32137983900117834,
        "nubia": {
            "semantic_relation": 4.21411,
            "contradiction": 4.10366,
            "irrelevancy": 14.23953,
            "logical_agreement": 81.65682,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.84003,
            "nubia_score": 0.76041
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 389,
        "total_length": 6170,
        "mean_pred_length": 15.861182519280206,
        "std_pred_length": 4.004657910105368,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.016693679092382497,
        "vocab_size-1": 103,
        "unique-1": 7,
        "entropy-1": 5.511605680063387,
        "distinct-2": 0.036152914720636566,
        "vocab_size-2": 209,
        "unique-2": 29,
        "entropy-2": 6.684063685374865,
        "cond_entropy-2": 1.0273440417941893,
        "distinct-3": 0.05879080118694362,
        "vocab_size-3": 317,
        "unique-3": 60,
        "entropy-3": 7.350037924825958,
        "cond_entropy-3": 0.6947570364141825,
        "total_length-nopunct": 5565,
        "mean_pred_length-nopunct": 14.305912596401027,
        "std_pred_length-nopunct": 3.615375762622332,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.018149146451033243,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 5.594208316865428,
        "distinct-2-nopunct": 0.03767387944358578,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 6.603744354380248,
        "cond_entropy-2-nopunct": 1.0614708533295678,
        "distinct-3-nopunct": 0.06371422602882808,
        "vocab_size-3-nopunct": 305,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 7.328562518407228,
        "cond_entropy-3-nopunct": 0.7246186946210681,
        "msttr-100": 0.23967,
        "msttr-100_nopunct": 0.24291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6545779801593755
        },
        "rouge1": {
            "precision": 0.78398,
            "recall": 0.67582,
            "fmeasure": 0.7107
        },
        "rouge2": {
            "precision": 0.51583,
            "recall": 0.44125,
            "fmeasure": 0.46496
        },
        "rougeL": {
            "precision": 0.62617,
            "recall": 0.5353,
            "fmeasure": 0.56539
        },
        "rougeLsum": {
            "precision": 0.62617,
            "recall": 0.5353,
            "fmeasure": 0.56539
        },
        "nist": 4.94351766997163,
        "bleu": 32.65833,
        "bertscore": {
            "precision": 0.93361,
            "recall": 0.9036,
            "f1": 0.91799
        },
        "bleurt": 0.21133,
        "meteor": 0.35260333547350164,
        "nubia": {
            "semantic_relation": 4.32662,
            "contradiction": 1.48321,
            "irrelevancy": 6.1391,
            "logical_agreement": 92.37769,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.89867,
            "nubia_score": 0.79538
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 500,
        "total_length": 9809,
        "mean_pred_length": 19.618,
        "std_pred_length": 4.26052531972291,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 54,
        "distinct-1": 0.23458048730757466,
        "vocab_size-1": 2301,
        "unique-1": 1450,
        "entropy-1": 8.510961589058256,
        "distinct-2": 0.616822429906542,
        "vocab_size-2": 5742,
        "unique-2": 4719,
        "entropy-2": 11.691164596235879,
        "cond_entropy-2": 2.95545919541583,
        "distinct-3": 0.8224543080939948,
        "vocab_size-3": 7245,
        "unique-3": 6619,
        "entropy-3": 12.542242664159199,
        "cond_entropy-3": 0.8823725217746099,
        "total_length-nopunct": 9103,
        "mean_pred_length-nopunct": 18.206,
        "std_pred_length-nopunct": 3.776713386001114,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.25167527188838845,
        "vocab_size-1-nopunct": 2291,
        "unique-1-nopunct": 1448,
        "entropy-1-nopunct": 8.667312104106674,
        "distinct-2-nopunct": 0.6187376496570963,
        "vocab_size-2-nopunct": 5323,
        "unique-2-nopunct": 4377,
        "entropy-2-nopunct": 11.581806020774746,
        "cond_entropy-2-nopunct": 3.060033173035135,
        "distinct-3-nopunct": 0.8309268172281871,
        "vocab_size-3-nopunct": 6733,
        "unique-3-nopunct": 6162,
        "entropy-3-nopunct": 12.466495584727298,
        "cond_entropy-3-nopunct": 0.9180469899097001,
        "msttr-100": 0.66806,
        "msttr-100_nopunct": 0.68659,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2743660855784469
        },
        "rouge1": {
            "precision": 0.35431,
            "recall": 0.30496,
            "fmeasure": 0.32103
        },
        "rouge2": {
            "precision": 0.10805,
            "recall": 0.09431,
            "fmeasure": 0.09846
        },
        "rougeL": {
            "precision": 0.2739,
            "recall": 0.23691,
            "fmeasure": 0.24889
        },
        "rougeLsum": {
            "precision": 0.2739,
            "recall": 0.23691,
            "fmeasure": 0.24889
        },
        "nist": 2.704330155082425,
        "bleu": 5.5851,
        "bertscore": {
            "precision": 0.81592,
            "recall": 0.79281,
            "f1": 0.80391
        },
        "bleurt": -0.50057,
        "meteor": 0.12929825951797683,
        "nubia": {
            "semantic_relation": 2.22198,
            "contradiction": 33.73557,
            "irrelevancy": 58.01965,
            "logical_agreement": 8.24477,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.71305,
            "nubia_score": 0.25858
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 414,
        "total_length": 9836,
        "mean_pred_length": 23.758454106280194,
        "std_pred_length": 11.026959213412852,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 96,
        "distinct-1": 0.12128914192761285,
        "vocab_size-1": 1193,
        "unique-1": 445,
        "entropy-1": 7.609836158732133,
        "distinct-2": 0.3381447675652728,
        "vocab_size-2": 3186,
        "unique-2": 1733,
        "entropy-2": 10.613871677686216,
        "cond_entropy-2": 2.855712720431208,
        "distinct-3": 0.5314165186500888,
        "vocab_size-3": 4787,
        "unique-3": 3192,
        "entropy-3": 11.700122398432379,
        "cond_entropy-3": 1.1497188460548151,
        "total_length-nopunct": 8693,
        "mean_pred_length-nopunct": 20.997584541062803,
        "std_pred_length-nopunct": 10.157812440966213,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 92,
        "distinct-1-nopunct": 0.1362015414701484,
        "vocab_size-1-nopunct": 1184,
        "unique-1-nopunct": 444,
        "entropy-1-nopunct": 7.827984653196403,
        "distinct-2-nopunct": 0.348230462616258,
        "vocab_size-2-nopunct": 2883,
        "unique-2-nopunct": 1626,
        "entropy-2-nopunct": 10.478365284284314,
        "cond_entropy-2-nopunct": 2.800241771457342,
        "distinct-3-nopunct": 0.5416401780038144,
        "vocab_size-3-nopunct": 4260,
        "unique-3-nopunct": 2907,
        "entropy-3-nopunct": 11.537059773809967,
        "cond_entropy-3-nopunct": 1.118100049588603,
        "msttr-100": 0.48806,
        "msttr-100_nopunct": 0.49605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22421142369991476,
            "2": 0.5554997488699146,
            "3": 0.7449681528662421,
            "4": 0.7272727272727273,
            "5": 0.75
        },
        "rouge1": {
            "precision": 0.62494,
            "recall": 0.68251,
            "fmeasure": 0.64293
        },
        "rouge2": {
            "precision": 0.39636,
            "recall": 0.43335,
            "fmeasure": 0.40752
        },
        "rougeL": {
            "precision": 0.51126,
            "recall": 0.56151,
            "fmeasure": 0.52672
        },
        "rougeLsum": {
            "precision": 0.51126,
            "recall": 0.56151,
            "fmeasure": 0.52672
        },
        "nist": 6.521001719790722,
        "bleu": 34.05028,
        "bertscore": {
            "precision": 0.88337,
            "recall": 0.89206,
            "f1": 0.88618
        },
        "bleurt": -0.09527,
        "meteor": 0.33505855459832895,
        "nubia": {
            "semantic_relation": 3.85171,
            "contradiction": 26.15673,
            "irrelevancy": 15.22657,
            "logical_agreement": 58.6167,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.51484,
            "nubia_score": 0.62247
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 737,
        "total_length": 14372,
        "mean_pred_length": 19.50067842605156,
        "std_pred_length": 3.3760770753906453,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.00772335096020039,
        "vocab_size-1": 111,
        "unique-1": 6,
        "entropy-1": 5.5495661898702675,
        "distinct-2": 0.02060872753942061,
        "vocab_size-2": 281,
        "unique-2": 28,
        "entropy-2": 6.827962647149137,
        "cond_entropy-2": 1.1675712627829815,
        "distinct-3": 0.03682741510311676,
        "vocab_size-3": 475,
        "unique-3": 56,
        "entropy-3": 7.545518394930173,
        "cond_entropy-3": 0.742528435071936,
        "total_length-nopunct": 13078,
        "mean_pred_length-nopunct": 17.7449118046133,
        "std_pred_length-nopunct": 3.1094994774662186,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.008334607738186266,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 5.606138311334365,
        "distinct-2-nopunct": 0.02147313831942306,
        "vocab_size-2-nopunct": 265,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 6.770055668733451,
        "cond_entropy-2-nopunct": 1.2059274321488018,
        "distinct-3-nopunct": 0.04024474319200276,
        "vocab_size-3-nopunct": 467,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 7.5328633100279765,
        "cond_entropy-3-nopunct": 0.7656783895419683,
        "msttr-100": 0.24853,
        "msttr-100_nopunct": 0.24323,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.697461159530125
        },
        "rouge1": {
            "precision": 0.77471,
            "recall": 0.71163,
            "fmeasure": 0.73084
        },
        "rouge2": {
            "precision": 0.49422,
            "recall": 0.45394,
            "fmeasure": 0.46593
        },
        "rougeL": {
            "precision": 0.60221,
            "recall": 0.55479,
            "fmeasure": 0.5692
        },
        "rougeLsum": {
            "precision": 0.60221,
            "recall": 0.55479,
            "fmeasure": 0.5692
        },
        "nist": 5.239049249786767,
        "bleu": 33.91882,
        "bertscore": {
            "precision": 0.93025,
            "recall": 0.90834,
            "f1": 0.91881
        },
        "bleurt": 0.26136,
        "meteor": 0.3672438944077349,
        "nubia": {
            "semantic_relation": 4.33256,
            "contradiction": 2.07356,
            "irrelevancy": 12.77369,
            "logical_agreement": 85.15274,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.53044,
            "nubia_score": 0.80255
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "mT5_small/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "total_length": 14529,
        "mean_pred_length": 29.058,
        "std_pred_length": 15.185342801530693,
        "median_pred_length": 29.0,
        "min_pred_length": 5,
        "max_pred_length": 100,
        "distinct-1": 0.1272627159474155,
        "vocab_size-1": 1849,
        "unique-1": 878,
        "entropy-1": 8.042641697854705,
        "distinct-2": 0.40979399814669615,
        "vocab_size-2": 5749,
        "unique-2": 3849,
        "entropy-2": 11.455087468560679,
        "cond_entropy-2": 3.2769152086398337,
        "distinct-3": 0.6609505506689334,
        "vocab_size-3": 8942,
        "unique-3": 7194,
        "entropy-3": 12.686597242469364,
        "cond_entropy-3": 1.2710336913316194,
        "total_length-nopunct": 12927,
        "mean_pred_length-nopunct": 25.854,
        "std_pred_length-nopunct": 13.810310785786104,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 95,
        "distinct-1-nopunct": 0.14226038524019494,
        "vocab_size-1-nopunct": 1839,
        "unique-1-nopunct": 878,
        "entropy-1-nopunct": 8.280852650893987,
        "distinct-2-nopunct": 0.42793916472197635,
        "vocab_size-2-nopunct": 5318,
        "unique-2-nopunct": 3673,
        "entropy-2-nopunct": 11.355808583890525,
        "cond_entropy-2-nopunct": 3.192441718782709,
        "distinct-3-nopunct": 0.6739330929823091,
        "vocab_size-3-nopunct": 8038,
        "unique-3-nopunct": 6573,
        "entropy-3-nopunct": 12.535181640251661,
        "cond_entropy-3-nopunct": 1.2178485280761593,
        "msttr-100": 0.62503,
        "msttr-100_nopunct": 0.65581,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "local_recall": {
            "1": 0.22809951913025298,
            "2": 0.5184038527691779,
            "3": 0.713568739917548,
            "4": 0.5555555555555556,
            "5": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.57509,
            "recall": 0.63136,
            "fmeasure": 0.59153
        },
        "rouge2": {
            "precision": 0.331,
            "recall": 0.36095,
            "fmeasure": 0.33906
        },
        "rougeL": {
            "precision": 0.44447,
            "recall": 0.49187,
            "fmeasure": 0.45843
        },
        "rougeLsum": {
            "precision": 0.44447,
            "recall": 0.49187,
            "fmeasure": 0.45843
        },
        "nist": 6.233028729087647,
        "bleu": 30.79019,
        "bertscore": {
            "precision": 0.86335,
            "recall": 0.87314,
            "f1": 0.86664
        },
        "bleurt": -0.33917,
        "meteor": 0.30585013589166743,
        "nubia": {
            "semantic_relation": 3.33314,
            "contradiction": 40.2802,
            "irrelevancy": 16.2244,
            "logical_agreement": 43.4954,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.7621,
            "nubia_score": 0.48138
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 382,
        "total_length": 12304,
        "mean_pred_length": 32.20942408376963,
        "std_pred_length": 10.272624892470741,
        "median_pred_length": 31.0,
        "min_pred_length": 10,
        "max_pred_length": 94,
        "distinct-1": 0.09647269180754227,
        "vocab_size-1": 1187,
        "unique-1": 355,
        "entropy-1": 7.630194942684068,
        "distinct-2": 0.2823351786612984,
        "vocab_size-2": 3366,
        "unique-2": 1663,
        "entropy-2": 10.586832234963339,
        "cond_entropy-2": 2.8443064397608984,
        "distinct-3": 0.4606585788561525,
        "vocab_size-3": 5316,
        "unique-3": 3357,
        "entropy-3": 11.724139823901325,
        "cond_entropy-3": 1.1835202530122062,
        "total_length-nopunct": 11002,
        "mean_pred_length-nopunct": 28.801047120418847,
        "std_pred_length-nopunct": 9.397125490804422,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 87,
        "distinct-1-nopunct": 0.1071623341210689,
        "vocab_size-1-nopunct": 1179,
        "unique-1-nopunct": 355,
        "entropy-1-nopunct": 7.822210817085513,
        "distinct-2-nopunct": 0.29538606403013185,
        "vocab_size-2-nopunct": 3137,
        "unique-2-nopunct": 1625,
        "entropy-2-nopunct": 10.500489947706383,
        "cond_entropy-2-nopunct": 2.7871529520202505,
        "distinct-3-nopunct": 0.47597186950576287,
        "vocab_size-3-nopunct": 4873,
        "unique-3-nopunct": 3177,
        "entropy-3-nopunct": 11.608988910232608,
        "cond_entropy-3-nopunct": 1.14805744023421,
        "msttr-100": 0.46244,
        "msttr-100_nopunct": 0.47155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22830141755782143,
            "2": 0.5594618055555556,
            "3": 0.7618122977346279,
            "4": 0.5,
            "5": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.586,
            "recall": 0.68468,
            "fmeasure": 0.62025
        },
        "rouge2": {
            "precision": 0.35833,
            "recall": 0.41832,
            "fmeasure": 0.37853
        },
        "rougeL": {
            "precision": 0.45726,
            "recall": 0.53819,
            "fmeasure": 0.48496
        },
        "rougeLsum": {
            "precision": 0.45726,
            "recall": 0.53819,
            "fmeasure": 0.48496
        },
        "nist": 6.393959274173323,
        "bleu": 33.77034,
        "bertscore": {
            "precision": 0.87725,
            "recall": 0.88573,
            "f1": 0.88
        },
        "bleurt": -0.15631,
        "meteor": 0.331863686851939,
        "nubia": {
            "semantic_relation": 3.78248,
            "contradiction": 29.52125,
            "irrelevancy": 15.16331,
            "logical_agreement": 55.31544,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.20156,
            "nubia_score": 0.59871
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 1187,
        "total_length": 26083,
        "mean_pred_length": 21.973883740522325,
        "std_pred_length": 4.6641357276449416,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.004255645439558333,
        "vocab_size-1": 111,
        "unique-1": 2,
        "entropy-1": 5.5390261263361875,
        "distinct-2": 0.013897814910025707,
        "vocab_size-2": 346,
        "unique-2": 40,
        "entropy-2": 6.76328500210715,
        "cond_entropy-2": 1.1359289119789104,
        "distinct-3": 0.026445653549285082,
        "vocab_size-3": 627,
        "unique-3": 100,
        "entropy-3": 7.452951886868268,
        "cond_entropy-3": 0.7284051796272608,
        "total_length-nopunct": 24051,
        "mean_pred_length-nopunct": 20.2620050547599,
        "std_pred_length-nopunct": 4.232254336836078,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.004532036089975469,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 5.5764405325774735,
        "distinct-2-nopunct": 0.014214485654303709,
        "vocab_size-2-nopunct": 325,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 6.693796534872205,
        "cond_entropy-2-nopunct": 1.1673555581475938,
        "distinct-3-nopunct": 0.028048161645984223,
        "vocab_size-3-nopunct": 608,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 7.41172426627436,
        "cond_entropy-3-nopunct": 0.7556247026947543,
        "msttr-100": 0.26646,
        "msttr-100_nopunct": 0.25842,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7022360719248747
        },
        "rouge1": {
            "precision": 0.76833,
            "recall": 0.70942,
            "fmeasure": 0.72565
        },
        "rouge2": {
            "precision": 0.45354,
            "recall": 0.41496,
            "fmeasure": 0.42595
        },
        "rougeL": {
            "precision": 0.55117,
            "recall": 0.50765,
            "fmeasure": 0.51984
        },
        "rougeLsum": {
            "precision": 0.55117,
            "recall": 0.50765,
            "fmeasure": 0.51984
        },
        "nist": 4.982100210465613,
        "bleu": 30.41211,
        "bertscore": {
            "precision": 0.91983,
            "recall": 0.90369,
            "f1": 0.91125
        },
        "bleurt": 0.1912,
        "meteor": 0.3579673282947002,
        "nubia": {
            "semantic_relation": 4.20979,
            "contradiction": 1.88764,
            "irrelevancy": 18.33492,
            "logical_agreement": 79.77743,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.5149,
            "nubia_score": 0.77081
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 1406,
        "total_length": 37599,
        "mean_pred_length": 26.741820768136556,
        "std_pred_length": 4.100556890573054,
        "median_pred_length": 27.0,
        "min_pred_length": 17,
        "max_pred_length": 43,
        "distinct-1": 0.0027394345594297723,
        "vocab_size-1": 103,
        "unique-1": 5,
        "entropy-1": 5.543765875628762,
        "distinct-2": 0.009062525902798884,
        "vocab_size-2": 328,
        "unique-2": 32,
        "entropy-2": 6.914401352520347,
        "cond_entropy-2": 1.2988382631300044,
        "distinct-3": 0.017707764394745164,
        "vocab_size-3": 616,
        "unique-3": 80,
        "entropy-3": 7.654196077246703,
        "cond_entropy-3": 0.7855900143890724,
        "total_length-nopunct": 34605,
        "mean_pred_length-nopunct": 24.612375533428164,
        "std_pred_length-nopunct": 3.950236741894292,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.0029186533737899146,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 5.570718496642696,
        "distinct-2-nopunct": 0.009458116208319527,
        "vocab_size-2-nopunct": 314,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 6.846344375296668,
        "cond_entropy-2-nopunct": 1.3209717915785817,
        "distinct-3-nopunct": 0.019123706476268362,
        "vocab_size-3-nopunct": 608,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 7.629790745545837,
        "cond_entropy-3-nopunct": 0.807536065853487,
        "msttr-100": 0.28392,
        "msttr-100_nopunct": 0.27795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7043956377775753
        },
        "rouge1": {
            "precision": 0.77971,
            "recall": 0.72295,
            "fmeasure": 0.74187
        },
        "rouge2": {
            "precision": 0.47838,
            "recall": 0.44222,
            "fmeasure": 0.45423
        },
        "rougeL": {
            "precision": 0.53511,
            "recall": 0.4969,
            "fmeasure": 0.50954
        },
        "rougeLsum": {
            "precision": 0.53511,
            "recall": 0.4969,
            "fmeasure": 0.50954
        },
        "nist": 5.189101313829292,
        "bleu": 31.97214,
        "bertscore": {
            "precision": 0.92517,
            "recall": 0.9071,
            "f1": 0.91581
        },
        "bleurt": 0.26509,
        "meteor": 0.3664179439930425,
        "nubia": {
            "semantic_relation": 4.40539,
            "contradiction": 2.18086,
            "irrelevancy": 10.4825,
            "logical_agreement": 87.33665,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.29181,
            "nubia_score": 0.82483
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 500,
        "total_length": 9692,
        "mean_pred_length": 19.384,
        "std_pred_length": 3.9990678913966944,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 38,
        "distinct-1": 0.2401981015270326,
        "vocab_size-1": 2328,
        "unique-1": 1433,
        "entropy-1": 8.531093051019024,
        "distinct-2": 0.6269582245430809,
        "vocab_size-2": 5763,
        "unique-2": 4700,
        "entropy-2": 11.735660698205546,
        "cond_entropy-2": 2.9731545354449507,
        "distinct-3": 0.8335250805338242,
        "vocab_size-3": 7245,
        "unique-3": 6603,
        "entropy-3": 12.578520909488715,
        "cond_entropy-3": 0.8716201896296708,
        "total_length-nopunct": 9013,
        "mean_pred_length-nopunct": 18.026,
        "std_pred_length-nopunct": 3.753574829412623,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.25718406745811606,
        "vocab_size-1-nopunct": 2318,
        "unique-1-nopunct": 1431,
        "entropy-1-nopunct": 8.68156008885659,
        "distinct-2-nopunct": 0.6276283331375543,
        "vocab_size-2-nopunct": 5343,
        "unique-2-nopunct": 4356,
        "entropy-2-nopunct": 11.62079088319406,
        "cond_entropy-2-nopunct": 3.0870455570511197,
        "distinct-3-nopunct": 0.8400099837763634,
        "vocab_size-3-nopunct": 6731,
        "unique-3-nopunct": 6140,
        "entropy-3-nopunct": 12.491415289625612,
        "cond_entropy-3-nopunct": 0.9035270265497646,
        "msttr-100": 0.67083,
        "msttr-100_nopunct": 0.68867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.27578653922739943
        },
        "rouge1": {
            "precision": 0.35744,
            "recall": 0.30429,
            "fmeasure": 0.32186
        },
        "rouge2": {
            "precision": 0.11501,
            "recall": 0.09717,
            "fmeasure": 0.10299
        },
        "rougeL": {
            "precision": 0.27727,
            "recall": 0.23618,
            "fmeasure": 0.24981
        },
        "rougeLsum": {
            "precision": 0.27727,
            "recall": 0.23618,
            "fmeasure": 0.24981
        },
        "nist": 2.742519797532074,
        "bleu": 6.07934,
        "bertscore": {
            "precision": 0.81837,
            "recall": 0.79344,
            "f1": 0.80541
        },
        "bleurt": -0.50319,
        "meteor": 0.13175889544722474,
        "nubia": {
            "semantic_relation": 2.21878,
            "contradiction": 35.01282,
            "irrelevancy": 56.2354,
            "logical_agreement": 8.75179,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.81163,
            "nubia_score": 0.2581
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 500,
        "total_length": 9747,
        "mean_pred_length": 19.494,
        "std_pred_length": 5.204417738806138,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 85,
        "distinct-1": 0.23915050784856878,
        "vocab_size-1": 2331,
        "unique-1": 1437,
        "entropy-1": 8.507626525694919,
        "distinct-2": 0.6191197145020007,
        "vocab_size-2": 5725,
        "unique-2": 4699,
        "entropy-2": 11.694942082171162,
        "cond_entropy-2": 2.960191467857397,
        "distinct-3": 0.8238253115353835,
        "vocab_size-3": 7206,
        "unique-3": 6549,
        "entropy-3": 12.542693559395154,
        "cond_entropy-3": 0.8796854883972073,
        "total_length-nopunct": 9021,
        "mean_pred_length-nopunct": 18.042,
        "std_pred_length-nopunct": 4.0214718698506395,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.25739940139674095,
        "vocab_size-1-nopunct": 2322,
        "unique-1-nopunct": 1435,
        "entropy-1-nopunct": 8.676965929838234,
        "distinct-2-nopunct": 0.6238704377420491,
        "vocab_size-2-nopunct": 5316,
        "unique-2-nopunct": 4375,
        "entropy-2-nopunct": 11.591977257052092,
        "cond_entropy-2-nopunct": 3.0645118001090883,
        "distinct-3-nopunct": 0.8368033910983668,
        "vocab_size-3-nopunct": 6712,
        "unique-3-nopunct": 6118,
        "entropy-3-nopunct": 12.47971409324782,
        "cond_entropy-3-nopunct": 0.9185471827742974,
        "msttr-100": 0.66155,
        "msttr-100_nopunct": 0.684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2810365608678184
        },
        "rouge1": {
            "precision": 0.36148,
            "recall": 0.30845,
            "fmeasure": 0.32538
        },
        "rouge2": {
            "precision": 0.11817,
            "recall": 0.09965,
            "fmeasure": 0.10565
        },
        "rougeL": {
            "precision": 0.28191,
            "recall": 0.24059,
            "fmeasure": 0.25383
        },
        "rougeLsum": {
            "precision": 0.28191,
            "recall": 0.24059,
            "fmeasure": 0.25383
        },
        "nist": 2.8196682075880073,
        "bleu": 6.38446,
        "bertscore": {
            "precision": 0.81783,
            "recall": 0.79357,
            "f1": 0.8052
        },
        "bleurt": -0.50412,
        "meteor": 0.13314704214610992,
        "nubia": {
            "semantic_relation": 2.25324,
            "contradiction": 34.73903,
            "irrelevancy": 56.34481,
            "logical_agreement": 8.91616,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.74714,
            "nubia_score": 0.26607
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 609,
        "total_length": 6653,
        "mean_pred_length": 10.924466338259442,
        "std_pred_length": 2.5815199795586166,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.06748835111979558,
        "vocab_size-1": 449,
        "unique-1": 184,
        "entropy-1": 6.431164442798519,
        "distinct-2": 0.17637326273990733,
        "vocab_size-2": 1066,
        "unique-2": 590,
        "entropy-2": 8.240692884782886,
        "cond_entropy-2": 1.506724178137482,
        "distinct-3": 0.27856485740570375,
        "vocab_size-3": 1514,
        "unique-3": 942,
        "entropy-3": 9.04050419644837,
        "cond_entropy-3": 0.991243791754107,
        "total_length-nopunct": 5752,
        "mean_pred_length-nopunct": 9.444991789819376,
        "std_pred_length-nopunct": 2.3837184544075947,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.07753824756606398,
        "vocab_size-1-nopunct": 446,
        "unique-1-nopunct": 184,
        "entropy-1-nopunct": 6.6093357989339365,
        "distinct-2-nopunct": 0.160412210771923,
        "vocab_size-2-nopunct": 825,
        "unique-2-nopunct": 444,
        "entropy-2-nopunct": 7.93811956905495,
        "cond_entropy-2-nopunct": 1.6841160785374456,
        "distinct-3-nopunct": 0.26290251433612705,
        "vocab_size-3-nopunct": 1192,
        "unique-3-nopunct": 695,
        "entropy-3-nopunct": 8.760317549476241,
        "cond_entropy-3-nopunct": 1.1482093039891452,
        "msttr-100": 0.52667,
        "msttr-100_nopunct": 0.56035,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4757677969110598
        },
        "rouge1": {
            "precision": 0.49291,
            "recall": 0.5168,
            "fmeasure": 0.49159
        },
        "rouge2": {
            "precision": 0.27893,
            "recall": 0.29811,
            "fmeasure": 0.27928
        },
        "rougeL": {
            "precision": 0.44204,
            "recall": 0.46284,
            "fmeasure": 0.4408
        },
        "rougeLsum": {
            "precision": 0.44204,
            "recall": 0.46284,
            "fmeasure": 0.4408
        },
        "nist": 4.043175729228336,
        "bleu": 18.60939,
        "bertscore": {
            "precision": 0.89724,
            "recall": 0.90521,
            "f1": 0.90098
        },
        "bleurt": -0.136,
        "meteor": 0.24036616502811176,
        "nubia": {
            "semantic_relation": 3.51873,
            "contradiction": 22.16403,
            "irrelevancy": 29.60505,
            "logical_agreement": 48.23092,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.85031,
            "nubia_score": 0.52483
        }
    },
    "common_gen_val": {
        "predictions_file": "mT5_small/common_gen_val",
        "N": 993,
        "total_length": 10873,
        "mean_pred_length": 10.949647532729104,
        "std_pred_length": 3.9716369011223764,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 85,
        "distinct-1": 0.12278120114043962,
        "vocab_size-1": 1335,
        "unique-1": 651,
        "entropy-1": 7.0322348976722955,
        "distinct-2": 0.4012145748987854,
        "vocab_size-2": 3964,
        "unique-2": 2746,
        "entropy-2": 10.60054387952164,
        "cond_entropy-2": 3.343895872392792,
        "distinct-3": 0.6695172724203894,
        "vocab_size-3": 5950,
        "unique-3": 4940,
        "entropy-3": 11.98167542237799,
        "cond_entropy-3": 1.4808054313184211,
        "total_length-nopunct": 10021,
        "mean_pred_length-nopunct": 10.091641490433032,
        "std_pred_length-nopunct": 3.8939440450463922,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.1330206566210957,
        "vocab_size-1-nopunct": 1333,
        "unique-1-nopunct": 651,
        "entropy-1-nopunct": 7.189774564463771,
        "distinct-2-nopunct": 0.3967656180770935,
        "vocab_size-2-nopunct": 3582,
        "unique-2-nopunct": 2514,
        "entropy-2-nopunct": 10.387067564780612,
        "cond_entropy-2-nopunct": 3.5558556874129703,
        "distinct-3-nopunct": 0.675295581829496,
        "vocab_size-3-nopunct": 5426,
        "unique-3-nopunct": 4553,
        "entropy-3-nopunct": 11.83298785790584,
        "cond_entropy-3-nopunct": 1.567961279449344,
        "msttr-100": 0.55065,
        "msttr-100_nopunct": 0.5753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_val.json",
        "local_recall": {
            "1": 0.09492563429571303,
            "2": 0.28297872340425534,
            "3": 0.43409806567701303,
            "4": 0.6742829363150219,
            "5": 0.6394849785407726,
            "6": 0.7023809523809523,
            "7": 0.5,
            "8": 0.8
        },
        "rouge1": {
            "precision": 0.58249,
            "recall": 0.55612,
            "fmeasure": 0.55598
        },
        "rouge2": {
            "precision": 0.25814,
            "recall": 0.24165,
            "fmeasure": 0.2424
        },
        "rougeL": {
            "precision": 0.50233,
            "recall": 0.4807,
            "fmeasure": 0.4798
        },
        "rougeLsum": {
            "precision": 0.50233,
            "recall": 0.4807,
            "fmeasure": 0.4798
        },
        "nist": 5.719412923673205,
        "bleu": 18.9457,
        "bertscore": {
            "precision": 0.86813,
            "recall": 0.86567,
            "f1": 0.86564
        },
        "bleurt": -0.64078,
        "meteor": 0.22746252212822768,
        "nubia": {
            "semantic_relation": 2.78015,
            "contradiction": 36.30229,
            "irrelevancy": 28.59957,
            "logical_agreement": 35.09814,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.88255,
            "nubia_score": 0.34482
        }
    },
    "common_gen_test": {
        "predictions_file": "mT5_small/common_gen_test",
        "N": 1497
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 22,
        "total_length": 227,
        "mean_pred_length": 10.318181818181818,
        "std_pred_length": 1.6064179133702083,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 12,
        "distinct-1": 0.09691629955947137,
        "vocab_size-1": 22,
        "unique-1": 0,
        "entropy-1": 4.227151138460092,
        "distinct-2": 0.14146341463414633,
        "vocab_size-2": 29,
        "unique-2": 0,
        "entropy-2": 4.7157385629631285,
        "cond_entropy-2": 0.39629106384088086,
        "distinct-3": 0.15300546448087432,
        "vocab_size-3": 28,
        "unique-3": 0,
        "entropy-3": 4.660108053958994,
        "cond_entropy-3": -0.04981986246581155,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 7.863636363636363,
        "std_pred_length-nopunct": 1.2896600871919188,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.11560693641618497,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.2036704092865715,
        "distinct-2-nopunct": 0.1456953642384106,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.342450540541372,
        "cond_entropy-2-nopunct": 0.18475434659444248,
        "distinct-3-nopunct": 0.14728682170542637,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.118590677679673,
        "cond_entropy-3-nopunct": -0.18954373993071358,
        "msttr-100": 0.215,
        "msttr-100_nopunct": 0.2,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.2342857142857143
        },
        "rouge1": {
            "precision": 0.35189,
            "recall": 0.36807,
            "fmeasure": 0.35683
        },
        "rouge2": {
            "precision": 0.1939,
            "recall": 0.18648,
            "fmeasure": 0.18898
        },
        "rougeL": {
            "precision": 0.31616,
            "recall": 0.32621,
            "fmeasure": 0.31855
        },
        "rougeLsum": {
            "precision": 0.31616,
            "recall": 0.32621,
            "fmeasure": 0.31855
        },
        "nist": 1.7137407255862112,
        "bleu": 16.18635,
        "bertscore": {
            "precision": 0.88288,
            "recall": 0.89237,
            "f1": 0.88755
        },
        "bleurt": -0.32209,
        "meteor": 0.14073354115791967,
        "nubia": {
            "semantic_relation": 2.45046,
            "contradiction": 36.09198,
            "irrelevancy": 26.95882,
            "logical_agreement": 36.9492,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.9217,
            "nubia_score": 0.30971
        }
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "mT5_small/common_gen_challenge_test_scramble",
        "N": 500
    },
    "dart_val": {
        "predictions_file": "mT5_small/dart_val",
        "N": 2768
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 16,
        "total_length": 251,
        "mean_pred_length": 15.6875,
        "std_pred_length": 1.9273929931386593,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.24302788844621515,
        "vocab_size-1": 61,
        "unique-1": 23,
        "entropy-1": 5.207236312020539,
        "distinct-2": 0.37872340425531914,
        "vocab_size-2": 89,
        "unique-2": 41,
        "entropy-2": 5.891526610503943,
        "cond_entropy-2": 0.6001580255935477,
        "distinct-3": 0.4885844748858447,
        "vocab_size-3": 107,
        "unique-3": 55,
        "entropy-3": 6.35166334422595,
        "cond_entropy-3": 0.44404373309110245,
        "total_length-nopunct": 218,
        "mean_pred_length-nopunct": 13.625,
        "std_pred_length-nopunct": 1.964529205687714,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.26605504587155965,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 5.172582867325142,
        "distinct-2-nopunct": 0.40594059405940597,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.8404465497854305,
        "cond_entropy-2-nopunct": 0.6783710857321527,
        "distinct-3-nopunct": 0.521505376344086,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 6.236041170505729,
        "cond_entropy-3-nopunct": 0.3486165216335573,
        "msttr-100": 0.395,
        "msttr-100_nopunct": 0.43,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.44129554655870445
        },
        "rouge1": {
            "precision": 0.58891,
            "recall": 0.51744,
            "fmeasure": 0.53496
        },
        "rouge2": {
            "precision": 0.36058,
            "recall": 0.3245,
            "fmeasure": 0.32969
        },
        "rougeL": {
            "precision": 0.49795,
            "recall": 0.44239,
            "fmeasure": 0.45479
        },
        "rougeLsum": {
            "precision": 0.49795,
            "recall": 0.44239,
            "fmeasure": 0.45479
        },
        "nist": 3.147519114764514,
        "bleu": 17.76753,
        "bertscore": {
            "precision": 0.91785,
            "recall": 0.91253,
            "f1": 0.91501
        },
        "bleurt": -0.01955,
        "meteor": 0.23382745116977463,
        "nubia": {
            "semantic_relation": 3.28744,
            "contradiction": 38.22796,
            "irrelevancy": 27.77867,
            "logical_agreement": 33.99337,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.29439,
            "nubia_score": 0.45698
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 34,
        "total_length": 350,
        "mean_pred_length": 10.294117647058824,
        "std_pred_length": 2.87514103761175,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.19142857142857142,
        "vocab_size-1": 67,
        "unique-1": 23,
        "entropy-1": 5.090786943377317,
        "distinct-2": 0.3259493670886076,
        "vocab_size-2": 103,
        "unique-2": 42,
        "entropy-2": 6.070047907028428,
        "cond_entropy-2": 0.7934403469579375,
        "distinct-3": 0.44680851063829785,
        "vocab_size-3": 126,
        "unique-3": 62,
        "entropy-3": 6.550725438356557,
        "cond_entropy-3": 0.35418691425262916,
        "total_length-nopunct": 306,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.43745286530596,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.21241830065359477,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 5.087598818483934,
        "distinct-2-nopunct": 0.3492647058823529,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 6.024287631093449,
        "cond_entropy-2-nopunct": 0.8620381255561649,
        "distinct-3-nopunct": 0.4789915966386555,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 6.437538894510916,
        "cond_entropy-3-nopunct": 0.38195104273483726,
        "msttr-100": 0.38,
        "msttr-100_nopunct": 0.41,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.417910447761194
        },
        "rouge1": {
            "precision": 0.54505,
            "recall": 0.50471,
            "fmeasure": 0.51519
        },
        "rouge2": {
            "precision": 0.31429,
            "recall": 0.29794,
            "fmeasure": 0.30128
        },
        "rougeL": {
            "precision": 0.4915,
            "recall": 0.45335,
            "fmeasure": 0.46399
        },
        "rougeLsum": {
            "precision": 0.4915,
            "recall": 0.45335,
            "fmeasure": 0.46399
        },
        "nist": 3.0347038316750314,
        "bleu": 20.92192,
        "bertscore": {
            "precision": 0.91999,
            "recall": 0.91508,
            "f1": 0.91743
        },
        "bleurt": -0.07693,
        "meteor": 0.2305305476572036,
        "nubia": {
            "semantic_relation": 3.30002,
            "contradiction": 25.30387,
            "irrelevancy": 18.72515,
            "logical_agreement": 55.97097,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.60832,
            "nubia_score": 0.45315
        }
    },
    "dart_test": {
        "predictions_file": "mT5_small/dart_test",
        "N": 6959
    },
    "totto_val": {
        "predictions_file": "mT5_small/totto_val",
        "N": 7700,
        "total_length": 124089,
        "mean_pred_length": 16.115454545454547,
        "std_pred_length": 6.774190524403702,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 112,
        "distinct-1": 0.17128834949109106,
        "vocab_size-1": 21255,
        "unique-1": 14551,
        "entropy-1": 10.004270759392192,
        "distinct-2": 0.526355583431424,
        "vocab_size-2": 61262,
        "unique-2": 50859,
        "entropy-2": 14.436205517149919,
        "cond_entropy-2": 4.034543535046248,
        "distinct-3": 0.7536641242444038,
        "vocab_size-3": 81915,
        "unique-3": 74043,
        "entropy-3": 15.744998420411967,
        "cond_entropy-3": 1.2906316409192824,
        "total_length-nopunct": 107526,
        "mean_pred_length-nopunct": 13.964415584415585,
        "std_pred_length-nopunct": 5.749717665232528,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 100,
        "distinct-1-nopunct": 0.19747781931811842,
        "vocab_size-1-nopunct": 21234,
        "unique-1-nopunct": 14550,
        "entropy-1-nopunct": 10.58348701095593,
        "distinct-2-nopunct": 0.5728167010598442,
        "vocab_size-2-nopunct": 57182,
        "unique-2-nopunct": 48641,
        "entropy-2-nopunct": 14.4363310128863,
        "cond_entropy-2-nopunct": 4.027699536023565,
        "distinct-3-nopunct": 0.7815057638451686,
        "vocab_size-3-nopunct": 71997,
        "unique-3-nopunct": 65963,
        "entropy-3-nopunct": 15.61892923907492,
        "cond_entropy-3-nopunct": 1.271302267134129,
        "msttr-100": 0.70843,
        "msttr-100_nopunct": 0.76248,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_val.json",
        "local_recall": {
            "1": 0.21914264597191427,
            "2": 0.42764718568039684,
            "3": 0.7432430739158219
        },
        "rouge1": {
            "precision": 0.74309,
            "recall": 0.70562,
            "fmeasure": 0.71174
        },
        "rouge2": {
            "precision": 0.51089,
            "recall": 0.48646,
            "fmeasure": 0.48984
        },
        "rougeL": {
            "precision": 0.64277,
            "recall": 0.61304,
            "fmeasure": 0.61673
        },
        "rougeLsum": {
            "precision": 0.64277,
            "recall": 0.61304,
            "fmeasure": 0.61673
        },
        "nist": 10.294772912973778,
        "bleu": 43.73212,
        "bertscore": {
            "precision": 0.92355,
            "recall": 0.91627,
            "f1": 0.91831
        },
        "bleurt": 0.23013,
        "meteor": 0.3773847417839333,
        "nubia": {
            "semantic_relation": 4.08564,
            "contradiction": 11.31975,
            "irrelevancy": 29.39916,
            "logical_agreement": 59.28109,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.66637,
            "nubia_score": 0.69516
        }
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "mT5_small/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "total_length": 12963,
        "mean_pred_length": 25.926,
        "std_pred_length": 7.050710886144744,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 45,
        "distinct-1": 0.027694206587981177,
        "vocab_size-1": 359,
        "unique-1": 123,
        "entropy-1": 6.2521572524841735,
        "distinct-2": 0.142261092834791,
        "vocab_size-2": 1773,
        "unique-2": 984,
        "entropy-2": 8.753207995425855,
        "cond_entropy-2": 2.4110797469419447,
        "distinct-3": 0.30661205383265067,
        "vocab_size-3": 3668,
        "unique-3": 2477,
        "entropy-3": 10.313205706602862,
        "cond_entropy-3": 1.570548475636937,
        "total_length-nopunct": 11792,
        "mean_pred_length-nopunct": 23.584,
        "std_pred_length-nopunct": 6.406164531137176,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.030189959294436908,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.314568227981331,
        "distinct-2-nopunct": 0.15497697484945094,
        "vocab_size-2-nopunct": 1750,
        "unique-2-nopunct": 1010,
        "entropy-2-nopunct": 8.715004760634459,
        "cond_entropy-2-nopunct": 2.441452714104835,
        "distinct-3-nopunct": 0.3244996293550778,
        "vocab_size-3-nopunct": 3502,
        "unique-3-nopunct": 2410,
        "entropy-3-nopunct": 10.314420048613654,
        "cond_entropy-3-nopunct": 1.591882245738212,
        "msttr-100": 0.52868,
        "msttr-100_nopunct": 0.53821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.6454012833627825
        },
        "rouge1": {
            "precision": 0.67705,
            "recall": 0.6626,
            "fmeasure": 0.65767
        },
        "rouge2": {
            "precision": 0.3743,
            "recall": 0.36583,
            "fmeasure": 0.36289
        },
        "rougeL": {
            "precision": 0.4573,
            "recall": 0.44863,
            "fmeasure": 0.44459
        },
        "rougeLsum": {
            "precision": 0.4573,
            "recall": 0.44863,
            "fmeasure": 0.44459
        },
        "nist": 4.600115522745824,
        "bleu": 25.04195,
        "bertscore": {
            "precision": 0.89713,
            "recall": 0.89283,
            "f1": 0.8946
        },
        "bleurt": 0.00524,
        "meteor": 0.3310291964524261,
        "nubia": {
            "semantic_relation": 3.99889,
            "contradiction": 8.13083,
            "irrelevancy": 32.47139,
            "logical_agreement": 59.39778,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.66817,
            "nubia_score": 0.67346
        }
    },
    "web_nlg_en_val": {
        "predictions_file": "mT5_small/web_nlg_en_val",
        "N": 1667,
        "total_length": 37031,
        "mean_pred_length": 22.214157168566288,
        "std_pred_length": 11.463736043963852,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 68,
        "distinct-1": 0.09178796143771435,
        "vocab_size-1": 3399,
        "unique-1": 1047,
        "entropy-1": 8.672616474617337,
        "distinct-2": 0.27643931681936434,
        "vocab_size-2": 9776,
        "unique-2": 4650,
        "entropy-2": 11.960478733671396,
        "cond_entropy-2": 3.059464778674669,
        "distinct-3": 0.44297711962489245,
        "vocab_size-3": 14927,
        "unique-3": 8931,
        "entropy-3": 13.100770972595784,
        "cond_entropy-3": 1.1918655773038187,
        "total_length-nopunct": 33003,
        "mean_pred_length-nopunct": 19.797840431913617,
        "std_pred_length-nopunct": 10.426791440293847,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.10268763445747356,
        "vocab_size-1-nopunct": 3389,
        "unique-1-nopunct": 1045,
        "entropy-1-nopunct": 9.021554555800874,
        "distinct-2-nopunct": 0.2875287209599183,
        "vocab_size-2-nopunct": 9010,
        "unique-2-nopunct": 4423,
        "entropy-2-nopunct": 11.863547459604368,
        "cond_entropy-2-nopunct": 2.982997996244885,
        "distinct-3-nopunct": 0.45667194715022413,
        "vocab_size-3-nopunct": 13549,
        "unique-3-nopunct": 8333,
        "entropy-3-nopunct": 12.974234716044762,
        "cond_entropy-3-nopunct": 1.16307377692792,
        "msttr-100": 0.53008,
        "msttr-100_nopunct": 0.55552,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_val.json",
        "local_recall": {
            "1": 0.31837254608122284,
            "2": 0.7525862068965518,
            "3": 0.9536895674300254,
            "4": 0.9787234042553191,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "rouge1": {
            "precision": 0.83297,
            "recall": 0.83183,
            "fmeasure": 0.82639
        },
        "rouge2": {
            "precision": 0.63396,
            "recall": 0.63439,
            "fmeasure": 0.62935
        },
        "rougeL": {
            "precision": 0.70817,
            "recall": 0.70968,
            "fmeasure": 0.70354
        },
        "rougeLsum": {
            "precision": 0.70817,
            "recall": 0.70968,
            "fmeasure": 0.70354
        },
        "nist": 11.600088492621753,
        "bleu": 65.44194,
        "bertscore": {
            "precision": 0.95841,
            "recall": 0.95511,
            "f1": 0.95597
        },
        "bleurt": 0.45701,
        "meteor": 0.46597919501756674,
        "nubia": {
            "semantic_relation": 4.76122,
            "contradiction": 2.92893,
            "irrelevancy": 3.77713,
            "logical_agreement": 93.29394,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.45521,
            "nubia_score": 0.90185
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 1779,
        "total_length": 50179,
        "mean_pred_length": 28.206295671725687,
        "std_pred_length": 14.987558818240835,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.04025588393551087,
        "vocab_size-1": 2020,
        "unique-1": 565,
        "entropy-1": 7.780406276749123,
        "distinct-2": 0.1459504132231405,
        "vocab_size-2": 7064,
        "unique-2": 3024,
        "entropy-2": 11.081781842989859,
        "cond_entropy-2": 3.165909589866434,
        "distinct-3": 0.28146114411960277,
        "vocab_size-3": 13122,
        "unique-3": 7207,
        "entropy-3": 12.510443383973696,
        "cond_entropy-3": 1.4951182732192432,
        "total_length-nopunct": 44594,
        "mean_pred_length-nopunct": 25.06689151208544,
        "std_pred_length-nopunct": 13.689913732545275,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.045095752791855404,
        "vocab_size-1-nopunct": 2011,
        "unique-1-nopunct": 565,
        "entropy-1-nopunct": 8.004983785270145,
        "distinct-2-nopunct": 0.15704776363424033,
        "vocab_size-2-nopunct": 6724,
        "unique-2-nopunct": 3060,
        "entropy-2-nopunct": 11.006089402299523,
        "cond_entropy-2-nopunct": 3.1427273653995105,
        "distinct-3-nopunct": 0.2972999317672288,
        "vocab_size-3-nopunct": 12200,
        "unique-3-nopunct": 6972,
        "entropy-3-nopunct": 12.410672817269491,
        "cond_entropy-3-nopunct": 1.4722145871892152,
        "msttr-100": 0.58395,
        "msttr-100_nopunct": 0.61497,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22554363417293016,
            "2": 0.5472467709041469,
            "3": 0.7432820512820513,
            "4": 0.8909090909090909,
            "5": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.61972,
            "recall": 0.66866,
            "fmeasure": 0.63291
        },
        "rouge2": {
            "precision": 0.37925,
            "recall": 0.40744,
            "fmeasure": 0.3861
        },
        "rougeL": {
            "precision": 0.49325,
            "recall": 0.53609,
            "fmeasure": 0.50495
        },
        "rougeLsum": {
            "precision": 0.49325,
            "recall": 0.53609,
            "fmeasure": 0.50495
        },
        "nist": 6.927941957703085,
        "bleu": 35.14103,
        "bertscore": {
            "precision": 0.88129,
            "recall": 0.88609,
            "f1": 0.88228
        },
        "bleurt": -0.1536,
        "meteor": 0.32381396909479776,
        "nubia": {
            "semantic_relation": 3.74826,
            "contradiction": 29.10695,
            "irrelevancy": 14.18284,
            "logical_agreement": 56.71021,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.49272,
            "nubia_score": 0.5933
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "mT5_small/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "total_length": 14263,
        "mean_pred_length": 28.526,
        "std_pred_length": 15.818638500199693,
        "median_pred_length": 27.0,
        "min_pred_length": 6,
        "max_pred_length": 98,
        "distinct-1": 0.13096823950080627,
        "vocab_size-1": 1868,
        "unique-1": 901,
        "entropy-1": 8.060510033941446,
        "distinct-2": 0.41509845237230253,
        "vocab_size-2": 5713,
        "unique-2": 3906,
        "entropy-2": 11.443745914227645,
        "cond_entropy-2": 3.2416152809072507,
        "distinct-3": 0.6603332579356104,
        "vocab_size-3": 8758,
        "unique-3": 7057,
        "entropy-3": 12.6585795612068,
        "cond_entropy-3": 1.250065192610431,
        "total_length-nopunct": 12703,
        "mean_pred_length-nopunct": 25.406,
        "std_pred_length-nopunct": 14.359009854443308,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 90,
        "distinct-1-nopunct": 0.14602849720538455,
        "vocab_size-1-nopunct": 1855,
        "unique-1-nopunct": 898,
        "entropy-1-nopunct": 8.300727880085413,
        "distinct-2-nopunct": 0.43399164139965585,
        "vocab_size-2-nopunct": 5296,
        "unique-2-nopunct": 3730,
        "entropy-2-nopunct": 11.361502545098876,
        "cond_entropy-2-nopunct": 3.1720629099811624,
        "distinct-3-nopunct": 0.6748696915320858,
        "vocab_size-3-nopunct": 7898,
        "unique-3-nopunct": 6496,
        "entropy-3-nopunct": 12.515222058045886,
        "cond_entropy-3-nopunct": 1.1947521926807148,
        "msttr-100": 0.54296,
        "msttr-100_nopunct": 0.55591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.21624827040917177,
            "2": 0.5171360705802511,
            "3": 0.706058339566193,
            "4": 0.2,
            "5": 0.5
        },
        "rouge1": {
            "precision": 0.56779,
            "recall": 0.62284,
            "fmeasure": 0.58335
        },
        "rouge2": {
            "precision": 0.32371,
            "recall": 0.3527,
            "fmeasure": 0.33108
        },
        "rougeL": {
            "precision": 0.44456,
            "recall": 0.48881,
            "fmeasure": 0.4571
        },
        "rougeLsum": {
            "precision": 0.44456,
            "recall": 0.48881,
            "fmeasure": 0.4571
        },
        "nist": 6.169651565667698,
        "bleu": 29.53648,
        "bertscore": {
            "precision": 0.86179,
            "recall": 0.86938,
            "f1": 0.86423
        },
        "bleurt": -0.33667,
        "meteor": 0.2971915058092586,
        "nubia": {
            "semantic_relation": 3.37309,
            "contradiction": 38.13701,
            "irrelevancy": 15.02423,
            "logical_agreement": 46.83876,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.86607,
            "nubia_score": 0.49891
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 12,
        "total_length": 85,
        "mean_pred_length": 7.083333333333333,
        "std_pred_length": 2.0190069065976197,
        "median_pred_length": 7.5,
        "min_pred_length": 5,
        "max_pred_length": 11,
        "distinct-1": 0.3764705882352941,
        "vocab_size-1": 32,
        "unique-1": 15,
        "entropy-1": 4.518000865896428,
        "distinct-2": 0.6164383561643836,
        "vocab_size-2": 45,
        "unique-2": 30,
        "entropy-2": 5.269844894550273,
        "cond_entropy-2": 0.47344856062975305,
        "distinct-3": 0.6721311475409836,
        "vocab_size-3": 41,
        "unique-3": 30,
        "entropy-3": 5.163622788063358,
        "cond_entropy-3": -0.08114045127986316,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 5.833333333333333,
        "std_pred_length-nopunct": 1.7240134054647667,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.515087038949381,
        "distinct-2-nopunct": 0.5862068965517241,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.86403719354577,
        "cond_entropy-2-nopunct": 0.432753201693286,
        "distinct-3-nopunct": 0.6521739130434783,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.713035597032136,
        "cond_entropy-3-nopunct": -0.19240110695347276,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.2926829268292683
        },
        "rouge1": {
            "precision": 0.47161,
            "recall": 0.37876,
            "fmeasure": 0.40901
        },
        "rouge2": {
            "precision": 0.34028,
            "recall": 0.26651,
            "fmeasure": 0.28957
        },
        "rougeL": {
            "precision": 0.47161,
            "recall": 0.37876,
            "fmeasure": 0.40901
        },
        "rougeLsum": {
            "precision": 0.47161,
            "recall": 0.37876,
            "fmeasure": 0.40901
        },
        "nist": 1.9594159951928163,
        "bleu": 19.9043,
        "bertscore": {
            "precision": 0.88386,
            "recall": 0.88224,
            "f1": 0.88293
        },
        "bleurt": -0.24345,
        "meteor": 0.1624568886644167,
        "nubia": {
            "semantic_relation": 2.73932,
            "contradiction": 29.75535,
            "irrelevancy": 23.97246,
            "logical_agreement": 46.27219,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.64253,
            "nubia_score": 0.23843
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 183,
        "total_length": 1951,
        "mean_pred_length": 10.66120218579235,
        "std_pred_length": 1.234730862732118,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 12,
        "distinct-1": 0.01998974884674526,
        "vocab_size-1": 39,
        "unique-1": 7,
        "entropy-1": 3.8090749433846436,
        "distinct-2": 0.035633484162895926,
        "vocab_size-2": 63,
        "unique-2": 19,
        "entropy-2": 4.155937267612588,
        "cond_entropy-2": 0.3060002543252769,
        "distinct-3": 0.039116719242902206,
        "vocab_size-3": 62,
        "unique-3": 20,
        "entropy-3": 4.0469112341719375,
        "cond_entropy-3": -0.09733101459366916,
        "total_length-nopunct": 1435,
        "mean_pred_length-nopunct": 7.841530054644808,
        "std_pred_length-nopunct": 0.8245030680391722,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.02578397212543554,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.7082880257678856,
        "distinct-2-nopunct": 0.037539936102236424,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7062569259135185,
        "cond_entropy-2-nopunct": 0.026739832018289538,
        "distinct-3-nopunct": 0.0411599625818522,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.5236873908705415,
        "cond_entropy-3-nopunct": -0.16223873130591696,
        "msttr-100": 0.16895,
        "msttr-100_nopunct": 0.16929,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.09571286141575275
        },
        "rouge1": {
            "precision": 0.11812,
            "recall": 0.16082,
            "fmeasure": 0.12876
        },
        "rouge2": {
            "precision": 0.05865,
            "recall": 0.07457,
            "fmeasure": 0.06026
        },
        "rougeL": {
            "precision": 0.11343,
            "recall": 0.1554,
            "fmeasure": 0.12377
        },
        "rougeLsum": {
            "precision": 0.11343,
            "recall": 0.1554,
            "fmeasure": 0.12377
        },
        "nist": 0.6939953947963458,
        "bleu": 3.55185,
        "bertscore": {
            "precision": 0.82058,
            "recall": 0.8575,
            "f1": 0.83851
        },
        "bleurt": -0.76329,
        "meteor": 0.061661673567153664,
        "nubia": {
            "semantic_relation": 1.31053,
            "contradiction": 51.47201,
            "irrelevancy": 34.40913,
            "logical_agreement": 14.11887,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.62819,
            "nubia_score": 0.11731
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 267,
        "total_length": 2562,
        "mean_pred_length": 9.595505617977528,
        "std_pred_length": 2.3609769186224723,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 16,
        "distinct-1": 0.11475409836065574,
        "vocab_size-1": 294,
        "unique-1": 154,
        "entropy-1": 5.8889114088985535,
        "distinct-2": 0.257516339869281,
        "vocab_size-2": 591,
        "unique-2": 366,
        "entropy-2": 7.5369690820834,
        "cond_entropy-2": 1.3399890373652041,
        "distinct-3": 0.34566074950690334,
        "vocab_size-3": 701,
        "unique-3": 471,
        "entropy-3": 8.051600565905204,
        "cond_entropy-3": 0.8732732256729792,
        "total_length-nopunct": 2259,
        "mean_pred_length-nopunct": 8.460674157303371,
        "std_pred_length-nopunct": 2.238860965293831,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.12881806108897742,
        "vocab_size-1-nopunct": 291,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.004676666862583,
        "distinct-2-nopunct": 0.20481927710843373,
        "vocab_size-2-nopunct": 408,
        "unique-2-nopunct": 239,
        "entropy-2-nopunct": 6.9658996175295655,
        "cond_entropy-2-nopunct": 1.4848707381762298,
        "distinct-3-nopunct": 0.2811594202898551,
        "vocab_size-3-nopunct": 485,
        "unique-3-nopunct": 296,
        "entropy-3-nopunct": 7.448366174900178,
        "cond_entropy-3-nopunct": 1.0121214716381899,
        "msttr-100": 0.4392,
        "msttr-100_nopunct": 0.45545,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4850597609561753
        },
        "rouge1": {
            "precision": 0.44213,
            "recall": 0.52,
            "fmeasure": 0.46806
        },
        "rouge2": {
            "precision": 0.22971,
            "recall": 0.28066,
            "fmeasure": 0.24644
        },
        "rougeL": {
            "precision": 0.38823,
            "recall": 0.45346,
            "fmeasure": 0.40975
        },
        "rougeLsum": {
            "precision": 0.38823,
            "recall": 0.45346,
            "fmeasure": 0.40975
        },
        "nist": 3.2658827535020825,
        "bleu": 14.568,
        "bertscore": {
            "precision": 0.88884,
            "recall": 0.90508,
            "f1": 0.89669
        },
        "bleurt": -0.14882,
        "meteor": 0.24167197469275103,
        "nubia": {
            "semantic_relation": 3.49835,
            "contradiction": 23.89083,
            "irrelevancy": 30.11909,
            "logical_agreement": 45.99008,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.11351,
            "nubia_score": 0.51977
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 297,
        "total_length": 3368,
        "mean_pred_length": 11.34006734006734,
        "std_pred_length": 2.0942869206254966,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.0745249406175772,
        "vocab_size-1": 251,
        "unique-1": 104,
        "entropy-1": 6.244212928752912,
        "distinct-2": 0.17225659394334092,
        "vocab_size-2": 529,
        "unique-2": 267,
        "entropy-2": 7.632697982631592,
        "cond_entropy-2": 1.1210843538565662,
        "distinct-3": 0.26820475847152125,
        "vocab_size-3": 744,
        "unique-3": 403,
        "entropy-3": 8.311553211045956,
        "cond_entropy-3": 0.7163114161445958,
        "total_length-nopunct": 2853,
        "mean_pred_length-nopunct": 9.606060606060606,
        "std_pred_length-nopunct": 1.9770646974430877,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.08692604276200491,
        "vocab_size-1-nopunct": 248,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.435102883188974,
        "distinct-2-nopunct": 0.17449139280125195,
        "vocab_size-2-nopunct": 446,
        "unique-2-nopunct": 201,
        "entropy-2-nopunct": 7.547447352693491,
        "cond_entropy-2-nopunct": 1.246018316395344,
        "distinct-3-nopunct": 0.281983178397521,
        "vocab_size-3-nopunct": 637,
        "unique-3-nopunct": 329,
        "entropy-3-nopunct": 8.211910556834164,
        "cond_entropy-3-nopunct": 0.816015458810609,
        "msttr-100": 0.51848,
        "msttr-100_nopunct": 0.55071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4820457018498368
        },
        "rouge1": {
            "precision": 0.50694,
            "recall": 0.52434,
            "fmeasure": 0.50431
        },
        "rouge2": {
            "precision": 0.30703,
            "recall": 0.3251,
            "fmeasure": 0.3078
        },
        "rougeL": {
            "precision": 0.4686,
            "recall": 0.4868,
            "fmeasure": 0.46753
        },
        "rougeLsum": {
            "precision": 0.4686,
            "recall": 0.4868,
            "fmeasure": 0.46753
        },
        "nist": 3.924163813749021,
        "bleu": 20.19538,
        "bertscore": {
            "precision": 0.89921,
            "recall": 0.906,
            "f1": 0.90239
        },
        "bleurt": -0.13567,
        "meteor": 0.2463866428557808,
        "nubia": {
            "semantic_relation": 3.56648,
            "contradiction": 22.84697,
            "irrelevancy": 31.25723,
            "logical_agreement": 45.8958,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.65946,
            "nubia_score": 0.53068
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 86,
        "total_length": 1170,
        "mean_pred_length": 13.604651162790697,
        "std_pred_length": 2.242709479300687,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.1641025641025641,
        "vocab_size-1": 192,
        "unique-1": 82,
        "entropy-1": 6.060112800225693,
        "distinct-2": 0.33210332103321033,
        "vocab_size-2": 360,
        "unique-2": 214,
        "entropy-2": 7.4666452156398835,
        "cond_entropy-2": 1.2232061613385736,
        "distinct-3": 0.4729458917835671,
        "vocab_size-3": 472,
        "unique-3": 342,
        "entropy-3": 8.020482611996194,
        "cond_entropy-3": 0.5473623613358126,
        "total_length-nopunct": 1028,
        "mean_pred_length-nopunct": 11.953488372093023,
        "std_pred_length-nopunct": 2.011056512477066,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.18385214007782102,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.1409000553394115,
        "distinct-2-nopunct": 0.3365180467091295,
        "vocab_size-2-nopunct": 317,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 7.375274007218156,
        "cond_entropy-2-nopunct": 1.3179553285503771,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 428,
        "unique-3-nopunct": 310,
        "entropy-3-nopunct": 8.000079683169508,
        "cond_entropy-3-nopunct": 0.5970524654740931,
        "msttr-100": 0.49909,
        "msttr-100_nopunct": 0.51,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.42433460076045626
        },
        "rouge1": {
            "precision": 0.63441,
            "recall": 0.47609,
            "fmeasure": 0.53511
        },
        "rouge2": {
            "precision": 0.36124,
            "recall": 0.26449,
            "fmeasure": 0.29976
        },
        "rougeL": {
            "precision": 0.54511,
            "recall": 0.40459,
            "fmeasure": 0.45715
        },
        "rougeLsum": {
            "precision": 0.54511,
            "recall": 0.40459,
            "fmeasure": 0.45715
        },
        "nist": 3.341071952274457,
        "bleu": 16.71963,
        "bertscore": {
            "precision": 0.92703,
            "recall": 0.90731,
            "f1": 0.91693
        },
        "bleurt": -0.05882,
        "meteor": 0.21953625522119202,
        "nubia": {
            "semantic_relation": 3.2864,
            "contradiction": 19.6269,
            "irrelevancy": 18.15318,
            "logical_agreement": 62.21991,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.55056,
            "nubia_score": 0.47567
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/cs_restaurants_test",
        "N": 9,
        "total_length": 154,
        "mean_pred_length": 17.11111111111111,
        "std_pred_length": 2.7261875880856214,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.4155844155844156,
        "vocab_size-1": 64,
        "unique-1": 35,
        "entropy-1": 5.4937877532909445,
        "distinct-2": 0.6482758620689655,
        "vocab_size-2": 94,
        "unique-2": 64,
        "entropy-2": 6.325781700828985,
        "cond_entropy-2": 0.7452881825287584,
        "distinct-3": 0.75,
        "vocab_size-3": 102,
        "unique-3": 76,
        "entropy-3": 6.52956355462587,
        "cond_entropy-3": 0.21063669938888768,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 15.11111111111111,
        "std_pred_length-nopunct": 2.7261875880856214,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.45588235294117646,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.499351346880861,
        "distinct-2-nopunct": 0.6692913385826772,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 6.19267221488396,
        "cond_entropy-2-nopunct": 0.735267475598879,
        "distinct-3-nopunct": 0.7627118644067796,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.347732748694345,
        "cond_entropy-3-nopunct": 0.1397921267114975,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.55,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5037037037037037
        },
        "rouge1": {
            "precision": 0.55207,
            "recall": 0.51708,
            "fmeasure": 0.52063
        },
        "rouge2": {
            "precision": 0.30448,
            "recall": 0.29259,
            "fmeasure": 0.28972
        },
        "rougeL": {
            "precision": 0.46314,
            "recall": 0.43505,
            "fmeasure": 0.4363
        },
        "rougeLsum": {
            "precision": 0.46314,
            "recall": 0.43505,
            "fmeasure": 0.4363
        },
        "nist": 3.261714553871693,
        "bleu": 23.06181,
        "bertscore": {
            "precision": 0.91956,
            "recall": 0.91337,
            "f1": 0.91632
        },
        "bleurt": -0.07367,
        "meteor": 0.2585108227209482,
        "nubia": {
            "semantic_relation": 3.52999,
            "contradiction": 13.06184,
            "irrelevancy": 24.91353,
            "logical_agreement": 62.02463,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.30189,
            "nubia_score": 0.5604
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 214,
        "total_length": 5751,
        "mean_pred_length": 26.873831775700936,
        "std_pred_length": 7.630360367386756,
        "median_pred_length": 25.5,
        "min_pred_length": 14,
        "max_pred_length": 60,
        "distinct-1": 0.2237871674491393,
        "vocab_size-1": 1287,
        "unique-1": 569,
        "entropy-1": 8.391388619987758,
        "distinct-2": 0.45746794292938414,
        "vocab_size-2": 2533,
        "unique-2": 1416,
        "entropy-2": 10.723564064810638,
        "cond_entropy-2": 2.155249639236039,
        "distinct-3": 0.5957167011083975,
        "vocab_size-3": 3171,
        "unique-3": 2072,
        "entropy-3": 11.309329974434148,
        "cond_entropy-3": 0.6014351797295359,
        "total_length-nopunct": 4664,
        "mean_pred_length-nopunct": 21.794392523364486,
        "std_pred_length-nopunct": 6.444208176610646,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.2746569468267582,
        "vocab_size-1-nopunct": 1281,
        "unique-1-nopunct": 568,
        "entropy-1-nopunct": 9.068406814662364,
        "distinct-2-nopunct": 0.5060674157303371,
        "vocab_size-2-nopunct": 2252,
        "unique-2-nopunct": 1318,
        "entropy-2-nopunct": 10.676077444880603,
        "cond_entropy-2-nopunct": 1.6585192346662845,
        "distinct-3-nopunct": 0.6385741265344664,
        "vocab_size-3-nopunct": 2705,
        "unique-3-nopunct": 1851,
        "entropy-3-nopunct": 11.135383596789243,
        "cond_entropy-3-nopunct": 0.476059917082822,
        "msttr-100": 0.66544,
        "msttr-100_nopunct": 0.75174,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2584364454443195,
            "2": 0.6288716814159292,
            "3": 0.8315018315018315
        },
        "rouge1": {
            "precision": 0.42351,
            "recall": 0.4186,
            "fmeasure": 0.41228
        },
        "rouge2": {
            "precision": 0.23307,
            "recall": 0.23098,
            "fmeasure": 0.22343
        },
        "rougeL": {
            "precision": 0.40636,
            "recall": 0.4016,
            "fmeasure": 0.39537
        },
        "rougeLsum": {
            "precision": 0.40636,
            "recall": 0.4016,
            "fmeasure": 0.39537
        },
        "nist": 8.376262328913661,
        "bleu": 48.07369,
        "bertscore": {
            "precision": 0.95216,
            "recall": 0.94324,
            "f1": 0.94711
        },
        "bleurt": 0.10282,
        "meteor": 0.5973036024876317,
        "nubia": {
            "semantic_relation": 3.90019,
            "contradiction": 19.06684,
            "irrelevancy": 21.47598,
            "logical_agreement": 59.45718,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.39136,
            "nubia_score": 0.8294
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 214,
        "total_length": 4833,
        "mean_pred_length": 22.58411214953271,
        "std_pred_length": 6.3716611125527445,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 42,
        "distinct-1": 0.23918890957997102,
        "vocab_size-1": 1156,
        "unique-1": 542,
        "entropy-1": 8.333849164954716,
        "distinct-2": 0.4938298332972505,
        "vocab_size-2": 2281,
        "unique-2": 1379,
        "entropy-2": 10.58594554055953,
        "cond_entropy-2": 2.0356142390591883,
        "distinct-3": 0.6463110102156641,
        "vocab_size-3": 2847,
        "unique-3": 1991,
        "entropy-3": 11.195643205346244,
        "cond_entropy-3": 0.6178696398659594,
        "total_length-nopunct": 4004,
        "mean_pred_length-nopunct": 18.710280373831775,
        "std_pred_length-nopunct": 5.935020956421823,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.28746253746253747,
        "vocab_size-1-nopunct": 1151,
        "unique-1-nopunct": 542,
        "entropy-1-nopunct": 8.88760204246115,
        "distinct-2-nopunct": 0.5313984168865435,
        "vocab_size-2-nopunct": 2014,
        "unique-2-nopunct": 1259,
        "entropy-2-nopunct": 10.512864746114701,
        "cond_entropy-2-nopunct": 1.6777222233011595,
        "distinct-3-nopunct": 0.6747762863534675,
        "vocab_size-3-nopunct": 2413,
        "unique-3-nopunct": 1748,
        "entropy-3-nopunct": 10.98095845776219,
        "cond_entropy-3-nopunct": 0.49429141759954714,
        "msttr-100": 0.65063,
        "msttr-100_nopunct": 0.711,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2656076837827854,
            "2": 0.621683093252464,
            "3": 0.8586572438162544,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.38344,
            "recall": 0.43609,
            "fmeasure": 0.40058
        },
        "rouge2": {
            "precision": 0.17091,
            "recall": 0.22044,
            "fmeasure": 0.1869
        },
        "rougeL": {
            "precision": 0.36955,
            "recall": 0.4208,
            "fmeasure": 0.38626
        },
        "rougeLsum": {
            "precision": 0.36955,
            "recall": 0.4208,
            "fmeasure": 0.38626
        },
        "nist": 7.403070703755084,
        "bleu": 41.70929,
        "bertscore": {
            "precision": 0.94744,
            "recall": 0.94321,
            "f1": 0.94427
        },
        "bleurt": 0.098,
        "meteor": 0.6024565821069826,
        "nubia": {
            "semantic_relation": 3.95268,
            "contradiction": 19.23381,
            "irrelevancy": 22.44775,
            "logical_agreement": 58.31844,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.36103,
            "nubia_score": 0.82903
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 200,
        "total_length": 3411,
        "mean_pred_length": 17.055,
        "std_pred_length": 6.125518345413718,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 50,
        "distinct-1": 0.2858399296394019,
        "vocab_size-1": 975,
        "unique-1": 484,
        "entropy-1": 8.286815894688486,
        "distinct-2": 0.5780130800373715,
        "vocab_size-2": 1856,
        "unique-2": 1231,
        "entropy-2": 10.427673684161954,
        "cond_entropy-2": 1.84999650465246,
        "distinct-3": 0.7356360013284623,
        "vocab_size-3": 2215,
        "unique-3": 1709,
        "entropy-3": 10.921280000199525,
        "cond_entropy-3": 0.5154051562865778,
        "total_length-nopunct": 2802,
        "mean_pred_length-nopunct": 14.01,
        "std_pred_length-nopunct": 5.3600279850015715,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.3461812990720914,
        "vocab_size-1-nopunct": 970,
        "unique-1-nopunct": 484,
        "entropy-1-nopunct": 8.852711182474424,
        "distinct-2-nopunct": 0.6083781706379708,
        "vocab_size-2-nopunct": 1583,
        "unique-2-nopunct": 1074,
        "entropy-2-nopunct": 10.268165419719724,
        "cond_entropy-2-nopunct": 1.4899295613430596,
        "distinct-3-nopunct": 0.757285595337219,
        "vocab_size-3-nopunct": 1819,
        "unique-3-nopunct": 1441,
        "entropy-3-nopunct": 10.655414647123207,
        "cond_entropy-3-nopunct": 0.4176734485638092,
        "msttr-100": 0.66765,
        "msttr-100_nopunct": 0.73821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26050830889540566,
            "2": 0.5917338709677419,
            "3": 0.8491547464239272,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.32366,
            "recall": 0.37876,
            "fmeasure": 0.34266
        },
        "rouge2": {
            "precision": 0.16043,
            "recall": 0.20438,
            "fmeasure": 0.17398
        },
        "rougeL": {
            "precision": 0.31493,
            "recall": 0.36959,
            "fmeasure": 0.33368
        },
        "rougeLsum": {
            "precision": 0.31493,
            "recall": 0.36959,
            "fmeasure": 0.33368
        },
        "nist": 7.256178180175106,
        "bleu": 43.65203,
        "bertscore": {
            "precision": 0.95214,
            "recall": 0.94857,
            "f1": 0.94953
        },
        "bleurt": 0.18217,
        "meteor": 0.629552099781942,
        "nubia": {
            "semantic_relation": 4.01357,
            "contradiction": 18.36032,
            "irrelevancy": 23.58159,
            "logical_agreement": 58.05809,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.47751,
            "nubia_score": 0.80818
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 32,
        "total_length": 1049,
        "mean_pred_length": 32.78125,
        "std_pred_length": 5.176475484101127,
        "median_pred_length": 32.5,
        "min_pred_length": 19,
        "max_pred_length": 48,
        "distinct-1": 0.27645376549094375,
        "vocab_size-1": 290,
        "unique-1": 111,
        "entropy-1": 7.115253815884388,
        "distinct-2": 0.4886922320550639,
        "vocab_size-2": 497,
        "unique-2": 252,
        "entropy-2": 8.594233462160796,
        "cond_entropy-2": 1.3760799990886674,
        "distinct-3": 0.601015228426396,
        "vocab_size-3": 592,
        "unique-3": 366,
        "entropy-3": 8.960136368810456,
        "cond_entropy-3": 0.3745715087179093,
        "total_length-nopunct": 905,
        "mean_pred_length-nopunct": 28.28125,
        "std_pred_length-nopunct": 5.063560845640151,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.3138121546961326,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 7.352005582901695,
        "distinct-2-nopunct": 0.5154639175257731,
        "vocab_size-2-nopunct": 450,
        "unique-2-nopunct": 240,
        "entropy-2-nopunct": 8.496055747178197,
        "cond_entropy-2-nopunct": 1.1597099805709636,
        "distinct-3-nopunct": 0.6183115338882283,
        "vocab_size-3-nopunct": 520,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 8.78110126384634,
        "cond_entropy-3-nopunct": 0.2974563025075856,
        "msttr-100": 0.644,
        "msttr-100_nopunct": 0.69556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.28448275862068967,
            "2": 0.6174496644295302,
            "3": 0.7891373801916933
        },
        "rouge1": {
            "precision": 0.81736,
            "recall": 0.75299,
            "fmeasure": 0.7658
        },
        "rouge2": {
            "precision": 0.49592,
            "recall": 0.4684,
            "fmeasure": 0.47355
        },
        "rougeL": {
            "precision": 0.78507,
            "recall": 0.72429,
            "fmeasure": 0.73508
        },
        "rougeLsum": {
            "precision": 0.78507,
            "recall": 0.72429,
            "fmeasure": 0.73508
        },
        "nist": 6.8281767156376105,
        "bleu": 51.7421,
        "bertscore": {
            "precision": 0.95675,
            "recall": 0.93761,
            "f1": 0.94672
        },
        "bleurt": 0.20028,
        "meteor": 0.6169750800112029,
        "nubia": {
            "semantic_relation": 3.70443,
            "contradiction": 20.52453,
            "irrelevancy": 26.12267,
            "logical_agreement": 53.3528,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.39003,
            "nubia_score": 0.83511
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 254,
        "total_length": 2168,
        "mean_pred_length": 8.535433070866143,
        "std_pred_length": 2.8306402146949106,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.4040590405904059,
        "vocab_size-1": 876,
        "unique-1": 568,
        "entropy-1": 8.295426989777466,
        "distinct-2": 0.7434691745036572,
        "vocab_size-2": 1423,
        "unique-2": 1142,
        "entropy-2": 10.227390235890352,
        "cond_entropy-2": 1.2416296466669867,
        "distinct-3": 0.8656626506024097,
        "vocab_size-3": 1437,
        "unique-3": 1268,
        "entropy-3": 10.392722994989583,
        "cond_entropy-3": 0.1710430050990842,
        "total_length-nopunct": 1730,
        "mean_pred_length-nopunct": 6.811023622047244,
        "std_pred_length-nopunct": 2.4276370788986505,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5034682080924856,
        "vocab_size-1-nopunct": 871,
        "unique-1-nopunct": 568,
        "entropy-1-nopunct": 9.038961313467318,
        "distinct-2-nopunct": 0.7628726287262872,
        "vocab_size-2-nopunct": 1126,
        "unique-2-nopunct": 929,
        "entropy-2-nopunct": 9.89945508638006,
        "cond_entropy-2-nopunct": 0.9937525064366136,
        "distinct-3-nopunct": 0.8723404255319149,
        "vocab_size-3-nopunct": 1066,
        "unique-3-nopunct": 955,
        "entropy-3-nopunct": 9.960122769979892,
        "cond_entropy-3-nopunct": 0.14573617547685466,
        "msttr-100": 0.7519,
        "msttr-100_nopunct": 0.87412,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.36820652173913043,
            "2": 0.6463245492371706,
            "3": 0.8054607508532423,
            "4": 0.7428571428571429,
            "5": 0.8181818181818182,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.32415,
            "recall": 0.32858,
            "fmeasure": 0.32319
        },
        "rouge2": {
            "precision": 0.17864,
            "recall": 0.18132,
            "fmeasure": 0.17693
        },
        "rougeL": {
            "precision": 0.32349,
            "recall": 0.32808,
            "fmeasure": 0.32262
        },
        "rougeLsum": {
            "precision": 0.32349,
            "recall": 0.32808,
            "fmeasure": 0.32262
        },
        "nist": 8.012620929121372,
        "bleu": 55.58932,
        "bertscore": {
            "precision": 0.96251,
            "recall": 0.95904,
            "f1": 0.96022
        },
        "bleurt": 0.3504,
        "meteor": 0.7185544460170055,
        "nubia": {
            "semantic_relation": 4.11244,
            "contradiction": 23.13521,
            "irrelevancy": 19.63014,
            "logical_agreement": 57.23464,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.90297,
            "nubia_score": 0.82389
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 774,
        "total_length": 24599,
        "mean_pred_length": 31.781653746770026,
        "std_pred_length": 4.136261072883872,
        "median_pred_length": 31.0,
        "min_pred_length": 20,
        "max_pred_length": 42,
        "distinct-1": 0.0038212935485182325,
        "vocab_size-1": 94,
        "unique-1": 4,
        "entropy-1": 5.622347684508821,
        "distinct-2": 0.010241343126967471,
        "vocab_size-2": 244,
        "unique-2": 17,
        "entropy-2": 6.854333544614685,
        "cond_entropy-2": 1.1712189272406244,
        "distinct-3": 0.017916793197692075,
        "vocab_size-3": 413,
        "unique-3": 45,
        "entropy-3": 7.560182439297488,
        "cond_entropy-3": 0.7078167424858677,
        "total_length-nopunct": 22728,
        "mean_pred_length-nopunct": 29.364341085271317,
        "std_pred_length-nopunct": 3.8369978800106286,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.0040478704681450196,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 5.6516233728970136,
        "distinct-2-nopunct": 0.010840849048009474,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 6.837809573088449,
        "cond_entropy-2-nopunct": 1.2049803376311148,
        "distinct-3-nopunct": 0.019735599622285174,
        "vocab_size-3-nopunct": 418,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 7.586937109252424,
        "cond_entropy-3-nopunct": 0.7279120963053121,
        "msttr-100": 0.30245,
        "msttr-100_nopunct": 0.29762,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7286785597838744
        },
        "rouge1": {
            "precision": 0.80475,
            "recall": 0.74392,
            "fmeasure": 0.76748
        },
        "rouge2": {
            "precision": 0.50591,
            "recall": 0.46694,
            "fmeasure": 0.48198
        },
        "rougeL": {
            "precision": 0.53714,
            "recall": 0.49863,
            "fmeasure": 0.51339
        },
        "rougeLsum": {
            "precision": 0.53714,
            "recall": 0.49863,
            "fmeasure": 0.51339
        },
        "nist": 5.594977108239457,
        "bleu": 35.52198,
        "bertscore": {
            "precision": 0.92748,
            "recall": 0.91057,
            "f1": 0.91877
        },
        "bleurt": 0.3012,
        "meteor": 0.3759403042746013,
        "nubia": {
            "semantic_relation": 4.34264,
            "contradiction": 2.9073,
            "irrelevancy": 11.70009,
            "logical_agreement": 85.39261,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.13609,
            "nubia_score": 0.80885
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "mT5_small/xsum_test",
        "N": 106,
        "total_length": 2072,
        "mean_pred_length": 19.547169811320753,
        "std_pred_length": 3.952863961669564,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.3701737451737452,
        "vocab_size-1": 767,
        "unique-1": 527,
        "entropy-1": 7.951544165240281,
        "distinct-2": 0.7736520854526958,
        "vocab_size-2": 1521,
        "unique-2": 1326,
        "entropy-2": 10.252985725031174,
        "cond_entropy-2": 2.1039636497173286,
        "distinct-3": 0.9188172043010753,
        "vocab_size-3": 1709,
        "unique-3": 1618,
        "entropy-3": 10.655062416164283,
        "cond_entropy-3": 0.42071642065587717,
        "total_length-nopunct": 1925,
        "mean_pred_length-nopunct": 18.160377358490567,
        "std_pred_length-nopunct": 3.711625775227941,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.39636363636363636,
        "vocab_size-1-nopunct": 763,
        "unique-1-nopunct": 527,
        "entropy-1-nopunct": 8.076752777425767,
        "distinct-2-nopunct": 0.7789994502473887,
        "vocab_size-2-nopunct": 1417,
        "unique-2-nopunct": 1240,
        "entropy-2-nopunct": 10.15315200228957,
        "cond_entropy-2-nopunct": 2.1864396462531963,
        "distinct-3-nopunct": 0.9311150029188558,
        "vocab_size-3-nopunct": 1595,
        "unique-3-nopunct": 1521,
        "entropy-3-nopunct": 10.573409612826948,
        "cond_entropy-3-nopunct": 0.4274422370360114,
        "msttr-100": 0.6775,
        "msttr-100_nopunct": 0.69684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3169114163903363
        },
        "rouge1": {
            "precision": 0.40326,
            "recall": 0.3435,
            "fmeasure": 0.36413
        },
        "rouge2": {
            "precision": 0.14993,
            "recall": 0.12538,
            "fmeasure": 0.13379
        },
        "rougeL": {
            "precision": 0.31083,
            "recall": 0.26628,
            "fmeasure": 0.28156
        },
        "rougeLsum": {
            "precision": 0.31083,
            "recall": 0.26628,
            "fmeasure": 0.28156
        },
        "nist": 2.9614320279152646,
        "bleu": 8.19563,
        "bertscore": {
            "precision": 0.83262,
            "recall": 0.80749,
            "f1": 0.81954
        },
        "bleurt": -0.41482,
        "meteor": 0.15531015262459713,
        "nubia": {
            "semantic_relation": 2.53534,
            "contradiction": 35.56674,
            "irrelevancy": 55.94574,
            "logical_agreement": 8.48753,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.75664,
            "nubia_score": 0.31391
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "mT5_small/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "total_length": 5419,
        "mean_pred_length": 10.838,
        "std_pred_length": 3.7602866911978934,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 24,
        "distinct-1": 0.12400811957925817,
        "vocab_size-1": 672,
        "unique-1": 299,
        "entropy-1": 7.41341633099501,
        "distinct-2": 0.3952022768855458,
        "vocab_size-2": 1944,
        "unique-2": 1301,
        "entropy-2": 9.878681268950045,
        "cond_entropy-2": 2.1997015140178697,
        "distinct-3": 0.612582032133967,
        "vocab_size-3": 2707,
        "unique-3": 2157,
        "entropy-3": 10.768795927092118,
        "cond_entropy-3": 0.9575769089380226,
        "total_length-nopunct": 4648,
        "mean_pred_length-nopunct": 9.296,
        "std_pred_length-nopunct": 3.4583788109459612,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.1430722891566265,
        "vocab_size-1-nopunct": 665,
        "unique-1-nopunct": 296,
        "entropy-1-nopunct": 7.689726505388963,
        "distinct-2-nopunct": 0.4103182256509161,
        "vocab_size-2-nopunct": 1702,
        "unique-2-nopunct": 1153,
        "entropy-2-nopunct": 9.723849983878054,
        "cond_entropy-2-nopunct": 2.2292144960197002,
        "distinct-3-nopunct": 0.6419956140350878,
        "vocab_size-3-nopunct": 2342,
        "unique-3-nopunct": 1894,
        "entropy-3-nopunct": 10.624028828271216,
        "cond_entropy-3-nopunct": 1.0231076429811217,
        "msttr-100": 0.65778,
        "msttr-100_nopunct": 0.70391,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.3866759841602609
        },
        "rouge1": {
            "precision": 0.38836,
            "recall": 0.42344,
            "fmeasure": 0.39108
        },
        "rouge2": {
            "precision": 0.19293,
            "recall": 0.21374,
            "fmeasure": 0.19426
        },
        "rougeL": {
            "precision": 0.34074,
            "recall": 0.36971,
            "fmeasure": 0.34217
        },
        "rougeLsum": {
            "precision": 0.34074,
            "recall": 0.36971,
            "fmeasure": 0.34217
        },
        "nist": 3.099837663313093,
        "bleu": 11.29327,
        "bertscore": {
            "precision": 0.87614,
            "recall": 0.88221,
            "f1": 0.87886
        },
        "bleurt": -0.3229,
        "meteor": 0.191989079129185,
        "nubia": {
            "semantic_relation": 2.86768,
            "contradiction": 29.14592,
            "irrelevancy": 32.54496,
            "logical_agreement": 38.30913,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.67486,
            "nubia_score": 0.39016
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 19,
        "total_length": 348,
        "mean_pred_length": 18.31578947368421,
        "std_pred_length": 9.547954487901954,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.39655172413793105,
        "vocab_size-1": 138,
        "unique-1": 83,
        "entropy-1": 6.3082543384666865,
        "distinct-2": 0.6534954407294833,
        "vocab_size-2": 215,
        "unique-2": 151,
        "entropy-2": 7.447715021882125,
        "cond_entropy-2": 0.9851122046043813,
        "distinct-3": 0.7580645161290323,
        "vocab_size-3": 235,
        "unique-3": 179,
        "entropy-3": 7.733614516549302,
        "cond_entropy-3": 0.26712811168369915,
        "total_length-nopunct": 285,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 8.466652852592683,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.4666666666666667,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.41145949955492,
        "distinct-2-nopunct": 0.6842105263157895,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.223957176599203,
        "cond_entropy-2-nopunct": 0.810379542288435,
        "distinct-3-nopunct": 0.7732793522267206,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.433555427956878,
        "cond_entropy-3-nopunct": 0.23810145952356873,
        "msttr-100": 0.6,
        "msttr-100_nopunct": 0.615,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.25153374233128833,
            "2": 0.53125,
            "3": 0.7934782608695652
        },
        "rouge1": {
            "precision": 0.31871,
            "recall": 0.33166,
            "fmeasure": 0.31809
        },
        "rouge2": {
            "precision": 0.22045,
            "recall": 0.22632,
            "fmeasure": 0.21366
        },
        "rougeL": {
            "precision": 0.29616,
            "recall": 0.31495,
            "fmeasure": 0.29861
        },
        "rougeLsum": {
            "precision": 0.29616,
            "recall": 0.31495,
            "fmeasure": 0.29861
        },
        "nist": 5.078552097493213,
        "bleu": 36.66173,
        "bertscore": {
            "precision": 0.93596,
            "recall": 0.93845,
            "f1": 0.9358
        },
        "bleurt": 0.08477,
        "meteor": 0.5995020105777453,
        "nubia": {
            "semantic_relation": 3.69748,
            "contradiction": 31.6387,
            "irrelevancy": 20.71993,
            "logical_agreement": 47.64137,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.78942,
            "nubia_score": 0.69549
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 159,
        "total_length": 4237,
        "mean_pred_length": 26.647798742138363,
        "std_pred_length": 5.651446483487363,
        "median_pred_length": 26.0,
        "min_pred_length": 15,
        "max_pred_length": 46,
        "distinct-1": 0.2402643379749823,
        "vocab_size-1": 1018,
        "unique-1": 464,
        "entropy-1": 8.168028379530693,
        "distinct-2": 0.48626777832270723,
        "vocab_size-2": 1983,
        "unique-2": 1165,
        "entropy-2": 10.385853196477036,
        "cond_entropy-2": 2.045910655523312,
        "distinct-3": 0.6351109977034958,
        "vocab_size-3": 2489,
        "unique-3": 1707,
        "entropy-3": 10.989464751206112,
        "cond_entropy-3": 0.6246312473142869,
        "total_length-nopunct": 3466,
        "mean_pred_length-nopunct": 21.79874213836478,
        "std_pred_length-nopunct": 5.408797718292555,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.2916907097518754,
        "vocab_size-1-nopunct": 1011,
        "unique-1-nopunct": 463,
        "entropy-1-nopunct": 8.775650379346509,
        "distinct-2-nopunct": 0.5346235258542485,
        "vocab_size-2-nopunct": 1768,
        "unique-2-nopunct": 1079,
        "entropy-2-nopunct": 10.36604469919051,
        "cond_entropy-2-nopunct": 1.6486836187610383,
        "distinct-3-nopunct": 0.682020330368488,
        "vocab_size-3-nopunct": 2147,
        "unique-3-nopunct": 1546,
        "entropy-3-nopunct": 10.832434734049894,
        "cond_entropy-3-nopunct": 0.48157728731670474,
        "msttr-100": 0.66643,
        "msttr-100_nopunct": 0.75088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.22319688109161792,
            "2": 0.5427652733118971,
            "3": 0.7617801047120419
        },
        "rouge1": {
            "precision": 0.43484,
            "recall": 0.40473,
            "fmeasure": 0.40479
        },
        "rouge2": {
            "precision": 0.19851,
            "recall": 0.18917,
            "fmeasure": 0.18743
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.38336,
            "fmeasure": 0.38181
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.38336,
            "fmeasure": 0.38181
        },
        "nist": 7.325348633582711,
        "bleu": 40.82925,
        "bertscore": {
            "precision": 0.94969,
            "recall": 0.93082,
            "f1": 0.9395
        },
        "bleurt": 0.08179,
        "meteor": 0.5307866220203159,
        "nubia": {
            "semantic_relation": 3.82003,
            "contradiction": 20.77371,
            "irrelevancy": 20.98273,
            "logical_agreement": 58.24356,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.3719,
            "nubia_score": 0.79968
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 4,
        "total_length": 80,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.041522986797286,
        "median_pred_length": 18.5,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.525,
        "vocab_size-1": 42,
        "unique-1": 21,
        "entropy-1": 5.120191026294642,
        "distinct-2": 0.7105263157894737,
        "vocab_size-2": 54,
        "unique-2": 33,
        "entropy-2": 5.659047414730914,
        "cond_entropy-2": 0.46605504990319124,
        "distinct-3": 0.8055555555555556,
        "vocab_size-3": 58,
        "unique-3": 44,
        "entropy-3": 5.781036112553424,
        "cond_entropy-3": 0.09914870330655272,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.14578098794425,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 5.127918415494726,
        "distinct-2-nopunct": 0.7796610169491526,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.4419650832601425,
        "cond_entropy-2-nopunct": 0.26993558356238145,
        "distinct-3-nopunct": 0.8727272727272727,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.5268142589792015,
        "cond_entropy-3-nopunct": 0.06235302779918196,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.6153846153846154,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.2877,
            "recall": 0.44848,
            "fmeasure": 0.34342
        },
        "rouge2": {
            "precision": 0.07292,
            "recall": 0.08935,
            "fmeasure": 0.07887
        },
        "rougeL": {
            "precision": 0.2877,
            "recall": 0.44848,
            "fmeasure": 0.34342
        },
        "rougeLsum": {
            "precision": 0.2877,
            "recall": 0.44848,
            "fmeasure": 0.34342
        },
        "nist": 3.4121517142488367,
        "bleu": 26.84343,
        "bertscore": {
            "precision": 0.92219,
            "recall": 0.92377,
            "f1": 0.92202
        },
        "bleurt": -0.02042,
        "meteor": 0.48382934539377265,
        "nubia": {
            "semantic_relation": 3.04139,
            "contradiction": 48.87207,
            "irrelevancy": 25.57675,
            "logical_agreement": 25.55119,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.79847,
            "nubia_score": 0.52253
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 29,
        "total_length": 991,
        "mean_pred_length": 34.172413793103445,
        "std_pred_length": 5.458741584911694,
        "median_pred_length": 34.0,
        "min_pred_length": 25,
        "max_pred_length": 47,
        "distinct-1": 0.28557013118062563,
        "vocab_size-1": 283,
        "unique-1": 147,
        "entropy-1": 6.949988170466403,
        "distinct-2": 0.4875259875259875,
        "vocab_size-2": 469,
        "unique-2": 275,
        "entropy-2": 8.405863266921962,
        "cond_entropy-2": 1.361007292670931,
        "distinct-3": 0.5916398713826366,
        "vocab_size-3": 552,
        "unique-3": 364,
        "entropy-3": 8.796123055300523,
        "cond_entropy-3": 0.3949731685927385,
        "total_length-nopunct": 850,
        "mean_pred_length-nopunct": 29.310344827586206,
        "std_pred_length-nopunct": 5.458959407444647,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.32588235294117646,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 7.177431935949364,
        "distinct-2-nopunct": 0.51278928136419,
        "vocab_size-2-nopunct": 421,
        "unique-2-nopunct": 258,
        "entropy-2-nopunct": 8.29725684132294,
        "cond_entropy-2-nopunct": 1.1391503193624193,
        "distinct-3-nopunct": 0.6085858585858586,
        "vocab_size-3-nopunct": 482,
        "unique-3-nopunct": 327,
        "entropy-3-nopunct": 8.615450839647355,
        "cond_entropy-3-nopunct": 0.3383525091094689,
        "msttr-100": 0.63667,
        "msttr-100_nopunct": 0.70125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.24125874125874125,
            "2": 0.5435294117647059,
            "3": 0.7859237536656891
        },
        "rouge1": {
            "precision": 0.85345,
            "recall": 0.80618,
            "fmeasure": 0.81866
        },
        "rouge2": {
            "precision": 0.62326,
            "recall": 0.61881,
            "fmeasure": 0.61252
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.78746,
            "fmeasure": 0.79816
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.78746,
            "fmeasure": 0.79816
        },
        "nist": 5.6738262424484045,
        "bleu": 42.28502,
        "bertscore": {
            "precision": 0.95462,
            "recall": 0.93368,
            "f1": 0.94361
        },
        "bleurt": 0.126,
        "meteor": 0.5687533228270258,
        "nubia": {
            "semantic_relation": 3.61367,
            "contradiction": 20.45044,
            "irrelevancy": 22.27267,
            "logical_agreement": 57.27689,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.47405,
            "nubia_score": 0.81967
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 339,
        "total_length": 3454,
        "mean_pred_length": 10.188790560471977,
        "std_pred_length": 4.4443187041149175,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.3242617255356109,
        "vocab_size-1": 1120,
        "unique-1": 652,
        "entropy-1": 8.40336970979729,
        "distinct-2": 0.6388443017656501,
        "vocab_size-2": 1990,
        "unique-2": 1465,
        "entropy-2": 10.544589621923793,
        "cond_entropy-2": 1.5825900156507247,
        "distinct-3": 0.7860230547550432,
        "vocab_size-3": 2182,
        "unique-3": 1799,
        "entropy-3": 10.9186132192025,
        "cond_entropy-3": 0.39632181211332074,
        "total_length-nopunct": 2768,
        "mean_pred_length-nopunct": 8.165191740412979,
        "std_pred_length-nopunct": 3.850736152482792,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4028179190751445,
        "vocab_size-1-nopunct": 1115,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 9.132556864272551,
        "distinct-2-nopunct": 0.6689995883079457,
        "vocab_size-2-nopunct": 1625,
        "unique-2-nopunct": 1232,
        "entropy-2-nopunct": 10.292859620493237,
        "cond_entropy-2-nopunct": 1.2946322843112843,
        "distinct-3-nopunct": 0.8043062200956937,
        "vocab_size-3-nopunct": 1681,
        "unique-3-nopunct": 1418,
        "entropy-3-nopunct": 10.555107878430443,
        "cond_entropy-3-nopunct": 0.3482814548979098,
        "msttr-100": 0.62529,
        "msttr-100_nopunct": 0.70556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.32281763180639583,
            "2": 0.6355394378966455,
            "3": 0.8291032148900169,
            "4": 0.75,
            "5": 0.8666666666666667,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.27974,
            "recall": 0.28454,
            "fmeasure": 0.27952
        },
        "rouge2": {
            "precision": 0.13385,
            "recall": 0.13586,
            "fmeasure": 0.13257
        },
        "rougeL": {
            "precision": 0.27925,
            "recall": 0.28417,
            "fmeasure": 0.27909
        },
        "rougeLsum": {
            "precision": 0.27925,
            "recall": 0.28417,
            "fmeasure": 0.27909
        },
        "nist": 8.143840555213552,
        "bleu": 52.31404,
        "bertscore": {
            "precision": 0.96203,
            "recall": 0.95807,
            "f1": 0.95941
        },
        "bleurt": 0.32273,
        "meteor": 0.6995154835594048,
        "nubia": {
            "semantic_relation": 4.09459,
            "contradiction": 22.14851,
            "irrelevancy": 20.46278,
            "logical_agreement": 57.38872,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.79587,
            "nubia_score": 0.82356
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 316,
        "total_length": 6917,
        "mean_pred_length": 21.889240506329113,
        "std_pred_length": 7.156285061319565,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 50,
        "distinct-1": 0.198496458002024,
        "vocab_size-1": 1373,
        "unique-1": 567,
        "entropy-1": 8.393555278020363,
        "distinct-2": 0.43932737464020605,
        "vocab_size-2": 2900,
        "unique-2": 1667,
        "entropy-2": 10.791662775151215,
        "cond_entropy-2": 2.1724200130620117,
        "distinct-3": 0.5875894988066825,
        "vocab_size-3": 3693,
        "unique-3": 2499,
        "entropy-3": 11.461040046209023,
        "cond_entropy-3": 0.6961377452036487,
        "total_length-nopunct": 5685,
        "mean_pred_length-nopunct": 17.990506329113924,
        "std_pred_length-nopunct": 6.292192147583531,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.24063324538258576,
        "vocab_size-1-nopunct": 1368,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 9.000229798514848,
        "distinct-2-nopunct": 0.4790463773514621,
        "vocab_size-2-nopunct": 2572,
        "unique-2-nopunct": 1553,
        "entropy-2-nopunct": 10.739810929202854,
        "cond_entropy-2-nopunct": 1.8116392185099008,
        "distinct-3-nopunct": 0.6235899465663962,
        "vocab_size-3-nopunct": 3151,
        "unique-3-nopunct": 2237,
        "entropy-3-nopunct": 11.268607837432837,
        "cond_entropy-3-nopunct": 0.5663083526193726,
        "msttr-100": 0.55609,
        "msttr-100_nopunct": 0.60964,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2685098406747891,
            "2": 0.6058851905451037,
            "3": 0.8302816901408451,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.33631,
            "recall": 0.37395,
            "fmeasure": 0.34664
        },
        "rouge2": {
            "precision": 0.15936,
            "recall": 0.19118,
            "fmeasure": 0.16779
        },
        "rougeL": {
            "precision": 0.33079,
            "recall": 0.36815,
            "fmeasure": 0.34096
        },
        "rougeLsum": {
            "precision": 0.33079,
            "recall": 0.36815,
            "fmeasure": 0.34096
        },
        "nist": 7.6051054618603615,
        "bleu": 41.70653,
        "bertscore": {
            "precision": 0.94812,
            "recall": 0.94235,
            "f1": 0.94452
        },
        "bleurt": 0.12056,
        "meteor": 0.5789433822652895,
        "nubia": {
            "semantic_relation": 3.9675,
            "contradiction": 18.74312,
            "irrelevancy": 22.48066,
            "logical_agreement": 58.77622,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.36924,
            "nubia_score": 0.81945
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 251,
        "total_length": 9635,
        "mean_pred_length": 38.386454183266935,
        "std_pred_length": 11.335786499165982,
        "median_pred_length": 36.0,
        "min_pred_length": 15,
        "max_pred_length": 96,
        "distinct-1": 0.102854177477945,
        "vocab_size-1": 991,
        "unique-1": 310,
        "entropy-1": 7.6174474677309725,
        "distinct-2": 0.27845268542199486,
        "vocab_size-2": 2613,
        "unique-2": 1256,
        "entropy-2": 10.342212208085524,
        "cond_entropy-2": 2.6311384111432403,
        "distinct-3": 0.4337019599255447,
        "vocab_size-3": 3961,
        "unique-3": 2417,
        "entropy-3": 11.2963492706082,
        "cond_entropy-3": 0.9914867784890933,
        "total_length-nopunct": 8620,
        "mean_pred_length-nopunct": 34.342629482071715,
        "std_pred_length-nopunct": 10.460423205759552,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 96,
        "distinct-1-nopunct": 0.11403712296983759,
        "vocab_size-1-nopunct": 983,
        "unique-1-nopunct": 310,
        "entropy-1-nopunct": 7.816104449050096,
        "distinct-2-nopunct": 0.2931055084239455,
        "vocab_size-2-nopunct": 2453,
        "unique-2-nopunct": 1231,
        "entropy-2-nopunct": 10.274669845188566,
        "cond_entropy-2-nopunct": 2.5409833384403906,
        "distinct-3-nopunct": 0.4502340477950234,
        "vocab_size-3-nopunct": 3655,
        "unique-3-nopunct": 2280,
        "entropy-3-nopunct": 11.193880901901519,
        "cond_entropy-3-nopunct": 0.948717235706873,
        "msttr-100": 0.46958,
        "msttr-100_nopunct": 0.48058,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23678235484917287,
            "2": 0.5876777251184834,
            "3": 0.7892655367231638
        },
        "rouge1": {
            "precision": 0.62633,
            "recall": 0.67405,
            "fmeasure": 0.63957
        },
        "rouge2": {
            "precision": 0.37382,
            "recall": 0.39663,
            "fmeasure": 0.3793
        },
        "rougeL": {
            "precision": 0.45801,
            "recall": 0.50192,
            "fmeasure": 0.47125
        },
        "rougeLsum": {
            "precision": 0.45801,
            "recall": 0.50192,
            "fmeasure": 0.47125
        },
        "nist": 6.884679212445454,
        "bleu": 38.27024,
        "bertscore": {
            "precision": 0.88003,
            "recall": 0.88224,
            "f1": 0.87972
        },
        "bleurt": -0.16161,
        "meteor": 0.337685739205346,
        "nubia": {
            "semantic_relation": 3.73856,
            "contradiction": 30.51403,
            "irrelevancy": 12.98039,
            "logical_agreement": 56.50558,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.16111,
            "nubia_score": 0.59615
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 158,
        "total_length": 6778,
        "mean_pred_length": 42.89873417721519,
        "std_pred_length": 13.167946253090303,
        "median_pred_length": 40.0,
        "min_pred_length": 20,
        "max_pred_length": 92,
        "distinct-1": 0.12348775449985247,
        "vocab_size-1": 837,
        "unique-1": 274,
        "entropy-1": 7.5079703760914915,
        "distinct-2": 0.32341389728096676,
        "vocab_size-2": 2141,
        "unique-2": 1063,
        "entropy-2": 10.181017312973328,
        "cond_entropy-2": 2.593154774063224,
        "distinct-3": 0.49303621169916434,
        "vocab_size-3": 3186,
        "unique-3": 2004,
        "entropy-3": 11.10096830345712,
        "cond_entropy-3": 0.9495795645068391,
        "total_length-nopunct": 6058,
        "mean_pred_length-nopunct": 38.34177215189873,
        "std_pred_length-nopunct": 11.985630717443312,
        "median_pred_length-nopunct": 35.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.1366787718719049,
        "vocab_size-1-nopunct": 828,
        "unique-1-nopunct": 273,
        "entropy-1-nopunct": 7.663799823148643,
        "distinct-2-nopunct": 0.33864406779661016,
        "vocab_size-2-nopunct": 1998,
        "unique-2-nopunct": 1030,
        "entropy-2-nopunct": 10.115655949020985,
        "cond_entropy-2-nopunct": 2.524431112558176,
        "distinct-3-nopunct": 0.5107976314872866,
        "vocab_size-3-nopunct": 2933,
        "unique-3-nopunct": 1908,
        "entropy-3-nopunct": 10.995965113827914,
        "cond_entropy-3-nopunct": 0.907866671644453,
        "msttr-100": 0.49642,
        "msttr-100_nopunct": 0.50317,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22821203953279426,
            "2": 0.4794168096054888,
            "3": 0.7516873889875666
        },
        "rouge1": {
            "precision": 0.61536,
            "recall": 0.63353,
            "fmeasure": 0.61529
        },
        "rouge2": {
            "precision": 0.35401,
            "recall": 0.35583,
            "fmeasure": 0.34998
        },
        "rougeL": {
            "precision": 0.43097,
            "recall": 0.44618,
            "fmeasure": 0.4313
        },
        "rougeLsum": {
            "precision": 0.43097,
            "recall": 0.44618,
            "fmeasure": 0.4313
        },
        "nist": 6.609861364041391,
        "bleu": 37.00557,
        "bertscore": {
            "precision": 0.86916,
            "recall": 0.86777,
            "f1": 0.86712
        },
        "bleurt": -0.2972,
        "meteor": 0.30747246811228107,
        "nubia": {
            "semantic_relation": 3.56174,
            "contradiction": 33.43924,
            "irrelevancy": 12.97306,
            "logical_agreement": 53.5877,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.11237,
            "nubia_score": 0.57444
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 217,
        "total_length": 5322,
        "mean_pred_length": 24.525345622119815,
        "std_pred_length": 6.304160939969969,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 46,
        "distinct-1": 0.2298008267568583,
        "vocab_size-1": 1223,
        "unique-1": 542,
        "entropy-1": 8.357796756604232,
        "distinct-2": 0.4701273261508325,
        "vocab_size-2": 2400,
        "unique-2": 1366,
        "entropy-2": 10.651263559993705,
        "cond_entropy-2": 2.0963068755890175,
        "distinct-3": 0.619885433715221,
        "vocab_size-3": 3030,
        "unique-3": 2029,
        "entropy-3": 11.271795343322408,
        "cond_entropy-3": 0.6369678967063702,
        "total_length-nopunct": 4369,
        "mean_pred_length-nopunct": 20.13364055299539,
        "std_pred_length-nopunct": 5.817154206288325,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.2785534447241932,
        "vocab_size-1-nopunct": 1217,
        "unique-1-nopunct": 541,
        "entropy-1-nopunct": 8.964048506062076,
        "distinct-2-nopunct": 0.5178227360308285,
        "vocab_size-2-nopunct": 2150,
        "unique-2-nopunct": 1269,
        "entropy-2-nopunct": 10.628808575888863,
        "cond_entropy-2-nopunct": 1.7209461538753663,
        "distinct-3-nopunct": 0.6622617534942821,
        "vocab_size-3-nopunct": 2606,
        "unique-3-nopunct": 1829,
        "entropy-3-nopunct": 11.099612372864524,
        "cond_entropy-3-nopunct": 0.49019179581292166,
        "msttr-100": 0.58208,
        "msttr-100_nopunct": 0.62279,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.23865030674846627,
            "2": 0.5935691318327975,
            "3": 0.826118855465884,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.45438,
            "recall": 0.48673,
            "fmeasure": 0.45755
        },
        "rouge2": {
            "precision": 0.22009,
            "recall": 0.2505,
            "fmeasure": 0.22597
        },
        "rougeL": {
            "precision": 0.43761,
            "recall": 0.46909,
            "fmeasure": 0.44067
        },
        "rougeLsum": {
            "precision": 0.43761,
            "recall": 0.46909,
            "fmeasure": 0.44067
        },
        "nist": 7.751393175084221,
        "bleu": 43.78103,
        "bertscore": {
            "precision": 0.9473,
            "recall": 0.93852,
            "f1": 0.94177
        },
        "bleurt": 0.08649,
        "meteor": 0.5757130098700398,
        "nubia": {
            "semantic_relation": 3.92019,
            "contradiction": 18.39738,
            "irrelevancy": 21.74368,
            "logical_agreement": 59.85894,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.36145,
            "nubia_score": 0.82367
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 143,
        "total_length": 4064,
        "mean_pred_length": 28.41958041958042,
        "std_pred_length": 7.778770272788585,
        "median_pred_length": 27.0,
        "min_pred_length": 16,
        "max_pred_length": 60,
        "distinct-1": 0.2359744094488189,
        "vocab_size-1": 959,
        "unique-1": 406,
        "entropy-1": 8.198775649453896,
        "distinct-2": 0.4685029329252742,
        "vocab_size-2": 1837,
        "unique-2": 998,
        "entropy-2": 10.355367567688534,
        "cond_entropy-2": 1.9975873669075395,
        "distinct-3": 0.5958178930651138,
        "vocab_size-3": 2251,
        "unique-3": 1428,
        "entropy-3": 10.838733059055137,
        "cond_entropy-3": 0.4899452750558465,
        "total_length-nopunct": 3311,
        "mean_pred_length-nopunct": 23.153846153846153,
        "std_pred_length-nopunct": 6.396357893208421,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.2878284506191483,
        "vocab_size-1-nopunct": 953,
        "unique-1-nopunct": 406,
        "entropy-1-nopunct": 8.802094993701793,
        "distinct-2-nopunct": 0.5113636363636364,
        "vocab_size-2-nopunct": 1620,
        "unique-2-nopunct": 925,
        "entropy-2-nopunct": 10.268483527762568,
        "cond_entropy-2-nopunct": 1.5019853087946156,
        "distinct-3-nopunct": 0.6290909090909091,
        "vocab_size-3-nopunct": 1903,
        "unique-3-nopunct": 1254,
        "entropy-3-nopunct": 10.645095321343721,
        "cond_entropy-3-nopunct": 0.3851645797903133,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.64939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.25029058504455637,
            "2": 0.5937286980231765,
            "3": 0.8128544423440454
        },
        "rouge1": {
            "precision": 0.50007,
            "recall": 0.49297,
            "fmeasure": 0.48551
        },
        "rouge2": {
            "precision": 0.31327,
            "recall": 0.31173,
            "fmeasure": 0.30058
        },
        "rougeL": {
            "precision": 0.47441,
            "recall": 0.46753,
            "fmeasure": 0.46022
        },
        "rougeLsum": {
            "precision": 0.47441,
            "recall": 0.46753,
            "fmeasure": 0.46022
        },
        "nist": 8.06589055281798,
        "bleu": 48.0908,
        "bertscore": {
            "precision": 0.95462,
            "recall": 0.94027,
            "f1": 0.94694
        },
        "bleurt": 0.10865,
        "meteor": 0.5957704419356401,
        "nubia": {
            "semantic_relation": 3.84715,
            "contradiction": 20.31198,
            "irrelevancy": 21.26901,
            "logical_agreement": 58.41901,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.45078,
            "nubia_score": 0.81664
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 56,
        "total_length": 1639,
        "mean_pred_length": 29.267857142857142,
        "std_pred_length": 6.294813827465351,
        "median_pred_length": 29.0,
        "min_pred_length": 18,
        "max_pred_length": 46,
        "distinct-1": 0.33007931665649787,
        "vocab_size-1": 541,
        "unique-1": 283,
        "entropy-1": 7.7979211018028085,
        "distinct-2": 0.6152874289324068,
        "vocab_size-2": 974,
        "unique-2": 645,
        "entropy-2": 9.60319662793024,
        "cond_entropy-2": 1.6624212524706306,
        "distinct-3": 0.7518009168303864,
        "vocab_size-3": 1148,
        "unique-3": 874,
        "entropy-3": 10.005678383935974,
        "cond_entropy-3": 0.41435077866820547,
        "total_length-nopunct": 1372,
        "mean_pred_length-nopunct": 24.5,
        "std_pred_length-nopunct": 5.821757221222571,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.3892128279883382,
        "vocab_size-1-nopunct": 534,
        "unique-1-nopunct": 282,
        "entropy-1-nopunct": 8.229830847761878,
        "distinct-2-nopunct": 0.6519756838905775,
        "vocab_size-2-nopunct": 858,
        "unique-2-nopunct": 586,
        "entropy-2-nopunct": 9.495960360651486,
        "cond_entropy-2-nopunct": 1.3064129872057815,
        "distinct-3-nopunct": 0.7785714285714286,
        "vocab_size-3-nopunct": 981,
        "unique-3-nopunct": 769,
        "entropy-3-nopunct": 9.80374112124339,
        "cond_entropy-3-nopunct": 0.3244954301353487,
        "msttr-100": 0.60812,
        "msttr-100_nopunct": 0.65077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.22038567493112948,
            "2": 0.5437201907790143,
            "3": 0.7707231040564374
        },
        "rouge1": {
            "precision": 0.73027,
            "recall": 0.67038,
            "fmeasure": 0.67884
        },
        "rouge2": {
            "precision": 0.44755,
            "recall": 0.44716,
            "fmeasure": 0.43603
        },
        "rougeL": {
            "precision": 0.67002,
            "recall": 0.61722,
            "fmeasure": 0.62192
        },
        "rougeLsum": {
            "precision": 0.67002,
            "recall": 0.61722,
            "fmeasure": 0.62192
        },
        "nist": 6.925031309700005,
        "bleu": 43.52134,
        "bertscore": {
            "precision": 0.94975,
            "recall": 0.93356,
            "f1": 0.94099
        },
        "bleurt": 0.10109,
        "meteor": 0.5548491412773524,
        "nubia": {
            "semantic_relation": 3.65443,
            "contradiction": 22.54977,
            "irrelevancy": 24.09772,
            "logical_agreement": 53.3525,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.4852,
            "nubia_score": 0.79707
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 19,
        "total_length": 627,
        "mean_pred_length": 33.0,
        "std_pred_length": 5.3606755269520985,
        "median_pred_length": 34.0,
        "min_pred_length": 19,
        "max_pred_length": 44,
        "distinct-1": 0.3062200956937799,
        "vocab_size-1": 192,
        "unique-1": 86,
        "entropy-1": 6.645988839246783,
        "distinct-2": 0.4868421052631579,
        "vocab_size-2": 296,
        "unique-2": 160,
        "entropy-2": 7.824650214330922,
        "cond_entropy-2": 1.0907520368003438,
        "distinct-3": 0.5721561969439728,
        "vocab_size-3": 337,
        "unique-3": 214,
        "entropy-3": 8.09749984063312,
        "cond_entropy-3": 0.27516298568651976,
        "total_length-nopunct": 548,
        "mean_pred_length-nopunct": 28.842105263157894,
        "std_pred_length-nopunct": 5.244176297718379,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.3448905109489051,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.803405103549721,
        "distinct-2-nopunct": 0.5103969754253308,
        "vocab_size-2-nopunct": 270,
        "unique-2-nopunct": 155,
        "entropy-2-nopunct": 7.718065798617276,
        "cond_entropy-2-nopunct": 0.9296165191765762,
        "distinct-3-nopunct": 0.5901960784313726,
        "vocab_size-3-nopunct": 301,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.938532754143467,
        "cond_entropy-3-nopunct": 0.23157899798842627,
        "msttr-100": 0.55667,
        "msttr-100_nopunct": 0.594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.288135593220339,
            "2": 0.6240601503759399,
            "3": 0.8465346534653465
        },
        "rouge1": {
            "precision": 0.89415,
            "recall": 0.84343,
            "fmeasure": 0.85408
        },
        "rouge2": {
            "precision": 0.56111,
            "recall": 0.55737,
            "fmeasure": 0.55337
        },
        "rougeL": {
            "precision": 0.83801,
            "recall": 0.79335,
            "fmeasure": 0.80059
        },
        "rougeLsum": {
            "precision": 0.83801,
            "recall": 0.79335,
            "fmeasure": 0.80059
        },
        "nist": 6.464825698838423,
        "bleu": 53.25815,
        "bertscore": {
            "precision": 0.96092,
            "recall": 0.94378,
            "f1": 0.95211
        },
        "bleurt": 0.14006,
        "meteor": 0.6550514211033555,
        "nubia": {
            "semantic_relation": 3.66129,
            "contradiction": 20.90371,
            "irrelevancy": 24.10839,
            "logical_agreement": 54.9879,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.47402,
            "nubia_score": 0.82083
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 80,
        "total_length": 3653,
        "mean_pred_length": 45.6625,
        "std_pred_length": 12.516932281913169,
        "median_pred_length": 44.0,
        "min_pred_length": 27,
        "max_pred_length": 89,
        "distinct-1": 0.17191349575691212,
        "vocab_size-1": 628,
        "unique-1": 271,
        "entropy-1": 7.187866105861335,
        "distinct-2": 0.41029946823397706,
        "vocab_size-2": 1466,
        "unique-2": 875,
        "entropy-2": 9.758682517877343,
        "cond_entropy-2": 2.5043843920285505,
        "distinct-3": 0.5908960778700257,
        "vocab_size-3": 2064,
        "unique-3": 1468,
        "entropy-3": 10.608767005746694,
        "cond_entropy-3": 0.8772923748122722,
        "total_length-nopunct": 3272,
        "mean_pred_length-nopunct": 40.9,
        "std_pred_length-nopunct": 11.909659944767524,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.18918092909535453,
        "vocab_size-1-nopunct": 619,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.306920350388048,
        "distinct-2-nopunct": 0.4241854636591479,
        "vocab_size-2-nopunct": 1354,
        "unique-2-nopunct": 824,
        "entropy-2-nopunct": 9.674744482171391,
        "cond_entropy-2-nopunct": 2.438114461194013,
        "distinct-3-nopunct": 0.6034704370179949,
        "vocab_size-3-nopunct": 1878,
        "unique-3-nopunct": 1356,
        "entropy-3-nopunct": 10.480032116896629,
        "cond_entropy-3-nopunct": 0.8247084144597776,
        "msttr-100": 0.49139,
        "msttr-100_nopunct": 0.49906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19650986342943855,
            "2": 0.514745308310992,
            "3": 0.6592442645074224
        },
        "rouge1": {
            "precision": 0.59295,
            "recall": 0.58894,
            "fmeasure": 0.58206
        },
        "rouge2": {
            "precision": 0.31447,
            "recall": 0.30869,
            "fmeasure": 0.30656
        },
        "rougeL": {
            "precision": 0.42267,
            "recall": 0.42195,
            "fmeasure": 0.41603
        },
        "rougeLsum": {
            "precision": 0.42267,
            "recall": 0.42195,
            "fmeasure": 0.41603
        },
        "nist": 6.246865450409131,
        "bleu": 32.91253,
        "bertscore": {
            "precision": 0.86159,
            "recall": 0.8535,
            "f1": 0.85611
        },
        "bleurt": -0.32622,
        "meteor": 0.27060068716943214,
        "nubia": {
            "semantic_relation": 3.34717,
            "contradiction": 36.02223,
            "irrelevancy": 15.38517,
            "logical_agreement": 48.5926,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.01277,
            "nubia_score": 0.51867
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 41,
        "total_length": 1913,
        "mean_pred_length": 46.65853658536585,
        "std_pred_length": 11.064356651080987,
        "median_pred_length": 47.0,
        "min_pred_length": 31,
        "max_pred_length": 86,
        "distinct-1": 0.23366440146366962,
        "vocab_size-1": 447,
        "unique-1": 225,
        "entropy-1": 6.985112146154114,
        "distinct-2": 0.5010683760683761,
        "vocab_size-2": 938,
        "unique-2": 596,
        "entropy-2": 9.318174106781862,
        "cond_entropy-2": 2.27230409146806,
        "distinct-3": 0.6821409066084108,
        "vocab_size-3": 1249,
        "unique-3": 939,
        "entropy-3": 10.031009502751386,
        "cond_entropy-3": 0.7282550809329191,
        "total_length-nopunct": 1713,
        "mean_pred_length-nopunct": 41.78048780487805,
        "std_pred_length-nopunct": 10.705622400475303,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.2574430823117338,
        "vocab_size-1-nopunct": 441,
        "unique-1-nopunct": 225,
        "entropy-1-nopunct": 7.102015448077102,
        "distinct-2-nopunct": 0.5197368421052632,
        "vocab_size-2-nopunct": 869,
        "unique-2-nopunct": 563,
        "entropy-2-nopunct": 9.258041891643652,
        "cond_entropy-2-nopunct": 2.2172428481451054,
        "distinct-3-nopunct": 0.6952789699570815,
        "vocab_size-3-nopunct": 1134,
        "unique-3-nopunct": 864,
        "entropy-3-nopunct": 9.908854497231227,
        "cond_entropy-3-nopunct": 0.6645653170534782,
        "msttr-100": 0.51211,
        "msttr-100_nopunct": 0.52118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17522658610271905,
            "2": 0.35714285714285715,
            "3": 0.6364653243847874
        },
        "rouge1": {
            "precision": 0.58105,
            "recall": 0.54882,
            "fmeasure": 0.55613
        },
        "rouge2": {
            "precision": 0.30254,
            "recall": 0.27975,
            "fmeasure": 0.28597
        },
        "rougeL": {
            "precision": 0.42075,
            "recall": 0.39184,
            "fmeasure": 0.39906
        },
        "rougeLsum": {
            "precision": 0.42075,
            "recall": 0.39184,
            "fmeasure": 0.39906
        },
        "nist": 5.81259609108553,
        "bleu": 32.07107,
        "bertscore": {
            "precision": 0.85723,
            "recall": 0.84283,
            "f1": 0.84823
        },
        "bleurt": -0.39315,
        "meteor": 0.2566622388306104,
        "nubia": {
            "semantic_relation": 3.11352,
            "contradiction": 42.24789,
            "irrelevancy": 14.06567,
            "logical_agreement": 43.68645,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.00126,
            "nubia_score": 0.4902
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 12,
        "total_length": 417,
        "mean_pred_length": 34.75,
        "std_pred_length": 5.261891294962297,
        "median_pred_length": 35.0,
        "min_pred_length": 27,
        "max_pred_length": 47,
        "distinct-1": 0.31894484412470026,
        "vocab_size-1": 133,
        "unique-1": 59,
        "entropy-1": 6.3225149701823105,
        "distinct-2": 0.508641975308642,
        "vocab_size-2": 206,
        "unique-2": 108,
        "entropy-2": 7.380635958766134,
        "cond_entropy-2": 0.9847404732693126,
        "distinct-3": 0.5954198473282443,
        "vocab_size-3": 234,
        "unique-3": 132,
        "entropy-3": 7.679900284524201,
        "cond_entropy-3": 0.30629757052553674,
        "total_length-nopunct": 368,
        "mean_pred_length-nopunct": 30.666666666666668,
        "std_pred_length-nopunct": 5.08811250749125,
        "median_pred_length-nopunct": 30.5,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.3532608695652174,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 6.417314812916447,
        "distinct-2-nopunct": 0.5196629213483146,
        "vocab_size-2-nopunct": 185,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 7.267509668386532,
        "cond_entropy-2-nopunct": 0.8599794161589586,
        "distinct-3-nopunct": 0.6075581395348837,
        "vocab_size-3-nopunct": 209,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 7.536930924527532,
        "cond_entropy-3-nopunct": 0.29023182343192966,
        "msttr-100": 0.55,
        "msttr-100_nopunct": 0.59667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29901960784313725,
            "2": 0.5862068965517241,
            "3": 0.7658227848101266
        },
        "rouge1": {
            "precision": 0.8912,
            "recall": 0.80278,
            "fmeasure": 0.82732
        },
        "rouge2": {
            "precision": 0.45066,
            "recall": 0.45926,
            "fmeasure": 0.446
        },
        "rougeL": {
            "precision": 0.85648,
            "recall": 0.77143,
            "fmeasure": 0.79167
        },
        "rougeLsum": {
            "precision": 0.85648,
            "recall": 0.77143,
            "fmeasure": 0.79167
        },
        "nist": 5.5444143228201295,
        "bleu": 45.78135,
        "bertscore": {
            "precision": 0.95589,
            "recall": 0.93333,
            "f1": 0.94383
        },
        "bleurt": 0.11232,
        "meteor": 0.5873784081017113,
        "nubia": {
            "semantic_relation": 3.47328,
            "contradiction": 25.80368,
            "irrelevancy": 25.99908,
            "logical_agreement": 48.19724,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.47274,
            "nubia_score": 0.79738
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 1099,
        "total_length": 22374,
        "mean_pred_length": 20.358507734303913,
        "std_pred_length": 9.62871936114323,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.10168052203450434,
        "vocab_size-1": 2275,
        "unique-1": 632,
        "entropy-1": 8.724140419301307,
        "distinct-2": 0.25941245593419504,
        "vocab_size-2": 5519,
        "unique-2": 2351,
        "entropy-2": 11.421756799875807,
        "cond_entropy-2": 2.435766615462204,
        "distinct-3": 0.39160388580491673,
        "vocab_size-3": 7901,
        "unique-3": 4274,
        "entropy-3": 12.294415903521584,
        "cond_entropy-3": 0.9044805182240309,
        "total_length-nopunct": 18375,
        "mean_pred_length-nopunct": 16.719745222929937,
        "std_pred_length-nopunct": 8.296248290334026,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.12337414965986394,
        "vocab_size-1-nopunct": 2267,
        "unique-1-nopunct": 631,
        "entropy-1-nopunct": 9.405135504586651,
        "distinct-2-nopunct": 0.2928339893493864,
        "vocab_size-2-nopunct": 5059,
        "unique-2-nopunct": 2335,
        "entropy-2-nopunct": 11.418751897613609,
        "cond_entropy-2-nopunct": 2.1011565273215527,
        "distinct-3-nopunct": 0.4298077517463065,
        "vocab_size-3-nopunct": 6953,
        "unique-3-nopunct": 4015,
        "entropy-3-nopunct": 12.157543130192542,
        "cond_entropy-3-nopunct": 0.794470138391159,
        "msttr-100": 0.58673,
        "msttr-100_nopunct": 0.63923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26463432088163735,
            "2": 0.6,
            "3": 0.8182329769274057,
            "4": 0.8831168831168831,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.40018,
            "recall": 0.41305,
            "fmeasure": 0.3978
        },
        "rouge2": {
            "precision": 0.20875,
            "recall": 0.22434,
            "fmeasure": 0.20952
        },
        "rougeL": {
            "precision": 0.38737,
            "recall": 0.40056,
            "fmeasure": 0.3852
        },
        "rougeLsum": {
            "precision": 0.38737,
            "recall": 0.40056,
            "fmeasure": 0.3852
        },
        "nist": 8.67958030074316,
        "bleu": 46.73438,
        "bertscore": {
            "precision": 0.95348,
            "recall": 0.94564,
            "f1": 0.94883
        },
        "bleurt": 0.1741,
        "meteor": 0.6005961642591103,
        "nubia": {
            "semantic_relation": 3.9555,
            "contradiction": 20.21779,
            "irrelevancy": 21.71554,
            "logical_agreement": 58.06667,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.51783,
            "nubia_score": 0.82003
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.515625,
            "3": 0.7543859649122807
        },
        "rouge1": {
            "precision": 0.71944,
            "recall": 0.65033,
            "fmeasure": 0.67001
        },
        "rouge2": {
            "precision": 0.51028,
            "recall": 0.45595,
            "fmeasure": 0.47661
        },
        "rougeL": {
            "precision": 0.6506,
            "recall": 0.60114,
            "fmeasure": 0.61413
        },
        "rougeLsum": {
            "precision": 0.6506,
            "recall": 0.60114,
            "fmeasure": 0.61413
        },
        "nist": 6.250097906598966,
        "bleu": 59.30921,
        "bertscore": {
            "precision": 0.91975,
            "recall": 0.90318,
            "f1": 0.91049
        },
        "bleurt": 0.20201,
        "meteor": 0.40422003246956656,
        "nubia": {
            "semantic_relation": 4.01379,
            "contradiction": 9.4783,
            "irrelevancy": 21.00039,
            "logical_agreement": 69.52131,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.47336,
            "nubia_score": 0.65822
        }
    },
    "web_nlg_ru_val": {
        "predictions_file": "mT5_small/web_nlg_ru_val",
        "N": 790,
        "total_length": 15176,
        "mean_pred_length": 19.21012658227848,
        "std_pred_length": 8.757284055836594,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 75,
        "distinct-1": 0.08039008961518186,
        "vocab_size-1": 1220,
        "unique-1": 349,
        "entropy-1": 7.945320973070442,
        "distinct-2": 0.19755317669956904,
        "vocab_size-2": 2842,
        "unique-2": 1214,
        "entropy-2": 10.227779438769321,
        "cond_entropy-2": 2.0452617017248818,
        "distinct-3": 0.2911150338334804,
        "vocab_size-3": 3958,
        "unique-3": 2046,
        "entropy-3": 10.993354386280117,
        "cond_entropy-3": 0.8029389999288761,
        "total_length-nopunct": 12306,
        "mean_pred_length-nopunct": 15.577215189873417,
        "std_pred_length-nopunct": 7.566648161288543,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.09873232569478303,
        "vocab_size-1-nopunct": 1215,
        "unique-1-nopunct": 349,
        "entropy-1-nopunct": 8.517604557332161,
        "distinct-2-nopunct": 0.22403612365404654,
        "vocab_size-2-nopunct": 2580,
        "unique-2-nopunct": 1187,
        "entropy-2-nopunct": 10.210739535961318,
        "cond_entropy-2-nopunct": 1.7627552119835954,
        "distinct-3-nopunct": 0.32537758717135934,
        "vocab_size-3-nopunct": 3490,
        "unique-3-nopunct": 1903,
        "entropy-3-nopunct": 10.865008519324675,
        "cond_entropy-3-nopunct": 0.7034253965569878,
        "msttr-100": 0.42636,
        "msttr-100_nopunct": 0.4587,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_val.json",
        "local_recall": {
            "1": 0.22708069286016055,
            "2": 0.5652173913043478,
            "3": 0.7701749804126404,
            "4": 0.7878787878787878,
            "5": 0.8461538461538461,
            "6": 0.9,
            "7": 0.75,
            "8": 0,
            "9": 1.0
        },
        "rouge1": {
            "precision": 0.29376,
            "recall": 0.30992,
            "fmeasure": 0.29643
        },
        "rouge2": {
            "precision": 0.10531,
            "recall": 0.11177,
            "fmeasure": 0.10495
        },
        "rougeL": {
            "precision": 0.28108,
            "recall": 0.29751,
            "fmeasure": 0.28393
        },
        "rougeLsum": {
            "precision": 0.28108,
            "recall": 0.29751,
            "fmeasure": 0.28393
        },
        "nist": 7.337699858449341,
        "bleu": 41.13367,
        "bertscore": {
            "precision": 0.94744,
            "recall": 0.93836,
            "f1": 0.94189
        },
        "bleurt": 0.12964,
        "meteor": 0.5525668915488812,
        "nubia": {
            "semantic_relation": 3.86751,
            "contradiction": 22.91514,
            "irrelevancy": 21.41198,
            "logical_agreement": 55.67288,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.46094,
            "nubia_score": 0.79169
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 1102,
        "total_length": 22440,
        "mean_pred_length": 20.362976406533576,
        "std_pred_length": 9.624568222214084,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.1017825311942959,
        "vocab_size-1": 2284,
        "unique-1": 639,
        "entropy-1": 8.724460685406497,
        "distinct-2": 0.2596307057831099,
        "vocab_size-2": 5540,
        "unique-2": 2365,
        "entropy-2": 11.424929755286028,
        "cond_entropy-2": 2.4387150373709705,
        "distinct-3": 0.3919252816762206,
        "vocab_size-3": 7931,
        "unique-3": 4299,
        "entropy-3": 12.298424638308449,
        "cond_entropy-3": 0.9054929847846892,
        "total_length-nopunct": 18421,
        "mean_pred_length-nopunct": 16.71597096188748,
        "std_pred_length-nopunct": 8.290664447388586,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.12355463872753922,
        "vocab_size-1-nopunct": 2276,
        "unique-1-nopunct": 638,
        "entropy-1-nopunct": 9.407811852742714,
        "distinct-2-nopunct": 0.29314625555748025,
        "vocab_size-2-nopunct": 5077,
        "unique-2-nopunct": 2350,
        "entropy-2-nopunct": 11.422388478765777,
        "cond_entropy-2-nopunct": 2.102040003107517,
        "distinct-3-nopunct": 0.43022753900228156,
        "vocab_size-3-nopunct": 6977,
        "unique-3-nopunct": 4036,
        "entropy-3-nopunct": 12.162259963582725,
        "cond_entropy-3-nopunct": 0.7954836664696444,
        "msttr-100": 0.67643,
        "msttr-100_nopunct": 0.76027,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2642923417314967,
            "2": 0.6001100866932709,
            "3": 0.8180630714685576,
            "4": 0.8831168831168831,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.39909,
            "recall": 0.41193,
            "fmeasure": 0.39672
        },
        "rouge2": {
            "precision": 0.20819,
            "recall": 0.22373,
            "fmeasure": 0.20895
        },
        "rougeL": {
            "precision": 0.38631,
            "recall": 0.39947,
            "fmeasure": 0.38415
        },
        "rougeLsum": {
            "precision": 0.38631,
            "recall": 0.39947,
            "fmeasure": 0.38415
        },
        "nist": 8.685244836782774,
        "bleu": 46.76243,
        "bertscore": {
            "precision": 0.95347,
            "recall": 0.94564,
            "f1": 0.94882
        },
        "bleurt": 0.17376,
        "meteor": 0.6007377559381059,
        "nubia": {
            "semantic_relation": 3.95509,
            "contradiction": 20.23377,
            "irrelevancy": 21.70612,
            "logical_agreement": 58.06011,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.51835,
            "nubia_score": 0.81983
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 73,
        "total_length": 2281,
        "mean_pred_length": 31.246575342465754,
        "std_pred_length": 3.354738304791982,
        "median_pred_length": 31.0,
        "min_pred_length": 23,
        "max_pred_length": 38,
        "distinct-1": 0.037264357737834285,
        "vocab_size-1": 85,
        "unique-1": 5,
        "entropy-1": 5.563800283314558,
        "distinct-2": 0.08922101449275362,
        "vocab_size-2": 197,
        "unique-2": 37,
        "entropy-2": 6.753161267226237,
        "cond_entropy-2": 1.127609160788171,
        "distinct-3": 0.14004683840749416,
        "vocab_size-3": 299,
        "unique-3": 82,
        "entropy-3": 7.431317126816792,
        "cond_entropy-3": 0.6791146346200174,
        "total_length-nopunct": 2092,
        "mean_pred_length-nopunct": 28.65753424657534,
        "std_pred_length-nopunct": 3.2275321505871553,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.039674952198852774,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 5.584400888318415,
        "distinct-2-nopunct": 0.0946012877662209,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 6.739147601983455,
        "cond_entropy-2-nopunct": 1.1771313280786462,
        "distinct-3-nopunct": 0.1551901336073998,
        "vocab_size-3-nopunct": 302,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 7.456496799918066,
        "cond_entropy-3-nopunct": 0.6999955991748728,
        "msttr-100": 0.36727,
        "msttr-100_nopunct": 0.362,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.728150406504065
        },
        "rouge1": {
            "precision": 0.78722,
            "recall": 0.73425,
            "fmeasure": 0.75528
        },
        "rouge2": {
            "precision": 0.51018,
            "recall": 0.47247,
            "fmeasure": 0.48748
        },
        "rougeL": {
            "precision": 0.53361,
            "recall": 0.49834,
            "fmeasure": 0.5123
        },
        "rougeLsum": {
            "precision": 0.53361,
            "recall": 0.49834,
            "fmeasure": 0.5123
        },
        "nist": 5.264879195830471,
        "bleu": 35.46063,
        "bertscore": {
            "precision": 0.92358,
            "recall": 0.91064,
            "f1": 0.9169
        },
        "bleurt": 0.27882,
        "meteor": 0.3747816878999328,
        "nubia": {
            "semantic_relation": 4.22224,
            "contradiction": 5.77185,
            "irrelevancy": 21.3014,
            "logical_agreement": 72.92675,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.19418,
            "nubia_score": 0.78477
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 3,
        "total_length": 66,
        "mean_pred_length": 22.0,
        "std_pred_length": 7.788880963698615,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.5303030303030303,
        "vocab_size-1": 35,
        "unique-1": 25,
        "entropy-1": 4.67400818036036,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 51,
        "unique-2": 45,
        "entropy-2": 5.524433494722446,
        "cond_entropy-2": 0.8204436924096161,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 50,
        "unique-3": 45,
        "entropy-3": 5.510649970428228,
        "cond_entropy-3": 0.008858797144659803,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 5.734883511361751,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.778677988524611,
        "distinct-2-nopunct": 0.813953488372093,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.983949638221775,
        "cond_entropy-2-nopunct": 0.21072867068779497,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.965311532225103,
        "cond_entropy-3-nopunct": 0.014535527739350974,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.6666666666666666,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "nist": 5.226287805927321,
        "bleu": 56.04254,
        "bertscore": {
            "precision": 0.94707,
            "recall": 0.94669,
            "f1": 0.94584
        },
        "bleurt": 0.04864,
        "meteor": 0.648375494334928,
        "nubia": {
            "semantic_relation": 3.80523,
            "contradiction": 26.08768,
            "irrelevancy": 18.25345,
            "logical_agreement": 55.65887,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.70914,
            "nubia_score": 0.74574
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 2,
        "total_length": 68,
        "mean_pred_length": 34.0,
        "std_pred_length": 0.0,
        "median_pred_length": 34.0,
        "min_pred_length": 34,
        "max_pred_length": 34,
        "distinct-1": 0.4264705882352941,
        "vocab_size-1": 29,
        "unique-1": 0,
        "entropy-1": 4.793345194191515,
        "distinct-2": 0.5,
        "vocab_size-2": 33,
        "unique-2": 0,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.22965855083538686,
        "distinct-3": 0.5,
        "vocab_size-3": 32,
        "unique-3": 0,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.04439411935845341,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 32.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 32,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4375,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.75,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.21226082651590766,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.04730571477835684,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.98438,
            "recall": 0.78885,
            "fmeasure": 0.87529
        },
        "rouge2": {
            "precision": 0.80645,
            "recall": 0.64272,
            "fmeasure": 0.71487
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.65414,
            "fmeasure": 0.72432
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.65414,
            "fmeasure": 0.72432
        },
        "nist": 4.457698346652484,
        "bleu": 54.70067,
        "bertscore": {
            "precision": 0.96491,
            "recall": 0.93829,
            "f1": 0.95142
        },
        "bleurt": 0.39829,
        "meteor": 0.4418113472536837,
        "nubia": {
            "semantic_relation": 4.79476,
            "contradiction": 0.1978,
            "irrelevancy": 0.42681,
            "logical_agreement": 99.37539,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.255,
            "nubia_score": 0.8781
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "mT5_small/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "total_length": 11370,
        "mean_pred_length": 22.74,
        "std_pred_length": 11.363291776593613,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 74,
        "distinct-1": 0.19762532981530342,
        "vocab_size-1": 2247,
        "unique-1": 1002,
        "entropy-1": 8.947459970500585,
        "distinct-2": 0.5234590616375345,
        "vocab_size-2": 5690,
        "unique-2": 3899,
        "entropy-2": 11.85364555493409,
        "cond_entropy-2": 2.6683927011238713,
        "distinct-3": 0.7426229508196721,
        "vocab_size-3": 7701,
        "unique-3": 6335,
        "entropy-3": 12.66126978399612,
        "cond_entropy-3": 0.8131272665855889,
        "total_length-nopunct": 9473,
        "mean_pred_length-nopunct": 18.946,
        "std_pred_length-nopunct": 9.831128317746646,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.2364615222210493,
        "vocab_size-1-nopunct": 2240,
        "unique-1-nopunct": 1002,
        "entropy-1-nopunct": 9.593201157388036,
        "distinct-2-nopunct": 0.5722723726735763,
        "vocab_size-2-nopunct": 5135,
        "unique-2-nopunct": 3730,
        "entropy-2-nopunct": 11.791781947851517,
        "cond_entropy-2-nopunct": 2.2638792815908744,
        "distinct-3-nopunct": 0.7733978520004721,
        "vocab_size-3-nopunct": 6553,
        "unique-3-nopunct": 5591,
        "entropy-3-nopunct": 12.44434305008469,
        "cond_entropy-3-nopunct": 0.6677112856992855,
        "msttr-100": 0.62212,
        "msttr-100_nopunct": 0.68021,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.25928943937418514,
            "2": 0.5518181818181818,
            "3": 0.7362637362637363,
            "4": 0.9111111111111111,
            "5": 0.6,
            "6": 1.0
        },
        "rouge1": {
            "precision": 0.34777,
            "recall": 0.39776,
            "fmeasure": 0.3601
        },
        "rouge2": {
            "precision": 0.16459,
            "recall": 0.202,
            "fmeasure": 0.17412
        },
        "rougeL": {
            "precision": 0.33259,
            "recall": 0.38271,
            "fmeasure": 0.34495
        },
        "rougeLsum": {
            "precision": 0.33259,
            "recall": 0.38271,
            "fmeasure": 0.34495
        },
        "nist": 6.725577442338192,
        "bleu": 33.60139,
        "bertscore": {
            "precision": 0.93576,
            "recall": 0.93547,
            "f1": 0.93472
        },
        "bleurt": 0.07317,
        "meteor": 0.5195259900922161,
        "nubia": {
            "semantic_relation": 3.80088,
            "contradiction": 24.24655,
            "irrelevancy": 24.40672,
            "logical_agreement": 51.34673,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.45585,
            "nubia_score": 0.74483
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 986,
        "total_length": 19723,
        "mean_pred_length": 20.003042596348884,
        "std_pred_length": 9.846334089509778,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.10951680778786188,
        "vocab_size-1": 2160,
        "unique-1": 644,
        "entropy-1": 8.699065656350218,
        "distinct-2": 0.2734162352564445,
        "vocab_size-2": 5123,
        "unique-2": 2278,
        "entropy-2": 11.356561030221203,
        "cond_entropy-2": 2.391370458227919,
        "distinct-3": 0.40707565770942483,
        "vocab_size-3": 7226,
        "unique-3": 4028,
        "entropy-3": 12.185992706861839,
        "cond_entropy-3": 0.8616031639016803,
        "total_length-nopunct": 16149,
        "mean_pred_length-nopunct": 16.378296146044626,
        "std_pred_length-nopunct": 8.419641357310033,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.13332094866555205,
        "vocab_size-1-nopunct": 2153,
        "unique-1-nopunct": 643,
        "entropy-1-nopunct": 9.389326781499863,
        "distinct-2-nopunct": 0.3077886961683044,
        "vocab_size-2-nopunct": 4667,
        "unique-2-nopunct": 2241,
        "entropy-2-nopunct": 11.33883419455778,
        "cond_entropy-2-nopunct": 2.036062578195788,
        "distinct-3-nopunct": 0.44487550257459263,
        "vocab_size-3-nopunct": 6307,
        "unique-3-nopunct": 3741,
        "entropy-3-nopunct": 12.034855567534416,
        "cond_entropy-3-nopunct": 0.7504449221460862,
        "msttr-100": 0.59299,
        "msttr-100_nopunct": 0.64429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.26979975480179813,
            "2": 0.6035207976320299,
            "3": 0.8180666948079358,
            "4": 0.8831168831168831,
            "5": 0.9459459459459459,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.43075,
            "recall": 0.44578,
            "fmeasure": 0.42888
        },
        "rouge2": {
            "precision": 0.22473,
            "recall": 0.2435,
            "fmeasure": 0.2266
        },
        "rougeL": {
            "precision": 0.41664,
            "recall": 0.43203,
            "fmeasure": 0.415
        },
        "rougeLsum": {
            "precision": 0.41664,
            "recall": 0.43203,
            "fmeasure": 0.415
        },
        "nist": 8.71429557551238,
        "bleu": 47.69448,
        "bertscore": {
            "precision": 0.95388,
            "recall": 0.94683,
            "f1": 0.94965
        },
        "bleurt": 0.18255,
        "meteor": 0.6095979906216964,
        "nubia": {
            "semantic_relation": 3.95334,
            "contradiction": 20.55307,
            "irrelevancy": 22.01188,
            "logical_agreement": 57.43505,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.54716,
            "nubia_score": 0.81673
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 213,
        "total_length": 8600,
        "mean_pred_length": 40.375586854460096,
        "std_pred_length": 11.844840609680967,
        "median_pred_length": 38.0,
        "min_pred_length": 20,
        "max_pred_length": 92,
        "distinct-1": 0.11732558139534884,
        "vocab_size-1": 1009,
        "unique-1": 348,
        "entropy-1": 7.604944062179719,
        "distinct-2": 0.31978061285322523,
        "vocab_size-2": 2682,
        "unique-2": 1361,
        "entropy-2": 10.428738188068168,
        "cond_entropy-2": 2.7353131740075787,
        "distinct-3": 0.49804257401517005,
        "vocab_size-3": 4071,
        "unique-3": 2599,
        "entropy-3": 11.464610207290118,
        "cond_entropy-3": 1.0697293534729448,
        "total_length-nopunct": 7706,
        "mean_pred_length-nopunct": 36.178403755868544,
        "std_pred_length-nopunct": 10.89110000981699,
        "median_pred_length-nopunct": 34.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.12976901116013495,
        "vocab_size-1-nopunct": 1000,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 7.7747884225997534,
        "distinct-2-nopunct": 0.33497931402642467,
        "vocab_size-2-nopunct": 2510,
        "unique-2-nopunct": 1333,
        "entropy-2-nopunct": 10.365144830382969,
        "cond_entropy-2-nopunct": 2.67203563660877,
        "distinct-3-nopunct": 0.5142857142857142,
        "vocab_size-3-nopunct": 3744,
        "unique-3-nopunct": 2466,
        "entropy-3-nopunct": 11.355943768643677,
        "cond_entropy-3-nopunct": 1.0220992890470086,
        "msttr-100": 0.58395,
        "msttr-100_nopunct": 0.60662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21005199306759098,
            "2": 0.4990814451928965,
            "3": 0.7457480541942924
        },
        "rouge1": {
            "precision": 0.61203,
            "recall": 0.63458,
            "fmeasure": 0.61509
        },
        "rouge2": {
            "precision": 0.35362,
            "recall": 0.35903,
            "fmeasure": 0.35168
        },
        "rougeL": {
            "precision": 0.43395,
            "recall": 0.45391,
            "fmeasure": 0.43717
        },
        "rougeLsum": {
            "precision": 0.43395,
            "recall": 0.45391,
            "fmeasure": 0.43717
        },
        "nist": 6.702004907463518,
        "bleu": 35.48324,
        "bertscore": {
            "precision": 0.87234,
            "recall": 0.87112,
            "f1": 0.87048
        },
        "bleurt": -0.25706,
        "meteor": 0.3085257715188457,
        "nubia": {
            "semantic_relation": 3.59849,
            "contradiction": 33.02331,
            "irrelevancy": 15.35852,
            "logical_agreement": 51.61818,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.11079,
            "nubia_score": 0.58179
        }
    },
    "mlsum_de_val": {
        "predictions_file": "mT5_small/mlsum_de_val",
        "N": 11392,
        "total_length": 305733,
        "mean_pred_length": 26.837517556179776,
        "std_pred_length": 10.827086125912277,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 116,
        "distinct-1": 0.11865582060163607,
        "vocab_size-1": 36277,
        "unique-1": 21753,
        "entropy-1": 10.53002503836285,
        "distinct-2": 0.5333235940626688,
        "vocab_size-2": 156979,
        "unique-2": 126526,
        "entropy-2": 16.004332069602594,
        "cond_entropy-2": 5.228165402192682,
        "distinct-3": 0.8481669841561553,
        "vocab_size-3": 239988,
        "unique-3": 220945,
        "entropy-3": 17.626013702963263,
        "cond_entropy-3": 1.5963643649517605,
        "total_length-nopunct": 270931,
        "mean_pred_length-nopunct": 23.782566713483146,
        "std_pred_length-nopunct": 9.55097214809988,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 105,
        "distinct-1-nopunct": 0.1338458869601485,
        "vocab_size-1-nopunct": 36263,
        "unique-1-nopunct": 21751,
        "entropy-1-nopunct": 11.091123030081938,
        "distinct-2-nopunct": 0.5937180924639457,
        "vocab_size-2-nopunct": 154093,
        "unique-2-nopunct": 127246,
        "entropy-2-nopunct": 16.26325601187341,
        "cond_entropy-2-nopunct": 5.270372533806377,
        "distinct-3-nopunct": 0.8828637863846833,
        "vocab_size-3-nopunct": 219080,
        "unique-3-nopunct": 204930,
        "entropy-3-nopunct": 17.563973002864653,
        "cond_entropy-3-nopunct": 1.3353673173578466,
        "msttr-100": 0.76894,
        "msttr-100_nopunct": 0.81929,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_val.json",
        "local_recall": {
            "1": 0.4572082196179162
        },
        "rouge1": {
            "precision": 0.43927,
            "recall": 0.44304,
            "fmeasure": 0.43141
        },
        "rouge2": {
            "precision": 0.33092,
            "recall": 0.33686,
            "fmeasure": 0.32991
        },
        "rougeL": {
            "precision": 0.40496,
            "recall": 0.4082,
            "fmeasure": 0.39874
        },
        "rougeLsum": {
            "precision": 0.40496,
            "recall": 0.4082,
            "fmeasure": 0.39874
        },
        "nist": 7.23194063662687,
        "bleu": 37.06483,
        "bertscore": {
            "precision": 0.88928,
            "recall": 0.89036,
            "f1": 0.88963
        },
        "bleurt": -0.26144,
        "meteor": 0.420059916500811,
        "nubia": {
            "semantic_relation": 2.70392,
            "contradiction": 25.63592,
            "irrelevancy": 39.91239,
            "logical_agreement": 34.45169,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.94046,
            "nubia_score": 0.39631
        }
    },
    "mlsum_de_test": {
        "predictions_file": "mT5_small/mlsum_de_test",
        "N": 10695,
        "total_length": 287196,
        "mean_pred_length": 26.853295932678822,
        "std_pred_length": 10.72100532797576,
        "median_pred_length": 25.0,
        "min_pred_length": 6,
        "max_pred_length": 86,
        "distinct-1": 0.12309015445897575,
        "vocab_size-1": 35351,
        "unique-1": 21290,
        "entropy-1": 10.528063908204988,
        "distinct-2": 0.5438389011251316,
        "vocab_size-2": 150372,
        "unique-2": 122011,
        "entropy-2": 15.974339043506506,
        "cond_entropy-2": 5.2004253133504275,
        "distinct-3": 0.8561695371812524,
        "vocab_size-3": 227575,
        "unique-3": 210287,
        "entropy-3": 17.564706399182022,
        "cond_entropy-3": 1.566770248504396,
        "total_length-nopunct": 254650,
        "mean_pred_length-nopunct": 23.81019167835437,
        "std_pred_length-nopunct": 9.465444592713725,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.1387590810916945,
        "vocab_size-1-nopunct": 35335,
        "unique-1-nopunct": 21289,
        "entropy-1-nopunct": 11.085951142877484,
        "distinct-2-nopunct": 0.6037178987928101,
        "vocab_size-2-nopunct": 147280,
        "unique-2-nopunct": 122333,
        "entropy-2-nopunct": 16.22505442705454,
        "cond_entropy-2-nopunct": 5.238637001703393,
        "distinct-3-nopunct": 0.8903626854154163,
        "vocab_size-3-nopunct": 207686,
        "unique-3-nopunct": 194962,
        "entropy-3-nopunct": 17.499693191002553,
        "cond_entropy-3-nopunct": 1.3094432630208368,
        "msttr-100": 0.76875,
        "msttr-100_nopunct": 0.81861,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "local_recall": {
            "1": 0.47168276907828693
        },
        "rouge1": {
            "precision": 0.45557,
            "recall": 0.45707,
            "fmeasure": 0.44675
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.35368,
            "fmeasure": 0.34701
        },
        "rougeL": {
            "precision": 0.42133,
            "recall": 0.42269,
            "fmeasure": 0.41431
        },
        "rougeLsum": {
            "precision": 0.42133,
            "recall": 0.42269,
            "fmeasure": 0.41431
        },
        "nist": 7.543257990105405,
        "bleu": 39.13433,
        "bertscore": {
            "precision": 0.89198,
            "recall": 0.89266,
            "f1": 0.89214
        },
        "bleurt": -0.23714,
        "meteor": 0.4355422134270874,
        "nubia": {
            "semantic_relation": 2.7567,
            "contradiction": 25.1916,
            "irrelevancy": 38.7307,
            "logical_agreement": 36.0777,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.93886,
            "nubia_score": 0.41021
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "mT5_small/mlsum_de_challenge_test_covid",
        "N": 5058,
        "total_length": 150657,
        "mean_pred_length": 29.7858837485172,
        "std_pred_length": 9.15389611998591,
        "median_pred_length": 30.0,
        "min_pred_length": 7,
        "max_pred_length": 81,
        "distinct-1": 0.11268643342161333,
        "vocab_size-1": 16977,
        "unique-1": 10770,
        "entropy-1": 9.454544499351409,
        "distinct-2": 0.4501473224404014,
        "vocab_size-2": 65541,
        "unique-2": 54990,
        "entropy-2": 13.441843144909827,
        "cond_entropy-2": 3.869502564921392,
        "distinct-3": 0.6588966920685067,
        "vocab_size-3": 92602,
        "unique-3": 87667,
        "entropy-3": 14.384922151060799,
        "cond_entropy-3": 0.9379391180159176,
        "total_length-nopunct": 132096,
        "mean_pred_length-nopunct": 26.116251482799527,
        "std_pred_length-nopunct": 7.96646346629227,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 75,
        "distinct-1-nopunct": 0.128414183624031,
        "vocab_size-1-nopunct": 16963,
        "unique-1-nopunct": 10768,
        "entropy-1-nopunct": 9.937887076185522,
        "distinct-2-nopunct": 0.5036760654292416,
        "vocab_size-2-nopunct": 63986,
        "unique-2-nopunct": 54955,
        "entropy-2-nopunct": 13.611455673883457,
        "cond_entropy-2-nopunct": 3.755054372370788,
        "distinct-3-nopunct": 0.6880718150516478,
        "vocab_size-3-nopunct": 83931,
        "unique-3-nopunct": 80708,
        "entropy-3-nopunct": 14.315030556039176,
        "cond_entropy-3-nopunct": 0.7194113923971901,
        "msttr-100": 0.72867,
        "msttr-100_nopunct": 0.77208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "local_recall": {
            "1": 0.3671313295661925
        },
        "rouge1": {
            "precision": 0.25871,
            "recall": 0.35708,
            "fmeasure": 0.29126
        },
        "rouge2": {
            "precision": 0.17693,
            "recall": 0.2456,
            "fmeasure": 0.20026
        },
        "rougeL": {
            "precision": 0.2373,
            "recall": 0.32713,
            "fmeasure": 0.26727
        },
        "rougeLsum": {
            "precision": 0.2373,
            "recall": 0.32713,
            "fmeasure": 0.26727
        },
        "nist": 3.743800180897135,
        "bleu": 19.09046,
        "bertscore": {
            "precision": 0.85555,
            "recall": 0.87301,
            "f1": 0.86394
        },
        "bleurt": -0.5552,
        "meteor": 0.31499694175050413,
        "nubia": {
            "semantic_relation": 1.82881,
            "contradiction": 25.96875,
            "irrelevancy": 58.8441,
            "logical_agreement": 15.18716,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.95816,
            "nubia_score": 0.2192
        }
    },
    "mlsum_es_val": {
        "predictions_file": "mT5_small/mlsum_es_val",
        "N": 9977,
        "total_length": 213753,
        "mean_pred_length": 21.424576526009822,
        "std_pred_length": 6.774415295769904,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 86,
        "distinct-1": 0.11643345356556399,
        "vocab_size-1": 24888,
        "unique-1": 13670,
        "entropy-1": 9.956386633722119,
        "distinct-2": 0.4863183103015075,
        "vocab_size-2": 99100,
        "unique-2": 77294,
        "entropy-2": 15.142080645923228,
        "cond_entropy-2": 5.3737855840971935,
        "distinct-3": 0.8078679456550344,
        "vocab_size-3": 156564,
        "unique-3": 141577,
        "entropy-3": 16.938296574119374,
        "cond_entropy-3": 1.8437852568755926,
        "total_length-nopunct": 203165,
        "mean_pred_length-nopunct": 20.363335672045704,
        "std_pred_length-nopunct": 6.2178221135785545,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 81,
        "distinct-1-nopunct": 0.12240789506066498,
        "vocab_size-1-nopunct": 24869,
        "unique-1-nopunct": 13668,
        "entropy-1-nopunct": 10.103754759301864,
        "distinct-2-nopunct": 0.5072830610596931,
        "vocab_size-2-nopunct": 98001,
        "unique-2-nopunct": 77535,
        "entropy-2-nopunct": 15.21521619093252,
        "cond_entropy-2-nopunct": 5.307871414167487,
        "distinct-3-nopunct": 0.8249613833230538,
        "vocab_size-3-nopunct": 151142,
        "unique-3-nopunct": 137784,
        "entropy-3-nopunct": 16.927198450236048,
        "cond_entropy-3-nopunct": 1.753759983696282,
        "msttr-100": 0.69996,
        "msttr-100_nopunct": 0.71143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_val.json",
        "local_recall": {
            "1": 0.2711754394034641
        },
        "rouge1": {
            "precision": 0.31364,
            "recall": 0.29225,
            "fmeasure": 0.29189
        },
        "rouge2": {
            "precision": 0.12152,
            "recall": 0.11449,
            "fmeasure": 0.11381
        },
        "rougeL": {
            "precision": 0.25253,
            "recall": 0.23658,
            "fmeasure": 0.23574
        },
        "rougeLsum": {
            "precision": 0.25253,
            "recall": 0.23658,
            "fmeasure": 0.23574
        },
        "nist": 3.0234806982709013,
        "bleu": 9.02914,
        "bertscore": {
            "precision": 0.84111,
            "recall": 0.83773,
            "f1": 0.83921
        },
        "bleurt": -0.42647,
        "meteor": 0.2116151440707168,
        "nubia": {
            "semantic_relation": 1.70937,
            "contradiction": 29.2172,
            "irrelevancy": 58.42012,
            "logical_agreement": 12.36269,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.16448,
            "nubia_score": 0.19275
        }
    },
    "mlsum_es_test": {
        "predictions_file": "mT5_small/mlsum_es_test",
        "N": 13366,
        "total_length": 284412,
        "mean_pred_length": 21.27876702079904,
        "std_pred_length": 6.704607872765953,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 101,
        "distinct-1": 0.10291759841356905,
        "vocab_size-1": 29271,
        "unique-1": 15558,
        "entropy-1": 9.992055292586821,
        "distinct-2": 0.4533547811072659,
        "vocab_size-2": 122880,
        "unique-2": 94311,
        "entropy-2": 15.287135475633104,
        "cond_entropy-2": 5.486687454413602,
        "distinct-3": 0.7785198696057125,
        "vocab_size-3": 200609,
        "unique-3": 179390,
        "entropy-3": 17.212695599492964,
        "cond_entropy-3": 1.9753610224211315,
        "total_length-nopunct": 270204,
        "mean_pred_length-nopunct": 20.21577136016759,
        "std_pred_length-nopunct": 6.118485171661849,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 91,
        "distinct-1-nopunct": 0.10827374872318693,
        "vocab_size-1-nopunct": 29256,
        "unique-1-nopunct": 15557,
        "entropy-1-nopunct": 10.145860352994688,
        "distinct-2-nopunct": 0.4752139480917933,
        "vocab_size-2-nopunct": 122053,
        "unique-2-nopunct": 95214,
        "entropy-2-nopunct": 15.37737406706553,
        "cond_entropy-2-nopunct": 5.4317950850101715,
        "distinct-3-nopunct": 0.7986051784188736,
        "vocab_size-3-nopunct": 194438,
        "unique-3-nopunct": 175480,
        "entropy-3-nopunct": 17.217973472072977,
        "cond_entropy-3-nopunct": 1.8837839036951216,
        "msttr-100": 0.69721,
        "msttr-100_nopunct": 0.70998,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "local_recall": {
            "1": 0.2641344024667659
        },
        "rouge1": {
            "precision": 0.31323,
            "recall": 0.28727,
            "fmeasure": 0.28903
        },
        "rouge2": {
            "precision": 0.11856,
            "recall": 0.10956,
            "fmeasure": 0.10993
        },
        "rougeL": {
            "precision": 0.25107,
            "recall": 0.23165,
            "fmeasure": 0.23248
        },
        "rougeLsum": {
            "precision": 0.25107,
            "recall": 0.23165,
            "fmeasure": 0.23248
        },
        "nist": 2.94621615076205,
        "bleu": 8.38563,
        "bertscore": {
            "precision": 0.84041,
            "recall": 0.83608,
            "f1": 0.83803
        },
        "bleurt": -0.43742,
        "meteor": 0.2062407007760584,
        "nubia": {
            "semantic_relation": 1.68692,
            "contradiction": 29.92073,
            "irrelevancy": 58.15229,
            "logical_agreement": 11.92698,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.16099,
            "nubia_score": 0.18758
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 116,
        "total_length": 2717,
        "mean_pred_length": 23.42241379310345,
        "std_pred_length": 6.743005139515607,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 42,
        "distinct-1": 0.2020610967979389,
        "vocab_size-1": 549,
        "unique-1": 217,
        "entropy-1": 7.508217632025403,
        "distinct-2": 0.39869281045751637,
        "vocab_size-2": 1037,
        "unique-2": 538,
        "entropy-2": 9.332776160341327,
        "cond_entropy-2": 1.6575704865233274,
        "distinct-3": 0.523943661971831,
        "vocab_size-3": 1302,
        "unique-3": 794,
        "entropy-3": 9.908974391166218,
        "cond_entropy-3": 0.5925373025032247,
        "total_length-nopunct": 2272,
        "mean_pred_length-nopunct": 19.586206896551722,
        "std_pred_length-nopunct": 6.419352429362811,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.23899647887323944,
        "vocab_size-1-nopunct": 543,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.872916253472025,
        "distinct-2-nopunct": 0.42810760667903525,
        "vocab_size-2-nopunct": 923,
        "unique-2-nopunct": 510,
        "entropy-2-nopunct": 9.209925333327904,
        "cond_entropy-2-nopunct": 1.3867032604607488,
        "distinct-3-nopunct": 0.5519607843137255,
        "vocab_size-3-nopunct": 1126,
        "unique-3-nopunct": 724,
        "entropy-3-nopunct": 9.70717174926211,
        "cond_entropy-3-nopunct": 0.5323715671184565,
        "msttr-100": 0.50556,
        "msttr-100_nopunct": 0.54318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.22635135135135134,
            "2": 0.5742924528301887,
            "3": 0.8180354267310789
        },
        "rouge1": {
            "precision": 0.13003,
            "recall": 0.12413,
            "fmeasure": 0.12336
        },
        "rouge2": {
            "precision": 0.06753,
            "recall": 0.05562,
            "fmeasure": 0.05891
        },
        "rougeL": {
            "precision": 0.12859,
            "recall": 0.12269,
            "fmeasure": 0.12193
        },
        "rougeLsum": {
            "precision": 0.12859,
            "recall": 0.12269,
            "fmeasure": 0.12193
        },
        "nist": 6.796882394391381,
        "bleu": 39.87977,
        "bertscore": {
            "precision": 0.94994,
            "recall": 0.93551,
            "f1": 0.94176
        },
        "bleurt": 0.09897,
        "meteor": 0.5345599902086716,
        "nubia": {
            "semantic_relation": 3.97001,
            "contradiction": 17.5197,
            "irrelevancy": 19.10711,
            "logical_agreement": 63.37318,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.27347,
            "nubia_score": 0.84617
        }
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "mT5_small/mlsum_es_challenge_test_covid",
        "N": 1938,
        "total_length": 42865,
        "mean_pred_length": 22.11816305469556,
        "std_pred_length": 6.995794869179494,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 69,
        "distinct-1": 0.18649247637933045,
        "vocab_size-1": 7994,
        "unique-1": 4858,
        "entropy-1": 9.456846070081786,
        "distinct-2": 0.627922887091651,
        "vocab_size-2": 25699,
        "unique-2": 21386,
        "entropy-2": 13.815175690822818,
        "cond_entropy-2": 4.497365065753344,
        "distinct-3": 0.9070763548693221,
        "vocab_size-3": 35366,
        "unique-3": 33424,
        "entropy-3": 14.999837563195706,
        "cond_entropy-3": 1.1953108506960926,
        "total_length-nopunct": 41145,
        "mean_pred_length-nopunct": 21.230650154798763,
        "std_pred_length-nopunct": 6.403603675382722,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.19394823186292381,
        "vocab_size-1-nopunct": 7980,
        "unique-1-nopunct": 4855,
        "entropy-1-nopunct": 9.52178524994661,
        "distinct-2-nopunct": 0.6427933787333895,
        "vocab_size-2-nopunct": 25202,
        "unique-2-nopunct": 21145,
        "entropy-2-nopunct": 13.8143785024512,
        "cond_entropy-2-nopunct": 4.439623370293828,
        "distinct-3-nopunct": 0.9126619979071078,
        "vocab_size-3-nopunct": 34014,
        "unique-3-nopunct": 32277,
        "entropy-3-nopunct": 14.9497250411498,
        "cond_entropy-3-nopunct": 1.143148841295578,
        "msttr-100": 0.71734,
        "msttr-100_nopunct": 0.71937,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "local_recall": {
            "1": 0.20821693478470282
        },
        "rouge1": {
            "precision": 0.26229,
            "recall": 0.23058,
            "fmeasure": 0.23559
        },
        "rouge2": {
            "precision": 0.06207,
            "recall": 0.05414,
            "fmeasure": 0.05566
        },
        "rougeL": {
            "precision": 0.19576,
            "recall": 0.17261,
            "fmeasure": 0.17602
        },
        "rougeLsum": {
            "precision": 0.19576,
            "recall": 0.17261,
            "fmeasure": 0.17602
        },
        "nist": 1.7733550664837459,
        "bleu": 3.37528,
        "bertscore": {
            "precision": 0.83264,
            "recall": 0.82582,
            "f1": 0.82907
        },
        "bleurt": -0.5011,
        "meteor": 0.14965906689113412,
        "nubia": {
            "semantic_relation": 1.26679,
            "contradiction": 34.05294,
            "irrelevancy": 57.74788,
            "logical_agreement": 8.19918,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.20708,
            "nubia_score": 0.13619
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.75,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.30435,
            "recall": 0.51453,
            "fmeasure": 0.38207
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.625,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.625,
            "fmeasure": 0.5
        },
        "nist": 2.686635181843708,
        "bleu": 16.91896,
        "bertscore": {
            "precision": 0.8162,
            "recall": 0.8979,
            "f1": 0.8551
        },
        "bleurt": 0.10494,
        "meteor": 0.35646989703158616,
        "nubia": {
            "semantic_relation": 3.70549,
            "contradiction": 0.59356,
            "irrelevancy": 98.48319,
            "logical_agreement": 0.92325,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.13037,
            "nubia_score": 0.73671
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_small/web_nlg_ru_test",
        "N": 642,
        "total_length": 11490,
        "mean_pred_length": 17.897196261682243,
        "std_pred_length": 10.145914801269907,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.14560487380330722,
        "vocab_size-1": 1673,
        "unique-1": 588,
        "entropy-1": 8.592932797613768,
        "distinct-2": 0.33849557522123896,
        "vocab_size-2": 3672,
        "unique-2": 1830,
        "entropy-2": 11.05828602177943,
        "cond_entropy-2": 2.168929877461268,
        "distinct-3": 0.4796198314716833,
        "vocab_size-3": 4895,
        "unique-3": 2969,
        "entropy-3": 11.74806534868889,
        "cond_entropy-3": 0.7128223487095939,
        "total_length-nopunct": 9465,
        "mean_pred_length-nopunct": 14.742990654205608,
        "std_pred_length-nopunct": 8.641581848850356,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.17612255678816693,
        "vocab_size-1-nopunct": 1667,
        "unique-1-nopunct": 587,
        "entropy-1-nopunct": 9.220538370392331,
        "distinct-2-nopunct": 0.36654199251955116,
        "vocab_size-2-nopunct": 3234,
        "unique-2-nopunct": 1681,
        "entropy-2-nopunct": 10.952909783627016,
        "cond_entropy-2-nopunct": 1.8164404751028334,
        "distinct-3-nopunct": 0.5075174184085075,
        "vocab_size-3-nopunct": 4152,
        "unique-3-nopunct": 2612,
        "entropy-3-nopunct": 11.549187674661711,
        "cond_entropy-3-nopunct": 0.6563252673859583,
        "msttr-100": 0.57904,
        "msttr-100_nopunct": 0.62851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2797243805893564,
            "2": 0.6100817438692098,
            "3": 0.8306508047585724,
            "4": 0.881578947368421,
            "5": 0.9393939393939394,
            "6": 1.0,
            "7": 1.0
        },
        "rouge1": {
            "precision": 0.45358,
            "recall": 0.47821,
            "fmeasure": 0.4556
        },
        "rouge2": {
            "precision": 0.26088,
            "recall": 0.2903,
            "fmeasure": 0.26657
        },
        "rougeL": {
            "precision": 0.43315,
            "recall": 0.45816,
            "fmeasure": 0.43543
        },
        "rougeLsum": {
            "precision": 0.43315,
            "recall": 0.45816,
            "fmeasure": 0.43543
        },
        "nist": 8.592902011399854,
        "bleu": 49.85591,
        "bertscore": {
            "precision": 0.95476,
            "recall": 0.94902,
            "f1": 0.95118
        },
        "bleurt": 0.20211,
        "meteor": 0.629328580259755,
        "nubia": {
            "semantic_relation": 3.97185,
            "contradiction": 21.03157,
            "irrelevancy": 21.50916,
            "logical_agreement": 57.45927,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.63542,
            "nubia_score": 0.81535
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3076923076923077,
            "3": 0.6533333333333333
        },
        "rouge1": {
            "precision": 0.70079,
            "recall": 0.67016,
            "fmeasure": 0.68103
        },
        "rouge2": {
            "precision": 0.40455,
            "recall": 0.36463,
            "fmeasure": 0.38081
        },
        "rougeL": {
            "precision": 0.57341,
            "recall": 0.5505,
            "fmeasure": 0.55894
        },
        "rougeLsum": {
            "precision": 0.57341,
            "recall": 0.5505,
            "fmeasure": 0.55894
        },
        "nist": 3.75392553717206,
        "bleu": 23.43737,
        "bertscore": {
            "precision": 0.9004,
            "recall": 0.88958,
            "f1": 0.89168
        },
        "bleurt": 0.14496,
        "meteor": 0.2962869719858611,
        "nubia": {
            "semantic_relation": 4.01717,
            "contradiction": 0.50427,
            "irrelevancy": 37.71332,
            "logical_agreement": 61.78241,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.5272,
            "nubia_score": 0.66798
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.46086,
            "recall": 0.72584,
            "fmeasure": 0.54768
        },
        "rouge2": {
            "precision": 0.3063,
            "recall": 0.5162,
            "fmeasure": 0.36928
        },
        "rougeL": {
            "precision": 0.43522,
            "recall": 0.70362,
            "fmeasure": 0.51968
        },
        "rougeLsum": {
            "precision": 0.43522,
            "recall": 0.70362,
            "fmeasure": 0.51968
        },
        "nist": 2.13301823974804,
        "bleu": 21.44605,
        "bertscore": {
            "precision": 0.82555,
            "recall": 0.93543,
            "f1": 0.86552
        },
        "bleurt": -0.21363,
        "meteor": 0.35545427678200586,
        "nubia": {
            "semantic_relation": 3.59181,
            "contradiction": 34.88088,
            "irrelevancy": 63.70122,
            "logical_agreement": 1.41791,
            "grammar_ref": 5.41182,
            "grammar_hyp": 3.94271,
            "nubia_score": 0.49484
        }
    },
    "wiki_lingua_spanish_es_val": {
        "predictions_file": "mT5_small/wiki_lingua_spanish_es_val",
        "N": 11316,
        "total_length": 385352,
        "mean_pred_length": 34.053729232944505,
        "std_pred_length": 27.32094141731026,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 145,
        "distinct-1": 0.018388382569702506,
        "vocab_size-1": 7086,
        "unique-1": 1526,
        "entropy-1": 7.852049158589506,
        "distinct-2": 0.09100995626089467,
        "vocab_size-2": 34041,
        "unique-2": 13556,
        "entropy-2": 11.982776045785476,
        "cond_entropy-2": 3.9852475663969127,
        "distinct-3": 0.22225959417732685,
        "vocab_size-3": 80618,
        "unique-3": 42774,
        "entropy-3": 14.007912936272659,
        "cond_entropy-3": 2.0660045065587904,
        "total_length-nopunct": 318978,
        "mean_pred_length-nopunct": 28.188229056203607,
        "std_pred_length-nopunct": 23.41926761130311,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 128,
        "distinct-1-nopunct": 0.02216767300566183,
        "vocab_size-1-nopunct": 7071,
        "unique-1-nopunct": 1524,
        "entropy-1-nopunct": 8.648761229042616,
        "distinct-2-nopunct": 0.14881120699462078,
        "vocab_size-2-nopunct": 45784,
        "unique-2-nopunct": 22941,
        "entropy-2-nopunct": 12.580460773415922,
        "cond_entropy-2-nopunct": 4.060323635221062,
        "distinct-3-nopunct": 0.2985469981643451,
        "vocab_size-3-nopunct": 88475,
        "unique-3-nopunct": 53096,
        "entropy-3-nopunct": 14.58814155391424,
        "cond_entropy-3-nopunct": 2.077681299732628,
        "msttr-100": 0.29984,
        "msttr-100_nopunct": 0.33604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_val.json",
        "local_recall": {
            "1": 0.16808254538117404
        },
        "rouge1": {
            "precision": 0.32152,
            "recall": 0.23123,
            "fmeasure": 0.24336
        },
        "rouge2": {
            "precision": 0.09108,
            "recall": 0.06614,
            "fmeasure": 0.06894
        },
        "rougeL": {
            "precision": 0.28055,
            "recall": 0.20445,
            "fmeasure": 0.2135
        },
        "rougeLsum": {
            "precision": 0.28055,
            "recall": 0.20445,
            "fmeasure": 0.2135
        },
        "nist": 2.4406216651614803,
        "bleu": 5.15378,
        "sari": 65.83402,
        "bertscore": {
            "precision": 0.84103,
            "recall": 0.78906,
            "f1": 0.81341
        },
        "bleurt": -0.53491,
        "meteor": 0.11103104884271756,
        "nubia": {
            "semantic_relation": 2.83201,
            "contradiction": 18.47342,
            "irrelevancy": 27.67819,
            "logical_agreement": 53.8484,
            "grammar_ref": 3.95671,
            "grammar_hyp": 2.91247,
            "nubia_score": 0.42001
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "mT5_small/wiki_lingua_spanish_es_test",
        "N": 22632,
        "total_length": 762744,
        "mean_pred_length": 33.70201484623542,
        "std_pred_length": 27.101920006720576,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 146,
        "distinct-1": 0.012190197497456551,
        "vocab_size-1": 9298,
        "unique-1": 1940,
        "entropy-1": 7.907253710997009,
        "distinct-2": 0.0708500875543161,
        "vocab_size-2": 52437,
        "unique-2": 20460,
        "entropy-2": 12.190800343920305,
        "cond_entropy-2": 4.134777508467788,
        "distinct-3": 0.191156547917712,
        "vocab_size-3": 137151,
        "unique-3": 70750,
        "entropy-3": 14.4440427841758,
        "cond_entropy-3": 2.2927449097125723,
        "total_length-nopunct": 630787,
        "mean_pred_length-nopunct": 27.871465182043124,
        "std_pred_length-nopunct": 23.201962933368524,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 128,
        "distinct-1-nopunct": 0.014705439395548735,
        "vocab_size-1-nopunct": 9276,
        "unique-1-nopunct": 1939,
        "entropy-1-nopunct": 8.72028500853336,
        "distinct-2-nopunct": 0.12274975499707312,
        "vocab_size-2-nopunct": 74651,
        "unique-2-nopunct": 36470,
        "entropy-2-nopunct": 12.877341756588109,
        "cond_entropy-2-nopunct": 4.289244759258973,
        "distinct-3-nopunct": 0.2664740200297851,
        "vocab_size-3-nopunct": 156028,
        "unique-3-nopunct": 91868,
        "entropy-3-nopunct": 15.146175062350999,
        "cond_entropy-3-nopunct": 2.342184114592037,
        "msttr-100": 0.29922,
        "msttr-100_nopunct": 0.33602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "local_recall": {
            "1": 0.16553550879642268
        },
        "rouge1": {
            "precision": 0.32097,
            "recall": 0.22847,
            "fmeasure": 0.24164
        },
        "rouge2": {
            "precision": 0.09148,
            "recall": 0.06505,
            "fmeasure": 0.06844
        },
        "rougeL": {
            "precision": 0.28014,
            "recall": 0.20182,
            "fmeasure": 0.21193
        },
        "rougeLsum": {
            "precision": 0.28014,
            "recall": 0.20182,
            "fmeasure": 0.21193
        },
        "nist": 2.405689303324396,
        "bleu": 5.05696,
        "sari": 65.7619,
        "bertscore": {
            "precision": 0.8413,
            "recall": 0.78797,
            "f1": 0.81297
        },
        "bleurt": -0.54262,
        "meteor": 0.10955409324635798,
        "nubia": {
            "semantic_relation": 2.81607,
            "contradiction": 19.06933,
            "irrelevancy": 27.64968,
            "logical_agreement": 53.28099,
            "grammar_ref": 3.9494,
            "grammar_hyp": 2.93052,
            "nubia_score": 0.41889
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.43137,
            "recall": 0.41587,
            "fmeasure": 0.41174
        },
        "rouge2": {
            "precision": 0.15625,
            "recall": 0.15579,
            "fmeasure": 0.14602
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.33333,
            "fmeasure": 0.33309
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.33333,
            "fmeasure": 0.33309
        },
        "nist": 2.282779964284326,
        "bleu": 8.49819,
        "bertscore": {
            "precision": 0.79301,
            "recall": 0.83124,
            "f1": 0.79833
        },
        "bleurt": -0.04741,
        "meteor": 0.20954796651230506,
        "nubia": {
            "semantic_relation": 3.10993,
            "contradiction": 0.57412,
            "irrelevancy": 44.7874,
            "logical_agreement": 54.63847,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.47245,
            "nubia_score": 0.46693
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "mT5_small/e2e_nlg_test",
        "N": 500,
        "total_length": 12003,
        "mean_pred_length": 24.006,
        "std_pred_length": 6.763280564932968,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 42,
        "distinct-1": 0.010330750645671915,
        "vocab_size-1": 124,
        "unique-1": 9,
        "entropy-1": 5.711565924367581,
        "distinct-2": 0.030687646700860646,
        "vocab_size-2": 353,
        "unique-2": 51,
        "entropy-2": 7.140977113571016,
        "cond_entropy-2": 1.33954988754693,
        "distinct-3": 0.05816595473961647,
        "vocab_size-3": 640,
        "unique-3": 140,
        "entropy-3": 7.9496535696119786,
        "cond_entropy-3": 0.8512341888809389,
        "total_length-nopunct": 11016,
        "mean_pred_length-nopunct": 22.032,
        "std_pred_length-nopunct": 6.34972251362215,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.011074800290486565,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 5.760372070122925,
        "distinct-2-nopunct": 0.03195131228604032,
        "vocab_size-2-nopunct": 336,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 7.086365718744117,
        "cond_entropy-2-nopunct": 1.376143427984226,
        "distinct-3-nopunct": 0.06299920127795527,
        "vocab_size-3-nopunct": 631,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.9462462669294105,
        "cond_entropy-3-nopunct": 0.8817176658565377,
        "msttr-100": 0.46267,
        "msttr-100_nopunct": 0.47118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.7065005114851669
        },
        "rouge1": {
            "precision": 0.77942,
            "recall": 0.71205,
            "fmeasure": 0.73404
        },
        "rouge2": {
            "precision": 0.47982,
            "recall": 0.43485,
            "fmeasure": 0.44953
        },
        "rougeL": {
            "precision": 0.55597,
            "recall": 0.50531,
            "fmeasure": 0.52195
        },
        "rougeLsum": {
            "precision": 0.55597,
            "recall": 0.50531,
            "fmeasure": 0.52195
        },
        "nist": 5.395112954292371,
        "bleu": 32.28275,
        "bertscore": {
            "precision": 0.92548,
            "recall": 0.90522,
            "f1": 0.91495
        },
        "bleurt": 0.23006,
        "meteor": 0.3654775015807295,
        "nubia": {
            "semantic_relation": 4.30406,
            "contradiction": 2.29938,
            "irrelevancy": 12.90497,
            "logical_agreement": 84.79566,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.43707,
            "nubia_score": 0.79693
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 500,
        "total_length": 14097,
        "mean_pred_length": 28.194,
        "std_pred_length": 15.21513601648043,
        "median_pred_length": 26.0,
        "min_pred_length": 7,
        "max_pred_length": 92,
        "distinct-1": 0.09541037100092219,
        "vocab_size-1": 1345,
        "unique-1": 449,
        "entropy-1": 7.692578056589849,
        "distinct-2": 0.2844745164374494,
        "vocab_size-2": 3868,
        "unique-2": 1962,
        "entropy-2": 10.77911091778406,
        "cond_entropy-2": 2.953658658174243,
        "distinct-3": 0.4681988241582042,
        "vocab_size-3": 6132,
        "unique-3": 3933,
        "entropy-3": 11.938171511677783,
        "cond_entropy-3": 1.216081933139798,
        "total_length-nopunct": 12548,
        "mean_pred_length-nopunct": 25.096,
        "std_pred_length-nopunct": 13.962477717081592,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.10647115078100096,
        "vocab_size-1-nopunct": 1336,
        "unique-1-nopunct": 449,
        "entropy-1-nopunct": 7.897520257224852,
        "distinct-2-nopunct": 0.29764276228419656,
        "vocab_size-2-nopunct": 3586,
        "unique-2-nopunct": 1901,
        "entropy-2-nopunct": 10.682301282964714,
        "cond_entropy-2-nopunct": 2.9156325202554787,
        "distinct-3-nopunct": 0.48190162798753033,
        "vocab_size-3-nopunct": 5565,
        "unique-3-nopunct": 3665,
        "entropy-3-nopunct": 11.806570684420976,
        "cond_entropy-3-nopunct": 1.1787798240640557,
        "msttr-100": 0.48721,
        "msttr-100_nopunct": 0.50096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22474797390788692,
            "2": 0.5561588055649813,
            "3": 0.7485041136873598,
            "4": 0.4,
            "5": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.62108,
            "recall": 0.67521,
            "fmeasure": 0.63648
        },
        "rouge2": {
            "precision": 0.38487,
            "recall": 0.41327,
            "fmeasure": 0.39139
        },
        "rougeL": {
            "precision": 0.49519,
            "recall": 0.54015,
            "fmeasure": 0.50773
        },
        "rougeLsum": {
            "precision": 0.49519,
            "recall": 0.54015,
            "fmeasure": 0.50773
        },
        "nist": 6.819873290730158,
        "bleu": 34.95756,
        "bertscore": {
            "precision": 0.88192,
            "recall": 0.88735,
            "f1": 0.88322
        },
        "bleurt": -0.15284,
        "meteor": 0.32468774673300516,
        "nubia": {
            "semantic_relation": 3.75313,
            "contradiction": 30.4376,
            "irrelevancy": 14.10499,
            "logical_agreement": 55.45741,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.50347,
            "nubia_score": 0.59242
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 500,
        "total_length": 14144,
        "mean_pred_length": 28.288,
        "std_pred_length": 14.724301545404453,
        "median_pred_length": 27.0,
        "min_pred_length": 5,
        "max_pred_length": 96,
        "distinct-1": 0.09488122171945701,
        "vocab_size-1": 1342,
        "unique-1": 450,
        "entropy-1": 7.7050335040556215,
        "distinct-2": 0.28048959249486954,
        "vocab_size-2": 3827,
        "unique-2": 1949,
        "entropy-2": 10.766059286251283,
        "cond_entropy-2": 2.928830370585178,
        "distinct-3": 0.459373097991479,
        "vocab_size-3": 6038,
        "unique-3": 3852,
        "entropy-3": 11.90627928589746,
        "cond_entropy-3": 1.1968368868345327,
        "total_length-nopunct": 12598,
        "mean_pred_length-nopunct": 25.196,
        "std_pred_length-nopunct": 13.50961080120371,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 92,
        "distinct-1-nopunct": 0.10581044610255597,
        "vocab_size-1-nopunct": 1333,
        "unique-1-nopunct": 450,
        "entropy-1-nopunct": 7.912117316471402,
        "distinct-2-nopunct": 0.2907092081335758,
        "vocab_size-2-nopunct": 3517,
        "unique-2-nopunct": 1844,
        "entropy-2-nopunct": 10.659014843904144,
        "cond_entropy-2-nopunct": 2.8754788930041757,
        "distinct-3-nopunct": 0.4702534919813761,
        "vocab_size-3-nopunct": 5454,
        "unique-3-nopunct": 3541,
        "entropy-3-nopunct": 11.768884172662602,
        "cond_entropy-3-nopunct": 1.164862635573477,
        "msttr-100": 0.58752,
        "msttr-100_nopunct": 0.61928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22747229772109553,
            "2": 0.5541795665634675,
            "3": 0.7524645993905718,
            "4": 0.6666666666666666,
            "5": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.62468,
            "recall": 0.67166,
            "fmeasure": 0.63691
        },
        "rouge2": {
            "precision": 0.3868,
            "recall": 0.41376,
            "fmeasure": 0.39305
        },
        "rougeL": {
            "precision": 0.49934,
            "recall": 0.53956,
            "fmeasure": 0.50966
        },
        "rougeLsum": {
            "precision": 0.49934,
            "recall": 0.53956,
            "fmeasure": 0.50966
        },
        "nist": 6.915176444555227,
        "bleu": 36.61116,
        "bertscore": {
            "precision": 0.88394,
            "recall": 0.88733,
            "f1": 0.88402
        },
        "bleurt": -0.15359,
        "meteor": 0.3292493247183192,
        "nubia": {
            "semantic_relation": 3.77029,
            "contradiction": 27.6389,
            "irrelevancy": 13.87597,
            "logical_agreement": 58.48513,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.43904,
            "nubia_score": 0.59659
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7860,
        "mean_pred_length": 21.894150417827298,
        "std_pred_length": 9.120972452778172,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3713740458015267,
        "vocab_size-1": 2919,
        "unique-1": 2124,
        "entropy-1": 9.290508185850303,
        "distinct-2": 0.8404212771630449,
        "vocab_size-2": 6304,
        "unique-2": 5837,
        "entropy-2": 12.315126428639841,
        "cond_entropy-2": 2.78775666453281,
        "distinct-3": 0.9687762531503781,
        "vocab_size-3": 6919,
        "unique-3": 6802,
        "entropy-3": 12.706209863482327,
        "cond_entropy-3": 0.4038224981293277,
        "total_length-nopunct": 6969,
        "mean_pred_length-nopunct": 19.41225626740947,
        "std_pred_length-nopunct": 7.982394638024873,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.41698952503946046,
        "vocab_size-1-nopunct": 2906,
        "unique-1-nopunct": 2123,
        "entropy-1-nopunct": 9.636808098693828,
        "distinct-2-nopunct": 0.8644478063540091,
        "vocab_size-2-nopunct": 5714,
        "unique-2-nopunct": 5337,
        "entropy-2-nopunct": 12.23112865091686,
        "cond_entropy-2-nopunct": 2.7206886997032753,
        "distinct-3-nopunct": 0.9833626619740842,
        "vocab_size-3-nopunct": 6147,
        "unique-3-nopunct": 6066,
        "entropy-3-nopunct": 12.57329021366977,
        "cond_entropy-3-nopunct": 0.36196576729118807,
        "msttr-100": 0.72974,
        "msttr-100_nopunct": 0.76783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.19002695417789758,
            "3": 0.43132530120481927,
            "4": 0.6406727828746177,
            "5": 0.7526555386949925,
            "6": 0.8690140845070422,
            "7": 0.9180327868852459,
            "8": 0.9529553679131484,
            "9": 0.9661375661375662,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.89752,
            "recall": 0.92032,
            "fmeasure": 0.90502
        },
        "rouge2": {
            "precision": 0.80505,
            "recall": 0.83496,
            "fmeasure": 0.81467
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "nist": 13.589369172315616,
        "bleu": 88.22733,
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.98001,
            "f1": 0.97453
        },
        "bleurt": 0.31744,
        "meteor": 0.5587553144887645,
        "nubia": {
            "semantic_relation": 4.40729,
            "contradiction": 2.29327,
            "irrelevancy": 33.60574,
            "logical_agreement": 64.10099,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70464,
            "nubia_score": 0.70017
        }
    },
    "wiki_lingua_russian_ru_val": {
        "predictions_file": "mT5_small/wiki_lingua_russian_ru_val",
        "N": 5288,
        "total_length": 156193,
        "mean_pred_length": 29.537254160363087,
        "std_pred_length": 25.64162512215529,
        "median_pred_length": 21.0,
        "min_pred_length": 2,
        "max_pred_length": 155,
        "distinct-1": 0.02920105254396804,
        "vocab_size-1": 4561,
        "unique-1": 954,
        "entropy-1": 7.6960308720070865,
        "distinct-2": 0.11605977270468175,
        "vocab_size-2": 17514,
        "unique-2": 6621,
        "entropy-2": 11.534773799567915,
        "cond_entropy-2": 3.668684518202366,
        "distinct-3": 0.2531709896509336,
        "vocab_size-3": 36866,
        "unique-3": 19511,
        "entropy-3": 13.228786010194751,
        "cond_entropy-3": 1.743081413022247,
        "total_length-nopunct": 128188,
        "mean_pred_length-nopunct": 24.24130105900151,
        "std_pred_length-nopunct": 21.89671161493867,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 125,
        "distinct-1-nopunct": 0.03547914001310575,
        "vocab_size-1-nopunct": 4548,
        "unique-1-nopunct": 953,
        "entropy-1-nopunct": 8.509425377175535,
        "distinct-2-nopunct": 0.18044458186197132,
        "vocab_size-2-nopunct": 22177,
        "unique-2-nopunct": 11014,
        "entropy-2-nopunct": 12.024592528820625,
        "cond_entropy-2-nopunct": 3.662016583862824,
        "distinct-3-nopunct": 0.3350139436811318,
        "vocab_size-3-nopunct": 39403,
        "unique-3-nopunct": 23953,
        "entropy-3-nopunct": 13.672977932071287,
        "cond_entropy-3-nopunct": 1.7214300734775636,
        "msttr-100": 0.31265,
        "msttr-100_nopunct": 0.35375,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_val.json",
        "local_recall": {
            "1": 0.14839456175875035
        },
        "rouge1": {
            "precision": 0.32165,
            "recall": 0.20441,
            "fmeasure": 0.22454
        },
        "rouge2": {
            "precision": 0.08651,
            "recall": 0.05589,
            "fmeasure": 0.06074
        },
        "rougeL": {
            "precision": 0.28224,
            "recall": 0.18164,
            "fmeasure": 0.19805
        },
        "rougeLsum": {
            "precision": 0.28224,
            "recall": 0.18164,
            "fmeasure": 0.19805
        },
        "nist": 1.8612568133379184,
        "bleu": 4.53414,
        "sari": 67.05901,
        "bertscore": {
            "precision": 0.83889,
            "recall": 0.78286,
            "f1": 0.80908
        },
        "bleurt": -0.59327,
        "meteor": 0.10067493333804124,
        "nubia": {
            "semantic_relation": 2.70662,
            "contradiction": 19.1659,
            "irrelevancy": 27.38027,
            "logical_agreement": 53.45383,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.06503,
            "nubia_score": 0.40722
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7860,
        "mean_pred_length": 21.894150417827298,
        "std_pred_length": 9.120972452778172,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3713740458015267,
        "vocab_size-1": 2919,
        "unique-1": 2124,
        "entropy-1": 9.290508185850303,
        "distinct-2": 0.8404212771630449,
        "vocab_size-2": 6304,
        "unique-2": 5837,
        "entropy-2": 12.315126428639841,
        "cond_entropy-2": 2.78775666453281,
        "distinct-3": 0.9687762531503781,
        "vocab_size-3": 6919,
        "unique-3": 6802,
        "entropy-3": 12.706209863482327,
        "cond_entropy-3": 0.4038224981293277,
        "total_length-nopunct": 6969,
        "mean_pred_length-nopunct": 19.41225626740947,
        "std_pred_length-nopunct": 7.982394638024873,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.41698952503946046,
        "vocab_size-1-nopunct": 2906,
        "unique-1-nopunct": 2123,
        "entropy-1-nopunct": 9.636808098693828,
        "distinct-2-nopunct": 0.8644478063540091,
        "vocab_size-2-nopunct": 5714,
        "unique-2-nopunct": 5337,
        "entropy-2-nopunct": 12.23112865091686,
        "cond_entropy-2-nopunct": 2.7206886997032753,
        "distinct-3-nopunct": 0.9833626619740842,
        "vocab_size-3-nopunct": 6147,
        "unique-3-nopunct": 6066,
        "entropy-3-nopunct": 12.57329021366977,
        "cond_entropy-3-nopunct": 0.36196576729118807,
        "msttr-100": 0.72974,
        "msttr-100_nopunct": 0.76783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.19002695417789758,
            "3": 0.43132530120481927,
            "4": 0.6406727828746177,
            "5": 0.7526555386949925,
            "6": 0.8690140845070422,
            "7": 0.9180327868852459,
            "8": 0.9529553679131484,
            "9": 0.9661375661375662,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.89752,
            "recall": 0.92032,
            "fmeasure": 0.90502
        },
        "rouge2": {
            "precision": 0.80505,
            "recall": 0.83496,
            "fmeasure": 0.81467
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "nist": 13.589369172315616,
        "bleu": 88.22733,
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.98001,
            "f1": 0.97453
        },
        "bleurt": 0.31744,
        "meteor": 0.5587553144887645,
        "nubia": {
            "semantic_relation": 4.40729,
            "contradiction": 2.29327,
            "irrelevancy": 33.60574,
            "logical_agreement": 64.10099,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70464,
            "nubia_score": 0.70017
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/web_nlg_en_test",
        "N": 349,
        "total_length": 7021,
        "mean_pred_length": 20.117478510028654,
        "std_pred_length": 6.813559584765824,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 51,
        "distinct-1": 0.1459905996296824,
        "vocab_size-1": 1025,
        "unique-1": 428,
        "entropy-1": 7.44368816944603,
        "distinct-2": 0.3735011990407674,
        "vocab_size-2": 2492,
        "unique-2": 1420,
        "entropy-2": 10.354518805882899,
        "cond_entropy-2": 2.7423556878825965,
        "distinct-3": 0.5604934366598133,
        "vocab_size-3": 3544,
        "unique-3": 2444,
        "entropy-3": 11.318643256336452,
        "cond_entropy-3": 1.0421844649713325,
        "total_length-nopunct": 6149,
        "mean_pred_length-nopunct": 17.6189111747851,
        "std_pred_length-nopunct": 5.93815190931718,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.16539274678809562,
        "vocab_size-1-nopunct": 1017,
        "unique-1-nopunct": 428,
        "entropy-1-nopunct": 7.701685584211831,
        "distinct-2-nopunct": 0.3786206896551724,
        "vocab_size-2-nopunct": 2196,
        "unique-2-nopunct": 1254,
        "entropy-2-nopunct": 10.197532063581368,
        "cond_entropy-2-nopunct": 2.674289321270959,
        "distinct-3-nopunct": 0.5661346541918914,
        "vocab_size-3-nopunct": 3086,
        "unique-3-nopunct": 2135,
        "entropy-3-nopunct": 11.135716917147747,
        "cond_entropy-3-nopunct": 1.0106806648846738,
        "msttr-100": 0.59057,
        "msttr-100_nopunct": 0.63311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23894862604540024,
            "2": 0.5491913746630728,
            "3": 0.7559808612440191,
            "4": 1.0
        },
        "rouge1": {
            "precision": 0.62545,
            "recall": 0.69093,
            "fmeasure": 0.64714
        },
        "rouge2": {
            "precision": 0.40049,
            "recall": 0.44244,
            "fmeasure": 0.4141
        },
        "rougeL": {
            "precision": 0.51506,
            "recall": 0.57125,
            "fmeasure": 0.53318
        },
        "rougeLsum": {
            "precision": 0.51506,
            "recall": 0.57125,
            "fmeasure": 0.53318
        },
        "nist": 6.557046472021107,
        "bleu": 35.38531,
        "bertscore": {
            "precision": 0.88318,
            "recall": 0.89283,
            "f1": 0.88651
        },
        "bleurt": -0.09643,
        "meteor": 0.3500929225246266,
        "nubia": {
            "semantic_relation": 3.89148,
            "contradiction": 25.10963,
            "irrelevancy": 13.42341,
            "logical_agreement": 61.46695,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.63665,
            "nubia_score": 0.63172
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7860,
        "mean_pred_length": 21.894150417827298,
        "std_pred_length": 9.120972452778172,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3713740458015267,
        "vocab_size-1": 2919,
        "unique-1": 2124,
        "entropy-1": 9.290508185850303,
        "distinct-2": 0.8404212771630449,
        "vocab_size-2": 6304,
        "unique-2": 5837,
        "entropy-2": 12.315126428639841,
        "cond_entropy-2": 2.78775666453281,
        "distinct-3": 0.9687762531503781,
        "vocab_size-3": 6919,
        "unique-3": 6802,
        "entropy-3": 12.706209863482327,
        "cond_entropy-3": 0.4038224981293277,
        "total_length-nopunct": 6969,
        "mean_pred_length-nopunct": 19.41225626740947,
        "std_pred_length-nopunct": 7.982394638024873,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.41698952503946046,
        "vocab_size-1-nopunct": 2906,
        "unique-1-nopunct": 2123,
        "entropy-1-nopunct": 9.636808098693828,
        "distinct-2-nopunct": 0.8644478063540091,
        "vocab_size-2-nopunct": 5714,
        "unique-2-nopunct": 5337,
        "entropy-2-nopunct": 12.23112865091686,
        "cond_entropy-2-nopunct": 2.7206886997032753,
        "distinct-3-nopunct": 0.9833626619740842,
        "vocab_size-3-nopunct": 6147,
        "unique-3-nopunct": 6066,
        "entropy-3-nopunct": 12.57329021366977,
        "cond_entropy-3-nopunct": 0.36196576729118807,
        "msttr-100": 0.72974,
        "msttr-100_nopunct": 0.76783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.19002695417789758,
            "3": 0.43132530120481927,
            "4": 0.6406727828746177,
            "5": 0.7526555386949925,
            "6": 0.8690140845070422,
            "7": 0.9180327868852459,
            "8": 0.9529553679131484,
            "9": 0.9661375661375662,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.89752,
            "recall": 0.92032,
            "fmeasure": 0.90502
        },
        "rouge2": {
            "precision": 0.80505,
            "recall": 0.83496,
            "fmeasure": 0.81467
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "nist": 13.589369172315616,
        "bleu": 88.22733,
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.98001,
            "f1": 0.97453
        },
        "bleurt": 0.31744,
        "meteor": 0.5587553144887645,
        "nubia": {
            "semantic_relation": 4.40729,
            "contradiction": 2.29327,
            "irrelevancy": 33.60574,
            "logical_agreement": 64.10099,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70464,
            "nubia_score": 0.70017
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.59375,
            "recall": 0.46072,
            "fmeasure": 0.51826
        },
        "rouge2": {
            "precision": 0.35484,
            "recall": 0.27498,
            "fmeasure": 0.30924
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.33815,
            "fmeasure": 0.38106
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.33815,
            "fmeasure": 0.38106
        },
        "nist": 3.5731817363729506,
        "bleu": 37.29896,
        "bertscore": {
            "precision": 0.93742,
            "recall": 0.87154,
            "f1": 0.90329
        },
        "bleurt": -0.58557,
        "meteor": 0.27588248781884644,
        "nubia": {
            "semantic_relation": 2.92275,
            "contradiction": 15.47167,
            "irrelevancy": 53.85029,
            "logical_agreement": 30.67804,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.28492,
            "nubia_score": 0.43007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "mT5_small/totto_test",
        "N": 71,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25139664804469275,
            "2": 0.6684210526315789,
            "3": 0.7951807228915663
        },
        "rouge1": {
            "precision": 0.75297,
            "recall": 0.77433,
            "fmeasure": 0.7489
        },
        "rouge2": {
            "precision": 0.56703,
            "recall": 0.59039,
            "fmeasure": 0.56577
        },
        "rougeL": {
            "precision": 0.71601,
            "recall": 0.74368,
            "fmeasure": 0.71539
        },
        "rougeLsum": {
            "precision": 0.71601,
            "recall": 0.74368,
            "fmeasure": 0.71539
        },
        "nist": 7.102657597294052,
        "bleu": 54.49358,
        "bertscore": {
            "precision": 0.94223,
            "recall": 0.94619,
            "f1": 0.94276
        },
        "bleurt": 0.39038,
        "meteor": 0.42989131434299516,
        "nubia": {
            "semantic_relation": 4.08957,
            "contradiction": 11.25778,
            "irrelevancy": 44.14695,
            "logical_agreement": 44.59527,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.16379,
            "nubia_score": 0.68942
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "mT5_small/wiki_lingua_russian_ru_test",
        "N": 10580,
        "total_length": 317963,
        "mean_pred_length": 30.05321361058601,
        "std_pred_length": 26.122264223463088,
        "median_pred_length": 22.0,
        "min_pred_length": 2,
        "max_pred_length": 151,
        "distinct-1": 0.019065111349433738,
        "vocab_size-1": 6062,
        "unique-1": 1236,
        "entropy-1": 7.778800639846009,
        "distinct-2": 0.08752273222657075,
        "vocab_size-2": 26903,
        "unique-2": 9947,
        "entropy-2": 11.764239786835994,
        "cond_entropy-2": 3.816883464713117,
        "distinct-3": 0.2112579724598471,
        "vocab_size-3": 62702,
        "unique-3": 31733,
        "entropy-3": 13.681743498285451,
        "cond_entropy-3": 1.9622665081475255,
        "total_length-nopunct": 261277,
        "mean_pred_length-nopunct": 24.695368620037808,
        "std_pred_length-nopunct": 22.322035475629733,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 126,
        "distinct-1-nopunct": 0.02312105543159176,
        "vocab_size-1-nopunct": 6041,
        "unique-1-nopunct": 1235,
        "entropy-1-nopunct": 8.591658670083573,
        "distinct-2-nopunct": 0.1444777286271006,
        "vocab_size-2-nopunct": 36221,
        "unique-2-nopunct": 17454,
        "entropy-2-nopunct": 12.339677664072687,
        "cond_entropy-2-nopunct": 3.890987797006398,
        "distinct-3-nopunct": 0.2899013034606255,
        "vocab_size-3-nopunct": 69614,
        "unique-3-nopunct": 40799,
        "entropy-3-nopunct": 14.235764775666418,
        "cond_entropy-3-nopunct": 1.9714262808642276,
        "msttr-100": 0.31056,
        "msttr-100_nopunct": 0.35013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "local_recall": {
            "1": 0.14988778213972062
        },
        "rouge1": {
            "precision": 0.31723,
            "recall": 0.20574,
            "fmeasure": 0.22414
        },
        "rouge2": {
            "precision": 0.08553,
            "recall": 0.05568,
            "fmeasure": 0.05988
        },
        "rougeL": {
            "precision": 0.2785,
            "recall": 0.18281,
            "fmeasure": 0.19772
        },
        "rougeLsum": {
            "precision": 0.2785,
            "recall": 0.18281,
            "fmeasure": 0.19772
        },
        "nist": 1.9771872681122336,
        "bleu": 4.60228,
        "sari": 66.9138,
        "bertscore": {
            "precision": 0.83779,
            "recall": 0.78265,
            "f1": 0.80847
        },
        "bleurt": -0.59679,
        "meteor": 0.10081433118509253,
        "nubia": {
            "semantic_relation": 2.69952,
            "contradiction": 19.82347,
            "irrelevancy": 27.44566,
            "logical_agreement": 52.73088,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.04736,
            "nubia_score": 0.4007
        }
    },
    "wiki_lingua_turkish_tr_val": {
        "predictions_file": "mT5_small/wiki_lingua_turkish_tr_val",
        "N": 449,
        "total_length": 16912,
        "mean_pred_length": 37.665924276169264,
        "std_pred_length": 19.2278501058067,
        "median_pred_length": 34.0,
        "min_pred_length": 3,
        "max_pred_length": 112,
        "distinct-1": 0.1400189214758751,
        "vocab_size-1": 2368,
        "unique-1": 1096,
        "entropy-1": 8.163217872076675,
        "distinct-2": 0.4532588228147968,
        "vocab_size-2": 7462,
        "unique-2": 5017,
        "entropy-2": 11.868615549868396,
        "cond_entropy-2": 3.5659399150349005,
        "distinct-3": 0.7000749344323717,
        "vocab_size-3": 11211,
        "unique-3": 8996,
        "entropy-3": 13.064226506148163,
        "cond_entropy-3": 1.2050320065672802,
        "total_length-nopunct": 14261,
        "mean_pred_length-nopunct": 31.761692650334076,
        "std_pred_length-nopunct": 16.654587382357537,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 98,
        "distinct-1-nopunct": 0.16534604866418906,
        "vocab_size-1-nopunct": 2358,
        "unique-1-nopunct": 1094,
        "entropy-1-nopunct": 8.858706650327441,
        "distinct-2-nopunct": 0.5488705473501303,
        "vocab_size-2-nopunct": 7581,
        "unique-2-nopunct": 5491,
        "entropy-2-nopunct": 12.201849010768106,
        "cond_entropy-2-nopunct": 3.4178695015898346,
        "distinct-3-nopunct": 0.7876225398488363,
        "vocab_size-3-nopunct": 10525,
        "unique-3-nopunct": 8895,
        "entropy-3-nopunct": 13.140073666863112,
        "cond_entropy-3-nopunct": 0.953512706442289,
        "msttr-100": 0.56935,
        "msttr-100_nopunct": 0.63408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_val.json",
        "local_recall": {
            "1": 0.2819264069264069
        },
        "rouge1": {
            "precision": 0.3172,
            "recall": 0.31543,
            "fmeasure": 0.29327
        },
        "rouge2": {
            "precision": 0.12075,
            "recall": 0.12487,
            "fmeasure": 0.11533
        },
        "rougeL": {
            "precision": 0.25228,
            "recall": 0.25381,
            "fmeasure": 0.23437
        },
        "rougeLsum": {
            "precision": 0.25228,
            "recall": 0.25381,
            "fmeasure": 0.23437
        },
        "nist": 3.2069083304301613,
        "bleu": 13.60097,
        "sari": 67.47525,
        "bertscore": {
            "precision": 0.82766,
            "recall": 0.81974,
            "f1": 0.8231
        },
        "bleurt": -0.59484,
        "meteor": 0.1519699698471558,
        "nubia": {
            "semantic_relation": 2.31493,
            "contradiction": 28.708,
            "irrelevancy": 46.66721,
            "logical_agreement": 24.62478,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.85736,
            "nubia_score": 0.27316
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7860,
        "mean_pred_length": 21.894150417827298,
        "std_pred_length": 9.120972452778172,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3713740458015267,
        "vocab_size-1": 2919,
        "unique-1": 2124,
        "entropy-1": 9.290508185850303,
        "distinct-2": 0.8404212771630449,
        "vocab_size-2": 6304,
        "unique-2": 5837,
        "entropy-2": 12.315126428639841,
        "cond_entropy-2": 2.78775666453281,
        "distinct-3": 0.9687762531503781,
        "vocab_size-3": 6919,
        "unique-3": 6802,
        "entropy-3": 12.706209863482327,
        "cond_entropy-3": 0.4038224981293277,
        "total_length-nopunct": 6969,
        "mean_pred_length-nopunct": 19.41225626740947,
        "std_pred_length-nopunct": 7.982394638024873,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.41698952503946046,
        "vocab_size-1-nopunct": 2906,
        "unique-1-nopunct": 2123,
        "entropy-1-nopunct": 9.636808098693828,
        "distinct-2-nopunct": 0.8644478063540091,
        "vocab_size-2-nopunct": 5714,
        "unique-2-nopunct": 5337,
        "entropy-2-nopunct": 12.23112865091686,
        "cond_entropy-2-nopunct": 2.7206886997032753,
        "distinct-3-nopunct": 0.9833626619740842,
        "vocab_size-3-nopunct": 6147,
        "unique-3-nopunct": 6066,
        "entropy-3-nopunct": 12.57329021366977,
        "cond_entropy-3-nopunct": 0.36196576729118807,
        "msttr-100": 0.72974,
        "msttr-100_nopunct": 0.76783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.19002695417789758,
            "3": 0.43132530120481927,
            "4": 0.6406727828746177,
            "5": 0.7526555386949925,
            "6": 0.8690140845070422,
            "7": 0.9180327868852459,
            "8": 0.9529553679131484,
            "9": 0.9661375661375662,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.89752,
            "recall": 0.92032,
            "fmeasure": 0.90502
        },
        "rouge2": {
            "precision": 0.80505,
            "recall": 0.83496,
            "fmeasure": 0.81467
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "nist": 13.589369172315616,
        "bleu": 88.22733,
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.98001,
            "f1": 0.97453
        },
        "bleurt": 0.31744,
        "meteor": 0.5587553144887645,
        "nubia": {
            "semantic_relation": 4.40729,
            "contradiction": 2.29327,
            "irrelevancy": 33.60574,
            "logical_agreement": 64.10099,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70464,
            "nubia_score": 0.70017
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "mT5_small/wiki_lingua_turkish_tr_test",
        "N": 900,
        "total_length": 34628,
        "mean_pred_length": 38.47555555555556,
        "std_pred_length": 19.786596535764705,
        "median_pred_length": 35.0,
        "min_pred_length": 5,
        "max_pred_length": 117,
        "distinct-1": 0.09717569596858033,
        "vocab_size-1": 3365,
        "unique-1": 1392,
        "entropy-1": 8.241827924828616,
        "distinct-2": 0.36432637571157495,
        "vocab_size-2": 12288,
        "unique-2": 7632,
        "entropy-2": 12.223488930597156,
        "cond_entropy-2": 3.844084437761664,
        "distinct-3": 0.6059156817351041,
        "vocab_size-3": 19891,
        "unique-3": 14914,
        "entropy-3": 13.679065667143597,
        "cond_entropy-3": 1.4664992493036697,
        "total_length-nopunct": 29193,
        "mean_pred_length-nopunct": 32.43666666666667,
        "std_pred_length-nopunct": 17.048016828293484,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 104,
        "distinct-1-nopunct": 0.11465077244544924,
        "vocab_size-1-nopunct": 3347,
        "unique-1-nopunct": 1391,
        "entropy-1-nopunct": 8.94518340478724,
        "distinct-2-nopunct": 0.45566041070229385,
        "vocab_size-2-nopunct": 12892,
        "unique-2-nopunct": 8640,
        "entropy-2-nopunct": 12.667458017652667,
        "cond_entropy-2-nopunct": 3.7990957683559365,
        "distinct-3-nopunct": 0.7047785930712226,
        "vocab_size-3-nopunct": 19306,
        "unique-3-nopunct": 15311,
        "entropy-3-nopunct": 13.888140093426097,
        "cond_entropy-3-nopunct": 1.240651317302207,
        "msttr-100": 0.56569,
        "msttr-100_nopunct": 0.6356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "local_recall": {
            "1": 0.28186042315153154
        },
        "rouge1": {
            "precision": 0.31967,
            "recall": 0.30947,
            "fmeasure": 0.29222
        },
        "rouge2": {
            "precision": 0.12007,
            "recall": 0.11621,
            "fmeasure": 0.11131
        },
        "rougeL": {
            "precision": 0.25579,
            "recall": 0.24968,
            "fmeasure": 0.23481
        },
        "rougeLsum": {
            "precision": 0.25579,
            "recall": 0.24968,
            "fmeasure": 0.23481
        },
        "nist": 3.221748943352219,
        "bleu": 13.27295,
        "sari": 66.58505,
        "bertscore": {
            "precision": 0.82726,
            "recall": 0.8206,
            "f1": 0.82341
        },
        "bleurt": -0.57233,
        "meteor": 0.15231067866533154,
        "nubia": {
            "semantic_relation": 2.28062,
            "contradiction": 29.80007,
            "irrelevancy": 48.43036,
            "logical_agreement": 21.76957,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.78681,
            "nubia_score": 0.26546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "mT5_small/totto_test",
        "N": 62,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1744186046511628,
            "2": 0.4011299435028249,
            "3": 0.7682215743440233
        },
        "rouge1": {
            "precision": 0.76599,
            "recall": 0.72057,
            "fmeasure": 0.73031
        },
        "rouge2": {
            "precision": 0.54087,
            "recall": 0.51503,
            "fmeasure": 0.51891
        },
        "rougeL": {
            "precision": 0.67637,
            "recall": 0.64173,
            "fmeasure": 0.647
        },
        "rougeLsum": {
            "precision": 0.67637,
            "recall": 0.64173,
            "fmeasure": 0.647
        },
        "nist": 7.076250380222285,
        "bleu": 47.40466,
        "bertscore": {
            "precision": 0.92738,
            "recall": 0.9194,
            "f1": 0.92104
        },
        "bleurt": 0.26729,
        "meteor": 0.38971714179245454,
        "nubia": {
            "semantic_relation": 4.1821,
            "contradiction": 5.97954,
            "irrelevancy": 30.24869,
            "logical_agreement": 63.77177,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.54918,
            "nubia_score": 0.72723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.74242,
            "recall": 0.66746,
            "fmeasure": 0.69592
        },
        "rouge2": {
            "precision": 0.54709,
            "recall": 0.51058,
            "fmeasure": 0.52141
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.63175,
            "fmeasure": 0.65592
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.63175,
            "fmeasure": 0.65592
        },
        "nist": 2.566201914107663,
        "bleu": 26.59449,
        "bertscore": {
            "precision": 0.93093,
            "recall": 0.92244,
            "f1": 0.92658
        },
        "bleurt": 0.22514,
        "meteor": 0.3221452686048736,
        "nubia": {
            "semantic_relation": 3.99161,
            "contradiction": 4.96526,
            "irrelevancy": 46.59038,
            "logical_agreement": 48.44436,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.47157,
            "nubia_score": 0.5727
        }
    },
    "wiki_lingua_vietnamese_vi_val": {
        "predictions_file": "mT5_small/wiki_lingua_vietnamese_vi_val",
        "N": 1957,
        "total_length": 64836,
        "mean_pred_length": 33.13030148185999,
        "std_pred_length": 27.069242323726883,
        "median_pred_length": 24.0,
        "min_pred_length": 4,
        "max_pred_length": 138,
        "distinct-1": 0.03718613116170029,
        "vocab_size-1": 2411,
        "unique-1": 472,
        "entropy-1": 7.517384215922867,
        "distinct-2": 0.11754321792649375,
        "vocab_size-2": 7391,
        "unique-2": 2358,
        "entropy-2": 10.820558923305818,
        "cond_entropy-2": 3.162612329643462,
        "distinct-3": 0.21931322018318505,
        "vocab_size-3": 13361,
        "unique-3": 5864,
        "entropy-3": 12.18391518697724,
        "cond_entropy-3": 1.4036029578483034,
        "total_length-nopunct": 53691,
        "mean_pred_length-nopunct": 27.435360245273376,
        "std_pred_length-nopunct": 23.136120197166484,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 126,
        "distinct-1-nopunct": 0.04466297889776685,
        "vocab_size-1-nopunct": 2398,
        "unique-1-nopunct": 471,
        "entropy-1-nopunct": 8.236465597048257,
        "distinct-2-nopunct": 0.16242703057950283,
        "vocab_size-2-nopunct": 8403,
        "unique-2-nopunct": 3413,
        "entropy-2-nopunct": 11.18411205293386,
        "cond_entropy-2-nopunct": 3.060114163441912,
        "distinct-3-nopunct": 0.27806014826124514,
        "vocab_size-3-nopunct": 13841,
        "unique-3-nopunct": 6984,
        "entropy-3-nopunct": 12.4953610211517,
        "cond_entropy-3-nopunct": 1.3654957302904422,
        "msttr-100": 0.28002,
        "msttr-100_nopunct": 0.31097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_val.json",
        "local_recall": {
            "1": 0.12911828662864644
        },
        "rouge1": {
            "precision": 0.24087,
            "recall": 0.17709,
            "fmeasure": 0.18384
        },
        "rouge2": {
            "precision": 0.05684,
            "recall": 0.04311,
            "fmeasure": 0.04358
        },
        "rougeL": {
            "precision": 0.21523,
            "recall": 0.15908,
            "fmeasure": 0.16441
        },
        "rougeLsum": {
            "precision": 0.21523,
            "recall": 0.15908,
            "fmeasure": 0.16441
        },
        "nist": 1.836966260780741,
        "bleu": 4.09207,
        "sari": 64.91793,
        "bertscore": {
            "precision": 0.81909,
            "recall": 0.76992,
            "f1": 0.79295
        },
        "bleurt": -0.63129,
        "meteor": 0.09328713189632716,
        "nubia": {
            "semantic_relation": 2.59567,
            "contradiction": 20.10865,
            "irrelevancy": 26.63828,
            "logical_agreement": 53.25307,
            "grammar_ref": 3.90718,
            "grammar_hyp": 2.6558,
            "nubia_score": 0.387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "mT5_small/totto_test",
        "N": 28,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.37333333333333335,
            "3": 0.7046783625730995
        },
        "rouge1": {
            "precision": 0.76293,
            "recall": 0.65707,
            "fmeasure": 0.69137
        },
        "rouge2": {
            "precision": 0.5061,
            "recall": 0.44428,
            "fmeasure": 0.46253
        },
        "rougeL": {
            "precision": 0.65254,
            "recall": 0.5725,
            "fmeasure": 0.59595
        },
        "rougeLsum": {
            "precision": 0.65254,
            "recall": 0.5725,
            "fmeasure": 0.59595
        },
        "nist": 5.595751471586757,
        "bleu": 40.8414,
        "bertscore": {
            "precision": 0.92195,
            "recall": 0.90375,
            "f1": 0.90891
        },
        "bleurt": 0.1602,
        "meteor": 0.3593765893045584,
        "nubia": {
            "semantic_relation": 3.89058,
            "contradiction": 21.5481,
            "irrelevancy": 25.84999,
            "logical_agreement": 52.60191,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.75554,
            "nubia_score": 0.62074
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "mT5_small/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "total_length": 132078,
        "mean_pred_length": 33.71917283635435,
        "std_pred_length": 28.133381071026914,
        "median_pred_length": 24.0,
        "min_pred_length": 3,
        "max_pred_length": 138,
        "distinct-1": 0.025787792062266238,
        "vocab_size-1": 3406,
        "unique-1": 625,
        "entropy-1": 7.612174288214928,
        "distinct-2": 0.09134604130741801,
        "vocab_size-2": 11707,
        "unique-2": 3606,
        "entropy-2": 11.105200738988467,
        "cond_entropy-2": 3.354877208536612,
        "distinct-3": 0.18447570908856767,
        "vocab_size-3": 22920,
        "unique-3": 9686,
        "entropy-3": 12.641109114216952,
        "cond_entropy-3": 1.5755059722122489,
        "total_length-nopunct": 109462,
        "mean_pred_length-nopunct": 27.945366351799848,
        "std_pred_length-nopunct": 24.145590171667738,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 127,
        "distinct-1-nopunct": 0.030978787159014087,
        "vocab_size-1-nopunct": 3391,
        "unique-1-nopunct": 623,
        "entropy-1-nopunct": 8.351673561086349,
        "distinct-2-nopunct": 0.1327585390117959,
        "vocab_size-2-nopunct": 14012,
        "unique-2-nopunct": 5450,
        "entropy-2-nopunct": 11.545852451316458,
        "cond_entropy-2-nopunct": 3.309143414061404,
        "distinct-3-nopunct": 0.24060298342976344,
        "vocab_size-3-nopunct": 24452,
        "unique-3-nopunct": 12028,
        "entropy-3-nopunct": 13.034890301667343,
        "cond_entropy-3-nopunct": 1.5466279313409745,
        "msttr-100": 0.27686,
        "msttr-100_nopunct": 0.30872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "local_recall": {
            "1": 0.13528594267562513
        },
        "rouge1": {
            "precision": 0.24286,
            "recall": 0.18396,
            "fmeasure": 0.18697
        },
        "rouge2": {
            "precision": 0.05799,
            "recall": 0.04668,
            "fmeasure": 0.04566
        },
        "rougeL": {
            "precision": 0.21572,
            "recall": 0.16522,
            "fmeasure": 0.16679
        },
        "rougeLsum": {
            "precision": 0.21572,
            "recall": 0.16522,
            "fmeasure": 0.16679
        },
        "nist": 1.9230509146274446,
        "bleu": 4.28788,
        "sari": 64.69102,
        "bertscore": {
            "precision": 0.82011,
            "recall": 0.77163,
            "f1": 0.7943
        },
        "bleurt": -0.63666,
        "meteor": 0.09533802333441095,
        "nubia": {
            "semantic_relation": 2.62571,
            "contradiction": 19.51492,
            "irrelevancy": 25.88795,
            "logical_agreement": 54.59712,
            "grammar_ref": 3.92068,
            "grammar_hyp": 2.65057,
            "nubia_score": 0.38986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "mT5_small/totto_test",
        "N": 20,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09803921568627451,
            "2": 0.5,
            "3": 0.8311111111111111
        },
        "rouge1": {
            "precision": 0.83372,
            "recall": 0.79821,
            "fmeasure": 0.81167
        },
        "rouge2": {
            "precision": 0.69373,
            "recall": 0.67011,
            "fmeasure": 0.67855
        },
        "rougeL": {
            "precision": 0.73956,
            "recall": 0.71297,
            "fmeasure": 0.72278
        },
        "rougeLsum": {
            "precision": 0.73956,
            "recall": 0.71297,
            "fmeasure": 0.72278
        },
        "nist": 6.402237924839785,
        "bleu": 61.08766,
        "bertscore": {
            "precision": 0.94786,
            "recall": 0.94507,
            "f1": 0.94618
        },
        "bleurt": 0.46616,
        "meteor": 0.45349731306404395,
        "nubia": {
            "semantic_relation": 4.30355,
            "contradiction": 8.16648,
            "irrelevancy": 20.64348,
            "logical_agreement": 71.19004,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.58936,
            "nubia_score": 0.7773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "mT5_small/totto_test",
        "N": 35,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18085106382978725,
            "2": 0.415929203539823,
            "3": 0.7204030226700252
        },
        "rouge1": {
            "precision": 0.77544,
            "recall": 0.71003,
            "fmeasure": 0.72742
        },
        "rouge2": {
            "precision": 0.5605,
            "recall": 0.51847,
            "fmeasure": 0.528
        },
        "rougeL": {
            "precision": 0.70675,
            "recall": 0.65279,
            "fmeasure": 0.66558
        },
        "rougeLsum": {
            "precision": 0.70675,
            "recall": 0.65279,
            "fmeasure": 0.66558
        },
        "nist": 6.320055003257438,
        "bleu": 45.54919,
        "bertscore": {
            "precision": 0.93391,
            "recall": 0.91622,
            "f1": 0.92254
        },
        "bleurt": 0.23299,
        "meteor": 0.3956773038268245,
        "nubia": {
            "semantic_relation": 4.08092,
            "contradiction": 9.20432,
            "irrelevancy": 25.87655,
            "logical_agreement": 64.91913,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.72308,
            "nubia_score": 0.69594
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7229,
        "mean_pred_length": 20.13649025069638,
        "std_pred_length": 9.1858423186049,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.36644072485821,
        "vocab_size-1": 2649,
        "unique-1": 1933,
        "entropy-1": 9.204601060334188,
        "distinct-2": 0.845414847161572,
        "vocab_size-2": 5808,
        "unique-2": 5386,
        "entropy-2": 12.214450573848323,
        "cond_entropy-2": 2.748968289552871,
        "distinct-3": 0.9688219935493779,
        "vocab_size-3": 6308,
        "unique-3": 6196,
        "entropy-3": 12.57353139728536,
        "cond_entropy-3": 0.3748342848513119,
        "total_length-nopunct": 6456,
        "mean_pred_length-nopunct": 17.983286908077993,
        "std_pred_length-nopunct": 8.15960218755718,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4083023543990087,
        "vocab_size-1-nopunct": 2636,
        "unique-1-nopunct": 1930,
        "entropy-1-nopunct": 9.521398318728968,
        "distinct-2-nopunct": 0.8651795965228801,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.12066793495952,
        "cond_entropy-2-nopunct": 2.7348537281635985,
        "distinct-3-nopunct": 0.9811781108400139,
        "vocab_size-3-nopunct": 5630,
        "unique-3-nopunct": 5542,
        "entropy-3-nopunct": 12.445366994834446,
        "cond_entropy-3-nopunct": 0.34460054672478496,
        "msttr-100": 0.73264,
        "msttr-100_nopunct": 0.77109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04265704584040747,
            "2": 0.18773946360153257,
            "3": 0.40919037199124725,
            "4": 0.5816164817749604,
            "5": 0.6915887850467289,
            "6": 0.7783816425120773,
            "7": 0.8736158839251623
        },
        "rouge1": {
            "precision": 0.85348,
            "recall": 0.80789,
            "fmeasure": 0.81987
        },
        "rouge2": {
            "precision": 0.70936,
            "recall": 0.67588,
            "fmeasure": 0.68255
        },
        "rougeL": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "rougeLsum": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "nist": 11.348324337318253,
        "bleu": 68.4974,
        "bertscore": {
            "precision": 0.95485,
            "recall": 0.94662,
            "f1": 0.94865
        },
        "bleurt": 0.21243,
        "meteor": 0.4688629598902241,
        "nubia": {
            "semantic_relation": 4.33162,
            "contradiction": 4.00834,
            "irrelevancy": 17.09194,
            "logical_agreement": 78.89971,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.98215,
            "nubia_score": 0.69949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "mT5_small/totto_test",
        "N": 48,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5897435897435898,
            "3": 0.6563706563706564
        },
        "rouge1": {
            "precision": 0.72529,
            "recall": 0.66118,
            "fmeasure": 0.68102
        },
        "rouge2": {
            "precision": 0.46748,
            "recall": 0.43238,
            "fmeasure": 0.44114
        },
        "rougeL": {
            "precision": 0.58738,
            "recall": 0.54729,
            "fmeasure": 0.55715
        },
        "rougeLsum": {
            "precision": 0.58738,
            "recall": 0.54729,
            "fmeasure": 0.55715
        },
        "nist": 6.097269600539171,
        "bleu": 30.47003,
        "bertscore": {
            "precision": 0.91321,
            "recall": 0.89939,
            "f1": 0.90355
        },
        "bleurt": 0.07516,
        "meteor": 0.3374377805362394,
        "nubia": {
            "semantic_relation": 3.93996,
            "contradiction": 14.11288,
            "irrelevancy": 33.36896,
            "logical_agreement": 52.51815,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.74965,
            "nubia_score": 0.64682
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7229,
        "mean_pred_length": 20.13649025069638,
        "std_pred_length": 9.1858423186049,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.36644072485821,
        "vocab_size-1": 2649,
        "unique-1": 1933,
        "entropy-1": 9.204601060334188,
        "distinct-2": 0.845414847161572,
        "vocab_size-2": 5808,
        "unique-2": 5386,
        "entropy-2": 12.214450573848323,
        "cond_entropy-2": 2.748968289552871,
        "distinct-3": 0.9688219935493779,
        "vocab_size-3": 6308,
        "unique-3": 6196,
        "entropy-3": 12.57353139728536,
        "cond_entropy-3": 0.3748342848513119,
        "total_length-nopunct": 6456,
        "mean_pred_length-nopunct": 17.983286908077993,
        "std_pred_length-nopunct": 8.15960218755718,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4083023543990087,
        "vocab_size-1-nopunct": 2636,
        "unique-1-nopunct": 1930,
        "entropy-1-nopunct": 9.521398318728968,
        "distinct-2-nopunct": 0.8651795965228801,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.12066793495952,
        "cond_entropy-2-nopunct": 2.7348537281635985,
        "distinct-3-nopunct": 0.9811781108400139,
        "vocab_size-3-nopunct": 5630,
        "unique-3-nopunct": 5542,
        "entropy-3-nopunct": 12.445366994834446,
        "cond_entropy-3-nopunct": 0.34460054672478496,
        "msttr-100": 0.73264,
        "msttr-100_nopunct": 0.77109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04265704584040747,
            "2": 0.18773946360153257,
            "3": 0.40919037199124725,
            "4": 0.5816164817749604,
            "5": 0.6915887850467289,
            "6": 0.7783816425120773,
            "7": 0.8736158839251623
        },
        "rouge1": {
            "precision": 0.85348,
            "recall": 0.80789,
            "fmeasure": 0.81987
        },
        "rouge2": {
            "precision": 0.70936,
            "recall": 0.67588,
            "fmeasure": 0.68255
        },
        "rougeL": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "rougeLsum": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "nist": 11.348324337318253,
        "bleu": 68.4974,
        "bertscore": {
            "precision": 0.95485,
            "recall": 0.94662,
            "f1": 0.94865
        },
        "bleurt": 0.21243,
        "meteor": 0.4688629598902241,
        "nubia": {
            "semantic_relation": 4.33162,
            "contradiction": 4.00834,
            "irrelevancy": 17.09194,
            "logical_agreement": 78.89971,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.98215,
            "nubia_score": 0.69949
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.29411764705882354
        },
        "rouge1": {
            "precision": 0.29885,
            "recall": 0.33251,
            "fmeasure": 0.31016
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.11111,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.27586,
            "recall": 0.3145,
            "fmeasure": 0.28996
        },
        "rougeLsum": {
            "precision": 0.27586,
            "recall": 0.3145,
            "fmeasure": 0.28996
        },
        "nist": 0.996534868058331,
        "bleu": 3.65746,
        "bertscore": {
            "precision": 0.8344,
            "recall": 0.79834,
            "f1": 0.81366
        },
        "bleurt": -0.32871,
        "meteor": 0.16920802306395305,
        "nubia": {
            "semantic_relation": 3.15221,
            "contradiction": 96.10739,
            "irrelevancy": 2.2229,
            "logical_agreement": 1.66972,
            "grammar_ref": 4.39709,
            "grammar_hyp": 3.411,
            "nubia_score": 0.51464
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.21088,
            "recall": 0.4919,
            "fmeasure": 0.29386
        },
        "rouge2": {
            "precision": 0.04167,
            "recall": 0.10741,
            "fmeasure": 0.06001
        },
        "rougeL": {
            "precision": 0.15646,
            "recall": 0.32794,
            "fmeasure": 0.21085
        },
        "rougeLsum": {
            "precision": 0.15646,
            "recall": 0.32794,
            "fmeasure": 0.21085
        },
        "nist": 1.054101305183272,
        "bleu": 8.60374,
        "bertscore": {
            "precision": 0.75294,
            "recall": 0.82233,
            "f1": 0.78611
        },
        "bleurt": -1.09798,
        "meteor": 0.1764220364303649,
        "nubia": {
            "semantic_relation": 2.31214,
            "contradiction": 0.58955,
            "irrelevancy": 80.06121,
            "logical_agreement": 19.34924,
            "grammar_ref": 4.75948,
            "grammar_hyp": 4.32778,
            "nubia_score": 0.01971
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.39394,
            "recall": 0.37963,
            "fmeasure": 0.37419
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.20175,
            "fmeasure": 0.19413
        },
        "rougeL": {
            "precision": 0.39394,
            "recall": 0.37963,
            "fmeasure": 0.37419
        },
        "rougeLsum": {
            "precision": 0.39394,
            "recall": 0.37963,
            "fmeasure": 0.37419
        },
        "nist": 0.9282649919316105,
        "bleu": 9.42516,
        "bertscore": {
            "precision": 0.88327,
            "recall": 0.85166,
            "f1": 0.85954
        },
        "bleurt": -0.4716,
        "meteor": 0.1814006247795225,
        "nubia": {
            "semantic_relation": 3.44766,
            "contradiction": 0.33016,
            "irrelevancy": 44.08435,
            "logical_agreement": 55.5855,
            "grammar_ref": 4.8547,
            "grammar_hyp": 5.47602,
            "nubia_score": 0.3963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "mT5_small/totto_test",
        "N": 54,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20670391061452514,
            "2": 0.35428571428571426,
            "3": 0.7258064516129032
        },
        "rouge1": {
            "precision": 0.74728,
            "recall": 0.70759,
            "fmeasure": 0.71456
        },
        "rouge2": {
            "precision": 0.51309,
            "recall": 0.48177,
            "fmeasure": 0.48961
        },
        "rougeL": {
            "precision": 0.65313,
            "recall": 0.60614,
            "fmeasure": 0.61837
        },
        "rougeLsum": {
            "precision": 0.65313,
            "recall": 0.60614,
            "fmeasure": 0.61837
        },
        "nist": 6.6713711719458075,
        "bleu": 42.60857,
        "bertscore": {
            "precision": 0.92728,
            "recall": 0.91907,
            "f1": 0.92159
        },
        "bleurt": 0.20932,
        "meteor": 0.3776065351178875,
        "nubia": {
            "semantic_relation": 4.05759,
            "contradiction": 11.8367,
            "irrelevancy": 28.44945,
            "logical_agreement": 59.71384,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.58711,
            "nubia_score": 0.69089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4166666666666667,
            "3": 0.7464114832535885
        },
        "rouge1": {
            "precision": 0.81066,
            "recall": 0.72819,
            "fmeasure": 0.76002
        },
        "rouge2": {
            "precision": 0.57256,
            "recall": 0.4888,
            "fmeasure": 0.51907
        },
        "rougeL": {
            "precision": 0.73056,
            "recall": 0.65086,
            "fmeasure": 0.6815
        },
        "rougeLsum": {
            "precision": 0.73056,
            "recall": 0.65086,
            "fmeasure": 0.6815
        },
        "nist": 5.8411349289750865,
        "bleu": 51.58139,
        "bertscore": {
            "precision": 0.94249,
            "recall": 0.92108,
            "f1": 0.93063
        },
        "bleurt": 0.3393,
        "meteor": 0.3976792424223387,
        "nubia": {
            "semantic_relation": 4.19728,
            "contradiction": 1.12157,
            "irrelevancy": 13.71968,
            "logical_agreement": 85.15875,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.66607,
            "nubia_score": 0.72517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "mT5_small/totto_test",
        "N": 52,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23026315789473684,
            "2": 0.5243243243243243,
            "3": 0.7789203084832905
        },
        "rouge1": {
            "precision": 0.73238,
            "recall": 0.73872,
            "fmeasure": 0.71186
        },
        "rouge2": {
            "precision": 0.53997,
            "recall": 0.50318,
            "fmeasure": 0.50522
        },
        "rougeL": {
            "precision": 0.69969,
            "recall": 0.70126,
            "fmeasure": 0.67846
        },
        "rougeLsum": {
            "precision": 0.69969,
            "recall": 0.70126,
            "fmeasure": 0.67846
        },
        "nist": 6.337702579401379,
        "bleu": 45.7001,
        "bertscore": {
            "precision": 0.93089,
            "recall": 0.93024,
            "f1": 0.92791
        },
        "bleurt": 0.33381,
        "meteor": 0.4055385299696559,
        "nubia": {
            "semantic_relation": 4.09596,
            "contradiction": 11.44255,
            "irrelevancy": 23.60588,
            "logical_agreement": 64.95157,
            "grammar_ref": 5.15177,
            "grammar_hyp": 5.07952,
            "nubia_score": 0.67577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8243243243243243
        },
        "rouge1": {
            "precision": 0.87146,
            "recall": 0.88459,
            "fmeasure": 0.87729
        },
        "rouge2": {
            "precision": 0.80317,
            "recall": 0.81131,
            "fmeasure": 0.80679
        },
        "rougeL": {
            "precision": 0.8449,
            "recall": 0.85753,
            "fmeasure": 0.8505
        },
        "rougeLsum": {
            "precision": 0.8449,
            "recall": 0.85753,
            "fmeasure": 0.8505
        },
        "nist": 4.613555616482326,
        "bleu": 57.99035,
        "bertscore": {
            "precision": 0.96957,
            "recall": 0.9737,
            "f1": 0.97162
        },
        "bleurt": 0.73797,
        "meteor": 0.4625420597633754,
        "nubia": {
            "semantic_relation": 4.46293,
            "contradiction": 3.27545,
            "irrelevancy": 14.38325,
            "logical_agreement": 82.34129,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.82654,
            "nubia_score": 0.84221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "mT5_small/totto_test",
        "N": 44,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.5576923076923077,
            "3": 0.751207729468599
        },
        "rouge1": {
            "precision": 0.77454,
            "recall": 0.72638,
            "fmeasure": 0.73884
        },
        "rouge2": {
            "precision": 0.55975,
            "recall": 0.53182,
            "fmeasure": 0.5363
        },
        "rougeL": {
            "precision": 0.69525,
            "recall": 0.66189,
            "fmeasure": 0.66729
        },
        "rougeLsum": {
            "precision": 0.69525,
            "recall": 0.66189,
            "fmeasure": 0.66729
        },
        "nist": 6.923460762962514,
        "bleu": 49.74384,
        "bertscore": {
            "precision": 0.94015,
            "recall": 0.93039,
            "f1": 0.93374
        },
        "bleurt": 0.31825,
        "meteor": 0.4126192783272357,
        "nubia": {
            "semantic_relation": 4.33611,
            "contradiction": 3.55874,
            "irrelevancy": 34.4392,
            "logical_agreement": 62.00206,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.63306,
            "nubia_score": 0.75937
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.18181818181818182,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.65468,
            "recall": 0.63674,
            "fmeasure": 0.63177
        },
        "rouge2": {
            "precision": 0.43665,
            "recall": 0.46202,
            "fmeasure": 0.43778
        },
        "rougeL": {
            "precision": 0.5386,
            "recall": 0.56828,
            "fmeasure": 0.53784
        },
        "rougeLsum": {
            "precision": 0.5386,
            "recall": 0.56828,
            "fmeasure": 0.53784
        },
        "nist": 4.133088075847745,
        "bleu": 35.38587,
        "bertscore": {
            "precision": 0.9039,
            "recall": 0.90734,
            "f1": 0.89459
        },
        "bleurt": -0.08504,
        "meteor": 0.31929476226727366,
        "nubia": {
            "semantic_relation": 3.89723,
            "contradiction": 0.71103,
            "irrelevancy": 59.21868,
            "logical_agreement": 40.0703,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.46219,
            "nubia_score": 0.6639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35,
            "2": 0.48717948717948717,
            "3": 0.7011494252873564
        },
        "rouge1": {
            "precision": 0.67209,
            "recall": 0.66239,
            "fmeasure": 0.65278
        },
        "rouge2": {
            "precision": 0.46236,
            "recall": 0.43906,
            "fmeasure": 0.43887
        },
        "rougeL": {
            "precision": 0.56708,
            "recall": 0.54408,
            "fmeasure": 0.54204
        },
        "rougeLsum": {
            "precision": 0.56708,
            "recall": 0.54408,
            "fmeasure": 0.54204
        },
        "nist": 4.820685707253601,
        "bleu": 28.95848,
        "bertscore": {
            "precision": 0.90684,
            "recall": 0.89404,
            "f1": 0.8991
        },
        "bleurt": 0.0379,
        "meteor": 0.3480389256796079,
        "nubia": {
            "semantic_relation": 3.85194,
            "contradiction": 14.32993,
            "irrelevancy": 38.34299,
            "logical_agreement": 47.32707,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.43989,
            "nubia_score": 0.62493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "mT5_small/totto_test",
        "N": 36,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20945945945945946,
            "2": 0.3595505617977528,
            "3": 0.7481840193704601
        },
        "rouge1": {
            "precision": 0.78728,
            "recall": 0.70132,
            "fmeasure": 0.73316
        },
        "rouge2": {
            "precision": 0.53513,
            "recall": 0.47633,
            "fmeasure": 0.4975
        },
        "rougeL": {
            "precision": 0.67806,
            "recall": 0.61951,
            "fmeasure": 0.63941
        },
        "rougeLsum": {
            "precision": 0.67806,
            "recall": 0.61951,
            "fmeasure": 0.63941
        },
        "nist": 6.206214675370568,
        "bleu": 38.9915,
        "bertscore": {
            "precision": 0.93004,
            "recall": 0.91245,
            "f1": 0.91967
        },
        "bleurt": 0.26455,
        "meteor": 0.3502483257055033,
        "nubia": {
            "semantic_relation": 4.25883,
            "contradiction": 2.60311,
            "irrelevancy": 20.02079,
            "logical_agreement": 77.37611,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.86206,
            "nubia_score": 0.73499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5769230769230769,
            "3": 0.6379310344827587
        },
        "rouge1": {
            "precision": 0.71094,
            "recall": 0.62819,
            "fmeasure": 0.6633
        },
        "rouge2": {
            "precision": 0.44499,
            "recall": 0.38783,
            "fmeasure": 0.41236
        },
        "rougeL": {
            "precision": 0.51249,
            "recall": 0.47178,
            "fmeasure": 0.48798
        },
        "rougeLsum": {
            "precision": 0.51249,
            "recall": 0.47178,
            "fmeasure": 0.48798
        },
        "nist": 4.631804673678643,
        "bleu": 35.4217,
        "bertscore": {
            "precision": 0.91421,
            "recall": 0.89301,
            "f1": 0.90337
        },
        "bleurt": 0.1474,
        "meteor": 0.3458885228485068,
        "nubia": {
            "semantic_relation": 3.71131,
            "contradiction": 15.47385,
            "irrelevancy": 55.91162,
            "logical_agreement": 28.61452,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.05457,
            "nubia_score": 0.60552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "mT5_small/totto_test",
        "N": 15,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.2692307692307692,
            "3": 0.7864583333333334
        },
        "rouge1": {
            "precision": 0.81005,
            "recall": 0.72803,
            "fmeasure": 0.75604
        },
        "rouge2": {
            "precision": 0.55732,
            "recall": 0.51148,
            "fmeasure": 0.52548
        },
        "rougeL": {
            "precision": 0.71733,
            "recall": 0.64453,
            "fmeasure": 0.66947
        },
        "rougeLsum": {
            "precision": 0.71733,
            "recall": 0.64453,
            "fmeasure": 0.66947
        },
        "nist": 5.673372602936904,
        "bleu": 46.41906,
        "bertscore": {
            "precision": 0.93943,
            "recall": 0.92658,
            "f1": 0.93158
        },
        "bleurt": 0.33463,
        "meteor": 0.39791828844738975,
        "nubia": {
            "semantic_relation": 4.17715,
            "contradiction": 1.44598,
            "irrelevancy": 30.25957,
            "logical_agreement": 68.29445,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.53389,
            "nubia_score": 0.70061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "mT5_small/totto_test",
        "N": 42,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2672413793103448,
            "2": 0.37735849056603776,
            "3": 0.7775280898876404
        },
        "rouge1": {
            "precision": 0.77605,
            "recall": 0.73814,
            "fmeasure": 0.74764
        },
        "rouge2": {
            "precision": 0.51842,
            "recall": 0.50327,
            "fmeasure": 0.50447
        },
        "rougeL": {
            "precision": 0.65805,
            "recall": 0.62593,
            "fmeasure": 0.63338
        },
        "rougeLsum": {
            "precision": 0.65805,
            "recall": 0.62593,
            "fmeasure": 0.63338
        },
        "nist": 6.911250174304528,
        "bleu": 44.64105,
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.92875,
            "f1": 0.93027
        },
        "bleurt": 0.21379,
        "meteor": 0.4002438930750285,
        "nubia": {
            "semantic_relation": 4.15633,
            "contradiction": 8.94241,
            "irrelevancy": 30.74256,
            "logical_agreement": 60.31502,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.78787,
            "nubia_score": 0.70327
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.0,
            "3": 0.782051282051282
        },
        "rouge1": {
            "precision": 0.81485,
            "recall": 0.75087,
            "fmeasure": 0.76955
        },
        "rouge2": {
            "precision": 0.61708,
            "recall": 0.56343,
            "fmeasure": 0.58283
        },
        "rougeL": {
            "precision": 0.71101,
            "recall": 0.66305,
            "fmeasure": 0.67685
        },
        "rougeLsum": {
            "precision": 0.71101,
            "recall": 0.66305,
            "fmeasure": 0.67685
        },
        "nist": 4.975087489978208,
        "bleu": 52.61747,
        "bertscore": {
            "precision": 0.94361,
            "recall": 0.93348,
            "f1": 0.93421
        },
        "bleurt": 0.39795,
        "meteor": 0.4126083702166386,
        "nubia": {
            "semantic_relation": 4.45067,
            "contradiction": 17.50268,
            "irrelevancy": 8.78781,
            "logical_agreement": 73.70951,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.88903,
            "nubia_score": 0.79169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.65236,
            "recall": 0.61269,
            "fmeasure": 0.62822
        },
        "rouge2": {
            "precision": 0.37145,
            "recall": 0.3587,
            "fmeasure": 0.36269
        },
        "rougeL": {
            "precision": 0.5047,
            "recall": 0.47658,
            "fmeasure": 0.48758
        },
        "rougeLsum": {
            "precision": 0.5047,
            "recall": 0.47658,
            "fmeasure": 0.48758
        },
        "nist": 3.779063611823906,
        "bleu": 24.38072,
        "bertscore": {
            "precision": 0.89597,
            "recall": 0.88796,
            "f1": 0.89141
        },
        "bleurt": 0.09528,
        "meteor": 0.3150593111888217,
        "nubia": {
            "semantic_relation": 4.10211,
            "contradiction": 19.9886,
            "irrelevancy": 24.23969,
            "logical_agreement": 55.77171,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.66797,
            "nubia_score": 0.69193
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.2222222222222222,
            "3": 0.6825396825396826
        },
        "rouge1": {
            "precision": 0.67909,
            "recall": 0.64127,
            "fmeasure": 0.65546
        },
        "rouge2": {
            "precision": 0.45031,
            "recall": 0.41973,
            "fmeasure": 0.43114
        },
        "rougeL": {
            "precision": 0.61083,
            "recall": 0.56962,
            "fmeasure": 0.58584
        },
        "rougeLsum": {
            "precision": 0.61083,
            "recall": 0.56962,
            "fmeasure": 0.58584
        },
        "nist": 4.58082025191139,
        "bleu": 35.62747,
        "bertscore": {
            "precision": 0.90677,
            "recall": 0.91542,
            "f1": 0.91051
        },
        "bleurt": 0.05284,
        "meteor": 0.3340289577357262,
        "nubia": {
            "semantic_relation": 3.95118,
            "contradiction": 19.62176,
            "irrelevancy": 28.46142,
            "logical_agreement": 51.91682,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.26688,
            "nubia_score": 0.64825
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.36363636363636365
        },
        "rouge1": {
            "precision": 0.62364,
            "recall": 0.42719,
            "fmeasure": 0.50303
        },
        "rouge2": {
            "precision": 0.20417,
            "recall": 0.14176,
            "fmeasure": 0.16577
        },
        "rougeL": {
            "precision": 0.47273,
            "recall": 0.32456,
            "fmeasure": 0.38182
        },
        "rougeLsum": {
            "precision": 0.47273,
            "recall": 0.32456,
            "fmeasure": 0.38182
        },
        "nist": 1.319588976824041,
        "bleu": 7.54003,
        "bertscore": {
            "precision": 0.845,
            "recall": 0.80996,
            "f1": 0.82711
        },
        "bleurt": -0.38251,
        "meteor": 0.2156779602043996,
        "nubia": {
            "semantic_relation": 3.33184,
            "contradiction": 49.13519,
            "irrelevancy": 49.71194,
            "logical_agreement": 1.15288,
            "grammar_ref": 3.96887,
            "grammar_hyp": 5.21584,
            "nubia_score": 0.29013
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.19231,
            "recall": 0.33333,
            "fmeasure": 0.2439
        },
        "rouge2": {
            "precision": 0.04,
            "recall": 0.07143,
            "fmeasure": 0.05128
        },
        "rougeL": {
            "precision": 0.11538,
            "recall": 0.2,
            "fmeasure": 0.14634
        },
        "rougeLsum": {
            "precision": 0.11538,
            "recall": 0.2,
            "fmeasure": 0.14634
        },
        "nist": 0.7407407407407407,
        "bleu": 3.49018,
        "bertscore": {
            "precision": 0.76032,
            "recall": 0.78671,
            "f1": 0.77249
        },
        "bleurt": -0.23495,
        "meteor": 0.11351267557834761,
        "nubia": {
            "semantic_relation": 2.51298,
            "contradiction": 0.36486,
            "irrelevancy": 99.39804,
            "logical_agreement": 0.2371,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.49952,
            "nubia_score": 0.42141
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "mT5_small/totto_test",
        "N": 36,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15841584158415842,
            "2": 0.5396825396825397,
            "3": 0.7038123167155426
        },
        "rouge1": {
            "precision": 0.7243,
            "recall": 0.69411,
            "fmeasure": 0.69167
        },
        "rouge2": {
            "precision": 0.51047,
            "recall": 0.50332,
            "fmeasure": 0.4924
        },
        "rougeL": {
            "precision": 0.65337,
            "recall": 0.62993,
            "fmeasure": 0.62474
        },
        "rougeLsum": {
            "precision": 0.65337,
            "recall": 0.62993,
            "fmeasure": 0.62474
        },
        "nist": 6.053128828572988,
        "bleu": 39.78613,
        "bertscore": {
            "precision": 0.91833,
            "recall": 0.90937,
            "f1": 0.9121
        },
        "bleurt": 0.17835,
        "meteor": 0.3609748995454577,
        "nubia": {
            "semantic_relation": 3.92947,
            "contradiction": 16.06687,
            "irrelevancy": 34.94333,
            "logical_agreement": 48.9898,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.69228,
            "nubia_score": 0.6478
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.4,
            "fmeasure": 0.36364
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.14286,
            "fmeasure": 0.12903
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.4,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.4,
            "fmeasure": 0.36364
        },
        "nist": 1.1904761904761905,
        "bleu": 4.96802,
        "bertscore": {
            "precision": 0.7175,
            "recall": 0.75854,
            "f1": 0.73745
        },
        "bleurt": -0.76415,
        "meteor": 0.12621054166719284,
        "nubia": {
            "semantic_relation": 2.45522,
            "contradiction": 4.91993,
            "irrelevancy": 77.37827,
            "logical_agreement": 17.70179,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.28393,
            "nubia_score": 0.3659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06779661016949153,
            "2": 0.15384615384615385,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.70452,
            "recall": 0.58858,
            "fmeasure": 0.58907
        },
        "rouge2": {
            "precision": 0.46498,
            "recall": 0.38588,
            "fmeasure": 0.37568
        },
        "rougeL": {
            "precision": 0.57583,
            "recall": 0.49624,
            "fmeasure": 0.49185
        },
        "rougeLsum": {
            "precision": 0.57583,
            "recall": 0.49624,
            "fmeasure": 0.49185
        },
        "nist": 3.170977059616851,
        "bleu": 20.50782,
        "bertscore": {
            "precision": 0.89517,
            "recall": 0.87377,
            "f1": 0.88133
        },
        "bleurt": 0.03464,
        "meteor": 0.28823226042231936,
        "nubia": {
            "semantic_relation": 3.75907,
            "contradiction": 2.2765,
            "irrelevancy": 50.11965,
            "logical_agreement": 47.60386,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.91618,
            "nubia_score": 0.55828
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.55385,
            "fmeasure": 0.63492
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.38889,
            "fmeasure": 0.37121
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.47436,
            "fmeasure": 0.56614
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.47436,
            "fmeasure": 0.56614
        },
        "nist": 1.927966445980129,
        "bleu": 19.64073,
        "bertscore": {
            "precision": 0.9286,
            "recall": 0.93053,
            "f1": 0.91051
        },
        "bleurt": 0.23163,
        "meteor": 0.2877528084471841,
        "nubia": {
            "semantic_relation": 3.53449,
            "contradiction": 15.98363,
            "irrelevancy": 44.5103,
            "logical_agreement": 39.50607,
            "grammar_ref": 6.66832,
            "grammar_hyp": 5.51603,
            "nubia_score": 0.6422
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "mT5_small/totto_test",
        "N": 78,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26180257510729615,
            "2": 0.49361702127659574,
            "3": 0.7615571776155717
        },
        "rouge1": {
            "precision": 0.76144,
            "recall": 0.71749,
            "fmeasure": 0.72697
        },
        "rouge2": {
            "precision": 0.51839,
            "recall": 0.48939,
            "fmeasure": 0.49433
        },
        "rougeL": {
            "precision": 0.66533,
            "recall": 0.62814,
            "fmeasure": 0.63568
        },
        "rougeLsum": {
            "precision": 0.66533,
            "recall": 0.62814,
            "fmeasure": 0.63568
        },
        "nist": 7.277300737124239,
        "bleu": 45.67037,
        "bertscore": {
            "precision": 0.92779,
            "recall": 0.92424,
            "f1": 0.9245
        },
        "bleurt": 0.28391,
        "meteor": 0.393356619138947,
        "nubia": {
            "semantic_relation": 4.23015,
            "contradiction": 7.91784,
            "irrelevancy": 31.04372,
            "logical_agreement": 61.03844,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.71429,
            "nubia_score": 0.72787
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45161290322580644,
            "2": 0.225,
            "3": 0.7207207207207207
        },
        "rouge1": {
            "precision": 0.67631,
            "recall": 0.70748,
            "fmeasure": 0.68144
        },
        "rouge2": {
            "precision": 0.43523,
            "recall": 0.45018,
            "fmeasure": 0.43721
        },
        "rougeL": {
            "precision": 0.57491,
            "recall": 0.56855,
            "fmeasure": 0.56624
        },
        "rougeLsum": {
            "precision": 0.57491,
            "recall": 0.56855,
            "fmeasure": 0.56624
        },
        "nist": 5.056082220555886,
        "bleu": 33.43222,
        "bertscore": {
            "precision": 0.89539,
            "recall": 0.90259,
            "f1": 0.89782
        },
        "bleurt": 0.01081,
        "meteor": 0.33611326066199115,
        "nubia": {
            "semantic_relation": 3.87084,
            "contradiction": 16.30907,
            "irrelevancy": 49.08086,
            "logical_agreement": 34.61007,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.4738,
            "nubia_score": 0.61772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.44642857142857145,
            "3": 0.7588235294117647
        },
        "rouge1": {
            "precision": 0.7079,
            "recall": 0.67883,
            "fmeasure": 0.68478
        },
        "rouge2": {
            "precision": 0.4334,
            "recall": 0.42554,
            "fmeasure": 0.42409
        },
        "rougeL": {
            "precision": 0.58531,
            "recall": 0.56746,
            "fmeasure": 0.5687
        },
        "rougeLsum": {
            "precision": 0.58531,
            "recall": 0.56746,
            "fmeasure": 0.5687
        },
        "nist": 5.399699517555042,
        "bleu": 37.19901,
        "bertscore": {
            "precision": 0.91557,
            "recall": 0.90977,
            "f1": 0.91123
        },
        "bleurt": 0.15881,
        "meteor": 0.34344489487809476,
        "nubia": {
            "semantic_relation": 4.19894,
            "contradiction": 3.78711,
            "irrelevancy": 33.67826,
            "logical_agreement": 62.53463,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.81942,
            "nubia_score": 0.71495
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.23809523809523808,
            "3": 0.6377952755905512
        },
        "rouge1": {
            "precision": 0.60636,
            "recall": 0.62053,
            "fmeasure": 0.59423
        },
        "rouge2": {
            "precision": 0.35635,
            "recall": 0.37272,
            "fmeasure": 0.3503
        },
        "rougeL": {
            "precision": 0.52068,
            "recall": 0.54692,
            "fmeasure": 0.51963
        },
        "rougeLsum": {
            "precision": 0.52068,
            "recall": 0.54692,
            "fmeasure": 0.51963
        },
        "nist": 4.45118466756198,
        "bleu": 28.54543,
        "bertscore": {
            "precision": 0.8896,
            "recall": 0.89214,
            "f1": 0.88771
        },
        "bleurt": 0.04872,
        "meteor": 0.30185313466297026,
        "nubia": {
            "semantic_relation": 3.71451,
            "contradiction": 22.0475,
            "irrelevancy": 36.50836,
            "logical_agreement": 41.44414,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.44185,
            "nubia_score": 0.59322
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.25,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.50222,
            "fmeasure": 0.54451
        },
        "rouge2": {
            "precision": 0.39216,
            "recall": 0.2924,
            "fmeasure": 0.33424
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.41,
            "fmeasure": 0.46389
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.41,
            "fmeasure": 0.46389
        },
        "nist": 3.576211811903686,
        "bleu": 34.20233,
        "bertscore": {
            "precision": 0.92436,
            "recall": 0.85963,
            "f1": 0.89082
        },
        "bleurt": -0.22634,
        "meteor": 0.3401980058584098,
        "nubia": {
            "semantic_relation": 2.95006,
            "contradiction": 4.17109,
            "irrelevancy": 73.30588,
            "logical_agreement": 22.52303,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.78514,
            "nubia_score": 0.40396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "mT5_small/totto_test",
        "N": 47,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1415929203539823,
            "2": 0.4764705882352941,
            "3": 0.7208333333333333
        },
        "rouge1": {
            "precision": 0.7521,
            "recall": 0.67867,
            "fmeasure": 0.7068
        },
        "rouge2": {
            "precision": 0.50961,
            "recall": 0.45558,
            "fmeasure": 0.47672
        },
        "rougeL": {
            "precision": 0.63661,
            "recall": 0.57465,
            "fmeasure": 0.59855
        },
        "rougeLsum": {
            "precision": 0.63661,
            "recall": 0.57465,
            "fmeasure": 0.59855
        },
        "nist": 6.3031905092181635,
        "bleu": 39.52123,
        "bertscore": {
            "precision": 0.92506,
            "recall": 0.91283,
            "f1": 0.91766
        },
        "bleurt": 0.24688,
        "meteor": 0.35488787667613125,
        "nubia": {
            "semantic_relation": 4.22649,
            "contradiction": 6.89023,
            "irrelevancy": 29.47214,
            "logical_agreement": 63.63762,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.96169,
            "nubia_score": 0.6971
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5357142857142857
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.41905,
            "fmeasure": 0.56855
        },
        "rouge2": {
            "precision": 0.55882,
            "recall": 0.25681,
            "fmeasure": 0.35125
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.2619,
            "fmeasure": 0.35535
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.2619,
            "fmeasure": 0.35535
        },
        "nist": 0.5365340734727791,
        "bleu": 19.77325,
        "bertscore": {
            "precision": 0.95266,
            "recall": 0.87426,
            "f1": 0.91178
        },
        "bleurt": -0.10405,
        "meteor": 0.2392750787933601,
        "nubia": {
            "semantic_relation": 3.09754,
            "contradiction": 10.09101,
            "irrelevancy": 2.33793,
            "logical_agreement": 87.57106,
            "grammar_ref": 3.72412,
            "grammar_hyp": 4.1066,
            "nubia_score": 0.27935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "mT5_small/totto_test",
        "N": 21,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25757575757575757,
            "2": 0.3723404255319149,
            "3": 0.7216494845360825
        },
        "rouge1": {
            "precision": 0.7161,
            "recall": 0.65412,
            "fmeasure": 0.6709
        },
        "rouge2": {
            "precision": 0.45355,
            "recall": 0.43045,
            "fmeasure": 0.43388
        },
        "rougeL": {
            "precision": 0.58532,
            "recall": 0.54759,
            "fmeasure": 0.55727
        },
        "rougeLsum": {
            "precision": 0.58532,
            "recall": 0.54759,
            "fmeasure": 0.55727
        },
        "nist": 5.872049724982108,
        "bleu": 37.83547,
        "bertscore": {
            "precision": 0.91593,
            "recall": 0.90814,
            "f1": 0.91062
        },
        "bleurt": 0.09636,
        "meteor": 0.353647739435028,
        "nubia": {
            "semantic_relation": 3.85897,
            "contradiction": 15.19668,
            "irrelevancy": 30.63444,
            "logical_agreement": 54.16888,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.77089,
            "nubia_score": 0.62544
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.25,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.36957,
            "recall": 0.43016,
            "fmeasure": 0.3966
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.10322,
            "fmeasure": 0.09179
        },
        "rougeL": {
            "precision": 0.24638,
            "recall": 0.28621,
            "fmeasure": 0.26419
        },
        "rougeLsum": {
            "precision": 0.24638,
            "recall": 0.28621,
            "fmeasure": 0.26419
        },
        "nist": 1.4387115475208416,
        "bleu": 4.23396,
        "bertscore": {
            "precision": 0.84285,
            "recall": 0.85592,
            "f1": 0.846
        },
        "bleurt": -0.20112,
        "meteor": 0.22634992369177087,
        "nubia": {
            "semantic_relation": 3.72957,
            "contradiction": 34.27738,
            "irrelevancy": 41.53185,
            "logical_agreement": 24.19078,
            "grammar_ref": 4.80653,
            "grammar_hyp": 2.64475,
            "nubia_score": 0.82577
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.31081,
            "recall": 0.68056,
            "fmeasure": 0.42642
        },
        "rouge2": {
            "precision": 0.15278,
            "recall": 0.34706,
            "fmeasure": 0.21199
        },
        "rougeL": {
            "precision": 0.28378,
            "recall": 0.62153,
            "fmeasure": 0.38937
        },
        "rougeLsum": {
            "precision": 0.28378,
            "recall": 0.62153,
            "fmeasure": 0.38937
        },
        "nist": 1.165631182898585,
        "bleu": 8.21384,
        "bertscore": {
            "precision": 0.79585,
            "recall": 0.89252,
            "f1": 0.84142
        },
        "bleurt": 0.09749,
        "meteor": 0.29985064285408536,
        "nubia": {
            "semantic_relation": 3.90125,
            "contradiction": 1.45137,
            "irrelevancy": 14.38086,
            "logical_agreement": 84.16776,
            "grammar_ref": 4.60656,
            "grammar_hyp": 2.30393,
            "nubia_score": 0.38889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "mT5_small/totto_test",
        "N": 22,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25333333333333335,
            "2": 0.43636363636363634,
            "3": 0.7336956521739131
        },
        "rouge1": {
            "precision": 0.69561,
            "recall": 0.68405,
            "fmeasure": 0.68193
        },
        "rouge2": {
            "precision": 0.45634,
            "recall": 0.4427,
            "fmeasure": 0.4407
        },
        "rougeL": {
            "precision": 0.6049,
            "recall": 0.59583,
            "fmeasure": 0.58847
        },
        "rougeLsum": {
            "precision": 0.6049,
            "recall": 0.59583,
            "fmeasure": 0.58847
        },
        "nist": 5.710893309119593,
        "bleu": 41.35141,
        "bertscore": {
            "precision": 0.9057,
            "recall": 0.91219,
            "f1": 0.90851
        },
        "bleurt": 0.1257,
        "meteor": 0.3568363386180023,
        "nubia": {
            "semantic_relation": 4.18551,
            "contradiction": 10.68004,
            "irrelevancy": 23.95596,
            "logical_agreement": 65.364,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.13569,
            "nubia_score": 0.7097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.8260869565217391
        },
        "rouge1": {
            "precision": 0.76162,
            "recall": 0.75311,
            "fmeasure": 0.75113
        },
        "rouge2": {
            "precision": 0.57259,
            "recall": 0.5797,
            "fmeasure": 0.57135
        },
        "rougeL": {
            "precision": 0.71616,
            "recall": 0.72824,
            "fmeasure": 0.71649
        },
        "rougeLsum": {
            "precision": 0.71616,
            "recall": 0.72824,
            "fmeasure": 0.71649
        },
        "nist": 5.673790490761424,
        "bleu": 59.06665,
        "bertscore": {
            "precision": 0.9382,
            "recall": 0.93885,
            "f1": 0.93662
        },
        "bleurt": 0.31233,
        "meteor": 0.4214028122045488,
        "nubia": {
            "semantic_relation": 3.85314,
            "contradiction": 22.33769,
            "irrelevancy": 40.54318,
            "logical_agreement": 37.11913,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.88478,
            "nubia_score": 0.62894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.73178,
            "fmeasure": 0.77904
        },
        "rouge2": {
            "precision": 0.6572,
            "recall": 0.57012,
            "fmeasure": 0.6104
        },
        "rougeL": {
            "precision": 0.81159,
            "recall": 0.71392,
            "fmeasure": 0.75943
        },
        "rougeLsum": {
            "precision": 0.81159,
            "recall": 0.71392,
            "fmeasure": 0.75943
        },
        "nist": 5.801545355944441,
        "bleu": 73.07377,
        "bertscore": {
            "precision": 0.95372,
            "recall": 0.90573,
            "f1": 0.92895
        },
        "bleurt": 0.31658,
        "meteor": 0.45804912819880694,
        "nubia": {
            "semantic_relation": 4.52343,
            "contradiction": 0.39869,
            "irrelevancy": 16.57137,
            "logical_agreement": 83.02994,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.64136,
            "nubia_score": 0.81621
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "mT5_small/totto_test",
        "N": 46,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3357664233576642,
            "3": 0.6897233201581028
        },
        "rouge1": {
            "precision": 0.76165,
            "recall": 0.69453,
            "fmeasure": 0.70867
        },
        "rouge2": {
            "precision": 0.52352,
            "recall": 0.47773,
            "fmeasure": 0.4877
        },
        "rougeL": {
            "precision": 0.66042,
            "recall": 0.60527,
            "fmeasure": 0.61665
        },
        "rougeLsum": {
            "precision": 0.66042,
            "recall": 0.60527,
            "fmeasure": 0.61665
        },
        "nist": 5.956854491354726,
        "bleu": 38.17053,
        "bertscore": {
            "precision": 0.91968,
            "recall": 0.90796,
            "f1": 0.91218
        },
        "bleurt": 0.24145,
        "meteor": 0.346974866840585,
        "nubia": {
            "semantic_relation": 4.09627,
            "contradiction": 12.69171,
            "irrelevancy": 35.32656,
            "logical_agreement": 51.98174,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.85838,
            "nubia_score": 0.66161
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "mT5_small/totto_test",
        "N": 23,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.32558139534883723,
            "3": 0.7948717948717948
        },
        "rouge1": {
            "precision": 0.78113,
            "recall": 0.71281,
            "fmeasure": 0.73165
        },
        "rouge2": {
            "precision": 0.5528,
            "recall": 0.49965,
            "fmeasure": 0.51478
        },
        "rougeL": {
            "precision": 0.66426,
            "recall": 0.61306,
            "fmeasure": 0.62674
        },
        "rougeLsum": {
            "precision": 0.66426,
            "recall": 0.61306,
            "fmeasure": 0.62674
        },
        "nist": 6.072331386790897,
        "bleu": 44.57777,
        "bertscore": {
            "precision": 0.93028,
            "recall": 0.91518,
            "f1": 0.9201
        },
        "bleurt": 0.30449,
        "meteor": 0.3791534390749125,
        "nubia": {
            "semantic_relation": 4.29962,
            "contradiction": 10.64559,
            "irrelevancy": 17.5148,
            "logical_agreement": 71.83961,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.65649,
            "nubia_score": 0.74703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285,
            "3": 0.8928571428571429
        },
        "rouge1": {
            "precision": 0.91111,
            "recall": 0.78836,
            "fmeasure": 0.83555
        },
        "rouge2": {
            "precision": 0.69974,
            "recall": 0.59861,
            "fmeasure": 0.63452
        },
        "rougeL": {
            "precision": 0.8321,
            "recall": 0.68679,
            "fmeasure": 0.74175
        },
        "rougeLsum": {
            "precision": 0.8321,
            "recall": 0.68679,
            "fmeasure": 0.74175
        },
        "nist": 4.7404575976315,
        "bleu": 47.88358,
        "bertscore": {
            "precision": 0.94465,
            "recall": 0.93483,
            "f1": 0.93909
        },
        "bleurt": 0.2082,
        "meteor": 0.43598021491424405,
        "nubia": {
            "semantic_relation": 4.57162,
            "contradiction": 1.4714,
            "irrelevancy": 33.67697,
            "logical_agreement": 64.85163,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.10903,
            "nubia_score": 0.78664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2831858407079646,
            "2": 0.42857142857142855,
            "3": 0.7851239669421488
        },
        "rouge1": {
            "precision": 0.76861,
            "recall": 0.75723,
            "fmeasure": 0.74699
        },
        "rouge2": {
            "precision": 0.5891,
            "recall": 0.5813,
            "fmeasure": 0.57317
        },
        "rougeL": {
            "precision": 0.69835,
            "recall": 0.68978,
            "fmeasure": 0.67965
        },
        "rougeLsum": {
            "precision": 0.69835,
            "recall": 0.68978,
            "fmeasure": 0.67965
        },
        "nist": 7.014319220927624,
        "bleu": 57.04125,
        "bertscore": {
            "precision": 0.9316,
            "recall": 0.92834,
            "f1": 0.92843
        },
        "bleurt": 0.31176,
        "meteor": 0.42981268472628237,
        "nubia": {
            "semantic_relation": 4.15703,
            "contradiction": 8.30095,
            "irrelevancy": 27.68468,
            "logical_agreement": 64.01437,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.78081,
            "nubia_score": 0.70516
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "mT5_small/totto_test",
        "N": 41,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32222222222222224,
            "2": 0.4297520661157025,
            "3": 0.7606060606060606
        },
        "rouge1": {
            "precision": 0.68952,
            "recall": 0.70594,
            "fmeasure": 0.68774
        },
        "rouge2": {
            "precision": 0.47385,
            "recall": 0.4913,
            "fmeasure": 0.47482
        },
        "rougeL": {
            "precision": 0.58239,
            "recall": 0.59594,
            "fmeasure": 0.58018
        },
        "rougeLsum": {
            "precision": 0.58239,
            "recall": 0.59594,
            "fmeasure": 0.58018
        },
        "nist": 5.8802572344761295,
        "bleu": 40.95937,
        "bertscore": {
            "precision": 0.91637,
            "recall": 0.92184,
            "f1": 0.91635
        },
        "bleurt": 0.27205,
        "meteor": 0.38444892008841236,
        "nubia": {
            "semantic_relation": 3.81726,
            "contradiction": 14.1342,
            "irrelevancy": 38.88751,
            "logical_agreement": 46.97829,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.37589,
            "nubia_score": 0.64299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "mT5_small/totto_test",
        "N": 75,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22264150943396227,
            "2": 0.4398148148148148,
            "3": 0.7796178343949045
        },
        "rouge1": {
            "precision": 0.75269,
            "recall": 0.74115,
            "fmeasure": 0.7354
        },
        "rouge2": {
            "precision": 0.53689,
            "recall": 0.53684,
            "fmeasure": 0.52827
        },
        "rougeL": {
            "precision": 0.6458,
            "recall": 0.64088,
            "fmeasure": 0.63322
        },
        "rougeLsum": {
            "precision": 0.6458,
            "recall": 0.64088,
            "fmeasure": 0.63322
        },
        "nist": 7.336610412376681,
        "bleu": 46.84234,
        "bertscore": {
            "precision": 0.92842,
            "recall": 0.92609,
            "f1": 0.92586
        },
        "bleurt": 0.25117,
        "meteor": 0.38728914075797793,
        "nubia": {
            "semantic_relation": 4.15498,
            "contradiction": 11.29581,
            "irrelevancy": 34.61894,
            "logical_agreement": 54.08525,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.85884,
            "nubia_score": 0.69985
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.675,
            "fmeasure": 0.52636
        },
        "rouge2": {
            "precision": 0.175,
            "recall": 0.27193,
            "fmeasure": 0.20601
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.575,
            "fmeasure": 0.4288
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.575,
            "fmeasure": 0.4288
        },
        "nist": 2.945135932225555,
        "bleu": 14.93764,
        "bertscore": {
            "precision": 0.87593,
            "recall": 0.94608,
            "f1": 0.90965
        },
        "bleurt": 0.22068,
        "meteor": 0.34748951982843684,
        "nubia": {
            "semantic_relation": 3.35307,
            "contradiction": 75.49359,
            "irrelevancy": 17.7065,
            "logical_agreement": 6.79991,
            "grammar_ref": 5.69136,
            "grammar_hyp": 4.24485,
            "nubia_score": 0.47748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12307692307692308,
            "2": 0.543859649122807,
            "3": 0.7674418604651163
        },
        "rouge1": {
            "precision": 0.7831,
            "recall": 0.72703,
            "fmeasure": 0.74489
        },
        "rouge2": {
            "precision": 0.52799,
            "recall": 0.50007,
            "fmeasure": 0.50721
        },
        "rougeL": {
            "precision": 0.65071,
            "recall": 0.60918,
            "fmeasure": 0.62114
        },
        "rougeLsum": {
            "precision": 0.65071,
            "recall": 0.60918,
            "fmeasure": 0.62114
        },
        "nist": 5.908523645942741,
        "bleu": 38.90916,
        "bertscore": {
            "precision": 0.94295,
            "recall": 0.93135,
            "f1": 0.93548
        },
        "bleurt": 0.22585,
        "meteor": 0.3818190872732792,
        "nubia": {
            "semantic_relation": 4.20016,
            "contradiction": 19.43822,
            "irrelevancy": 19.68189,
            "logical_agreement": 60.87989,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.87995,
            "nubia_score": 0.70831
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365
        },
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.20606,
            "fmeasure": 0.29206
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.04502,
            "fmeasure": 0.06737
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.16364,
            "fmeasure": 0.23333
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.16364,
            "fmeasure": 0.23333
        },
        "nist": 0.06784113004060655,
        "bleu": 9.17989,
        "bertscore": {
            "precision": 0.89657,
            "recall": 0.83075,
            "f1": 0.84796
        },
        "bleurt": -0.36937,
        "meteor": 0.1207349217317309,
        "nubia": {
            "semantic_relation": 2.33456,
            "contradiction": 89.94806,
            "irrelevancy": 4.9887,
            "logical_agreement": 5.06324,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.93063,
            "nubia_score": 0.18884
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.28356,
            "fmeasure": 0.28355
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07639,
            "fmeasure": 0.07632
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.23379,
            "fmeasure": 0.24612
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.23379,
            "fmeasure": 0.24612
        },
        "nist": 1.2896535733446404,
        "bleu": 6.60897,
        "bertscore": {
            "precision": 0.67318,
            "recall": 0.65047,
            "f1": 0.66163
        },
        "bleurt": -0.56245,
        "meteor": 0.12298666213114799,
        "nubia": {
            "semantic_relation": 1.19878,
            "contradiction": 33.61452,
            "irrelevancy": 65.59581,
            "logical_agreement": 0.78967,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.88775,
            "nubia_score": 0.09475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.48148,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "nist": 1.7503473569799732,
        "bleu": 18.29565,
        "bertscore": {
            "precision": 0.87103,
            "recall": 0.90546,
            "f1": 0.88791
        },
        "bleurt": 0.12284,
        "meteor": 0.35356235305705724,
        "nubia": {
            "semantic_relation": 3.99409,
            "contradiction": 0.26568,
            "irrelevancy": 22.76223,
            "logical_agreement": 76.97209,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.24002,
            "nubia_score": 0.64181
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.85714,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.45098,
            "recall": 0.58974,
            "fmeasure": 0.51111
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.85348,
            "fmeasure": 0.73656
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.85348,
            "fmeasure": 0.73656
        },
        "nist": 3.530327202443996,
        "bleu": 45.07483,
        "bertscore": {
            "precision": 0.90431,
            "recall": 0.94667,
            "f1": 0.925
        },
        "bleurt": 0.16067,
        "meteor": 0.4074080348018741,
        "nubia": {
            "semantic_relation": 2.12166,
            "contradiction": 89.06826,
            "irrelevancy": 10.40701,
            "logical_agreement": 0.52473,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.28978,
            "nubia_score": 0.30177
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35294,
            "fmeasure": 0.41379
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.25,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "nist": 1.2518755231080134,
        "bleu": 19.82688,
        "bertscore": {
            "precision": 0.87412,
            "recall": 0.78643,
            "f1": 0.82796
        },
        "bleurt": -0.2294,
        "meteor": 0.22195679961878512,
        "nubia": {
            "semantic_relation": 2.37725,
            "contradiction": 70.67274,
            "irrelevancy": 28.59182,
            "logical_agreement": 0.73544,
            "grammar_ref": 4.28272,
            "grammar_hyp": 3.88229,
            "nubia_score": 0.19987
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.2963,
            "recall": 0.17634,
            "fmeasure": 0.20702
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.03333,
            "fmeasure": 0.05263
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.09677,
            "fmeasure": 0.15
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.09677,
            "fmeasure": 0.15
        },
        "nist": 0.03525105957435651,
        "bleu": 8.6398,
        "bertscore": {
            "precision": 0.85562,
            "recall": 0.74732,
            "f1": 0.79187
        },
        "bleurt": -0.53143,
        "meteor": 0.0795092418437589,
        "nubia": {
            "semantic_relation": 1.62674,
            "contradiction": 40.42508,
            "irrelevancy": 21.67918,
            "logical_agreement": 37.89574,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.14668,
            "nubia_score": 0.12892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.35714,
            "recall": 0.41667,
            "fmeasure": 0.38462
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.41667,
            "fmeasure": 0.38462
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.41667,
            "fmeasure": 0.38462
        },
        "nist": 1.3468425539231035,
        "bleu": 4.11298,
        "bertscore": {
            "precision": 0.79807,
            "recall": 0.81416,
            "f1": 0.80603
        },
        "bleurt": -0.94183,
        "meteor": 0.18835675252073666,
        "nubia": {
            "semantic_relation": 1.42455,
            "contradiction": 87.30323,
            "irrelevancy": 12.3163,
            "logical_agreement": 0.38047,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.13187,
            "nubia_score": 0.10553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "mT5_small/totto_test",
        "N": 50,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.5220125786163522,
            "3": 0.6788321167883211
        },
        "rouge1": {
            "precision": 0.75317,
            "recall": 0.67744,
            "fmeasure": 0.70382
        },
        "rouge2": {
            "precision": 0.50427,
            "recall": 0.46077,
            "fmeasure": 0.47466
        },
        "rougeL": {
            "precision": 0.65873,
            "recall": 0.59398,
            "fmeasure": 0.61588
        },
        "rougeLsum": {
            "precision": 0.65873,
            "recall": 0.59398,
            "fmeasure": 0.61588
        },
        "nist": 6.441896591322682,
        "bleu": 37.38784,
        "bertscore": {
            "precision": 0.92552,
            "recall": 0.91025,
            "f1": 0.91627
        },
        "bleurt": 0.2182,
        "meteor": 0.3480873125850609,
        "nubia": {
            "semantic_relation": 4.08243,
            "contradiction": 12.93157,
            "irrelevancy": 21.75677,
            "logical_agreement": 65.31166,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.87418,
            "nubia_score": 0.681
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "mT5_small/totto_test",
        "N": 42,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1565217391304348,
            "2": 0.5483870967741935,
            "3": 0.7582644628099173
        },
        "rouge1": {
            "precision": 0.77077,
            "recall": 0.75716,
            "fmeasure": 0.75281
        },
        "rouge2": {
            "precision": 0.56244,
            "recall": 0.54526,
            "fmeasure": 0.54515
        },
        "rougeL": {
            "precision": 0.67555,
            "recall": 0.65451,
            "fmeasure": 0.65322
        },
        "rougeLsum": {
            "precision": 0.67555,
            "recall": 0.65451,
            "fmeasure": 0.65322
        },
        "nist": 6.829041295952447,
        "bleu": 48.38315,
        "bertscore": {
            "precision": 0.93537,
            "recall": 0.93073,
            "f1": 0.93171
        },
        "bleurt": 0.33374,
        "meteor": 0.4042609374872011,
        "nubia": {
            "semantic_relation": 4.22732,
            "contradiction": 19.24763,
            "irrelevancy": 24.06259,
            "logical_agreement": 56.68978,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.55414,
            "nubia_score": 0.7159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "mT5_small/totto_test",
        "N": 169,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20711297071129708,
            "2": 0.3752808988764045,
            "3": 0.7334401709401709
        },
        "rouge1": {
            "precision": 0.73848,
            "recall": 0.70501,
            "fmeasure": 0.70835
        },
        "rouge2": {
            "precision": 0.50947,
            "recall": 0.48523,
            "fmeasure": 0.48832
        },
        "rougeL": {
            "precision": 0.64377,
            "recall": 0.61493,
            "fmeasure": 0.61732
        },
        "rougeLsum": {
            "precision": 0.64377,
            "recall": 0.61493,
            "fmeasure": 0.61732
        },
        "nist": 7.348040643642153,
        "bleu": 41.21703,
        "bertscore": {
            "precision": 0.92198,
            "recall": 0.90987,
            "f1": 0.91429
        },
        "bleurt": 0.23884,
        "meteor": 0.36682282658547233,
        "nubia": {
            "semantic_relation": 4.05629,
            "contradiction": 11.8807,
            "irrelevancy": 29.14468,
            "logical_agreement": 58.97462,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.66984,
            "nubia_score": 0.68599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "mT5_small/totto_test",
        "N": 79,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24115755627009647,
            "2": 0.3801369863013699,
            "3": 0.7180500658761528
        },
        "rouge1": {
            "precision": 0.71717,
            "recall": 0.65465,
            "fmeasure": 0.66638
        },
        "rouge2": {
            "precision": 0.46914,
            "recall": 0.42994,
            "fmeasure": 0.43553
        },
        "rougeL": {
            "precision": 0.61447,
            "recall": 0.55538,
            "fmeasure": 0.56679
        },
        "rougeLsum": {
            "precision": 0.61447,
            "recall": 0.55538,
            "fmeasure": 0.56679
        },
        "nist": 6.534762124725911,
        "bleu": 36.73259,
        "bertscore": {
            "precision": 0.92107,
            "recall": 0.90451,
            "f1": 0.91089
        },
        "bleurt": 0.10699,
        "meteor": 0.355808132228069,
        "nubia": {
            "semantic_relation": 4.00515,
            "contradiction": 8.80884,
            "irrelevancy": 31.21995,
            "logical_agreement": 59.97121,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.97357,
            "nubia_score": 0.65319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "mT5_small/totto_test",
        "N": 15,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.3181818181818182,
            "3": 0.7388535031847133
        },
        "rouge1": {
            "precision": 0.76717,
            "recall": 0.71781,
            "fmeasure": 0.73121
        },
        "rouge2": {
            "precision": 0.50253,
            "recall": 0.47794,
            "fmeasure": 0.48315
        },
        "rougeL": {
            "precision": 0.63341,
            "recall": 0.60093,
            "fmeasure": 0.60797
        },
        "rougeLsum": {
            "precision": 0.63341,
            "recall": 0.60093,
            "fmeasure": 0.60797
        },
        "nist": 5.044918624511723,
        "bleu": 37.25498,
        "bertscore": {
            "precision": 0.92307,
            "recall": 0.91642,
            "f1": 0.9194
        },
        "bleurt": 0.20954,
        "meteor": 0.3567097946756536,
        "nubia": {
            "semantic_relation": 4.13287,
            "contradiction": 11.70661,
            "irrelevancy": 38.40397,
            "logical_agreement": 49.88942,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.81613,
            "nubia_score": 0.67877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.2857142857142857,
            "3": 0.6756756756756757
        },
        "rouge1": {
            "precision": 0.73398,
            "recall": 0.68851,
            "fmeasure": 0.69189
        },
        "rouge2": {
            "precision": 0.42535,
            "recall": 0.43079,
            "fmeasure": 0.41972
        },
        "rougeL": {
            "precision": 0.57495,
            "recall": 0.5966,
            "fmeasure": 0.56889
        },
        "rougeLsum": {
            "precision": 0.57495,
            "recall": 0.5966,
            "fmeasure": 0.56889
        },
        "nist": 3.630994017288839,
        "bleu": 37.5461,
        "bertscore": {
            "precision": 0.90029,
            "recall": 0.89033,
            "f1": 0.88831
        },
        "bleurt": 0.06171,
        "meteor": 0.34789172918598343,
        "nubia": {
            "semantic_relation": 3.65225,
            "contradiction": 1.93445,
            "irrelevancy": 54.92831,
            "logical_agreement": 43.13724,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.78268,
            "nubia_score": 0.66458
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.1111111111111111,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.83796,
            "recall": 0.77862,
            "fmeasure": 0.80307
        },
        "rouge2": {
            "precision": 0.62616,
            "recall": 0.58878,
            "fmeasure": 0.6042
        },
        "rougeL": {
            "precision": 0.75278,
            "recall": 0.7064,
            "fmeasure": 0.726
        },
        "rougeLsum": {
            "precision": 0.75278,
            "recall": 0.7064,
            "fmeasure": 0.726
        },
        "nist": 4.236102568891087,
        "bleu": 56.6743,
        "bertscore": {
            "precision": 0.96022,
            "recall": 0.95911,
            "f1": 0.95961
        },
        "bleurt": 0.47662,
        "meteor": 0.441029069400302,
        "nubia": {
            "semantic_relation": 4.43646,
            "contradiction": 0.98757,
            "irrelevancy": 7.72808,
            "logical_agreement": 91.28435,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.10214,
            "nubia_score": 0.75768
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.3877551020408163,
            "3": 0.7258064516129032
        },
        "rouge1": {
            "precision": 0.72914,
            "recall": 0.70019,
            "fmeasure": 0.70485
        },
        "rouge2": {
            "precision": 0.48956,
            "recall": 0.49771,
            "fmeasure": 0.48693
        },
        "rougeL": {
            "precision": 0.63329,
            "recall": 0.62081,
            "fmeasure": 0.61823
        },
        "rougeLsum": {
            "precision": 0.63329,
            "recall": 0.62081,
            "fmeasure": 0.61823
        },
        "nist": 5.757256037071426,
        "bleu": 40.79646,
        "bertscore": {
            "precision": 0.93139,
            "recall": 0.92384,
            "f1": 0.92551
        },
        "bleurt": 0.32948,
        "meteor": 0.3638214925712395,
        "nubia": {
            "semantic_relation": 4.2577,
            "contradiction": 12.8018,
            "irrelevancy": 22.35959,
            "logical_agreement": 64.83861,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.10467,
            "nubia_score": 0.75486
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.7755102040816326
        },
        "rouge1": {
            "precision": 0.78803,
            "recall": 0.76799,
            "fmeasure": 0.77592
        },
        "rouge2": {
            "precision": 0.65846,
            "recall": 0.6623,
            "fmeasure": 0.65754
        },
        "rougeL": {
            "precision": 0.70711,
            "recall": 0.68931,
            "fmeasure": 0.69595
        },
        "rougeLsum": {
            "precision": 0.70711,
            "recall": 0.68931,
            "fmeasure": 0.69595
        },
        "nist": 5.208269552421197,
        "bleu": 47.81037,
        "bertscore": {
            "precision": 0.94319,
            "recall": 0.90297,
            "f1": 0.92041
        },
        "bleurt": 0.25863,
        "meteor": 0.39888215658616655,
        "nubia": {
            "semantic_relation": 4.0588,
            "contradiction": 15.85094,
            "irrelevancy": 23.65037,
            "logical_agreement": 60.49868,
            "grammar_ref": 5.56433,
            "grammar_hyp": 5.02586,
            "nubia_score": 0.72181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5294117647058824,
            "3": 0.7830188679245284
        },
        "rouge1": {
            "precision": 0.79548,
            "recall": 0.73903,
            "fmeasure": 0.75158
        },
        "rouge2": {
            "precision": 0.48025,
            "recall": 0.45433,
            "fmeasure": 0.45419
        },
        "rougeL": {
            "precision": 0.7017,
            "recall": 0.65389,
            "fmeasure": 0.66204
        },
        "rougeLsum": {
            "precision": 0.7017,
            "recall": 0.65389,
            "fmeasure": 0.66204
        },
        "nist": 5.725046155688427,
        "bleu": 42.66109,
        "bertscore": {
            "precision": 0.93294,
            "recall": 0.92617,
            "f1": 0.92883
        },
        "bleurt": 0.35275,
        "meteor": 0.3860767069772533,
        "nubia": {
            "semantic_relation": 4.61717,
            "contradiction": 9.51478,
            "irrelevancy": 11.87368,
            "logical_agreement": 78.61155,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.5441,
            "nubia_score": 0.77376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23255813953488372,
            "2": 0.3684210526315789,
            "3": 0.6838235294117647
        },
        "rouge1": {
            "precision": 0.77162,
            "recall": 0.67828,
            "fmeasure": 0.69789
        },
        "rouge2": {
            "precision": 0.54208,
            "recall": 0.47657,
            "fmeasure": 0.48853
        },
        "rougeL": {
            "precision": 0.67108,
            "recall": 0.57344,
            "fmeasure": 0.59537
        },
        "rougeLsum": {
            "precision": 0.67108,
            "recall": 0.57344,
            "fmeasure": 0.59537
        },
        "nist": 5.23898845560707,
        "bleu": 36.7656,
        "bertscore": {
            "precision": 0.91748,
            "recall": 0.9067,
            "f1": 0.91093
        },
        "bleurt": 0.2032,
        "meteor": 0.38251531383455656,
        "nubia": {
            "semantic_relation": 4.31043,
            "contradiction": 9.28529,
            "irrelevancy": 20.91368,
            "logical_agreement": 69.80103,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.90921,
            "nubia_score": 0.70153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16393442622950818,
            "2": 0.42857142857142855,
            "3": 0.5974842767295597
        },
        "rouge1": {
            "precision": 0.72824,
            "recall": 0.64232,
            "fmeasure": 0.67327
        },
        "rouge2": {
            "precision": 0.47408,
            "recall": 0.42058,
            "fmeasure": 0.43567
        },
        "rougeL": {
            "precision": 0.59903,
            "recall": 0.53419,
            "fmeasure": 0.55657
        },
        "rougeLsum": {
            "precision": 0.59903,
            "recall": 0.53419,
            "fmeasure": 0.55657
        },
        "nist": 4.629827933713825,
        "bleu": 34.89554,
        "bertscore": {
            "precision": 0.92189,
            "recall": 0.89117,
            "f1": 0.90403
        },
        "bleurt": 0.13617,
        "meteor": 0.330134394000105,
        "nubia": {
            "semantic_relation": 3.96252,
            "contradiction": 19.33591,
            "irrelevancy": 34.80889,
            "logical_agreement": 45.8552,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.60531,
            "nubia_score": 0.66276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.88426,
            "fmeasure": 0.82066
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.42857,
            "fmeasure": 0.39706
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.61111,
            "fmeasure": 0.5692
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.61111,
            "fmeasure": 0.5692
        },
        "nist": 3.158771874579326,
        "bleu": 13.32919,
        "bertscore": {
            "precision": 0.88829,
            "recall": 0.89264,
            "f1": 0.88713
        },
        "bleurt": 0.0303,
        "meteor": 0.3970980027653008,
        "nubia": {
            "semantic_relation": 4.78221,
            "contradiction": 1.99926,
            "irrelevancy": 1.49663,
            "logical_agreement": 96.50411,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.01928,
            "nubia_score": 0.86253
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.3333333333333333,
            "3": 0.7176470588235294
        },
        "rouge1": {
            "precision": 0.76278,
            "recall": 0.70342,
            "fmeasure": 0.71658
        },
        "rouge2": {
            "precision": 0.51996,
            "recall": 0.47803,
            "fmeasure": 0.48901
        },
        "rougeL": {
            "precision": 0.6595,
            "recall": 0.60638,
            "fmeasure": 0.62014
        },
        "rougeLsum": {
            "precision": 0.6595,
            "recall": 0.60638,
            "fmeasure": 0.62014
        },
        "nist": 5.165293461072133,
        "bleu": 40.31595,
        "bertscore": {
            "precision": 0.93001,
            "recall": 0.92975,
            "f1": 0.92918
        },
        "bleurt": 0.26448,
        "meteor": 0.37951388513433865,
        "nubia": {
            "semantic_relation": 4.28172,
            "contradiction": 9.84545,
            "irrelevancy": 17.82575,
            "logical_agreement": 72.3288,
            "grammar_ref": 4.7817,
            "grammar_hyp": 5.02354,
            "nubia_score": 0.72135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.87338,
            "recall": 0.71861,
            "fmeasure": 0.78052
        },
        "rouge2": {
            "precision": 0.69615,
            "recall": 0.575,
            "fmeasure": 0.62273
        },
        "rougeL": {
            "precision": 0.76623,
            "recall": 0.64719,
            "fmeasure": 0.69481
        },
        "rougeLsum": {
            "precision": 0.76623,
            "recall": 0.64719,
            "fmeasure": 0.69481
        },
        "nist": 3.260697777087073,
        "bleu": 39.21692,
        "bertscore": {
            "precision": 0.96326,
            "recall": 0.94342,
            "f1": 0.9531
        },
        "bleurt": 0.41963,
        "meteor": 0.37541312957895034,
        "nubia": {
            "semantic_relation": 4.34343,
            "contradiction": 0.91667,
            "irrelevancy": 0.73274,
            "logical_agreement": 98.35058,
            "grammar_ref": 5.14789,
            "grammar_hyp": 5.45687,
            "nubia_score": 0.73773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23728813559322035,
            "2": 0.15217391304347827,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.68671,
            "recall": 0.59275,
            "fmeasure": 0.62293
        },
        "rouge2": {
            "precision": 0.39826,
            "recall": 0.35346,
            "fmeasure": 0.36323
        },
        "rougeL": {
            "precision": 0.59258,
            "recall": 0.53364,
            "fmeasure": 0.54758
        },
        "rougeLsum": {
            "precision": 0.59258,
            "recall": 0.53364,
            "fmeasure": 0.54758
        },
        "nist": 4.664268373557343,
        "bleu": 26.24025,
        "bertscore": {
            "precision": 0.90554,
            "recall": 0.8913,
            "f1": 0.89617
        },
        "bleurt": 0.12346,
        "meteor": 0.3325891754448245,
        "nubia": {
            "semantic_relation": 3.87062,
            "contradiction": 10.22975,
            "irrelevancy": 31.01263,
            "logical_agreement": 58.75762,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.4599,
            "nubia_score": 0.63416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.20588235294117646,
            "3": 0.7903930131004366
        },
        "rouge1": {
            "precision": 0.7681,
            "recall": 0.7368,
            "fmeasure": 0.74476
        },
        "rouge2": {
            "precision": 0.55797,
            "recall": 0.5256,
            "fmeasure": 0.5352
        },
        "rougeL": {
            "precision": 0.71935,
            "recall": 0.68379,
            "fmeasure": 0.69427
        },
        "rougeLsum": {
            "precision": 0.71935,
            "recall": 0.68379,
            "fmeasure": 0.69427
        },
        "nist": 6.40575976713583,
        "bleu": 52.24701,
        "bertscore": {
            "precision": 0.94073,
            "recall": 0.93342,
            "f1": 0.93653
        },
        "bleurt": 0.36058,
        "meteor": 0.4132162390694743,
        "nubia": {
            "semantic_relation": 4.36432,
            "contradiction": 6.0991,
            "irrelevancy": 29.94808,
            "logical_agreement": 63.95282,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.42443,
            "nubia_score": 0.78375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.2,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.76402,
            "recall": 0.73064,
            "fmeasure": 0.74099
        },
        "rouge2": {
            "precision": 0.53621,
            "recall": 0.53263,
            "fmeasure": 0.52998
        },
        "rougeL": {
            "precision": 0.63409,
            "recall": 0.6218,
            "fmeasure": 0.62322
        },
        "rougeLsum": {
            "precision": 0.63409,
            "recall": 0.6218,
            "fmeasure": 0.62322
        },
        "nist": 5.0893447702466235,
        "bleu": 45.92217,
        "bertscore": {
            "precision": 0.93404,
            "recall": 0.92848,
            "f1": 0.92989
        },
        "bleurt": 0.30207,
        "meteor": 0.4138564452554983,
        "nubia": {
            "semantic_relation": 4.16066,
            "contradiction": 22.51212,
            "irrelevancy": 22.39077,
            "logical_agreement": 55.09711,
            "grammar_ref": 5.14697,
            "grammar_hyp": 4.99937,
            "nubia_score": 0.72245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "mT5_small/totto_test",
        "N": 81,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22184300341296928,
            "2": 0.4418604651162791,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.74589,
            "recall": 0.72529,
            "fmeasure": 0.72089
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51663,
            "fmeasure": 0.51659
        },
        "rougeL": {
            "precision": 0.64383,
            "recall": 0.6211,
            "fmeasure": 0.61994
        },
        "rougeLsum": {
            "precision": 0.64383,
            "recall": 0.6211,
            "fmeasure": 0.61994
        },
        "nist": 7.222939430401863,
        "bleu": 47.55579,
        "bertscore": {
            "precision": 0.92445,
            "recall": 0.92167,
            "f1": 0.92158
        },
        "bleurt": 0.20059,
        "meteor": 0.390128441837152,
        "nubia": {
            "semantic_relation": 4.05923,
            "contradiction": 11.59656,
            "irrelevancy": 29.76365,
            "logical_agreement": 58.63979,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.55789,
            "nubia_score": 0.69358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.34615384615384615,
            "3": 0.7936507936507936
        },
        "rouge1": {
            "precision": 0.71872,
            "recall": 0.7119,
            "fmeasure": 0.70105
        },
        "rouge2": {
            "precision": 0.46289,
            "recall": 0.45605,
            "fmeasure": 0.45312
        },
        "rougeL": {
            "precision": 0.60085,
            "recall": 0.5866,
            "fmeasure": 0.58244
        },
        "rougeLsum": {
            "precision": 0.60085,
            "recall": 0.5866,
            "fmeasure": 0.58244
        },
        "nist": 5.263556231097492,
        "bleu": 39.23382,
        "bertscore": {
            "precision": 0.91824,
            "recall": 0.9143,
            "f1": 0.91571
        },
        "bleurt": 0.18932,
        "meteor": 0.38386148822170546,
        "nubia": {
            "semantic_relation": 3.99239,
            "contradiction": 16.28087,
            "irrelevancy": 33.24913,
            "logical_agreement": 50.47,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.48211,
            "nubia_score": 0.68056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.5,
            "3": 0.8765432098765432
        },
        "rouge1": {
            "precision": 0.83437,
            "recall": 0.81052,
            "fmeasure": 0.81641
        },
        "rouge2": {
            "precision": 0.63317,
            "recall": 0.61581,
            "fmeasure": 0.61809
        },
        "rougeL": {
            "precision": 0.77936,
            "recall": 0.75829,
            "fmeasure": 0.76147
        },
        "rougeLsum": {
            "precision": 0.77936,
            "recall": 0.75829,
            "fmeasure": 0.76147
        },
        "nist": 5.444505382158194,
        "bleu": 48.24074,
        "bertscore": {
            "precision": 0.942,
            "recall": 0.94296,
            "f1": 0.94068
        },
        "bleurt": 0.37624,
        "meteor": 0.4092217657538742,
        "nubia": {
            "semantic_relation": 4.53163,
            "contradiction": 1.33713,
            "irrelevancy": 48.68468,
            "logical_agreement": 49.97819,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.84845,
            "nubia_score": 0.8244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.89935,
            "fmeasure": 0.76507
        },
        "rouge2": {
            "precision": 0.46032,
            "recall": 0.67619,
            "fmeasure": 0.54762
        },
        "rougeL": {
            "precision": 0.5303,
            "recall": 0.71503,
            "fmeasure": 0.60845
        },
        "rougeLsum": {
            "precision": 0.5303,
            "recall": 0.71503,
            "fmeasure": 0.60845
        },
        "nist": 2.9275490900736547,
        "bleu": 24.76165,
        "bertscore": {
            "precision": 0.88284,
            "recall": 0.95311,
            "f1": 0.9151
        },
        "bleurt": 0.14202,
        "meteor": 0.4397196703295262,
        "nubia": {
            "semantic_relation": 4.21833,
            "contradiction": 1.01609,
            "irrelevancy": 79.47672,
            "logical_agreement": 19.5072,
            "grammar_ref": 5.18542,
            "grammar_hyp": 4.57029,
            "nubia_score": 0.7469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.3103448275862069,
            "3": 0.8206521739130435
        },
        "rouge1": {
            "precision": 0.80457,
            "recall": 0.7472,
            "fmeasure": 0.76582
        },
        "rouge2": {
            "precision": 0.53418,
            "recall": 0.50409,
            "fmeasure": 0.51152
        },
        "rougeL": {
            "precision": 0.67479,
            "recall": 0.64924,
            "fmeasure": 0.65156
        },
        "rougeLsum": {
            "precision": 0.67479,
            "recall": 0.64924,
            "fmeasure": 0.65156
        },
        "nist": 5.912168291843804,
        "bleu": 44.90275,
        "bertscore": {
            "precision": 0.93914,
            "recall": 0.93767,
            "f1": 0.93747
        },
        "bleurt": 0.3496,
        "meteor": 0.414709502419604,
        "nubia": {
            "semantic_relation": 4.42588,
            "contradiction": 5.20641,
            "irrelevancy": 24.7368,
            "logical_agreement": 70.05679,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.87685,
            "nubia_score": 0.75956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7575757575757576
        },
        "rouge1": {
            "precision": 0.76498,
            "recall": 0.69789,
            "fmeasure": 0.72805
        },
        "rouge2": {
            "precision": 0.54101,
            "recall": 0.49176,
            "fmeasure": 0.51384
        },
        "rougeL": {
            "precision": 0.63771,
            "recall": 0.57997,
            "fmeasure": 0.60611
        },
        "rougeLsum": {
            "precision": 0.63771,
            "recall": 0.57997,
            "fmeasure": 0.60611
        },
        "nist": 4.087096789608622,
        "bleu": 37.90927,
        "bertscore": {
            "precision": 0.95358,
            "recall": 0.93994,
            "f1": 0.94653
        },
        "bleurt": 0.37942,
        "meteor": 0.38625632750346567,
        "nubia": {
            "semantic_relation": 4.44343,
            "contradiction": 1.86393,
            "irrelevancy": 28.00511,
            "logical_agreement": 70.13096,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.04532,
            "nubia_score": 0.81473
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "mT5_small/totto_test",
        "N": 300,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18203033838973162,
            "2": 0.37900128040973113,
            "3": 0.7789634146341463
        },
        "rouge1": {
            "precision": 0.79018,
            "recall": 0.74329,
            "fmeasure": 0.75598
        },
        "rouge2": {
            "precision": 0.55111,
            "recall": 0.51466,
            "fmeasure": 0.5245
        },
        "rougeL": {
            "precision": 0.67748,
            "recall": 0.63731,
            "fmeasure": 0.64752
        },
        "rougeLsum": {
            "precision": 0.67748,
            "recall": 0.63731,
            "fmeasure": 0.64752
        },
        "nist": 8.301744676697313,
        "bleu": 43.40566,
        "bertscore": {
            "precision": 0.93778,
            "recall": 0.93037,
            "f1": 0.93285
        },
        "bleurt": 0.34321,
        "meteor": 0.39200222873354423,
        "nubia": {
            "semantic_relation": 4.31142,
            "contradiction": 7.49132,
            "irrelevancy": 24.70622,
            "logical_agreement": 67.80246,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.90556,
            "nubia_score": 0.75329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.5211267605633803,
            "3": 0.6935483870967742
        },
        "rouge1": {
            "precision": 0.65615,
            "recall": 0.68286,
            "fmeasure": 0.66042
        },
        "rouge2": {
            "precision": 0.3806,
            "recall": 0.41882,
            "fmeasure": 0.38588
        },
        "rougeL": {
            "precision": 0.53154,
            "recall": 0.59202,
            "fmeasure": 0.54221
        },
        "rougeLsum": {
            "precision": 0.53154,
            "recall": 0.59202,
            "fmeasure": 0.54221
        },
        "nist": 5.277249806279627,
        "bleu": 29.55539,
        "bertscore": {
            "precision": 0.90104,
            "recall": 0.90797,
            "f1": 0.90189
        },
        "bleurt": 0.08685,
        "meteor": 0.36843567221330986,
        "nubia": {
            "semantic_relation": 3.88347,
            "contradiction": 22.14049,
            "irrelevancy": 38.79197,
            "logical_agreement": 39.06753,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.44571,
            "nubia_score": 0.64176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "mT5_small/totto_test",
        "N": 37,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.3979591836734694,
            "3": 0.7028985507246377
        },
        "rouge1": {
            "precision": 0.68487,
            "recall": 0.69271,
            "fmeasure": 0.66906
        },
        "rouge2": {
            "precision": 0.45755,
            "recall": 0.4666,
            "fmeasure": 0.44506
        },
        "rougeL": {
            "precision": 0.58591,
            "recall": 0.59658,
            "fmeasure": 0.57264
        },
        "rougeLsum": {
            "precision": 0.58591,
            "recall": 0.59658,
            "fmeasure": 0.57264
        },
        "nist": 5.732981664673983,
        "bleu": 35.22295,
        "bertscore": {
            "precision": 0.90741,
            "recall": 0.90855,
            "f1": 0.90596
        },
        "bleurt": 0.08529,
        "meteor": 0.3579817519033087,
        "nubia": {
            "semantic_relation": 3.8966,
            "contradiction": 11.37985,
            "irrelevancy": 40.11404,
            "logical_agreement": 48.50611,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.78577,
            "nubia_score": 0.63642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "mT5_small/totto_test",
        "N": 76,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1605351170568562,
            "2": 0.45934959349593496,
            "3": 0.7188365650969529
        },
        "rouge1": {
            "precision": 0.71475,
            "recall": 0.66823,
            "fmeasure": 0.67592
        },
        "rouge2": {
            "precision": 0.45633,
            "recall": 0.42746,
            "fmeasure": 0.43066
        },
        "rougeL": {
            "precision": 0.62185,
            "recall": 0.58616,
            "fmeasure": 0.58972
        },
        "rougeLsum": {
            "precision": 0.62185,
            "recall": 0.58616,
            "fmeasure": 0.58972
        },
        "nist": 6.650326287909533,
        "bleu": 39.80487,
        "bertscore": {
            "precision": 0.92042,
            "recall": 0.91351,
            "f1": 0.91485
        },
        "bleurt": 0.17339,
        "meteor": 0.3621909908677656,
        "nubia": {
            "semantic_relation": 3.9779,
            "contradiction": 12.5391,
            "irrelevancy": 29.36207,
            "logical_agreement": 58.09883,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.76236,
            "nubia_score": 0.64949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "mT5_small/totto_test",
        "N": 25,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.3488372093023256,
            "3": 0.8506493506493507
        },
        "rouge1": {
            "precision": 0.8274,
            "recall": 0.79906,
            "fmeasure": 0.80704
        },
        "rouge2": {
            "precision": 0.64589,
            "recall": 0.6401,
            "fmeasure": 0.64054
        },
        "rougeL": {
            "precision": 0.75311,
            "recall": 0.72768,
            "fmeasure": 0.73482
        },
        "rougeLsum": {
            "precision": 0.75311,
            "recall": 0.72768,
            "fmeasure": 0.73482
        },
        "nist": 7.012971821661568,
        "bleu": 60.50519,
        "bertscore": {
            "precision": 0.94874,
            "recall": 0.94223,
            "f1": 0.94489
        },
        "bleurt": 0.42833,
        "meteor": 0.4525130895094194,
        "nubia": {
            "semantic_relation": 4.34504,
            "contradiction": 10.1725,
            "irrelevancy": 25.49191,
            "logical_agreement": 64.33558,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.07095,
            "nubia_score": 0.74754
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.68421,
            "fmeasure": 0.74286
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.27778,
            "fmeasure": 0.30303
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.42105,
            "fmeasure": 0.45714
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.42105,
            "fmeasure": 0.45714
        },
        "nist": 2.900252472127076,
        "bleu": 14.85784,
        "bertscore": {
            "precision": 0.92475,
            "recall": 0.89427,
            "f1": 0.90925
        },
        "bleurt": 0.32747,
        "meteor": 0.3205296644254571,
        "nubia": {
            "semantic_relation": 4.68643,
            "contradiction": 0.36664,
            "irrelevancy": 0.61885,
            "logical_agreement": 99.01451,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.36028,
            "nubia_score": 0.94177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.77037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.64286,
            "fmeasure": 0.68182
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.77037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.77037,
            "fmeasure": 0.81481
        },
        "nist": 1.8787503831609698,
        "bleu": 65.8037,
        "bertscore": {
            "precision": 0.99136,
            "recall": 0.99136,
            "f1": 0.99136
        },
        "bleurt": 0.40704,
        "meteor": 0.9538461538461539,
        "nubia": {
            "semantic_relation": 4.07092,
            "contradiction": 0.13865,
            "irrelevancy": 0.46001,
            "logical_agreement": 99.40134,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.81095,
            "nubia_score": 0.62711
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.21875,
            "3": 0.725
        },
        "rouge1": {
            "precision": 0.63328,
            "recall": 0.67288,
            "fmeasure": 0.63236
        },
        "rouge2": {
            "precision": 0.34786,
            "recall": 0.36462,
            "fmeasure": 0.34467
        },
        "rougeL": {
            "precision": 0.48456,
            "recall": 0.49251,
            "fmeasure": 0.47285
        },
        "rougeLsum": {
            "precision": 0.48456,
            "recall": 0.49251,
            "fmeasure": 0.47285
        },
        "nist": 3.6753243459881455,
        "bleu": 19.63527,
        "bertscore": {
            "precision": 0.90389,
            "recall": 0.89066,
            "f1": 0.89016
        },
        "bleurt": -0.1034,
        "meteor": 0.3412658355566743,
        "nubia": {
            "semantic_relation": 3.58669,
            "contradiction": 10.28038,
            "irrelevancy": 42.83787,
            "logical_agreement": 46.88175,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.46862,
            "nubia_score": 0.53057
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "mT5_small/totto_test",
        "N": 24,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10638297872340426,
            "2": 0.29069767441860467,
            "3": 0.759493670886076
        },
        "rouge1": {
            "precision": 0.74895,
            "recall": 0.70686,
            "fmeasure": 0.7177
        },
        "rouge2": {
            "precision": 0.46637,
            "recall": 0.44496,
            "fmeasure": 0.44964
        },
        "rougeL": {
            "precision": 0.67301,
            "recall": 0.62479,
            "fmeasure": 0.63893
        },
        "rougeLsum": {
            "precision": 0.67301,
            "recall": 0.62479,
            "fmeasure": 0.63893
        },
        "nist": 5.4141779366737595,
        "bleu": 36.81487,
        "bertscore": {
            "precision": 0.92003,
            "recall": 0.91633,
            "f1": 0.91678
        },
        "bleurt": 0.25341,
        "meteor": 0.3561395904227428,
        "nubia": {
            "semantic_relation": 4.18171,
            "contradiction": 11.36536,
            "irrelevancy": 33.85546,
            "logical_agreement": 54.77919,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.87335,
            "nubia_score": 0.71061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23863636363636365,
            "2": 0.4406779661016949,
            "3": 0.7267080745341615
        },
        "rouge1": {
            "precision": 0.6622,
            "recall": 0.65694,
            "fmeasure": 0.64872
        },
        "rouge2": {
            "precision": 0.39937,
            "recall": 0.39588,
            "fmeasure": 0.39077
        },
        "rougeL": {
            "precision": 0.53829,
            "recall": 0.53962,
            "fmeasure": 0.53023
        },
        "rougeLsum": {
            "precision": 0.53829,
            "recall": 0.53962,
            "fmeasure": 0.53023
        },
        "nist": 5.727685510573219,
        "bleu": 35.75588,
        "bertscore": {
            "precision": 0.90594,
            "recall": 0.90893,
            "f1": 0.90553
        },
        "bleurt": 0.16246,
        "meteor": 0.3500820397474954,
        "nubia": {
            "semantic_relation": 4.11883,
            "contradiction": 12.77666,
            "irrelevancy": 41.03151,
            "logical_agreement": 46.19183,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.46305,
            "nubia_score": 0.71086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "mT5_small/totto_test",
        "N": 56,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21164021164021163,
            "2": 0.4240506329113924,
            "3": 0.7180685358255452
        },
        "rouge1": {
            "precision": 0.75576,
            "recall": 0.68453,
            "fmeasure": 0.7041
        },
        "rouge2": {
            "precision": 0.51798,
            "recall": 0.4676,
            "fmeasure": 0.48119
        },
        "rougeL": {
            "precision": 0.66114,
            "recall": 0.60078,
            "fmeasure": 0.61667
        },
        "rougeLsum": {
            "precision": 0.66114,
            "recall": 0.60078,
            "fmeasure": 0.61667
        },
        "nist": 6.667259617807127,
        "bleu": 41.92916,
        "bertscore": {
            "precision": 0.92551,
            "recall": 0.9108,
            "f1": 0.91652
        },
        "bleurt": 0.20536,
        "meteor": 0.37068866351054947,
        "nubia": {
            "semantic_relation": 4.14992,
            "contradiction": 7.98962,
            "irrelevancy": 27.01843,
            "logical_agreement": 64.99195,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.86304,
            "nubia_score": 0.6849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06,
            "2": 0.19230769230769232,
            "3": 0.7176470588235294
        },
        "rouge1": {
            "precision": 0.77978,
            "recall": 0.66424,
            "fmeasure": 0.70927
        },
        "rouge2": {
            "precision": 0.5235,
            "recall": 0.44628,
            "fmeasure": 0.47447
        },
        "rougeL": {
            "precision": 0.70148,
            "recall": 0.59168,
            "fmeasure": 0.63309
        },
        "rougeLsum": {
            "precision": 0.70148,
            "recall": 0.59168,
            "fmeasure": 0.63309
        },
        "nist": 4.842300789706213,
        "bleu": 34.27921,
        "bertscore": {
            "precision": 0.9229,
            "recall": 0.90411,
            "f1": 0.9111
        },
        "bleurt": 0.19203,
        "meteor": 0.32926307095563634,
        "nubia": {
            "semantic_relation": 4.01594,
            "contradiction": 14.65209,
            "irrelevancy": 31.95406,
            "logical_agreement": 53.39385,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.48379,
            "nubia_score": 0.67094
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "mT5_small/totto_test",
        "N": 48,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18120805369127516,
            "2": 0.43125,
            "3": 0.7603960396039604
        },
        "rouge1": {
            "precision": 0.77865,
            "recall": 0.72421,
            "fmeasure": 0.74268
        },
        "rouge2": {
            "precision": 0.52191,
            "recall": 0.4876,
            "fmeasure": 0.4982
        },
        "rougeL": {
            "precision": 0.64156,
            "recall": 0.59078,
            "fmeasure": 0.60863
        },
        "rougeLsum": {
            "precision": 0.64156,
            "recall": 0.59078,
            "fmeasure": 0.60863
        },
        "nist": 6.8401180158759916,
        "bleu": 42.13582,
        "bertscore": {
            "precision": 0.93174,
            "recall": 0.92512,
            "f1": 0.92729
        },
        "bleurt": 0.25256,
        "meteor": 0.3834815917832914,
        "nubia": {
            "semantic_relation": 4.23008,
            "contradiction": 8.37514,
            "irrelevancy": 24.81573,
            "logical_agreement": 66.80912,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.94394,
            "nubia_score": 0.72766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.2413793103448276,
            "3": 0.6774193548387096
        },
        "rouge1": {
            "precision": 0.67162,
            "recall": 0.66108,
            "fmeasure": 0.64485
        },
        "rouge2": {
            "precision": 0.41266,
            "recall": 0.41544,
            "fmeasure": 0.39478
        },
        "rougeL": {
            "precision": 0.60492,
            "recall": 0.61892,
            "fmeasure": 0.58907
        },
        "rougeLsum": {
            "precision": 0.60492,
            "recall": 0.61892,
            "fmeasure": 0.58907
        },
        "nist": 4.6327664446356405,
        "bleu": 34.09599,
        "bertscore": {
            "precision": 0.90367,
            "recall": 0.90421,
            "f1": 0.90174
        },
        "bleurt": 0.27248,
        "meteor": 0.35130740019248313,
        "nubia": {
            "semantic_relation": 4.23654,
            "contradiction": 1.60343,
            "irrelevancy": 47.88987,
            "logical_agreement": 50.50669,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.91605,
            "nubia_score": 0.72297
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.4722222222222222,
            "3": 0.8633093525179856
        },
        "rouge1": {
            "precision": 0.78799,
            "recall": 0.76636,
            "fmeasure": 0.77116
        },
        "rouge2": {
            "precision": 0.62839,
            "recall": 0.6173,
            "fmeasure": 0.61798
        },
        "rougeL": {
            "precision": 0.73518,
            "recall": 0.71843,
            "fmeasure": 0.72123
        },
        "rougeLsum": {
            "precision": 0.73518,
            "recall": 0.71843,
            "fmeasure": 0.72123
        },
        "nist": 6.51730500402109,
        "bleu": 68.33764,
        "bertscore": {
            "precision": 0.94241,
            "recall": 0.94121,
            "f1": 0.94142
        },
        "bleurt": 0.4192,
        "meteor": 0.481717353073883,
        "nubia": {
            "semantic_relation": 3.93971,
            "contradiction": 10.1718,
            "irrelevancy": 30.55766,
            "logical_agreement": 59.27054,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.12026,
            "nubia_score": 0.68845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "mT5_small/totto_test",
        "N": 114,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21393034825870647,
            "2": 0.4137055837563452,
            "3": 0.7190517998244074
        },
        "rouge1": {
            "precision": 0.70951,
            "recall": 0.66724,
            "fmeasure": 0.67291
        },
        "rouge2": {
            "precision": 0.4477,
            "recall": 0.4234,
            "fmeasure": 0.42604
        },
        "rougeL": {
            "precision": 0.59174,
            "recall": 0.55772,
            "fmeasure": 0.56122
        },
        "rougeLsum": {
            "precision": 0.59174,
            "recall": 0.55772,
            "fmeasure": 0.56122
        },
        "nist": 6.846443068384769,
        "bleu": 35.87958,
        "bertscore": {
            "precision": 0.91188,
            "recall": 0.90747,
            "f1": 0.90823
        },
        "bleurt": 0.11518,
        "meteor": 0.3483979998515922,
        "nubia": {
            "semantic_relation": 3.94554,
            "contradiction": 11.90179,
            "irrelevancy": 36.01235,
            "logical_agreement": 52.08586,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.72773,
            "nubia_score": 0.64607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18055555555555555,
            "2": 0.45901639344262296,
            "3": 0.6583850931677019
        },
        "rouge1": {
            "precision": 0.68581,
            "recall": 0.62794,
            "fmeasure": 0.64611
        },
        "rouge2": {
            "precision": 0.38361,
            "recall": 0.35022,
            "fmeasure": 0.36027
        },
        "rougeL": {
            "precision": 0.57466,
            "recall": 0.53418,
            "fmeasure": 0.54468
        },
        "rougeLsum": {
            "precision": 0.57466,
            "recall": 0.53418,
            "fmeasure": 0.54468
        },
        "nist": 5.265358512774985,
        "bleu": 35.00441,
        "bertscore": {
            "precision": 0.91418,
            "recall": 0.90669,
            "f1": 0.91009
        },
        "bleurt": 0.20063,
        "meteor": 0.33190858379668664,
        "nubia": {
            "semantic_relation": 4.02681,
            "contradiction": 13.8056,
            "irrelevancy": 37.37357,
            "logical_agreement": 48.82084,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.80284,
            "nubia_score": 0.68136
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "mT5_small/totto_test",
        "N": 44,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2376237623762376,
            "2": 0.536,
            "3": 0.7688984881209503
        },
        "rouge1": {
            "precision": 0.75768,
            "recall": 0.74318,
            "fmeasure": 0.74045
        },
        "rouge2": {
            "precision": 0.49228,
            "recall": 0.48929,
            "fmeasure": 0.48373
        },
        "rougeL": {
            "precision": 0.64431,
            "recall": 0.63441,
            "fmeasure": 0.63075
        },
        "rougeLsum": {
            "precision": 0.64431,
            "recall": 0.63441,
            "fmeasure": 0.63075
        },
        "nist": 6.70560224816932,
        "bleu": 44.93868,
        "bertscore": {
            "precision": 0.92986,
            "recall": 0.91967,
            "f1": 0.9237
        },
        "bleurt": 0.3203,
        "meteor": 0.38998819247437694,
        "nubia": {
            "semantic_relation": 4.18032,
            "contradiction": 19.82203,
            "irrelevancy": 19.73688,
            "logical_agreement": 60.44109,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.76382,
            "nubia_score": 0.71586
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.2894736842105263,
            "3": 0.7926267281105991
        },
        "rouge1": {
            "precision": 0.77969,
            "recall": 0.74912,
            "fmeasure": 0.75237
        },
        "rouge2": {
            "precision": 0.57923,
            "recall": 0.56361,
            "fmeasure": 0.56445
        },
        "rougeL": {
            "precision": 0.67703,
            "recall": 0.65561,
            "fmeasure": 0.65825
        },
        "rougeLsum": {
            "precision": 0.67703,
            "recall": 0.65561,
            "fmeasure": 0.65825
        },
        "nist": 6.6134174268546335,
        "bleu": 60.93598,
        "bertscore": {
            "precision": 0.93819,
            "recall": 0.93167,
            "f1": 0.93365
        },
        "bleurt": 0.40562,
        "meteor": 0.45592120991439444,
        "nubia": {
            "semantic_relation": 4.40262,
            "contradiction": 8.79988,
            "irrelevancy": 19.01378,
            "logical_agreement": 72.18634,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.50336,
            "nubia_score": 0.79251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "mT5_small/totto_test",
        "N": 40,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3162393162393162,
            "2": 0.36923076923076925,
            "3": 0.7470449172576832
        },
        "rouge1": {
            "precision": 0.74855,
            "recall": 0.72751,
            "fmeasure": 0.7292
        },
        "rouge2": {
            "precision": 0.53291,
            "recall": 0.50332,
            "fmeasure": 0.51046
        },
        "rougeL": {
            "precision": 0.64914,
            "recall": 0.62898,
            "fmeasure": 0.63
        },
        "rougeLsum": {
            "precision": 0.64914,
            "recall": 0.62898,
            "fmeasure": 0.63
        },
        "nist": 6.438463341480261,
        "bleu": 46.19517,
        "bertscore": {
            "precision": 0.92323,
            "recall": 0.92205,
            "f1": 0.92094
        },
        "bleurt": 0.30111,
        "meteor": 0.37789151123046355,
        "nubia": {
            "semantic_relation": 4.19367,
            "contradiction": 10.36062,
            "irrelevancy": 27.8892,
            "logical_agreement": 61.75017,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.39872,
            "nubia_score": 0.72393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "mT5_small/totto_test",
        "N": 57,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17511520737327188,
            "2": 0.43414634146341463,
            "3": 0.7476280834914611
        },
        "rouge1": {
            "precision": 0.72376,
            "recall": 0.6905,
            "fmeasure": 0.69169
        },
        "rouge2": {
            "precision": 0.49258,
            "recall": 0.47492,
            "fmeasure": 0.47212
        },
        "rougeL": {
            "precision": 0.62498,
            "recall": 0.59787,
            "fmeasure": 0.59762
        },
        "rougeLsum": {
            "precision": 0.62498,
            "recall": 0.59787,
            "fmeasure": 0.59762
        },
        "nist": 6.47019269193513,
        "bleu": 39.73703,
        "bertscore": {
            "precision": 0.91462,
            "recall": 0.90962,
            "f1": 0.90983
        },
        "bleurt": 0.17861,
        "meteor": 0.3701910508862384,
        "nubia": {
            "semantic_relation": 3.9166,
            "contradiction": 14.6997,
            "irrelevancy": 39.53024,
            "logical_agreement": 45.77006,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.64408,
            "nubia_score": 0.65845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "mT5_small/totto_test",
        "N": 24,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10714285714285714,
            "2": 0.46236559139784944,
            "3": 0.8600823045267489
        },
        "rouge1": {
            "precision": 0.75416,
            "recall": 0.75085,
            "fmeasure": 0.74603
        },
        "rouge2": {
            "precision": 0.48595,
            "recall": 0.49017,
            "fmeasure": 0.48331
        },
        "rougeL": {
            "precision": 0.65146,
            "recall": 0.65219,
            "fmeasure": 0.6455
        },
        "rougeLsum": {
            "precision": 0.65146,
            "recall": 0.65219,
            "fmeasure": 0.6455
        },
        "nist": 6.420557170565486,
        "bleu": 45.90089,
        "bertscore": {
            "precision": 0.93101,
            "recall": 0.92971,
            "f1": 0.92943
        },
        "bleurt": 0.27925,
        "meteor": 0.41042413740962747,
        "nubia": {
            "semantic_relation": 4.23145,
            "contradiction": 5.50848,
            "irrelevancy": 34.74267,
            "logical_agreement": 59.74885,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.42035,
            "nubia_score": 0.76593
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rouge2": {
            "precision": 0.57576,
            "recall": 0.7037,
            "fmeasure": 0.63333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "nist": 3.1022169742211996,
        "bleu": 54.91005,
        "bertscore": {
            "precision": 0.9505,
            "recall": 0.97425,
            "f1": 0.96223
        },
        "bleurt": 0.66643,
        "meteor": 0.4780944755307461,
        "nubia": {
            "semantic_relation": 3.84299,
            "contradiction": 0.27272,
            "irrelevancy": 98.23718,
            "logical_agreement": 1.49011,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.62344,
            "nubia_score": 0.62142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "mT5_small/totto_test",
        "N": 33,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1375,
            "2": 0.22388059701492538,
            "3": 0.8195121951219512
        },
        "rouge1": {
            "precision": 0.8659,
            "recall": 0.79505,
            "fmeasure": 0.82176
        },
        "rouge2": {
            "precision": 0.63856,
            "recall": 0.58747,
            "fmeasure": 0.60573
        },
        "rougeL": {
            "precision": 0.73127,
            "recall": 0.6778,
            "fmeasure": 0.69722
        },
        "rougeLsum": {
            "precision": 0.73127,
            "recall": 0.6778,
            "fmeasure": 0.69722
        },
        "nist": 7.107563911391727,
        "bleu": 50.43929,
        "bertscore": {
            "precision": 0.95322,
            "recall": 0.94012,
            "f1": 0.94605
        },
        "bleurt": 0.38992,
        "meteor": 0.4246115895835318,
        "nubia": {
            "semantic_relation": 4.53813,
            "contradiction": 3.77033,
            "irrelevancy": 17.71173,
            "logical_agreement": 78.51794,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.09925,
            "nubia_score": 0.80568
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "mT5_small/totto_test",
        "N": 29,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24271844660194175,
            "2": 0.4186046511627907,
            "3": 0.7317880794701986
        },
        "rouge1": {
            "precision": 0.7449,
            "recall": 0.70219,
            "fmeasure": 0.70439
        },
        "rouge2": {
            "precision": 0.49731,
            "recall": 0.46159,
            "fmeasure": 0.46738
        },
        "rougeL": {
            "precision": 0.65193,
            "recall": 0.61586,
            "fmeasure": 0.6171
        },
        "rougeLsum": {
            "precision": 0.65193,
            "recall": 0.61586,
            "fmeasure": 0.6171
        },
        "nist": 6.18928712231904,
        "bleu": 40.88396,
        "bertscore": {
            "precision": 0.92474,
            "recall": 0.91534,
            "f1": 0.91757
        },
        "bleurt": 0.25449,
        "meteor": 0.36065922834080355,
        "nubia": {
            "semantic_relation": 4.07726,
            "contradiction": 7.44864,
            "irrelevancy": 30.05626,
            "logical_agreement": 62.49509,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.50586,
            "nubia_score": 0.69868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "mT5_small/totto_test",
        "N": 32,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2653061224489796,
            "2": 0.3493975903614458,
            "3": 0.7627551020408163
        },
        "rouge1": {
            "precision": 0.72427,
            "recall": 0.71291,
            "fmeasure": 0.70466
        },
        "rouge2": {
            "precision": 0.51704,
            "recall": 0.50005,
            "fmeasure": 0.49861
        },
        "rougeL": {
            "precision": 0.63349,
            "recall": 0.6255,
            "fmeasure": 0.61679
        },
        "rougeLsum": {
            "precision": 0.63349,
            "recall": 0.6255,
            "fmeasure": 0.61679
        },
        "nist": 6.30297225531476,
        "bleu": 43.30726,
        "bertscore": {
            "precision": 0.91894,
            "recall": 0.91868,
            "f1": 0.91673
        },
        "bleurt": 0.1773,
        "meteor": 0.36839860110325756,
        "nubia": {
            "semantic_relation": 4.13148,
            "contradiction": 13.07265,
            "irrelevancy": 33.94808,
            "logical_agreement": 52.97927,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.1838,
            "nubia_score": 0.71295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2621359223300971,
            "2": 0.3409090909090909,
            "3": 0.6836734693877551
        },
        "rouge1": {
            "precision": 0.708,
            "recall": 0.64852,
            "fmeasure": 0.65164
        },
        "rouge2": {
            "precision": 0.449,
            "recall": 0.40417,
            "fmeasure": 0.40966
        },
        "rougeL": {
            "precision": 0.57638,
            "recall": 0.54694,
            "fmeasure": 0.53865
        },
        "rougeLsum": {
            "precision": 0.57638,
            "recall": 0.54694,
            "fmeasure": 0.53865
        },
        "nist": 5.476911741704072,
        "bleu": 32.86969,
        "bertscore": {
            "precision": 0.89491,
            "recall": 0.89813,
            "f1": 0.89466
        },
        "bleurt": -0.00709,
        "meteor": 0.34702937817915736,
        "nubia": {
            "semantic_relation": 3.96673,
            "contradiction": 10.53862,
            "irrelevancy": 39.90321,
            "logical_agreement": 49.55817,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.6078,
            "nubia_score": 0.6379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.46153846153846156
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.44765,
            "fmeasure": 0.51732
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.275,
            "fmeasure": 0.32895
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.35154,
            "fmeasure": 0.39935
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.35154,
            "fmeasure": 0.39935
        },
        "nist": 0.8936705109800245,
        "bleu": 13.17046,
        "bertscore": {
            "precision": 0.88863,
            "recall": 0.83687,
            "f1": 0.86022
        },
        "bleurt": -0.62606,
        "meteor": 0.21980254210776076,
        "nubia": {
            "semantic_relation": 3.13547,
            "contradiction": 47.21702,
            "irrelevancy": 50.19509,
            "logical_agreement": 2.58789,
            "grammar_ref": 4.83168,
            "grammar_hyp": 6.25802,
            "nubia_score": 0.20626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.20689655172413793,
            "3": 0.7603305785123967
        },
        "rouge1": {
            "precision": 0.7984,
            "recall": 0.69302,
            "fmeasure": 0.72804
        },
        "rouge2": {
            "precision": 0.58366,
            "recall": 0.49734,
            "fmeasure": 0.52571
        },
        "rougeL": {
            "precision": 0.7539,
            "recall": 0.64057,
            "fmeasure": 0.67759
        },
        "rougeLsum": {
            "precision": 0.7539,
            "recall": 0.64057,
            "fmeasure": 0.67759
        },
        "nist": 5.060488961270754,
        "bleu": 44.25937,
        "bertscore": {
            "precision": 0.9474,
            "recall": 0.92429,
            "f1": 0.93408
        },
        "bleurt": 0.34208,
        "meteor": 0.38146462504794687,
        "nubia": {
            "semantic_relation": 4.24717,
            "contradiction": 21.12251,
            "irrelevancy": 23.7192,
            "logical_agreement": 55.15829,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.47289,
            "nubia_score": 0.73483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "mT5_small/totto_test",
        "N": 13,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.18181818181818182,
            "3": 0.9078947368421053
        },
        "rouge1": {
            "precision": 0.85438,
            "recall": 0.87788,
            "fmeasure": 0.85708
        },
        "rouge2": {
            "precision": 0.65898,
            "recall": 0.69153,
            "fmeasure": 0.66545
        },
        "rougeL": {
            "precision": 0.75697,
            "recall": 0.77874,
            "fmeasure": 0.75885
        },
        "rougeLsum": {
            "precision": 0.75697,
            "recall": 0.77874,
            "fmeasure": 0.75885
        },
        "nist": 6.7645324011408645,
        "bleu": 63.37455,
        "bertscore": {
            "precision": 0.96493,
            "recall": 0.96791,
            "f1": 0.96421
        },
        "bleurt": 0.59913,
        "meteor": 0.49326482467747235,
        "nubia": {
            "semantic_relation": 4.69696,
            "contradiction": 5.90604,
            "irrelevancy": 20.8165,
            "logical_agreement": 73.27746,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.13195,
            "nubia_score": 0.86865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.8636363636363636
        },
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.70143,
            "fmeasure": 0.63674
        },
        "rouge2": {
            "precision": 0.43148,
            "recall": 0.43611,
            "fmeasure": 0.43258
        },
        "rougeL": {
            "precision": 0.55288,
            "recall": 0.65014,
            "fmeasure": 0.58546
        },
        "rougeLsum": {
            "precision": 0.55288,
            "recall": 0.65014,
            "fmeasure": 0.58546
        },
        "nist": 3.576116245220543,
        "bleu": 45.0911,
        "bertscore": {
            "precision": 0.87414,
            "recall": 0.88759,
            "f1": 0.88057
        },
        "bleurt": 0.10571,
        "meteor": 0.3522043667345201,
        "nubia": {
            "semantic_relation": 4.05367,
            "contradiction": 21.39171,
            "irrelevancy": 44.0924,
            "logical_agreement": 34.51588,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.62371,
            "nubia_score": 0.67376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "mT5_small/totto_test",
        "N": 20,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12,
            "2": 0.3770491803278688,
            "3": 0.7225130890052356
        },
        "rouge1": {
            "precision": 0.71966,
            "recall": 0.68773,
            "fmeasure": 0.69223
        },
        "rouge2": {
            "precision": 0.49208,
            "recall": 0.4588,
            "fmeasure": 0.46884
        },
        "rougeL": {
            "precision": 0.62403,
            "recall": 0.59768,
            "fmeasure": 0.60058
        },
        "rougeLsum": {
            "precision": 0.62403,
            "recall": 0.59768,
            "fmeasure": 0.60058
        },
        "nist": 5.509326010112743,
        "bleu": 44.12788,
        "bertscore": {
            "precision": 0.91891,
            "recall": 0.91562,
            "f1": 0.91651
        },
        "bleurt": 0.21376,
        "meteor": 0.3718324947183697,
        "nubia": {
            "semantic_relation": 3.98179,
            "contradiction": 9.96849,
            "irrelevancy": 26.62499,
            "logical_agreement": 63.40652,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.84758,
            "nubia_score": 0.65579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "mT5_small/totto_test",
        "N": 29,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.32653061224489793,
            "3": 0.7701492537313432
        },
        "rouge1": {
            "precision": 0.83011,
            "recall": 0.73928,
            "fmeasure": 0.7754
        },
        "rouge2": {
            "precision": 0.60906,
            "recall": 0.55982,
            "fmeasure": 0.57269
        },
        "rougeL": {
            "precision": 0.72264,
            "recall": 0.65001,
            "fmeasure": 0.67416
        },
        "rougeLsum": {
            "precision": 0.72264,
            "recall": 0.65001,
            "fmeasure": 0.67416
        },
        "nist": 6.806989563541843,
        "bleu": 51.59594,
        "bertscore": {
            "precision": 0.94792,
            "recall": 0.93313,
            "f1": 0.93792
        },
        "bleurt": 0.36551,
        "meteor": 0.41553435565555574,
        "nubia": {
            "semantic_relation": 4.39204,
            "contradiction": 11.43875,
            "irrelevancy": 17.847,
            "logical_agreement": 70.71426,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.68975,
            "nubia_score": 0.7917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "mT5_small/totto_test",
        "N": 77,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2490272373540856,
            "2": 0.4069767441860465,
            "3": 0.7516254876462939
        },
        "rouge1": {
            "precision": 0.76073,
            "recall": 0.70318,
            "fmeasure": 0.71949
        },
        "rouge2": {
            "precision": 0.51028,
            "recall": 0.46951,
            "fmeasure": 0.48179
        },
        "rougeL": {
            "precision": 0.65109,
            "recall": 0.60134,
            "fmeasure": 0.6146
        },
        "rougeLsum": {
            "precision": 0.65109,
            "recall": 0.60134,
            "fmeasure": 0.6146
        },
        "nist": 7.0268310936223735,
        "bleu": 44.69543,
        "bertscore": {
            "precision": 0.9274,
            "recall": 0.91946,
            "f1": 0.92131
        },
        "bleurt": 0.2265,
        "meteor": 0.38079155208451687,
        "nubia": {
            "semantic_relation": 4.066,
            "contradiction": 14.91516,
            "irrelevancy": 21.90297,
            "logical_agreement": 63.18186,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.73326,
            "nubia_score": 0.67945
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "mT5_small/totto_test",
        "N": 9,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5909090909090909,
            "3": 0.7761194029850746
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.71445,
            "fmeasure": 0.69284
        },
        "rouge2": {
            "precision": 0.44049,
            "recall": 0.4452,
            "fmeasure": 0.43354
        },
        "rougeL": {
            "precision": 0.54929,
            "recall": 0.57595,
            "fmeasure": 0.55007
        },
        "rougeLsum": {
            "precision": 0.54929,
            "recall": 0.57595,
            "fmeasure": 0.55007
        },
        "nist": 4.9377551732297755,
        "bleu": 33.36259,
        "bertscore": {
            "precision": 0.89638,
            "recall": 0.91299,
            "f1": 0.90272
        },
        "bleurt": 0.21342,
        "meteor": 0.3585561299300243,
        "nubia": {
            "semantic_relation": 4.11957,
            "contradiction": 2.04314,
            "irrelevancy": 33.80164,
            "logical_agreement": 64.15522,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.83506,
            "nubia_score": 0.70973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3448275862068966,
            "3": 0.6949152542372882
        },
        "rouge1": {
            "precision": 0.77347,
            "recall": 0.71326,
            "fmeasure": 0.72627
        },
        "rouge2": {
            "precision": 0.52992,
            "recall": 0.49821,
            "fmeasure": 0.50436
        },
        "rougeL": {
            "precision": 0.6517,
            "recall": 0.62667,
            "fmeasure": 0.62929
        },
        "rougeLsum": {
            "precision": 0.6517,
            "recall": 0.62667,
            "fmeasure": 0.62929
        },
        "nist": 2.9584408767817467,
        "bleu": 30.30349,
        "bertscore": {
            "precision": 0.91295,
            "recall": 0.90254,
            "f1": 0.90604
        },
        "bleurt": 0.19188,
        "meteor": 0.30292267161091746,
        "nubia": {
            "semantic_relation": 4.10197,
            "contradiction": 18.42149,
            "irrelevancy": 21.67135,
            "logical_agreement": 59.90716,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.42844,
            "nubia_score": 0.69153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "mT5_small/totto_test",
        "N": 26,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2235294117647059,
            "2": 0.5149253731343284,
            "3": 0.7283464566929134
        },
        "rouge1": {
            "precision": 0.7235,
            "recall": 0.69995,
            "fmeasure": 0.69949
        },
        "rouge2": {
            "precision": 0.48439,
            "recall": 0.47387,
            "fmeasure": 0.47097
        },
        "rougeL": {
            "precision": 0.59652,
            "recall": 0.58444,
            "fmeasure": 0.58126
        },
        "rougeLsum": {
            "precision": 0.59652,
            "recall": 0.58444,
            "fmeasure": 0.58126
        },
        "nist": 6.183543837315063,
        "bleu": 43.14147,
        "bertscore": {
            "precision": 0.9236,
            "recall": 0.92122,
            "f1": 0.92022
        },
        "bleurt": 0.2075,
        "meteor": 0.37613876676205354,
        "nubia": {
            "semantic_relation": 4.16644,
            "contradiction": 13.12618,
            "irrelevancy": 36.32029,
            "logical_agreement": 50.55353,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.55638,
            "nubia_score": 0.71416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "mT5_small/totto_test",
        "N": 144,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2490272373540856,
            "2": 0.46799116997792495,
            "3": 0.7089494163424125
        },
        "rouge1": {
            "precision": 0.7346,
            "recall": 0.67846,
            "fmeasure": 0.68468
        },
        "rouge2": {
            "precision": 0.48844,
            "recall": 0.45457,
            "fmeasure": 0.45686
        },
        "rougeL": {
            "precision": 0.6342,
            "recall": 0.59263,
            "fmeasure": 0.59289
        },
        "rougeLsum": {
            "precision": 0.6342,
            "recall": 0.59263,
            "fmeasure": 0.59289
        },
        "nist": 7.167325227236267,
        "bleu": 42.64384,
        "bertscore": {
            "precision": 0.92004,
            "recall": 0.91022,
            "f1": 0.91275
        },
        "bleurt": 0.22432,
        "meteor": 0.37689959465280337,
        "nubia": {
            "semantic_relation": 3.95769,
            "contradiction": 13.67707,
            "irrelevancy": 31.02638,
            "logical_agreement": 55.29655,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.82193,
            "nubia_score": 0.65878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20253164556962025,
            "2": 0.3888888888888889,
            "3": 0.7070422535211267
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.67722,
            "fmeasure": 0.68478
        },
        "rouge2": {
            "precision": 0.47753,
            "recall": 0.45845,
            "fmeasure": 0.46082
        },
        "rougeL": {
            "precision": 0.61217,
            "recall": 0.58066,
            "fmeasure": 0.58692
        },
        "rougeLsum": {
            "precision": 0.61217,
            "recall": 0.58066,
            "fmeasure": 0.58692
        },
        "nist": 5.996924231887766,
        "bleu": 39.4376,
        "bertscore": {
            "precision": 0.91521,
            "recall": 0.90437,
            "f1": 0.90776
        },
        "bleurt": 0.17838,
        "meteor": 0.3641255784514306,
        "nubia": {
            "semantic_relation": 3.99054,
            "contradiction": 12.17315,
            "irrelevancy": 33.47534,
            "logical_agreement": 54.35152,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.58185,
            "nubia_score": 0.67731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.308411214953271,
            "2": 0.34177215189873417,
            "3": 0.8065268065268065
        },
        "rouge1": {
            "precision": 0.80183,
            "recall": 0.76204,
            "fmeasure": 0.77309
        },
        "rouge2": {
            "precision": 0.58212,
            "recall": 0.55777,
            "fmeasure": 0.56392
        },
        "rougeL": {
            "precision": 0.69506,
            "recall": 0.66449,
            "fmeasure": 0.67147
        },
        "rougeLsum": {
            "precision": 0.69506,
            "recall": 0.66449,
            "fmeasure": 0.67147
        },
        "nist": 7.161526039575206,
        "bleu": 52.36789,
        "bertscore": {
            "precision": 0.94335,
            "recall": 0.93836,
            "f1": 0.93956
        },
        "bleurt": 0.33756,
        "meteor": 0.41533259722082283,
        "nubia": {
            "semantic_relation": 4.29467,
            "contradiction": 3.98331,
            "irrelevancy": 20.82863,
            "logical_agreement": 75.18806,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.68233,
            "nubia_score": 0.75554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5,
            "3": 0.7102803738317757
        },
        "rouge1": {
            "precision": 0.76368,
            "recall": 0.70895,
            "fmeasure": 0.7246
        },
        "rouge2": {
            "precision": 0.51122,
            "recall": 0.44191,
            "fmeasure": 0.46237
        },
        "rougeL": {
            "precision": 0.65544,
            "recall": 0.60186,
            "fmeasure": 0.61922
        },
        "rougeLsum": {
            "precision": 0.65544,
            "recall": 0.60186,
            "fmeasure": 0.61922
        },
        "nist": 5.0652525510714295,
        "bleu": 37.51604,
        "bertscore": {
            "precision": 0.91436,
            "recall": 0.9032,
            "f1": 0.90609
        },
        "bleurt": 0.06212,
        "meteor": 0.37674217145256167,
        "nubia": {
            "semantic_relation": 4.15177,
            "contradiction": 19.16411,
            "irrelevancy": 21.31342,
            "logical_agreement": 59.52246,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.18847,
            "nubia_score": 0.66461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "mT5_small/totto_test",
        "N": 30,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15306122448979592,
            "2": 0.3364485981308411,
            "3": 0.7820895522388059
        },
        "rouge1": {
            "precision": 0.7505,
            "recall": 0.71257,
            "fmeasure": 0.72135
        },
        "rouge2": {
            "precision": 0.50611,
            "recall": 0.4809,
            "fmeasure": 0.48576
        },
        "rougeL": {
            "precision": 0.62277,
            "recall": 0.60497,
            "fmeasure": 0.60395
        },
        "rougeLsum": {
            "precision": 0.62277,
            "recall": 0.60497,
            "fmeasure": 0.60395
        },
        "nist": 6.1255473107388445,
        "bleu": 41.4241,
        "bertscore": {
            "precision": 0.92631,
            "recall": 0.91925,
            "f1": 0.91995
        },
        "bleurt": 0.19554,
        "meteor": 0.3836814220202278,
        "nubia": {
            "semantic_relation": 4.07857,
            "contradiction": 10.15703,
            "irrelevancy": 31.15887,
            "logical_agreement": 58.6841,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.79542,
            "nubia_score": 0.68458
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "mT5_small/totto_test",
        "N": 36,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19135802469135801,
            "2": 0.4915254237288136,
            "3": 0.7569230769230769
        },
        "rouge1": {
            "precision": 0.68473,
            "recall": 0.71415,
            "fmeasure": 0.68457
        },
        "rouge2": {
            "precision": 0.45733,
            "recall": 0.48561,
            "fmeasure": 0.45975
        },
        "rougeL": {
            "precision": 0.56672,
            "recall": 0.59564,
            "fmeasure": 0.56799
        },
        "rougeLsum": {
            "precision": 0.56672,
            "recall": 0.59564,
            "fmeasure": 0.56799
        },
        "nist": 6.041363572660766,
        "bleu": 38.50279,
        "bertscore": {
            "precision": 0.91109,
            "recall": 0.91297,
            "f1": 0.90948
        },
        "bleurt": 0.20155,
        "meteor": 0.3776598918610055,
        "nubia": {
            "semantic_relation": 4.123,
            "contradiction": 9.10774,
            "irrelevancy": 46.49931,
            "logical_agreement": 44.39295,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.4056,
            "nubia_score": 0.70859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "mT5_small/totto_test",
        "N": 19,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26229508196721313,
            "2": 0.4067796610169492,
            "3": 0.7246376811594203
        },
        "rouge1": {
            "precision": 0.69842,
            "recall": 0.68891,
            "fmeasure": 0.6848
        },
        "rouge2": {
            "precision": 0.44109,
            "recall": 0.42991,
            "fmeasure": 0.42814
        },
        "rougeL": {
            "precision": 0.6224,
            "recall": 0.6209,
            "fmeasure": 0.61259
        },
        "rougeLsum": {
            "precision": 0.6224,
            "recall": 0.6209,
            "fmeasure": 0.61259
        },
        "nist": 5.728668226299983,
        "bleu": 39.79643,
        "bertscore": {
            "precision": 0.91735,
            "recall": 0.91553,
            "f1": 0.91431
        },
        "bleurt": 0.14583,
        "meteor": 0.3675097240790301,
        "nubia": {
            "semantic_relation": 3.86375,
            "contradiction": 12.10886,
            "irrelevancy": 46.67929,
            "logical_agreement": 41.21186,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.34023,
            "nubia_score": 0.6604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "mT5_small/totto_test",
        "N": 23,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5409836065573771,
            "3": 0.7711864406779662
        },
        "rouge1": {
            "precision": 0.77084,
            "recall": 0.75384,
            "fmeasure": 0.75221
        },
        "rouge2": {
            "precision": 0.56435,
            "recall": 0.55197,
            "fmeasure": 0.55014
        },
        "rougeL": {
            "precision": 0.66935,
            "recall": 0.65883,
            "fmeasure": 0.65593
        },
        "rougeLsum": {
            "precision": 0.66935,
            "recall": 0.65883,
            "fmeasure": 0.65593
        },
        "nist": 6.346384932707754,
        "bleu": 48.01897,
        "bertscore": {
            "precision": 0.9248,
            "recall": 0.92358,
            "f1": 0.92281
        },
        "bleurt": 0.29281,
        "meteor": 0.4053847179183711,
        "nubia": {
            "semantic_relation": 4.28441,
            "contradiction": 4.96215,
            "irrelevancy": 26.1331,
            "logical_agreement": 68.90475,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.05133,
            "nubia_score": 0.80278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "mT5_small/totto_test",
        "N": 47,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2206896551724138,
            "2": 0.3237410071942446,
            "3": 0.7268817204301076
        },
        "rouge1": {
            "precision": 0.69331,
            "recall": 0.7146,
            "fmeasure": 0.68693
        },
        "rouge2": {
            "precision": 0.45063,
            "recall": 0.45506,
            "fmeasure": 0.44247
        },
        "rougeL": {
            "precision": 0.61895,
            "recall": 0.62823,
            "fmeasure": 0.60822
        },
        "rougeLsum": {
            "precision": 0.61895,
            "recall": 0.62823,
            "fmeasure": 0.60822
        },
        "nist": 6.12969931975565,
        "bleu": 42.58943,
        "bertscore": {
            "precision": 0.91266,
            "recall": 0.91202,
            "f1": 0.91007
        },
        "bleurt": 0.22577,
        "meteor": 0.37150131382481794,
        "nubia": {
            "semantic_relation": 3.85197,
            "contradiction": 15.42011,
            "irrelevancy": 34.36814,
            "logical_agreement": 50.21175,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.29645,
            "nubia_score": 0.63796
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_small/totto_test",
        "N": 483,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2164048865619546,
            "2": 0.3709677419354839,
            "3": 0.7279626386456509
        },
        "rouge1": {
            "precision": 0.7398,
            "recall": 0.69131,
            "fmeasure": 0.70387
        },
        "rouge2": {
            "precision": 0.47954,
            "recall": 0.44771,
            "fmeasure": 0.45568
        },
        "rougeL": {
            "precision": 0.60159,
            "recall": 0.56192,
            "fmeasure": 0.57166
        },
        "rougeLsum": {
            "precision": 0.60159,
            "recall": 0.56192,
            "fmeasure": 0.57166
        },
        "nist": 8.426146186330795,
        "bleu": 38.46839,
        "bertscore": {
            "precision": 0.91974,
            "recall": 0.9102,
            "f1": 0.91303
        },
        "bleurt": 0.14767,
        "meteor": 0.3640191598332656,
        "nubia": {
            "semantic_relation": 4.01174,
            "contradiction": 14.68129,
            "irrelevancy": 31.19761,
            "logical_agreement": 54.1211,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.32644,
            "nubia_score": 0.67503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.65972,
            "recall": 0.65456,
            "fmeasure": 0.64672
        },
        "rouge2": {
            "precision": 0.47681,
            "recall": 0.43803,
            "fmeasure": 0.44949
        },
        "rougeL": {
            "precision": 0.59343,
            "recall": 0.60684,
            "fmeasure": 0.58709
        },
        "rougeLsum": {
            "precision": 0.59343,
            "recall": 0.60684,
            "fmeasure": 0.58709
        },
        "nist": 3.4774248864084796,
        "bleu": 34.18088,
        "bertscore": {
            "precision": 0.85802,
            "recall": 0.90407,
            "f1": 0.87909
        },
        "bleurt": 0.21825,
        "meteor": 0.3140629367867944,
        "nubia": {
            "semantic_relation": 4.16498,
            "contradiction": 0.28184,
            "irrelevancy": 50.11816,
            "logical_agreement": 49.60001,
            "grammar_ref": 4.99819,
            "grammar_hyp": 4.97372,
            "nubia_score": 0.73639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "nist": 2.0052535157554314,
        "bleu": 16.51582,
        "bertscore": {
            "precision": 0.87519,
            "recall": 0.87347,
            "f1": 0.87433
        },
        "bleurt": -0.06824,
        "meteor": 0.31253823342571707,
        "nubia": {
            "semantic_relation": 3.12986,
            "contradiction": 71.68311,
            "irrelevancy": 20.1839,
            "logical_agreement": 8.133,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.78582,
            "nubia_score": 0.30685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.3870967741935484,
            "3": 0.6938775510204082
        },
        "rouge1": {
            "precision": 0.77919,
            "recall": 0.63493,
            "fmeasure": 0.68561
        },
        "rouge2": {
            "precision": 0.55041,
            "recall": 0.44746,
            "fmeasure": 0.48226
        },
        "rougeL": {
            "precision": 0.7353,
            "recall": 0.60118,
            "fmeasure": 0.64834
        },
        "rougeLsum": {
            "precision": 0.7353,
            "recall": 0.60118,
            "fmeasure": 0.64834
        },
        "nist": 4.825171520605327,
        "bleu": 46.21792,
        "bertscore": {
            "precision": 0.92723,
            "recall": 0.89069,
            "f1": 0.90712
        },
        "bleurt": 0.16067,
        "meteor": 0.39341827958519576,
        "nubia": {
            "semantic_relation": 3.85455,
            "contradiction": 10.46638,
            "irrelevancy": 24.89126,
            "logical_agreement": 64.64236,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.90526,
            "nubia_score": 0.59177
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2111111111111111,
            "2": 0.3,
            "3": 0.6818181818181818
        },
        "rouge1": {
            "precision": 0.73844,
            "recall": 0.65453,
            "fmeasure": 0.67275
        },
        "rouge2": {
            "precision": 0.50799,
            "recall": 0.45836,
            "fmeasure": 0.46504
        },
        "rougeL": {
            "precision": 0.63099,
            "recall": 0.58556,
            "fmeasure": 0.59011
        },
        "rougeLsum": {
            "precision": 0.63099,
            "recall": 0.58556,
            "fmeasure": 0.59011
        },
        "nist": 5.59575142547115,
        "bleu": 41.33964,
        "bertscore": {
            "precision": 0.9139,
            "recall": 0.89982,
            "f1": 0.90407
        },
        "bleurt": 0.10848,
        "meteor": 0.3688319141068848,
        "nubia": {
            "semantic_relation": 3.96389,
            "contradiction": 7.19311,
            "irrelevancy": 28.21175,
            "logical_agreement": 64.59514,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.45688,
            "nubia_score": 0.64829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "mT5_small/totto_test",
        "N": 9,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.32142857142857145,
            "3": 0.7402597402597403
        },
        "rouge1": {
            "precision": 0.65541,
            "recall": 0.69281,
            "fmeasure": 0.65896
        },
        "rouge2": {
            "precision": 0.40411,
            "recall": 0.4506,
            "fmeasure": 0.41608
        },
        "rougeL": {
            "precision": 0.61298,
            "recall": 0.67196,
            "fmeasure": 0.62417
        },
        "rougeLsum": {
            "precision": 0.61298,
            "recall": 0.67196,
            "fmeasure": 0.62417
        },
        "nist": 4.250586176747239,
        "bleu": 32.51114,
        "bertscore": {
            "precision": 0.91938,
            "recall": 0.9139,
            "f1": 0.91556
        },
        "bleurt": 0.34615,
        "meteor": 0.326592355519525,
        "nubia": {
            "semantic_relation": 3.95219,
            "contradiction": 17.30609,
            "irrelevancy": 26.47746,
            "logical_agreement": 56.21645,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.71001,
            "nubia_score": 0.67454
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3333333333333333,
            "3": 0.84
        },
        "rouge1": {
            "precision": 0.7753,
            "recall": 0.85714,
            "fmeasure": 0.81186
        },
        "rouge2": {
            "precision": 0.4197,
            "recall": 0.46655,
            "fmeasure": 0.4402
        },
        "rougeL": {
            "precision": 0.63815,
            "recall": 0.71683,
            "fmeasure": 0.67274
        },
        "rougeLsum": {
            "precision": 0.63815,
            "recall": 0.71683,
            "fmeasure": 0.67274
        },
        "nist": 4.925277981952764,
        "bleu": 38.24681,
        "bertscore": {
            "precision": 0.92761,
            "recall": 0.9289,
            "f1": 0.92762
        },
        "bleurt": 0.40747,
        "meteor": 0.4236518738262708,
        "nubia": {
            "semantic_relation": 4.51431,
            "contradiction": 9.53995,
            "irrelevancy": 20.04852,
            "logical_agreement": 70.41153,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.79176,
            "nubia_score": 0.81354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.40476190476190477,
            "3": 0.7452830188679245
        },
        "rouge1": {
            "precision": 0.65677,
            "recall": 0.6997,
            "fmeasure": 0.66698
        },
        "rouge2": {
            "precision": 0.41199,
            "recall": 0.45451,
            "fmeasure": 0.42345
        },
        "rougeL": {
            "precision": 0.53281,
            "recall": 0.58201,
            "fmeasure": 0.54602
        },
        "rougeLsum": {
            "precision": 0.53281,
            "recall": 0.58201,
            "fmeasure": 0.54602
        },
        "nist": 5.184637753637428,
        "bleu": 33.41894,
        "bertscore": {
            "precision": 0.89691,
            "recall": 0.90502,
            "f1": 0.89655
        },
        "bleurt": 0.07058,
        "meteor": 0.3590982802676788,
        "nubia": {
            "semantic_relation": 3.72069,
            "contradiction": 37.7234,
            "irrelevancy": 32.23759,
            "logical_agreement": 30.03901,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.41839,
            "nubia_score": 0.58858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "mT5_small/totto_test",
        "N": 43,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26356589147286824,
            "2": 0.5862068965517241,
            "3": 0.7860262008733624
        },
        "rouge1": {
            "precision": 0.79652,
            "recall": 0.7489,
            "fmeasure": 0.75999
        },
        "rouge2": {
            "precision": 0.56006,
            "recall": 0.52517,
            "fmeasure": 0.53216
        },
        "rougeL": {
            "precision": 0.6929,
            "recall": 0.65636,
            "fmeasure": 0.66257
        },
        "rougeLsum": {
            "precision": 0.6929,
            "recall": 0.65636,
            "fmeasure": 0.66257
        },
        "nist": 7.0400990066014355,
        "bleu": 44.8058,
        "bertscore": {
            "precision": 0.93644,
            "recall": 0.92904,
            "f1": 0.93122
        },
        "bleurt": 0.34135,
        "meteor": 0.4037526438276193,
        "nubia": {
            "semantic_relation": 4.34777,
            "contradiction": 4.29809,
            "irrelevancy": 25.62233,
            "logical_agreement": 70.07958,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.61794,
            "nubia_score": 0.77991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.42105263157894735,
            "3": 0.7357142857142858
        },
        "rouge1": {
            "precision": 0.71688,
            "recall": 0.74714,
            "fmeasure": 0.71658
        },
        "rouge2": {
            "precision": 0.46516,
            "recall": 0.49083,
            "fmeasure": 0.46559
        },
        "rougeL": {
            "precision": 0.62485,
            "recall": 0.64633,
            "fmeasure": 0.62177
        },
        "rougeLsum": {
            "precision": 0.62485,
            "recall": 0.64633,
            "fmeasure": 0.62177
        },
        "nist": 5.517667823461779,
        "bleu": 44.1101,
        "bertscore": {
            "precision": 0.90892,
            "recall": 0.91521,
            "f1": 0.91069
        },
        "bleurt": 0.11874,
        "meteor": 0.40477709901003883,
        "nubia": {
            "semantic_relation": 4.06977,
            "contradiction": 15.80788,
            "irrelevancy": 40.98703,
            "logical_agreement": 43.20509,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.31097,
            "nubia_score": 0.68964
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.5051546391752577,
            "3": 0.7483221476510067
        },
        "rouge1": {
            "precision": 0.77633,
            "recall": 0.70524,
            "fmeasure": 0.72194
        },
        "rouge2": {
            "precision": 0.51279,
            "recall": 0.46184,
            "fmeasure": 0.47386
        },
        "rougeL": {
            "precision": 0.66055,
            "recall": 0.59638,
            "fmeasure": 0.61089
        },
        "rougeLsum": {
            "precision": 0.66055,
            "recall": 0.59638,
            "fmeasure": 0.61089
        },
        "nist": 6.099026443505796,
        "bleu": 42.95314,
        "bertscore": {
            "precision": 0.92715,
            "recall": 0.91772,
            "f1": 0.92089
        },
        "bleurt": 0.24963,
        "meteor": 0.3766779733389699,
        "nubia": {
            "semantic_relation": 4.13248,
            "contradiction": 4.55176,
            "irrelevancy": 28.97811,
            "logical_agreement": 66.47012,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.53795,
            "nubia_score": 0.71447
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "mT5_small/totto_test",
        "N": 15,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24285714285714285,
            "2": 0.25,
            "3": 0.7017543859649122
        },
        "rouge1": {
            "precision": 0.75103,
            "recall": 0.63094,
            "fmeasure": 0.67708
        },
        "rouge2": {
            "precision": 0.44937,
            "recall": 0.37122,
            "fmeasure": 0.40273
        },
        "rougeL": {
            "precision": 0.6348,
            "recall": 0.54444,
            "fmeasure": 0.5781
        },
        "rougeLsum": {
            "precision": 0.6348,
            "recall": 0.54444,
            "fmeasure": 0.5781
        },
        "nist": 5.254355631495209,
        "bleu": 40.20479,
        "bertscore": {
            "precision": 0.90272,
            "recall": 0.89286,
            "f1": 0.89575
        },
        "bleurt": 0.04483,
        "meteor": 0.3507185200420177,
        "nubia": {
            "semantic_relation": 4.02214,
            "contradiction": 7.02265,
            "irrelevancy": 39.48276,
            "logical_agreement": 53.4946,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.72293,
            "nubia_score": 0.63871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.1111111111111111,
            "3": 0.5844155844155844
        },
        "rouge1": {
            "precision": 0.64287,
            "recall": 0.49581,
            "fmeasure": 0.53268
        },
        "rouge2": {
            "precision": 0.2556,
            "recall": 0.22462,
            "fmeasure": 0.23345
        },
        "rougeL": {
            "precision": 0.52563,
            "recall": 0.41787,
            "fmeasure": 0.44594
        },
        "rougeLsum": {
            "precision": 0.52563,
            "recall": 0.41787,
            "fmeasure": 0.44594
        },
        "nist": 3.920903153403591,
        "bleu": 25.17504,
        "bertscore": {
            "precision": 0.89539,
            "recall": 0.85631,
            "f1": 0.86986
        },
        "bleurt": -0.18167,
        "meteor": 0.28474660883629616,
        "nubia": {
            "semantic_relation": 3.39231,
            "contradiction": 27.15971,
            "irrelevancy": 29.86723,
            "logical_agreement": 42.97306,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.35938,
            "nubia_score": 0.44637
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5789473684210527,
            "3": 0.8217821782178217
        },
        "rouge1": {
            "precision": 0.72846,
            "recall": 0.72397,
            "fmeasure": 0.71592
        },
        "rouge2": {
            "precision": 0.50936,
            "recall": 0.5062,
            "fmeasure": 0.50232
        },
        "rougeL": {
            "precision": 0.6081,
            "recall": 0.60189,
            "fmeasure": 0.59841
        },
        "rougeLsum": {
            "precision": 0.6081,
            "recall": 0.60189,
            "fmeasure": 0.59841
        },
        "nist": 5.392808108783857,
        "bleu": 48.43071,
        "bertscore": {
            "precision": 0.91839,
            "recall": 0.91663,
            "f1": 0.91695
        },
        "bleurt": 0.28757,
        "meteor": 0.41501918165469615,
        "nubia": {
            "semantic_relation": 4.32081,
            "contradiction": 14.97693,
            "irrelevancy": 24.72667,
            "logical_agreement": 60.29639,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.77631,
            "nubia_score": 0.76101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "mT5_small/totto_test",
        "N": 51,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2864583333333333,
            "2": 0.463768115942029,
            "3": 0.779385171790235
        },
        "rouge1": {
            "precision": 0.79007,
            "recall": 0.75951,
            "fmeasure": 0.76145
        },
        "rouge2": {
            "precision": 0.55187,
            "recall": 0.52943,
            "fmeasure": 0.53083
        },
        "rougeL": {
            "precision": 0.67273,
            "recall": 0.65508,
            "fmeasure": 0.65162
        },
        "rougeLsum": {
            "precision": 0.67273,
            "recall": 0.65508,
            "fmeasure": 0.65162
        },
        "nist": 7.354310511182913,
        "bleu": 49.81184,
        "bertscore": {
            "precision": 0.93705,
            "recall": 0.93267,
            "f1": 0.9331
        },
        "bleurt": 0.3034,
        "meteor": 0.40881656781386005,
        "nubia": {
            "semantic_relation": 4.27324,
            "contradiction": 4.55901,
            "irrelevancy": 26.98483,
            "logical_agreement": 68.45616,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.93183,
            "nubia_score": 0.72686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.18181818181818182,
            "3": 0.7380952380952381
        },
        "rouge1": {
            "precision": 0.76934,
            "recall": 0.70205,
            "fmeasure": 0.72729
        },
        "rouge2": {
            "precision": 0.48783,
            "recall": 0.45289,
            "fmeasure": 0.46639
        },
        "rougeL": {
            "precision": 0.57763,
            "recall": 0.53016,
            "fmeasure": 0.54758
        },
        "rougeLsum": {
            "precision": 0.57763,
            "recall": 0.53016,
            "fmeasure": 0.54758
        },
        "nist": 5.206576795545885,
        "bleu": 33.62397,
        "bertscore": {
            "precision": 0.9126,
            "recall": 0.91265,
            "f1": 0.9111
        },
        "bleurt": 0.1613,
        "meteor": 0.37926558323901627,
        "nubia": {
            "semantic_relation": 4.22038,
            "contradiction": 15.33066,
            "irrelevancy": 20.11013,
            "logical_agreement": 64.55921,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.37976,
            "nubia_score": 0.74393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.36667,
            "fmeasure": 0.38182
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.275,
            "fmeasure": 0.28636
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.275,
            "fmeasure": 0.28636
        },
        "nist": 2.070107326581967,
        "bleu": 5.86559,
        "bertscore": {
            "precision": 0.84947,
            "recall": 0.78168,
            "f1": 0.81417
        },
        "bleurt": -0.43031,
        "meteor": 0.2140845070422535,
        "nubia": {
            "semantic_relation": 2.94319,
            "contradiction": 11.17838,
            "irrelevancy": 3.47938,
            "logical_agreement": 85.34224,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.19241,
            "nubia_score": 0.30389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "mT5_small/totto_test",
        "N": 22,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2222222222222222,
            "3": 0.8537549407114624
        },
        "rouge1": {
            "precision": 0.85705,
            "recall": 0.83187,
            "fmeasure": 0.83577
        },
        "rouge2": {
            "precision": 0.70641,
            "recall": 0.68069,
            "fmeasure": 0.68618
        },
        "rougeL": {
            "precision": 0.78829,
            "recall": 0.77101,
            "fmeasure": 0.77013
        },
        "rougeLsum": {
            "precision": 0.78829,
            "recall": 0.77101,
            "fmeasure": 0.77013
        },
        "nist": 6.882898171791,
        "bleu": 63.56529,
        "bertscore": {
            "precision": 0.96141,
            "recall": 0.95648,
            "f1": 0.95727
        },
        "bleurt": 0.51131,
        "meteor": 0.49165833151589766,
        "nubia": {
            "semantic_relation": 4.45752,
            "contradiction": 0.50167,
            "irrelevancy": 25.85109,
            "logical_agreement": 73.64724,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.45005,
            "nubia_score": 0.82233
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.63675,
            "recall": 0.61507,
            "fmeasure": 0.61931
        },
        "rouge2": {
            "precision": 0.42929,
            "recall": 0.45085,
            "fmeasure": 0.4324
        },
        "rougeL": {
            "precision": 0.59615,
            "recall": 0.63736,
            "fmeasure": 0.60647
        },
        "rougeLsum": {
            "precision": 0.59615,
            "recall": 0.63736,
            "fmeasure": 0.60647
        },
        "nist": 3.371240836903038,
        "bleu": 38.56149,
        "bertscore": {
            "precision": 0.90767,
            "recall": 0.90558,
            "f1": 0.90614
        },
        "bleurt": 0.31954,
        "meteor": 0.35169886779140014,
        "nubia": {
            "semantic_relation": 4.17918,
            "contradiction": 34.37397,
            "irrelevancy": 21.3823,
            "logical_agreement": 44.24373,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.84587,
            "nubia_score": 0.67248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2127659574468085,
            "3": 0.8387096774193549
        },
        "rouge1": {
            "precision": 0.81688,
            "recall": 0.60902,
            "fmeasure": 0.68405
        },
        "rouge2": {
            "precision": 0.55204,
            "recall": 0.41106,
            "fmeasure": 0.46244
        },
        "rougeL": {
            "precision": 0.73079,
            "recall": 0.54162,
            "fmeasure": 0.61097
        },
        "rougeLsum": {
            "precision": 0.73079,
            "recall": 0.54162,
            "fmeasure": 0.61097
        },
        "nist": 3.9310527127799646,
        "bleu": 40.62965,
        "bertscore": {
            "precision": 0.92964,
            "recall": 0.89282,
            "f1": 0.90964
        },
        "bleurt": 0.08747,
        "meteor": 0.34034574977701143,
        "nubia": {
            "semantic_relation": 3.75728,
            "contradiction": 4.90226,
            "irrelevancy": 27.49606,
            "logical_agreement": 67.60167,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.91202,
            "nubia_score": 0.55826
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "mT5_small/totto_test",
        "N": 55,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28921568627450983,
            "2": 0.37158469945355194,
            "3": 0.7137546468401487
        },
        "rouge1": {
            "precision": 0.70141,
            "recall": 0.66264,
            "fmeasure": 0.67066
        },
        "rouge2": {
            "precision": 0.46135,
            "recall": 0.4379,
            "fmeasure": 0.4421
        },
        "rougeL": {
            "precision": 0.60706,
            "recall": 0.58012,
            "fmeasure": 0.58353
        },
        "rougeLsum": {
            "precision": 0.60706,
            "recall": 0.58012,
            "fmeasure": 0.58353
        },
        "nist": 6.72791341355493,
        "bleu": 43.34865,
        "bertscore": {
            "precision": 0.91255,
            "recall": 0.90665,
            "f1": 0.90785
        },
        "bleurt": 0.14089,
        "meteor": 0.37208390765791977,
        "nubia": {
            "semantic_relation": 3.98691,
            "contradiction": 7.34671,
            "irrelevancy": 35.03626,
            "logical_agreement": 57.61703,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.83691,
            "nubia_score": 0.67461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "mT5_small/totto_test",
        "N": 122,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20224719101123595,
            "2": 0.39762611275964393,
            "3": 0.7342709104367136
        },
        "rouge1": {
            "precision": 0.74009,
            "recall": 0.70196,
            "fmeasure": 0.70941
        },
        "rouge2": {
            "precision": 0.50036,
            "recall": 0.47273,
            "fmeasure": 0.47813
        },
        "rougeL": {
            "precision": 0.62895,
            "recall": 0.60077,
            "fmeasure": 0.60512
        },
        "rougeLsum": {
            "precision": 0.62895,
            "recall": 0.60077,
            "fmeasure": 0.60512
        },
        "nist": 7.2769082475594145,
        "bleu": 41.16343,
        "bertscore": {
            "precision": 0.91985,
            "recall": 0.91424,
            "f1": 0.91564
        },
        "bleurt": 0.19591,
        "meteor": 0.3703851625247425,
        "nubia": {
            "semantic_relation": 4.09662,
            "contradiction": 11.59076,
            "irrelevancy": 31.6485,
            "logical_agreement": 56.76074,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.67437,
            "nubia_score": 0.68863
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "mT5_small/totto_test",
        "N": 300,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19182746878547105,
            "2": 0.3573446327683616,
            "3": 0.7651679306608884
        },
        "rouge1": {
            "precision": 0.80244,
            "recall": 0.73304,
            "fmeasure": 0.75519
        },
        "rouge2": {
            "precision": 0.54103,
            "recall": 0.4959,
            "fmeasure": 0.50996
        },
        "rougeL": {
            "precision": 0.68294,
            "recall": 0.62434,
            "fmeasure": 0.64306
        },
        "rougeLsum": {
            "precision": 0.68294,
            "recall": 0.62434,
            "fmeasure": 0.64306
        },
        "nist": 8.225725605026197,
        "bleu": 43.32798,
        "bertscore": {
            "precision": 0.93688,
            "recall": 0.92618,
            "f1": 0.93022
        },
        "bleurt": 0.30353,
        "meteor": 0.38757439241488145,
        "nubia": {
            "semantic_relation": 4.31952,
            "contradiction": 5.98674,
            "irrelevancy": 23.34973,
            "logical_agreement": 70.66353,
            "grammar_ref": 4.91577,
            "grammar_hyp": 5.02451,
            "nubia_score": 0.7371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2037037037037037,
            "2": 0.5806451612903226,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.71159,
            "recall": 0.68195,
            "fmeasure": 0.68827
        },
        "rouge2": {
            "precision": 0.51965,
            "recall": 0.50108,
            "fmeasure": 0.50304
        },
        "rougeL": {
            "precision": 0.61864,
            "recall": 0.59935,
            "fmeasure": 0.59963
        },
        "rougeLsum": {
            "precision": 0.61864,
            "recall": 0.59935,
            "fmeasure": 0.59963
        },
        "nist": 5.604354243073489,
        "bleu": 49.3717,
        "bertscore": {
            "precision": 0.9265,
            "recall": 0.92433,
            "f1": 0.92289
        },
        "bleurt": 0.12833,
        "meteor": 0.4003159675630195,
        "nubia": {
            "semantic_relation": 3.69443,
            "contradiction": 21.75599,
            "irrelevancy": 38.84706,
            "logical_agreement": 39.39695,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.32473,
            "nubia_score": 0.62073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.8444444444444444
        },
        "rouge1": {
            "precision": 0.74825,
            "recall": 0.76914,
            "fmeasure": 0.757
        },
        "rouge2": {
            "precision": 0.56886,
            "recall": 0.57978,
            "fmeasure": 0.5724
        },
        "rougeL": {
            "precision": 0.7331,
            "recall": 0.74187,
            "fmeasure": 0.73486
        },
        "rougeLsum": {
            "precision": 0.7331,
            "recall": 0.74187,
            "fmeasure": 0.73486
        },
        "nist": 5.130260945479308,
        "bleu": 66.0584,
        "bertscore": {
            "precision": 0.93762,
            "recall": 0.93883,
            "f1": 0.93747
        },
        "bleurt": 0.48549,
        "meteor": 0.4752304362007848,
        "nubia": {
            "semantic_relation": 4.28184,
            "contradiction": 2.6424,
            "irrelevancy": 44.68376,
            "logical_agreement": 52.67383,
            "grammar_ref": 4.43427,
            "grammar_hyp": 5.00404,
            "nubia_score": 0.71688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36666666666666664,
            "2": 0.16666666666666666,
            "3": 0.6794871794871795
        },
        "rouge1": {
            "precision": 0.71035,
            "recall": 0.68879,
            "fmeasure": 0.69593
        },
        "rouge2": {
            "precision": 0.53665,
            "recall": 0.52073,
            "fmeasure": 0.52614
        },
        "rougeL": {
            "precision": 0.61501,
            "recall": 0.59485,
            "fmeasure": 0.60207
        },
        "rougeLsum": {
            "precision": 0.61501,
            "recall": 0.59485,
            "fmeasure": 0.60207
        },
        "nist": 4.88366457476813,
        "bleu": 42.49944,
        "bertscore": {
            "precision": 0.92338,
            "recall": 0.90338,
            "f1": 0.91278
        },
        "bleurt": 0.2143,
        "meteor": 0.3838550621595532,
        "nubia": {
            "semantic_relation": 4.04453,
            "contradiction": 0.22765,
            "irrelevancy": 35.93086,
            "logical_agreement": 63.84149,
            "grammar_ref": 4.20009,
            "grammar_hyp": 3.84336,
            "nubia_score": 0.74173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "mT5_small/totto_test",
        "N": 16,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12195121951219512,
            "2": 0.43478260869565216,
            "3": 0.7317073170731707
        },
        "rouge1": {
            "precision": 0.74515,
            "recall": 0.72136,
            "fmeasure": 0.72956
        },
        "rouge2": {
            "precision": 0.50775,
            "recall": 0.49447,
            "fmeasure": 0.49851
        },
        "rougeL": {
            "precision": 0.63951,
            "recall": 0.62194,
            "fmeasure": 0.62754
        },
        "rougeLsum": {
            "precision": 0.63951,
            "recall": 0.62194,
            "fmeasure": 0.62754
        },
        "nist": 5.607509460635894,
        "bleu": 42.30149,
        "bertscore": {
            "precision": 0.91709,
            "recall": 0.91775,
            "f1": 0.91702
        },
        "bleurt": 0.30602,
        "meteor": 0.37605139472785,
        "nubia": {
            "semantic_relation": 4.32185,
            "contradiction": 8.56157,
            "irrelevancy": 29.45031,
            "logical_agreement": 61.98812,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.54264,
            "nubia_score": 0.75262
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3153153153153153,
            "2": 0.4578313253012048,
            "3": 0.7626666666666667
        },
        "rouge1": {
            "precision": 0.73271,
            "recall": 0.73382,
            "fmeasure": 0.72355
        },
        "rouge2": {
            "precision": 0.5189,
            "recall": 0.50283,
            "fmeasure": 0.50306
        },
        "rougeL": {
            "precision": 0.64998,
            "recall": 0.64332,
            "fmeasure": 0.6384
        },
        "rougeLsum": {
            "precision": 0.64998,
            "recall": 0.64332,
            "fmeasure": 0.6384
        },
        "nist": 6.60385985988975,
        "bleu": 44.45801,
        "bertscore": {
            "precision": 0.92811,
            "recall": 0.92326,
            "f1": 0.92448
        },
        "bleurt": 0.27136,
        "meteor": 0.378264512519589,
        "nubia": {
            "semantic_relation": 4.04281,
            "contradiction": 18.51448,
            "irrelevancy": 32.68506,
            "logical_agreement": 48.80047,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.62826,
            "nubia_score": 0.70749
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "mT5_small/totto_test",
        "N": 35,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25773195876288657,
            "2": 0.36036036036036034,
            "3": 0.6843575418994413
        },
        "rouge1": {
            "precision": 0.69828,
            "recall": 0.63315,
            "fmeasure": 0.65161
        },
        "rouge2": {
            "precision": 0.45616,
            "recall": 0.4056,
            "fmeasure": 0.42005
        },
        "rougeL": {
            "precision": 0.59147,
            "recall": 0.54215,
            "fmeasure": 0.55573
        },
        "rougeLsum": {
            "precision": 0.59147,
            "recall": 0.54215,
            "fmeasure": 0.55573
        },
        "nist": 6.311643407096896,
        "bleu": 38.48908,
        "bertscore": {
            "precision": 0.91251,
            "recall": 0.89107,
            "f1": 0.90005
        },
        "bleurt": 0.08079,
        "meteor": 0.3290004017946107,
        "nubia": {
            "semantic_relation": 3.7704,
            "contradiction": 13.71921,
            "irrelevancy": 32.07975,
            "logical_agreement": 54.20104,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.68373,
            "nubia_score": 0.58939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "mT5_small/totto_test",
        "N": 66,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23383084577114427,
            "2": 0.39285714285714285,
            "3": 0.7241379310344828
        },
        "rouge1": {
            "precision": 0.7161,
            "recall": 0.69479,
            "fmeasure": 0.69322
        },
        "rouge2": {
            "precision": 0.49248,
            "recall": 0.47543,
            "fmeasure": 0.47505
        },
        "rougeL": {
            "precision": 0.61879,
            "recall": 0.59765,
            "fmeasure": 0.59654
        },
        "rougeLsum": {
            "precision": 0.61879,
            "recall": 0.59765,
            "fmeasure": 0.59654
        },
        "nist": 6.401504681179455,
        "bleu": 38.4657,
        "bertscore": {
            "precision": 0.91044,
            "recall": 0.91198,
            "f1": 0.90973
        },
        "bleurt": 0.20533,
        "meteor": 0.3703754709724518,
        "nubia": {
            "semantic_relation": 4.07617,
            "contradiction": 6.67471,
            "irrelevancy": 34.88721,
            "logical_agreement": 58.43808,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.35993,
            "nubia_score": 0.70642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.50667,
            "recall": 0.86905,
            "fmeasure": 0.63957
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.58803,
            "fmeasure": 0.42504
        },
        "rougeL": {
            "precision": 0.50667,
            "recall": 0.86905,
            "fmeasure": 0.63957
        },
        "rougeLsum": {
            "precision": 0.50667,
            "recall": 0.86905,
            "fmeasure": 0.63957
        },
        "nist": 2.0735806042191665,
        "bleu": 26.98809,
        "bertscore": {
            "precision": 0.89521,
            "recall": 0.95092,
            "f1": 0.92222
        },
        "bleurt": 0.28301,
        "meteor": 0.4284862436876113,
        "nubia": {
            "semantic_relation": 3.38506,
            "contradiction": 46.50952,
            "irrelevancy": 47.29415,
            "logical_agreement": 6.19634,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.06099,
            "nubia_score": 0.52733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "mT5_small/totto_test",
        "N": 9,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.125,
            "3": 0.7478260869565218
        },
        "rouge1": {
            "precision": 0.74113,
            "recall": 0.71376,
            "fmeasure": 0.71989
        },
        "rouge2": {
            "precision": 0.43545,
            "recall": 0.45184,
            "fmeasure": 0.43598
        },
        "rougeL": {
            "precision": 0.57032,
            "recall": 0.57776,
            "fmeasure": 0.56549
        },
        "rougeLsum": {
            "precision": 0.57032,
            "recall": 0.57776,
            "fmeasure": 0.56549
        },
        "nist": 5.190407137224782,
        "bleu": 29.4817,
        "bertscore": {
            "precision": 0.91306,
            "recall": 0.91107,
            "f1": 0.91152
        },
        "bleurt": 0.19319,
        "meteor": 0.36182802965456956,
        "nubia": {
            "semantic_relation": 4.26917,
            "contradiction": 1.11171,
            "irrelevancy": 35.12899,
            "logical_agreement": 63.7593,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.45883,
            "nubia_score": 0.7733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "mT5_small/totto_test",
        "N": 59,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3018867924528302,
            "2": 0.45864661654135336,
            "3": 0.7605633802816901
        },
        "rouge1": {
            "precision": 0.78705,
            "recall": 0.72258,
            "fmeasure": 0.74522
        },
        "rouge2": {
            "precision": 0.55597,
            "recall": 0.50976,
            "fmeasure": 0.52589
        },
        "rougeL": {
            "precision": 0.67987,
            "recall": 0.62861,
            "fmeasure": 0.64454
        },
        "rougeLsum": {
            "precision": 0.67987,
            "recall": 0.62861,
            "fmeasure": 0.64454
        },
        "nist": 7.189291676635364,
        "bleu": 47.40277,
        "bertscore": {
            "precision": 0.93838,
            "recall": 0.92318,
            "f1": 0.92964
        },
        "bleurt": 0.26294,
        "meteor": 0.391748565762018,
        "nubia": {
            "semantic_relation": 4.13576,
            "contradiction": 7.52337,
            "irrelevancy": 27.54043,
            "logical_agreement": 64.9362,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.52353,
            "nubia_score": 0.72604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.43333333333333335,
            "3": 0.7578125
        },
        "rouge1": {
            "precision": 0.71696,
            "recall": 0.74378,
            "fmeasure": 0.71981
        },
        "rouge2": {
            "precision": 0.51157,
            "recall": 0.53402,
            "fmeasure": 0.51419
        },
        "rougeL": {
            "precision": 0.65273,
            "recall": 0.6824,
            "fmeasure": 0.65628
        },
        "rougeLsum": {
            "precision": 0.65273,
            "recall": 0.6824,
            "fmeasure": 0.65628
        },
        "nist": 5.427624895334973,
        "bleu": 46.0211,
        "bertscore": {
            "precision": 0.92671,
            "recall": 0.92649,
            "f1": 0.92522
        },
        "bleurt": 0.28994,
        "meteor": 0.4175755457840139,
        "nubia": {
            "semantic_relation": 4.20451,
            "contradiction": 5.01956,
            "irrelevancy": 24.30315,
            "logical_agreement": 70.6773,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.24904,
            "nubia_score": 0.74221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.4,
            "3": 0.8153846153846154
        },
        "rouge1": {
            "precision": 0.68873,
            "recall": 0.71429,
            "fmeasure": 0.68979
        },
        "rouge2": {
            "precision": 0.52324,
            "recall": 0.5012,
            "fmeasure": 0.50209
        },
        "rougeL": {
            "precision": 0.6339,
            "recall": 0.62291,
            "fmeasure": 0.61567
        },
        "rougeLsum": {
            "precision": 0.6339,
            "recall": 0.62291,
            "fmeasure": 0.61567
        },
        "nist": 4.887712134468575,
        "bleu": 46.20933,
        "bertscore": {
            "precision": 0.89802,
            "recall": 0.89869,
            "f1": 0.89757
        },
        "bleurt": 0.08757,
        "meteor": 0.37653386471672706,
        "nubia": {
            "semantic_relation": 3.99741,
            "contradiction": 14.78073,
            "irrelevancy": 33.56836,
            "logical_agreement": 51.65091,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.88057,
            "nubia_score": 0.68656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "mT5_small/totto_test",
        "N": 23,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2987012987012987,
            "2": 0.4782608695652174,
            "3": 0.8464912280701754
        },
        "rouge1": {
            "precision": 0.77463,
            "recall": 0.74928,
            "fmeasure": 0.75678
        },
        "rouge2": {
            "precision": 0.5626,
            "recall": 0.54775,
            "fmeasure": 0.5518
        },
        "rougeL": {
            "precision": 0.68192,
            "recall": 0.65785,
            "fmeasure": 0.66511
        },
        "rougeLsum": {
            "precision": 0.68192,
            "recall": 0.65785,
            "fmeasure": 0.66511
        },
        "nist": 6.651774289296114,
        "bleu": 52.60424,
        "bertscore": {
            "precision": 0.9367,
            "recall": 0.93384,
            "f1": 0.93465
        },
        "bleurt": 0.28417,
        "meteor": 0.4341871055860214,
        "nubia": {
            "semantic_relation": 4.27753,
            "contradiction": 6.1828,
            "irrelevancy": 27.99224,
            "logical_agreement": 65.82495,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.69614,
            "nubia_score": 0.76817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "mT5_small/totto_test",
        "N": 43,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29310344827586204,
            "2": 0.39849624060150374,
            "3": 0.7971698113207547
        },
        "rouge1": {
            "precision": 0.78777,
            "recall": 0.75451,
            "fmeasure": 0.75765
        },
        "rouge2": {
            "precision": 0.57806,
            "recall": 0.54981,
            "fmeasure": 0.55558
        },
        "rougeL": {
            "precision": 0.7029,
            "recall": 0.678,
            "fmeasure": 0.67731
        },
        "rougeLsum": {
            "precision": 0.7029,
            "recall": 0.678,
            "fmeasure": 0.67731
        },
        "nist": 6.7960593294419205,
        "bleu": 49.10869,
        "bertscore": {
            "precision": 0.93172,
            "recall": 0.92138,
            "f1": 0.92479
        },
        "bleurt": 0.2413,
        "meteor": 0.3949905269188217,
        "nubia": {
            "semantic_relation": 4.13545,
            "contradiction": 9.56792,
            "irrelevancy": 28.5118,
            "logical_agreement": 61.92028,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.48954,
            "nubia_score": 0.70389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.47619,
            "fmeasure": 0.51282
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.30556,
            "fmeasure": 0.31752
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.40476,
            "fmeasure": 0.39487
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.40476,
            "fmeasure": 0.39487
        },
        "nist": 3.3427481233919667,
        "bleu": 35.34548,
        "bertscore": {
            "precision": 0.89201,
            "recall": 0.86355,
            "f1": 0.87755
        },
        "bleurt": -0.02115,
        "meteor": 0.2802960253906843,
        "nubia": {
            "semantic_relation": 3.95215,
            "contradiction": 0.29613,
            "irrelevancy": 56.56658,
            "logical_agreement": 43.13729,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.52842,
            "nubia_score": 0.71194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3142857142857143,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.81127,
            "recall": 0.73209,
            "fmeasure": 0.76523
        },
        "rouge2": {
            "precision": 0.61073,
            "recall": 0.55713,
            "fmeasure": 0.57819
        },
        "rougeL": {
            "precision": 0.66989,
            "recall": 0.61458,
            "fmeasure": 0.6365
        },
        "rougeLsum": {
            "precision": 0.66989,
            "recall": 0.61458,
            "fmeasure": 0.6365
        },
        "nist": 5.586584172585203,
        "bleu": 54.79377,
        "bertscore": {
            "precision": 0.92991,
            "recall": 0.93513,
            "f1": 0.93178
        },
        "bleurt": 0.22849,
        "meteor": 0.44222972602010635,
        "nubia": {
            "semantic_relation": 4.3957,
            "contradiction": 8.97576,
            "irrelevancy": 19.46725,
            "logical_agreement": 71.55699,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.49855,
            "nubia_score": 0.81551
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "mT5_small/totto_test",
        "N": 128,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14545454545454545,
            "2": 0.32558139534883723,
            "3": 0.7779282329045363
        },
        "rouge1": {
            "precision": 0.79999,
            "recall": 0.75382,
            "fmeasure": 0.76683
        },
        "rouge2": {
            "precision": 0.56262,
            "recall": 0.53192,
            "fmeasure": 0.53974
        },
        "rougeL": {
            "precision": 0.68229,
            "recall": 0.64945,
            "fmeasure": 0.65689
        },
        "rougeLsum": {
            "precision": 0.68229,
            "recall": 0.64945,
            "fmeasure": 0.65689
        },
        "nist": 7.403603537507722,
        "bleu": 43.97556,
        "bertscore": {
            "precision": 0.93776,
            "recall": 0.93165,
            "f1": 0.93294
        },
        "bleurt": 0.34053,
        "meteor": 0.3935117592055672,
        "nubia": {
            "semantic_relation": 4.3536,
            "contradiction": 9.17644,
            "irrelevancy": 24.37831,
            "logical_agreement": 66.44525,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.27032,
            "nubia_score": 0.79871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "mT5_small/totto_test",
        "N": 47,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.265625,
            "2": 0.32558139534883723,
            "3": 0.7763636363636364
        },
        "rouge1": {
            "precision": 0.77678,
            "recall": 0.73278,
            "fmeasure": 0.74176
        },
        "rouge2": {
            "precision": 0.56267,
            "recall": 0.53323,
            "fmeasure": 0.53766
        },
        "rougeL": {
            "precision": 0.67973,
            "recall": 0.64514,
            "fmeasure": 0.65121
        },
        "rougeLsum": {
            "precision": 0.67973,
            "recall": 0.64514,
            "fmeasure": 0.65121
        },
        "nist": 7.0482064398775295,
        "bleu": 50.50084,
        "bertscore": {
            "precision": 0.93462,
            "recall": 0.92364,
            "f1": 0.9263
        },
        "bleurt": 0.28919,
        "meteor": 0.4088813006898913,
        "nubia": {
            "semantic_relation": 4.17405,
            "contradiction": 9.30692,
            "irrelevancy": 24.77214,
            "logical_agreement": 65.92094,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.47209,
            "nubia_score": 0.71599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "mT5_small/totto_test",
        "N": 9,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4864864864864865,
            "2": 0.6,
            "3": 0.788235294117647
        },
        "rouge1": {
            "precision": 0.80573,
            "recall": 0.77187,
            "fmeasure": 0.78008
        },
        "rouge2": {
            "precision": 0.61021,
            "recall": 0.59093,
            "fmeasure": 0.59245
        },
        "rougeL": {
            "precision": 0.70298,
            "recall": 0.6892,
            "fmeasure": 0.68762
        },
        "rougeLsum": {
            "precision": 0.70298,
            "recall": 0.6892,
            "fmeasure": 0.68762
        },
        "nist": 5.884735412415249,
        "bleu": 52.40053,
        "bertscore": {
            "precision": 0.94538,
            "recall": 0.92929,
            "f1": 0.93637
        },
        "bleurt": 0.26336,
        "meteor": 0.40580198819019464,
        "nubia": {
            "semantic_relation": 4.2012,
            "contradiction": 0.76038,
            "irrelevancy": 22.65463,
            "logical_agreement": 76.58499,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.00102,
            "nubia_score": 0.70304
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "mT5_small/totto_test",
        "N": 49,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.211340206185567,
            "2": 0.4161849710982659,
            "3": 0.7362428842504743
        },
        "rouge1": {
            "precision": 0.77011,
            "recall": 0.67593,
            "fmeasure": 0.70732
        },
        "rouge2": {
            "precision": 0.51805,
            "recall": 0.45775,
            "fmeasure": 0.47564
        },
        "rougeL": {
            "precision": 0.65677,
            "recall": 0.57727,
            "fmeasure": 0.60391
        },
        "rougeLsum": {
            "precision": 0.65677,
            "recall": 0.57727,
            "fmeasure": 0.60391
        },
        "nist": 6.618167499962669,
        "bleu": 42.25799,
        "bertscore": {
            "precision": 0.93456,
            "recall": 0.91066,
            "f1": 0.9203
        },
        "bleurt": 0.20811,
        "meteor": 0.3674513832729149,
        "nubia": {
            "semantic_relation": 4.08715,
            "contradiction": 7.66911,
            "irrelevancy": 27.35544,
            "logical_agreement": 64.97545,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.87513,
            "nubia_score": 0.68574
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.4,
            "3": 0.7321428571428571
        },
        "rouge1": {
            "precision": 0.77292,
            "recall": 0.75964,
            "fmeasure": 0.76519
        },
        "rouge2": {
            "precision": 0.63503,
            "recall": 0.64259,
            "fmeasure": 0.63767
        },
        "rougeL": {
            "precision": 0.71875,
            "recall": 0.71572,
            "fmeasure": 0.71419
        },
        "rougeLsum": {
            "precision": 0.71875,
            "recall": 0.71572,
            "fmeasure": 0.71419
        },
        "nist": 4.8886058553494145,
        "bleu": 58.13393,
        "bertscore": {
            "precision": 0.94059,
            "recall": 0.93592,
            "f1": 0.93715
        },
        "bleurt": 0.47289,
        "meteor": 0.3977253123149932,
        "nubia": {
            "semantic_relation": 4.45527,
            "contradiction": 0.38636,
            "irrelevancy": 6.76478,
            "logical_agreement": 92.84886,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.19602,
            "nubia_score": 0.8641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "mT5_small/totto_test",
        "N": 21,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15942028985507245,
            "2": 0.3018867924528302,
            "3": 0.7606382978723404
        },
        "rouge1": {
            "precision": 0.74961,
            "recall": 0.70147,
            "fmeasure": 0.71483
        },
        "rouge2": {
            "precision": 0.52356,
            "recall": 0.48543,
            "fmeasure": 0.49807
        },
        "rougeL": {
            "precision": 0.68529,
            "recall": 0.64725,
            "fmeasure": 0.65689
        },
        "rougeLsum": {
            "precision": 0.68529,
            "recall": 0.64725,
            "fmeasure": 0.65689
        },
        "nist": 5.309804842444689,
        "bleu": 37.93701,
        "bertscore": {
            "precision": 0.91905,
            "recall": 0.90724,
            "f1": 0.91054
        },
        "bleurt": 0.11689,
        "meteor": 0.3635654093747747,
        "nubia": {
            "semantic_relation": 3.92443,
            "contradiction": 11.13944,
            "irrelevancy": 40.1261,
            "logical_agreement": 48.73445,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.97168,
            "nubia_score": 0.65959
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "mT5_small/totto_test",
        "N": 128,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20943952802359883,
            "2": 0.3306122448979592,
            "3": 0.7773279352226721
        },
        "rouge1": {
            "precision": 0.79442,
            "recall": 0.74529,
            "fmeasure": 0.75956
        },
        "rouge2": {
            "precision": 0.53666,
            "recall": 0.50394,
            "fmeasure": 0.51214
        },
        "rougeL": {
            "precision": 0.68393,
            "recall": 0.64422,
            "fmeasure": 0.65494
        },
        "rougeLsum": {
            "precision": 0.68393,
            "recall": 0.64422,
            "fmeasure": 0.65494
        },
        "nist": 7.6621829728008,
        "bleu": 44.12231,
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.92721,
            "f1": 0.92933
        },
        "bleurt": 0.34804,
        "meteor": 0.3925363652890065,
        "nubia": {
            "semantic_relation": 4.41003,
            "contradiction": 8.01939,
            "irrelevancy": 21.56159,
            "logical_agreement": 70.41902,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.63568,
            "nubia_score": 0.78737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5333333333333333,
            "2": 0.1935483870967742,
            "3": 0.6793893129770993
        },
        "rouge1": {
            "precision": 0.69071,
            "recall": 0.66829,
            "fmeasure": 0.66438
        },
        "rouge2": {
            "precision": 0.46721,
            "recall": 0.47049,
            "fmeasure": 0.46122
        },
        "rougeL": {
            "precision": 0.60644,
            "recall": 0.58959,
            "fmeasure": 0.58464
        },
        "rougeLsum": {
            "precision": 0.60644,
            "recall": 0.58959,
            "fmeasure": 0.58464
        },
        "nist": 5.149451916643069,
        "bleu": 42.12893,
        "bertscore": {
            "precision": 0.92425,
            "recall": 0.91175,
            "f1": 0.91735
        },
        "bleurt": 0.13641,
        "meteor": 0.36288156496811014,
        "nubia": {
            "semantic_relation": 3.79823,
            "contradiction": 26.90418,
            "irrelevancy": 29.16754,
            "logical_agreement": 43.92828,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.68693,
            "nubia_score": 0.59561
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.8055555555555556
        },
        "rouge1": {
            "precision": 0.56332,
            "recall": 0.64795,
            "fmeasure": 0.59203
        },
        "rouge2": {
            "precision": 0.3845,
            "recall": 0.42107,
            "fmeasure": 0.39731
        },
        "rougeL": {
            "precision": 0.43472,
            "recall": 0.52437,
            "fmeasure": 0.46614
        },
        "rougeLsum": {
            "precision": 0.43472,
            "recall": 0.52437,
            "fmeasure": 0.46614
        },
        "nist": 3.2639430798372673,
        "bleu": 28.6832,
        "bertscore": {
            "precision": 0.86311,
            "recall": 0.92317,
            "f1": 0.89176
        },
        "bleurt": 0.01916,
        "meteor": 0.41150798405976535,
        "nubia": {
            "semantic_relation": 3.88317,
            "contradiction": 0.4969,
            "irrelevancy": 82.7272,
            "logical_agreement": 16.77591,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.09628,
            "nubia_score": 0.6509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.4782608695652174,
            "3": 0.5614035087719298
        },
        "rouge1": {
            "precision": 0.61899,
            "recall": 0.55288,
            "fmeasure": 0.56516
        },
        "rouge2": {
            "precision": 0.30231,
            "recall": 0.29555,
            "fmeasure": 0.28758
        },
        "rougeL": {
            "precision": 0.49701,
            "recall": 0.46324,
            "fmeasure": 0.46264
        },
        "rougeLsum": {
            "precision": 0.49701,
            "recall": 0.46324,
            "fmeasure": 0.46264
        },
        "nist": 3.8138748569864713,
        "bleu": 22.68303,
        "bertscore": {
            "precision": 0.89666,
            "recall": 0.87658,
            "f1": 0.88477
        },
        "bleurt": -0.12362,
        "meteor": 0.2741386265231499,
        "nubia": {
            "semantic_relation": 3.56168,
            "contradiction": 18.73891,
            "irrelevancy": 49.90645,
            "logical_agreement": 31.35464,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.57645,
            "nubia_score": 0.5766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "mT5_small/totto_test",
        "N": 23,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.43373493975903615,
            "3": 0.7037037037037037
        },
        "rouge1": {
            "precision": 0.77355,
            "recall": 0.68451,
            "fmeasure": 0.71061
        },
        "rouge2": {
            "precision": 0.51768,
            "recall": 0.46314,
            "fmeasure": 0.47566
        },
        "rougeL": {
            "precision": 0.65704,
            "recall": 0.59035,
            "fmeasure": 0.60683
        },
        "rougeLsum": {
            "precision": 0.65704,
            "recall": 0.59035,
            "fmeasure": 0.60683
        },
        "nist": 6.096694773045439,
        "bleu": 42.40846,
        "bertscore": {
            "precision": 0.92114,
            "recall": 0.90258,
            "f1": 0.90961
        },
        "bleurt": 0.15138,
        "meteor": 0.3568044415883278,
        "nubia": {
            "semantic_relation": 3.99687,
            "contradiction": 11.75592,
            "irrelevancy": 28.44107,
            "logical_agreement": 59.803,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.49775,
            "nubia_score": 0.65438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 0.98333,
            "recall": 0.89286,
            "fmeasure": 0.93123
        },
        "rouge2": {
            "precision": 0.91296,
            "recall": 0.82532,
            "fmeasure": 0.86189
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 0.89286,
            "fmeasure": 0.93123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 0.89286,
            "fmeasure": 0.93123
        },
        "nist": 4.882313268289273,
        "bleu": 82.49637,
        "bertscore": {
            "precision": 0.99528,
            "recall": 0.97061,
            "f1": 0.98263
        },
        "bleurt": 0.83783,
        "meteor": 0.5870050228076797,
        "nubia": {
            "semantic_relation": 4.89466,
            "contradiction": 0.73596,
            "irrelevancy": 0.61695,
            "logical_agreement": 98.64709,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.95387,
            "nubia_score": 0.91806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.72744,
            "fmeasure": 0.65352
        },
        "rouge2": {
            "precision": 0.43056,
            "recall": 0.53086,
            "fmeasure": 0.47246
        },
        "rougeL": {
            "precision": 0.49333,
            "recall": 0.58709,
            "fmeasure": 0.5323
        },
        "rougeLsum": {
            "precision": 0.49333,
            "recall": 0.58709,
            "fmeasure": 0.5323
        },
        "nist": 3.461158600353164,
        "bleu": 33.38497,
        "bertscore": {
            "precision": 0.9028,
            "recall": 0.94637,
            "f1": 0.92407
        },
        "bleurt": -0.39853,
        "meteor": 0.43472086304450797,
        "nubia": {
            "semantic_relation": 3.64579,
            "contradiction": 99.09499,
            "irrelevancy": 0.74113,
            "logical_agreement": 0.16388,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.18948,
            "nubia_score": 0.46315
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "mT5_small/totto_test",
        "N": 45,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4609375,
            "3": 0.7489878542510121
        },
        "rouge1": {
            "precision": 0.80734,
            "recall": 0.72025,
            "fmeasure": 0.74934
        },
        "rouge2": {
            "precision": 0.57208,
            "recall": 0.50608,
            "fmeasure": 0.52749
        },
        "rougeL": {
            "precision": 0.68041,
            "recall": 0.60165,
            "fmeasure": 0.62636
        },
        "rougeLsum": {
            "precision": 0.68041,
            "recall": 0.60165,
            "fmeasure": 0.62636
        },
        "nist": 6.666394751122831,
        "bleu": 42.64851,
        "bertscore": {
            "precision": 0.94299,
            "recall": 0.92507,
            "f1": 0.93319
        },
        "bleurt": 0.34275,
        "meteor": 0.38663590054431124,
        "nubia": {
            "semantic_relation": 4.31937,
            "contradiction": 9.386,
            "irrelevancy": 20.38781,
            "logical_agreement": 70.22619,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.86994,
            "nubia_score": 0.76198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24074074074074073,
            "2": 0.3,
            "3": 0.8675675675675676
        },
        "rouge1": {
            "precision": 0.80357,
            "recall": 0.81479,
            "fmeasure": 0.80086
        },
        "rouge2": {
            "precision": 0.60994,
            "recall": 0.62432,
            "fmeasure": 0.60934
        },
        "rougeL": {
            "precision": 0.69851,
            "recall": 0.71706,
            "fmeasure": 0.69931
        },
        "rougeLsum": {
            "precision": 0.69851,
            "recall": 0.71706,
            "fmeasure": 0.69931
        },
        "nist": 7.434366306176529,
        "bleu": 57.89496,
        "bertscore": {
            "precision": 0.94506,
            "recall": 0.94571,
            "f1": 0.94333
        },
        "bleurt": 0.42605,
        "meteor": 0.44869278554968606,
        "nubia": {
            "semantic_relation": 4.34618,
            "contradiction": 9.05178,
            "irrelevancy": 21.11851,
            "logical_agreement": 69.82971,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.55805,
            "nubia_score": 0.78216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "mT5_small/totto_test",
        "N": 16,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.3,
            "3": 0.8288770053475936
        },
        "rouge1": {
            "precision": 0.78049,
            "recall": 0.78774,
            "fmeasure": 0.77216
        },
        "rouge2": {
            "precision": 0.58474,
            "recall": 0.59921,
            "fmeasure": 0.58074
        },
        "rougeL": {
            "precision": 0.69816,
            "recall": 0.69838,
            "fmeasure": 0.68733
        },
        "rougeLsum": {
            "precision": 0.69816,
            "recall": 0.69838,
            "fmeasure": 0.68733
        },
        "nist": 6.362979674239447,
        "bleu": 51.40718,
        "bertscore": {
            "precision": 0.93748,
            "recall": 0.93453,
            "f1": 0.93421
        },
        "bleurt": 0.2924,
        "meteor": 0.41312523347594166,
        "nubia": {
            "semantic_relation": 4.16871,
            "contradiction": 7.86597,
            "irrelevancy": 33.26405,
            "logical_agreement": 58.86998,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.65654,
            "nubia_score": 0.73805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.91931,
            "fmeasure": 0.81103
        },
        "rouge2": {
            "precision": 0.54261,
            "recall": 0.64828,
            "fmeasure": 0.57862
        },
        "rougeL": {
            "precision": 0.6201,
            "recall": 0.76128,
            "fmeasure": 0.671
        },
        "rougeLsum": {
            "precision": 0.6201,
            "recall": 0.76128,
            "fmeasure": 0.671
        },
        "nist": 3.4376911647839683,
        "bleu": 48.3674,
        "bertscore": {
            "precision": 0.93112,
            "recall": 0.95906,
            "f1": 0.94465
        },
        "bleurt": 0.46655,
        "meteor": 0.48573594253453317,
        "nubia": {
            "semantic_relation": 4.49771,
            "contradiction": 0.17177,
            "irrelevancy": 18.78289,
            "logical_agreement": 81.04534,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.69434,
            "nubia_score": 0.88314
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.37037037037037035,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.75467,
            "recall": 0.71099,
            "fmeasure": 0.71627
        },
        "rouge2": {
            "precision": 0.60388,
            "recall": 0.58169,
            "fmeasure": 0.57983
        },
        "rougeL": {
            "precision": 0.6559,
            "recall": 0.62383,
            "fmeasure": 0.62687
        },
        "rougeLsum": {
            "precision": 0.6559,
            "recall": 0.62383,
            "fmeasure": 0.62687
        },
        "nist": 3.4672885716262116,
        "bleu": 29.12932,
        "bertscore": {
            "precision": 0.93409,
            "recall": 0.92,
            "f1": 0.92002
        },
        "bleurt": 0.29814,
        "meteor": 0.3457701494964546,
        "nubia": {
            "semantic_relation": 4.34306,
            "contradiction": 13.82648,
            "irrelevancy": 9.61364,
            "logical_agreement": 76.55988,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.61222,
            "nubia_score": 0.82774
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "mT5_small/totto_test",
        "N": 13,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.17647058823529413,
            "3": 0.803921568627451
        },
        "rouge1": {
            "precision": 0.77827,
            "recall": 0.74374,
            "fmeasure": 0.75707
        },
        "rouge2": {
            "precision": 0.59438,
            "recall": 0.57247,
            "fmeasure": 0.58054
        },
        "rougeL": {
            "precision": 0.6717,
            "recall": 0.64027,
            "fmeasure": 0.65294
        },
        "rougeLsum": {
            "precision": 0.6717,
            "recall": 0.64027,
            "fmeasure": 0.65294
        },
        "nist": 5.751376468764054,
        "bleu": 49.60281,
        "bertscore": {
            "precision": 0.94875,
            "recall": 0.94104,
            "f1": 0.94473
        },
        "bleurt": 0.53552,
        "meteor": 0.41941633219154195,
        "nubia": {
            "semantic_relation": 4.37178,
            "contradiction": 8.51166,
            "irrelevancy": 13.40168,
            "logical_agreement": 78.08666,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.77392,
            "nubia_score": 0.79425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.5,
            "3": 0.6638655462184874
        },
        "rouge1": {
            "precision": 0.68679,
            "recall": 0.62056,
            "fmeasure": 0.62542
        },
        "rouge2": {
            "precision": 0.40997,
            "recall": 0.34565,
            "fmeasure": 0.36016
        },
        "rougeL": {
            "precision": 0.55841,
            "recall": 0.47761,
            "fmeasure": 0.49244
        },
        "rougeLsum": {
            "precision": 0.55841,
            "recall": 0.47761,
            "fmeasure": 0.49244
        },
        "nist": 4.398540654015251,
        "bleu": 27.23004,
        "bertscore": {
            "precision": 0.89309,
            "recall": 0.87473,
            "f1": 0.88279
        },
        "bleurt": -0.11537,
        "meteor": 0.30779276258938193,
        "nubia": {
            "semantic_relation": 3.43503,
            "contradiction": 16.14679,
            "irrelevancy": 36.03719,
            "logical_agreement": 47.81602,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.07046,
            "nubia_score": 0.50299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.74928,
            "recall": 0.75675,
            "fmeasure": 0.75095
        },
        "rouge2": {
            "precision": 0.52347,
            "recall": 0.5184,
            "fmeasure": 0.51757
        },
        "rougeL": {
            "precision": 0.69489,
            "recall": 0.70336,
            "fmeasure": 0.69664
        },
        "rougeLsum": {
            "precision": 0.69489,
            "recall": 0.70336,
            "fmeasure": 0.69664
        },
        "nist": 5.099119116451847,
        "bleu": 51.5343,
        "bertscore": {
            "precision": 0.93497,
            "recall": 0.93465,
            "f1": 0.93081
        },
        "bleurt": 0.07038,
        "meteor": 0.4008469022945549,
        "nubia": {
            "semantic_relation": 4.15884,
            "contradiction": 2.49078,
            "irrelevancy": 47.67392,
            "logical_agreement": 49.8353,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.23906,
            "nubia_score": 0.73785
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "rouge1": {
            "precision": 0.41975,
            "recall": 0.49735,
            "fmeasure": 0.4537
        },
        "rouge2": {
            "precision": 0.19231,
            "recall": 0.23077,
            "fmeasure": 0.20903
        },
        "rougeL": {
            "precision": 0.28395,
            "recall": 0.34039,
            "fmeasure": 0.30864
        },
        "rougeLsum": {
            "precision": 0.28395,
            "recall": 0.34039,
            "fmeasure": 0.30864
        },
        "nist": 2.3089874300394175,
        "bleu": 20.13009,
        "bertscore": {
            "precision": 0.79869,
            "recall": 0.8445,
            "f1": 0.82096
        },
        "bleurt": -0.5623,
        "meteor": 0.21552123579315335,
        "nubia": {
            "semantic_relation": 2.89253,
            "contradiction": 0.12024,
            "irrelevancy": 99.7623,
            "logical_agreement": 0.11745,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.59134,
            "nubia_score": 0.42155
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "mT5_small/totto_test",
        "N": 150,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19955654101995565,
            "2": 0.42702702702702705,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.81826,
            "recall": 0.76543,
            "fmeasure": 0.78143
        },
        "rouge2": {
            "precision": 0.58982,
            "recall": 0.55727,
            "fmeasure": 0.5654
        },
        "rougeL": {
            "precision": 0.69861,
            "recall": 0.65653,
            "fmeasure": 0.66818
        },
        "rougeLsum": {
            "precision": 0.69861,
            "recall": 0.65653,
            "fmeasure": 0.66818
        },
        "nist": 8.102859113562657,
        "bleu": 46.90636,
        "bertscore": {
            "precision": 0.94642,
            "recall": 0.93765,
            "f1": 0.94095
        },
        "bleurt": 0.35851,
        "meteor": 0.4048118393723312,
        "nubia": {
            "semantic_relation": 4.44371,
            "contradiction": 8.06311,
            "irrelevancy": 22.05411,
            "logical_agreement": 69.88279,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.25666,
            "nubia_score": 0.76751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7894736842105263
        },
        "rouge1": {
            "precision": 0.76078,
            "recall": 0.86111,
            "fmeasure": 0.80697
        },
        "rouge2": {
            "precision": 0.39815,
            "recall": 0.46389,
            "fmeasure": 0.42801
        },
        "rougeL": {
            "precision": 0.48431,
            "recall": 0.54907,
            "fmeasure": 0.51409
        },
        "rougeLsum": {
            "precision": 0.48431,
            "recall": 0.54907,
            "fmeasure": 0.51409
        },
        "nist": 4.502117377493192,
        "bleu": 34.57208,
        "bertscore": {
            "precision": 0.92666,
            "recall": 0.9278,
            "f1": 0.92637
        },
        "bleurt": 0.03976,
        "meteor": 0.4249730089166597,
        "nubia": {
            "semantic_relation": 4.0066,
            "contradiction": 10.52418,
            "irrelevancy": 42.92188,
            "logical_agreement": 46.55394,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.39795,
            "nubia_score": 0.68499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.46511627906976744,
            "3": 0.7299270072992701
        },
        "rouge1": {
            "precision": 0.69298,
            "recall": 0.69333,
            "fmeasure": 0.67613
        },
        "rouge2": {
            "precision": 0.42816,
            "recall": 0.42541,
            "fmeasure": 0.41441
        },
        "rougeL": {
            "precision": 0.59286,
            "recall": 0.59003,
            "fmeasure": 0.5775
        },
        "rougeLsum": {
            "precision": 0.59286,
            "recall": 0.59003,
            "fmeasure": 0.5775
        },
        "nist": 5.200328527946139,
        "bleu": 35.11511,
        "bertscore": {
            "precision": 0.91183,
            "recall": 0.91264,
            "f1": 0.91034
        },
        "bleurt": 0.21157,
        "meteor": 0.3651144375503938,
        "nubia": {
            "semantic_relation": 3.93138,
            "contradiction": 25.445,
            "irrelevancy": 36.78396,
            "logical_agreement": 37.77104,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.36682,
            "nubia_score": 0.62942
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5416666666666666,
            "3": 0.6619718309859155
        },
        "rouge1": {
            "precision": 0.71294,
            "recall": 0.63286,
            "fmeasure": 0.65989
        },
        "rouge2": {
            "precision": 0.4465,
            "recall": 0.40556,
            "fmeasure": 0.4178
        },
        "rougeL": {
            "precision": 0.59689,
            "recall": 0.54473,
            "fmeasure": 0.56218
        },
        "rougeLsum": {
            "precision": 0.59689,
            "recall": 0.54473,
            "fmeasure": 0.56218
        },
        "nist": 4.6156642270873345,
        "bleu": 33.99896,
        "bertscore": {
            "precision": 0.90674,
            "recall": 0.90919,
            "f1": 0.90679
        },
        "bleurt": 0.24687,
        "meteor": 0.3175434080233756,
        "nubia": {
            "semantic_relation": 3.89605,
            "contradiction": 18.75832,
            "irrelevancy": 39.60619,
            "logical_agreement": 41.63548,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.36703,
            "nubia_score": 0.67675
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "mT5_small/totto_test",
        "N": 83,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23387096774193547,
            "2": 0.491869918699187,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.75399,
            "recall": 0.71095,
            "fmeasure": 0.7184
        },
        "rouge2": {
            "precision": 0.51674,
            "recall": 0.48675,
            "fmeasure": 0.49223
        },
        "rougeL": {
            "precision": 0.66081,
            "recall": 0.61924,
            "fmeasure": 0.62782
        },
        "rougeLsum": {
            "precision": 0.66081,
            "recall": 0.61924,
            "fmeasure": 0.62782
        },
        "nist": 7.36948127122397,
        "bleu": 45.18241,
        "bertscore": {
            "precision": 0.92988,
            "recall": 0.92013,
            "f1": 0.92359
        },
        "bleurt": 0.24722,
        "meteor": 0.3851308492170256,
        "nubia": {
            "semantic_relation": 4.21604,
            "contradiction": 9.88176,
            "irrelevancy": 25.65724,
            "logical_agreement": 64.461,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.67533,
            "nubia_score": 0.71981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "mT5_small/totto_test",
        "N": 80,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2768361581920904,
            "2": 0.4327485380116959,
            "3": 0.6998706338939198
        },
        "rouge1": {
            "precision": 0.68626,
            "recall": 0.64051,
            "fmeasure": 0.64345
        },
        "rouge2": {
            "precision": 0.41716,
            "recall": 0.38882,
            "fmeasure": 0.38944
        },
        "rougeL": {
            "precision": 0.5756,
            "recall": 0.54878,
            "fmeasure": 0.54423
        },
        "rougeLsum": {
            "precision": 0.5756,
            "recall": 0.54878,
            "fmeasure": 0.54423
        },
        "nist": 6.444429725586349,
        "bleu": 34.16134,
        "bertscore": {
            "precision": 0.90186,
            "recall": 0.89093,
            "f1": 0.89391
        },
        "bleurt": 0.06935,
        "meteor": 0.32931675599498816,
        "nubia": {
            "semantic_relation": 3.80675,
            "contradiction": 14.6461,
            "irrelevancy": 37.69813,
            "logical_agreement": 47.65577,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.56808,
            "nubia_score": 0.59989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "mT5_small/totto_test",
        "N": 13,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2112676056338028,
            "2": 0.49056603773584906,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.64713,
            "recall": 0.66631,
            "fmeasure": 0.64594
        },
        "rouge2": {
            "precision": 0.37765,
            "recall": 0.37859,
            "fmeasure": 0.37152
        },
        "rougeL": {
            "precision": 0.54267,
            "recall": 0.54377,
            "fmeasure": 0.53332
        },
        "rougeLsum": {
            "precision": 0.54267,
            "recall": 0.54377,
            "fmeasure": 0.53332
        },
        "nist": 4.866737276816241,
        "bleu": 33.61773,
        "bertscore": {
            "precision": 0.89806,
            "recall": 0.89918,
            "f1": 0.89752
        },
        "bleurt": 0.04694,
        "meteor": 0.35065250516408475,
        "nubia": {
            "semantic_relation": 3.70255,
            "contradiction": 42.0462,
            "irrelevancy": 29.99646,
            "logical_agreement": 27.95734,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.19013,
            "nubia_score": 0.58357
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "mT5_small/totto_test",
        "N": 150,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16810344827586207,
            "2": 0.41081081081081083,
            "3": 0.779385171790235
        },
        "rouge1": {
            "precision": 0.78702,
            "recall": 0.73147,
            "fmeasure": 0.7477
        },
        "rouge2": {
            "precision": 0.54527,
            "recall": 0.50716,
            "fmeasure": 0.51803
        },
        "rougeL": {
            "precision": 0.6666,
            "recall": 0.62165,
            "fmeasure": 0.63377
        },
        "rougeLsum": {
            "precision": 0.6666,
            "recall": 0.62165,
            "fmeasure": 0.63377
        },
        "nist": 7.821517624411727,
        "bleu": 44.72757,
        "bertscore": {
            "precision": 0.93694,
            "recall": 0.93009,
            "f1": 0.93195
        },
        "bleurt": 0.33724,
        "meteor": 0.3948138266539064,
        "nubia": {
            "semantic_relation": 4.34516,
            "contradiction": 5.39852,
            "irrelevancy": 22.76584,
            "logical_agreement": 71.83564,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.81896,
            "nubia_score": 0.76952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.13333333333333333,
            "3": 0.8214285714285714
        },
        "rouge1": {
            "precision": 0.88405,
            "recall": 0.72779,
            "fmeasure": 0.78992
        },
        "rouge2": {
            "precision": 0.6628,
            "recall": 0.54891,
            "fmeasure": 0.59359
        },
        "rougeL": {
            "precision": 0.7984,
            "recall": 0.65952,
            "fmeasure": 0.71483
        },
        "rougeLsum": {
            "precision": 0.7984,
            "recall": 0.65952,
            "fmeasure": 0.71483
        },
        "nist": 4.543943047347056,
        "bleu": 47.34308,
        "bertscore": {
            "precision": 0.9574,
            "recall": 0.92338,
            "f1": 0.93986
        },
        "bleurt": 0.30276,
        "meteor": 0.4169823800276999,
        "nubia": {
            "semantic_relation": 4.36987,
            "contradiction": 14.61549,
            "irrelevancy": 18.21977,
            "logical_agreement": 67.16475,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.96208,
            "nubia_score": 0.73352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4375,
            "3": 0.8780487804878049
        },
        "rouge1": {
            "precision": 0.84696,
            "recall": 0.86028,
            "fmeasure": 0.84765
        },
        "rouge2": {
            "precision": 0.72288,
            "recall": 0.73721,
            "fmeasure": 0.72497
        },
        "rougeL": {
            "precision": 0.79537,
            "recall": 0.8037,
            "fmeasure": 0.79396
        },
        "rougeLsum": {
            "precision": 0.79537,
            "recall": 0.8037,
            "fmeasure": 0.79396
        },
        "nist": 6.398296280709011,
        "bleu": 66.341,
        "bertscore": {
            "precision": 0.9639,
            "recall": 0.95675,
            "f1": 0.95986
        },
        "bleurt": 0.54768,
        "meteor": 0.49343427198167145,
        "nubia": {
            "semantic_relation": 4.698,
            "contradiction": 0.41104,
            "irrelevancy": 12.47653,
            "logical_agreement": 87.11243,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.24128,
            "nubia_score": 0.90954
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_small/totto_test",
        "N": 379,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2269345238095238,
            "2": 0.394109396914446,
            "3": 0.7170767004341534
        },
        "rouge1": {
            "precision": 0.72271,
            "recall": 0.67568,
            "fmeasure": 0.68815
        },
        "rouge2": {
            "precision": 0.45161,
            "recall": 0.42073,
            "fmeasure": 0.42894
        },
        "rougeL": {
            "precision": 0.57379,
            "recall": 0.53735,
            "fmeasure": 0.54629
        },
        "rougeLsum": {
            "precision": 0.57379,
            "recall": 0.53735,
            "fmeasure": 0.54629
        },
        "nist": 8.022812720228082,
        "bleu": 35.82977,
        "bertscore": {
            "precision": 0.91486,
            "recall": 0.90157,
            "f1": 0.90651
        },
        "bleurt": 0.11906,
        "meteor": 0.3479644809570032,
        "nubia": {
            "semantic_relation": 3.905,
            "contradiction": 17.02017,
            "irrelevancy": 28.05408,
            "logical_agreement": 54.92575,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.24328,
            "nubia_score": 0.64606
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.1111111111111111,
            "3": 0.8472222222222222
        },
        "rouge1": {
            "precision": 0.84373,
            "recall": 0.77252,
            "fmeasure": 0.80227
        },
        "rouge2": {
            "precision": 0.67524,
            "recall": 0.62135,
            "fmeasure": 0.64338
        },
        "rougeL": {
            "precision": 0.74066,
            "recall": 0.68914,
            "fmeasure": 0.70983
        },
        "rougeLsum": {
            "precision": 0.74066,
            "recall": 0.68914,
            "fmeasure": 0.70983
        },
        "nist": 6.145137789207324,
        "bleu": 65.74642,
        "bertscore": {
            "precision": 0.9552,
            "recall": 0.93728,
            "f1": 0.94558
        },
        "bleurt": 0.2257,
        "meteor": 0.4511812040388177,
        "nubia": {
            "semantic_relation": 4.23412,
            "contradiction": 19.71318,
            "irrelevancy": 18.04797,
            "logical_agreement": 62.23885,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.8636,
            "nubia_score": 0.70126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5227272727272727,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.82621,
            "recall": 0.82699,
            "fmeasure": 0.82119
        },
        "rouge2": {
            "precision": 0.66041,
            "recall": 0.6589,
            "fmeasure": 0.65626
        },
        "rougeL": {
            "precision": 0.7199,
            "recall": 0.72386,
            "fmeasure": 0.71723
        },
        "rougeLsum": {
            "precision": 0.7199,
            "recall": 0.72386,
            "fmeasure": 0.71723
        },
        "nist": 6.335885720888005,
        "bleu": 60.34919,
        "bertscore": {
            "precision": 0.95427,
            "recall": 0.95109,
            "f1": 0.95048
        },
        "bleurt": 0.44587,
        "meteor": 0.4628329617340919,
        "nubia": {
            "semantic_relation": 4.31912,
            "contradiction": 7.6746,
            "irrelevancy": 27.81935,
            "logical_agreement": 64.50605,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.65201,
            "nubia_score": 0.77759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "mT5_small/totto_test",
        "N": 20,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5,
            "3": 0.7669902912621359
        },
        "rouge1": {
            "precision": 0.79618,
            "recall": 0.70078,
            "fmeasure": 0.73224
        },
        "rouge2": {
            "precision": 0.58732,
            "recall": 0.51062,
            "fmeasure": 0.53476
        },
        "rougeL": {
            "precision": 0.70478,
            "recall": 0.62399,
            "fmeasure": 0.64746
        },
        "rougeLsum": {
            "precision": 0.70478,
            "recall": 0.62399,
            "fmeasure": 0.64746
        },
        "nist": 6.140992918651151,
        "bleu": 48.92669,
        "bertscore": {
            "precision": 0.93359,
            "recall": 0.91819,
            "f1": 0.92366
        },
        "bleurt": 0.31739,
        "meteor": 0.3978910384010437,
        "nubia": {
            "semantic_relation": 4.27171,
            "contradiction": 8.99046,
            "irrelevancy": 26.69032,
            "logical_agreement": 64.31921,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.8702,
            "nubia_score": 0.72168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5517241379310345
        },
        "rouge1": {
            "precision": 0.48056,
            "recall": 0.55388,
            "fmeasure": 0.50681
        },
        "rouge2": {
            "precision": 0.25542,
            "recall": 0.28874,
            "fmeasure": 0.26662
        },
        "rougeL": {
            "precision": 0.37222,
            "recall": 0.43779,
            "fmeasure": 0.39614
        },
        "rougeLsum": {
            "precision": 0.37222,
            "recall": 0.43779,
            "fmeasure": 0.39614
        },
        "nist": 2.3626824077818323,
        "bleu": 13.65537,
        "bertscore": {
            "precision": 0.85992,
            "recall": 0.89222,
            "f1": 0.87573
        },
        "bleurt": -0.03177,
        "meteor": 0.289815476896726,
        "nubia": {
            "semantic_relation": 3.5553,
            "contradiction": 52.47016,
            "irrelevancy": 27.01275,
            "logical_agreement": 20.51709,
            "grammar_ref": 4.49155,
            "grammar_hyp": 3.20591,
            "nubia_score": 0.7296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "mT5_small/totto_test",
        "N": 31,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5443037974683544,
            "3": 0.76875
        },
        "rouge1": {
            "precision": 0.77061,
            "recall": 0.7484,
            "fmeasure": 0.74799
        },
        "rouge2": {
            "precision": 0.55264,
            "recall": 0.54704,
            "fmeasure": 0.54228
        },
        "rougeL": {
            "precision": 0.6487,
            "recall": 0.63646,
            "fmeasure": 0.63229
        },
        "rougeLsum": {
            "precision": 0.6487,
            "recall": 0.63646,
            "fmeasure": 0.63229
        },
        "nist": 6.3650958502190305,
        "bleu": 46.60406,
        "bertscore": {
            "precision": 0.92842,
            "recall": 0.92893,
            "f1": 0.92752
        },
        "bleurt": 0.35285,
        "meteor": 0.4068575137805736,
        "nubia": {
            "semantic_relation": 4.25976,
            "contradiction": 7.25532,
            "irrelevancy": 31.72209,
            "logical_agreement": 61.02259,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.68788,
            "nubia_score": 0.73872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47058823529411764,
            "3": 0.6811594202898551
        },
        "rouge1": {
            "precision": 0.66386,
            "recall": 0.68206,
            "fmeasure": 0.66537
        },
        "rouge2": {
            "precision": 0.4346,
            "recall": 0.45515,
            "fmeasure": 0.44022
        },
        "rougeL": {
            "precision": 0.58741,
            "recall": 0.61771,
            "fmeasure": 0.59241
        },
        "rougeLsum": {
            "precision": 0.58741,
            "recall": 0.61771,
            "fmeasure": 0.59241
        },
        "nist": 3.8301629559017027,
        "bleu": 21.33728,
        "bertscore": {
            "precision": 0.89973,
            "recall": 0.90513,
            "f1": 0.90048
        },
        "bleurt": 0.12061,
        "meteor": 0.3597880517763435,
        "nubia": {
            "semantic_relation": 3.93708,
            "contradiction": 1.08565,
            "irrelevancy": 53.72591,
            "logical_agreement": 45.18844,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.16529,
            "nubia_score": 0.65581
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "mT5_small/totto_test",
        "N": 19,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23376623376623376,
            "2": 0.27450980392156865,
            "3": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.73934,
            "recall": 0.6161,
            "fmeasure": 0.65853
        },
        "rouge2": {
            "precision": 0.51079,
            "recall": 0.43272,
            "fmeasure": 0.45683
        },
        "rougeL": {
            "precision": 0.6433,
            "recall": 0.5386,
            "fmeasure": 0.57403
        },
        "rougeLsum": {
            "precision": 0.6433,
            "recall": 0.5386,
            "fmeasure": 0.57403
        },
        "nist": 4.968205097755166,
        "bleu": 39.92683,
        "bertscore": {
            "precision": 0.92175,
            "recall": 0.8927,
            "f1": 0.90454
        },
        "bleurt": 0.12734,
        "meteor": 0.3464006763326251,
        "nubia": {
            "semantic_relation": 3.67999,
            "contradiction": 19.81087,
            "irrelevancy": 27.1041,
            "logical_agreement": 53.08504,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.58105,
            "nubia_score": 0.55881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.90278,
            "fmeasure": 0.69032
        },
        "rouge2": {
            "precision": 0.44048,
            "recall": 0.68788,
            "fmeasure": 0.51626
        },
        "rougeL": {
            "precision": 0.51282,
            "recall": 0.81439,
            "fmeasure": 0.6081
        },
        "rougeLsum": {
            "precision": 0.51282,
            "recall": 0.81439,
            "fmeasure": 0.6081
        },
        "nist": 2.6084899508269985,
        "bleu": 35.99756,
        "bertscore": {
            "precision": 0.87396,
            "recall": 0.93979,
            "f1": 0.905
        },
        "bleurt": 0.1546,
        "meteor": 0.45922929164461707,
        "nubia": {
            "semantic_relation": 3.95406,
            "contradiction": 0.3996,
            "irrelevancy": 69.02861,
            "logical_agreement": 30.5718,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.49804,
            "nubia_score": 0.72807
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.625,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.62325,
            "recall": 0.67937,
            "fmeasure": 0.63444
        },
        "rouge2": {
            "precision": 0.40972,
            "recall": 0.44352,
            "fmeasure": 0.41874
        },
        "rougeL": {
            "precision": 0.56443,
            "recall": 0.58846,
            "fmeasure": 0.56301
        },
        "rougeLsum": {
            "precision": 0.56443,
            "recall": 0.58846,
            "fmeasure": 0.56301
        },
        "nist": 3.9807409803577727,
        "bleu": 44.4391,
        "bertscore": {
            "precision": 0.89199,
            "recall": 0.90035,
            "f1": 0.89509
        },
        "bleurt": 0.06712,
        "meteor": 0.4056669932730872,
        "nubia": {
            "semantic_relation": 3.17885,
            "contradiction": 18.35082,
            "irrelevancy": 48.59097,
            "logical_agreement": 33.05821,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.45434,
            "nubia_score": 0.49556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4375,
            "2": 0.6153846153846154,
            "3": 0.8035714285714286
        },
        "rouge1": {
            "precision": 0.82364,
            "recall": 0.7929,
            "fmeasure": 0.80271
        },
        "rouge2": {
            "precision": 0.61799,
            "recall": 0.57982,
            "fmeasure": 0.59439
        },
        "rougeL": {
            "precision": 0.76582,
            "recall": 0.73217,
            "fmeasure": 0.74406
        },
        "rougeLsum": {
            "precision": 0.76582,
            "recall": 0.73217,
            "fmeasure": 0.74406
        },
        "nist": 5.046725253749803,
        "bleu": 52.23847,
        "bertscore": {
            "precision": 0.95469,
            "recall": 0.95366,
            "f1": 0.95356
        },
        "bleurt": 0.4963,
        "meteor": 0.41509874788240736,
        "nubia": {
            "semantic_relation": 4.40058,
            "contradiction": 23.62274,
            "irrelevancy": 17.15962,
            "logical_agreement": 59.21764,
            "grammar_ref": 5.14386,
            "grammar_hyp": 4.98589,
            "nubia_score": 0.78561
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_small/totto_test",
        "N": 124,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2236024844720497,
            "2": 0.4018058690744921,
            "3": 0.6918016194331984
        },
        "rouge1": {
            "precision": 0.69779,
            "recall": 0.65114,
            "fmeasure": 0.66319
        },
        "rouge2": {
            "precision": 0.41947,
            "recall": 0.40154,
            "fmeasure": 0.40172
        },
        "rougeL": {
            "precision": 0.55676,
            "recall": 0.52599,
            "fmeasure": 0.53135
        },
        "rougeLsum": {
            "precision": 0.55676,
            "recall": 0.52599,
            "fmeasure": 0.53135
        },
        "nist": 7.172896549911393,
        "bleu": 34.63668,
        "bertscore": {
            "precision": 0.90757,
            "recall": 0.89576,
            "f1": 0.89937
        },
        "bleurt": 0.04692,
        "meteor": 0.33168029397830967,
        "nubia": {
            "semantic_relation": 3.76797,
            "contradiction": 19.56744,
            "irrelevancy": 30.95255,
            "logical_agreement": 49.48001,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.206,
            "nubia_score": 0.60611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.79259,
            "fmeasure": 0.77895
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "nist": 3.9319229794768673,
        "bleu": 70.71068,
        "bertscore": {
            "precision": 0.98752,
            "recall": 0.98752,
            "f1": 0.98752
        },
        "bleurt": 0.60413,
        "meteor": 0.5023397349274512,
        "nubia": {
            "semantic_relation": 3.6291,
            "contradiction": 98.43253,
            "irrelevancy": 0.66284,
            "logical_agreement": 0.90463,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.04098,
            "nubia_score": 0.63864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7551020408163265
        },
        "rouge1": {
            "precision": 0.78525,
            "recall": 0.72508,
            "fmeasure": 0.74741
        },
        "rouge2": {
            "precision": 0.52608,
            "recall": 0.49246,
            "fmeasure": 0.50244
        },
        "rougeL": {
            "precision": 0.67857,
            "recall": 0.6473,
            "fmeasure": 0.65543
        },
        "rougeLsum": {
            "precision": 0.67857,
            "recall": 0.6473,
            "fmeasure": 0.65543
        },
        "nist": 4.99976241756955,
        "bleu": 37.89519,
        "bertscore": {
            "precision": 0.92592,
            "recall": 0.92606,
            "f1": 0.92511
        },
        "bleurt": 0.2099,
        "meteor": 0.38291361050386125,
        "nubia": {
            "semantic_relation": 4.1518,
            "contradiction": 31.06373,
            "irrelevancy": 8.83514,
            "logical_agreement": 60.10113,
            "grammar_ref": 5.41078,
            "grammar_hyp": 6.10484,
            "nubia_score": 0.60992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "mT5_small/totto_test",
        "N": 73,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2558139534883721,
            "2": 0.40963855421686746,
            "3": 0.7575757575757576
        },
        "rouge1": {
            "precision": 0.80626,
            "recall": 0.7352,
            "fmeasure": 0.75698
        },
        "rouge2": {
            "precision": 0.58792,
            "recall": 0.53468,
            "fmeasure": 0.54938
        },
        "rougeL": {
            "precision": 0.71487,
            "recall": 0.65737,
            "fmeasure": 0.67278
        },
        "rougeLsum": {
            "precision": 0.71487,
            "recall": 0.65737,
            "fmeasure": 0.67278
        },
        "nist": 7.286699297116262,
        "bleu": 48.54714,
        "bertscore": {
            "precision": 0.9382,
            "recall": 0.92141,
            "f1": 0.92818
        },
        "bleurt": 0.24356,
        "meteor": 0.39080817653010674,
        "nubia": {
            "semantic_relation": 4.1997,
            "contradiction": 7.52306,
            "irrelevancy": 28.98608,
            "logical_agreement": 63.49086,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.73241,
            "nubia_score": 0.71805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.375,
            "3": 0.6551724137931034
        },
        "rouge1": {
            "precision": 0.88715,
            "recall": 0.69996,
            "fmeasure": 0.7597
        },
        "rouge2": {
            "precision": 0.63952,
            "recall": 0.53373,
            "fmeasure": 0.56417
        },
        "rougeL": {
            "precision": 0.83047,
            "recall": 0.66189,
            "fmeasure": 0.71412
        },
        "rougeLsum": {
            "precision": 0.83047,
            "recall": 0.66189,
            "fmeasure": 0.71412
        },
        "nist": 2.5713461528714867,
        "bleu": 33.23234,
        "bertscore": {
            "precision": 0.96068,
            "recall": 0.9229,
            "f1": 0.93504
        },
        "bleurt": 0.41065,
        "meteor": 0.3474810519310695,
        "nubia": {
            "semantic_relation": 4.3971,
            "contradiction": 6.33836,
            "irrelevancy": 20.49731,
            "logical_agreement": 73.16433,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.74804,
            "nubia_score": 0.77739
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.4375,
            "3": 0.8227848101265823
        },
        "rouge1": {
            "precision": 0.82459,
            "recall": 0.82481,
            "fmeasure": 0.82113
        },
        "rouge2": {
            "precision": 0.67458,
            "recall": 0.66401,
            "fmeasure": 0.66712
        },
        "rougeL": {
            "precision": 0.74901,
            "recall": 0.74817,
            "fmeasure": 0.74524
        },
        "rougeLsum": {
            "precision": 0.74901,
            "recall": 0.74817,
            "fmeasure": 0.74524
        },
        "nist": 5.3800788604291485,
        "bleu": 57.73311,
        "bertscore": {
            "precision": 0.95683,
            "recall": 0.95145,
            "f1": 0.95363
        },
        "bleurt": 0.49027,
        "meteor": 0.4417895978947112,
        "nubia": {
            "semantic_relation": 4.38872,
            "contradiction": 5.75737,
            "irrelevancy": 27.31595,
            "logical_agreement": 66.92668,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.67005,
            "nubia_score": 0.79898
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2465753424657534,
            "2": 0.4,
            "3": 0.7739130434782608
        },
        "rouge1": {
            "precision": 0.6901,
            "recall": 0.61693,
            "fmeasure": 0.64087
        },
        "rouge2": {
            "precision": 0.48434,
            "recall": 0.4262,
            "fmeasure": 0.44413
        },
        "rougeL": {
            "precision": 0.59115,
            "recall": 0.54075,
            "fmeasure": 0.55561
        },
        "rougeLsum": {
            "precision": 0.59115,
            "recall": 0.54075,
            "fmeasure": 0.55561
        },
        "nist": 4.931384736776707,
        "bleu": 40.70253,
        "bertscore": {
            "precision": 0.90329,
            "recall": 0.89122,
            "f1": 0.89503
        },
        "bleurt": -0.02819,
        "meteor": 0.3390857430483002,
        "nubia": {
            "semantic_relation": 3.63939,
            "contradiction": 13.36164,
            "irrelevancy": 39.47008,
            "logical_agreement": 47.16828,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.12881,
            "nubia_score": 0.61082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77249
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "nist": 2.210473320391313,
        "bleu": 34.38931,
        "bertscore": {
            "precision": 0.95642,
            "recall": 0.96183,
            "f1": 0.95427
        },
        "bleurt": 0.72139,
        "meteor": 0.5228493300640051,
        "nubia": {
            "semantic_relation": 4.97174,
            "contradiction": 0.18493,
            "irrelevancy": 28.82608,
            "logical_agreement": 70.98899,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.7485,
            "nubia_score": 0.90007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.5588235294117647
        },
        "rouge1": {
            "precision": 0.70635,
            "recall": 0.46757,
            "fmeasure": 0.55891
        },
        "rouge2": {
            "precision": 0.39167,
            "recall": 0.28307,
            "fmeasure": 0.32861
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.39778,
            "fmeasure": 0.47837
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.39778,
            "fmeasure": 0.47837
        },
        "nist": 2.7457049629939125,
        "bleu": 41.44355,
        "bertscore": {
            "precision": 0.91939,
            "recall": 0.87971,
            "f1": 0.89833
        },
        "bleurt": 0.07099,
        "meteor": 0.32495464006591923,
        "nubia": {
            "semantic_relation": 2.80546,
            "contradiction": 2.60474,
            "irrelevancy": 34.96052,
            "logical_agreement": 62.43473,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.8349,
            "nubia_score": 0.35065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.36,
            "3": 0.7304964539007093
        },
        "rouge1": {
            "precision": 0.76287,
            "recall": 0.68239,
            "fmeasure": 0.71455
        },
        "rouge2": {
            "precision": 0.50145,
            "recall": 0.44972,
            "fmeasure": 0.47027
        },
        "rougeL": {
            "precision": 0.65285,
            "recall": 0.5822,
            "fmeasure": 0.61079
        },
        "rougeLsum": {
            "precision": 0.65285,
            "recall": 0.5822,
            "fmeasure": 0.61079
        },
        "nist": 5.237506947044267,
        "bleu": 38.25094,
        "bertscore": {
            "precision": 0.91756,
            "recall": 0.90774,
            "f1": 0.91104
        },
        "bleurt": 0.16376,
        "meteor": 0.3726413357862196,
        "nubia": {
            "semantic_relation": 4.17792,
            "contradiction": 1.61191,
            "irrelevancy": 31.55746,
            "logical_agreement": 66.83063,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.9776,
            "nubia_score": 0.69437
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.66667,
            "fmeasure": 0.63158
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 3.1221860348123966,
        "bleu": 58.59059,
        "bertscore": {
            "precision": 0.97571,
            "recall": 0.97571,
            "f1": 0.97571
        },
        "bleurt": 0.8196,
        "meteor": 0.47231119431689506,
        "nubia": {
            "semantic_relation": 4.91575,
            "contradiction": 0.24599,
            "irrelevancy": 0.48083,
            "logical_agreement": 99.27318,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.82283,
            "nubia_score": 0.94828
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "mT5_small/totto_test",
        "N": 29,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17105263157894737,
            "2": 0.5074626865671642,
            "3": 0.7846607669616519
        },
        "rouge1": {
            "precision": 0.82361,
            "recall": 0.7783,
            "fmeasure": 0.78841
        },
        "rouge2": {
            "precision": 0.6358,
            "recall": 0.61047,
            "fmeasure": 0.61621
        },
        "rougeL": {
            "precision": 0.75032,
            "recall": 0.70142,
            "fmeasure": 0.71398
        },
        "rougeLsum": {
            "precision": 0.75032,
            "recall": 0.70142,
            "fmeasure": 0.71398
        },
        "nist": 6.707759716278844,
        "bleu": 51.53995,
        "bertscore": {
            "precision": 0.94855,
            "recall": 0.93527,
            "f1": 0.94118
        },
        "bleurt": 0.39464,
        "meteor": 0.41779054114712844,
        "nubia": {
            "semantic_relation": 4.2935,
            "contradiction": 11.48407,
            "irrelevancy": 19.23648,
            "logical_agreement": 69.27945,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.77361,
            "nubia_score": 0.76741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75972,
            "recall": 0.80096,
            "fmeasure": 0.77149
        },
        "rouge2": {
            "precision": 0.60952,
            "recall": 0.58333,
            "fmeasure": 0.59317
        },
        "rougeL": {
            "precision": 0.69722,
            "recall": 0.72448,
            "fmeasure": 0.70409
        },
        "rougeLsum": {
            "precision": 0.69722,
            "recall": 0.72448,
            "fmeasure": 0.70409
        },
        "nist": 4.727736365372694,
        "bleu": 63.12109,
        "bertscore": {
            "precision": 0.94735,
            "recall": 0.95725,
            "f1": 0.94716
        },
        "bleurt": 0.34848,
        "meteor": 0.4536050910071727,
        "nubia": {
            "semantic_relation": 4.0164,
            "contradiction": 46.63282,
            "irrelevancy": 10.88886,
            "logical_agreement": 42.47833,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.20826,
            "nubia_score": 0.66285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.9361702127659575
        },
        "rouge1": {
            "precision": 0.85125,
            "recall": 0.85431,
            "fmeasure": 0.84755
        },
        "rouge2": {
            "precision": 0.68911,
            "recall": 0.69987,
            "fmeasure": 0.68827
        },
        "rougeL": {
            "precision": 0.71849,
            "recall": 0.73753,
            "fmeasure": 0.72057
        },
        "rougeLsum": {
            "precision": 0.71849,
            "recall": 0.73753,
            "fmeasure": 0.72057
        },
        "nist": 5.208423738023162,
        "bleu": 57.16245,
        "bertscore": {
            "precision": 0.96538,
            "recall": 0.95768,
            "f1": 0.9615
        },
        "bleurt": 0.53116,
        "meteor": 0.4642903851806498,
        "nubia": {
            "semantic_relation": 4.3518,
            "contradiction": 21.38875,
            "irrelevancy": 14.27253,
            "logical_agreement": 64.33872,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.30229,
            "nubia_score": 0.79395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.875,
            "3": 0.8157894736842105
        },
        "rouge1": {
            "precision": 0.82666,
            "recall": 0.76822,
            "fmeasure": 0.79191
        },
        "rouge2": {
            "precision": 0.55081,
            "recall": 0.53582,
            "fmeasure": 0.54084
        },
        "rougeL": {
            "precision": 0.76475,
            "recall": 0.73581,
            "fmeasure": 0.74746
        },
        "rougeLsum": {
            "precision": 0.76475,
            "recall": 0.73581,
            "fmeasure": 0.74746
        },
        "nist": 4.668172998504106,
        "bleu": 47.39226,
        "bertscore": {
            "precision": 0.94399,
            "recall": 0.9238,
            "f1": 0.93368
        },
        "bleurt": 0.42232,
        "meteor": 0.4219486990361178,
        "nubia": {
            "semantic_relation": 4.41731,
            "contradiction": 18.47281,
            "irrelevancy": 4.68029,
            "logical_agreement": 76.84691,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.83444,
            "nubia_score": 0.81691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.8260869565217391
        },
        "rouge1": {
            "precision": 0.73767,
            "recall": 0.73047,
            "fmeasure": 0.73139
        },
        "rouge2": {
            "precision": 0.55246,
            "recall": 0.55376,
            "fmeasure": 0.55179
        },
        "rougeL": {
            "precision": 0.6876,
            "recall": 0.68268,
            "fmeasure": 0.68332
        },
        "rougeLsum": {
            "precision": 0.6876,
            "recall": 0.68268,
            "fmeasure": 0.68332
        },
        "nist": 5.193266980568923,
        "bleu": 50.76799,
        "bertscore": {
            "precision": 0.93592,
            "recall": 0.93389,
            "f1": 0.93467
        },
        "bleurt": 0.37127,
        "meteor": 0.4220743620515712,
        "nubia": {
            "semantic_relation": 4.43879,
            "contradiction": 0.73883,
            "irrelevancy": 32.8988,
            "logical_agreement": 66.36237,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.679,
            "nubia_score": 0.80834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.4166666666666667,
            "3": 0.7368421052631579
        },
        "rouge1": {
            "precision": 0.73429,
            "recall": 0.68411,
            "fmeasure": 0.70107
        },
        "rouge2": {
            "precision": 0.49695,
            "recall": 0.4383,
            "fmeasure": 0.4621
        },
        "rougeL": {
            "precision": 0.65842,
            "recall": 0.63613,
            "fmeasure": 0.63911
        },
        "rougeLsum": {
            "precision": 0.65842,
            "recall": 0.63613,
            "fmeasure": 0.63911
        },
        "nist": 5.155634440647865,
        "bleu": 43.83047,
        "bertscore": {
            "precision": 0.912,
            "recall": 0.91338,
            "f1": 0.9101
        },
        "bleurt": 0.14439,
        "meteor": 0.3709344460050276,
        "nubia": {
            "semantic_relation": 4.15695,
            "contradiction": 6.73356,
            "irrelevancy": 34.17956,
            "logical_agreement": 59.08688,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.79127,
            "nubia_score": 0.70474
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.55,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7395
        },
        "nist": 3.7913310434313825,
        "bleu": 59.11603,
        "bertscore": {
            "precision": 0.96286,
            "recall": 0.94809,
            "f1": 0.95542
        },
        "bleurt": 0.29208,
        "meteor": 0.5566661162140665,
        "nubia": {
            "semantic_relation": 4.01773,
            "contradiction": 0.37617,
            "irrelevancy": 35.05729,
            "logical_agreement": 64.56654,
            "grammar_ref": 4.09688,
            "grammar_hyp": 4.86154,
            "nubia_score": 0.65596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.125,
            "3": 0.7446808510638298
        },
        "rouge1": {
            "precision": 0.82401,
            "recall": 0.79445,
            "fmeasure": 0.8063
        },
        "rouge2": {
            "precision": 0.66636,
            "recall": 0.64577,
            "fmeasure": 0.65433
        },
        "rougeL": {
            "precision": 0.74233,
            "recall": 0.72054,
            "fmeasure": 0.72918
        },
        "rougeLsum": {
            "precision": 0.74233,
            "recall": 0.72054,
            "fmeasure": 0.72918
        },
        "nist": 4.964777664589514,
        "bleu": 47.52509,
        "bertscore": {
            "precision": 0.95445,
            "recall": 0.94497,
            "f1": 0.94911
        },
        "bleurt": 0.61545,
        "meteor": 0.3970323562273102,
        "nubia": {
            "semantic_relation": 4.58101,
            "contradiction": 0.31093,
            "irrelevancy": 28.78204,
            "logical_agreement": 70.90703,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.61226,
            "nubia_score": 0.86426
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_small/totto_test",
        "N": 128,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2585034013605442,
            "2": 0.3817829457364341,
            "3": 0.7306122448979592
        },
        "rouge1": {
            "precision": 0.71973,
            "recall": 0.67787,
            "fmeasure": 0.6884
        },
        "rouge2": {
            "precision": 0.48709,
            "recall": 0.45896,
            "fmeasure": 0.46634
        },
        "rougeL": {
            "precision": 0.59793,
            "recall": 0.57178,
            "fmeasure": 0.57607
        },
        "rougeLsum": {
            "precision": 0.59793,
            "recall": 0.57178,
            "fmeasure": 0.57607
        },
        "nist": 7.624580654381609,
        "bleu": 45.39461,
        "bertscore": {
            "precision": 0.91642,
            "recall": 0.90194,
            "f1": 0.90724
        },
        "bleurt": 0.06496,
        "meteor": 0.3691922497815885,
        "nubia": {
            "semantic_relation": 3.66261,
            "contradiction": 29.46526,
            "irrelevancy": 28.67066,
            "logical_agreement": 41.86407,
            "grammar_ref": 4.11595,
            "grammar_hyp": 3.96105,
            "nubia_score": 0.58345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10714285714285714,
            "2": 0.275,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.7227,
            "recall": 0.6211,
            "fmeasure": 0.65708
        },
        "rouge2": {
            "precision": 0.45598,
            "recall": 0.39417,
            "fmeasure": 0.41522
        },
        "rougeL": {
            "precision": 0.55577,
            "recall": 0.4741,
            "fmeasure": 0.50286
        },
        "rougeLsum": {
            "precision": 0.55577,
            "recall": 0.4741,
            "fmeasure": 0.50286
        },
        "nist": 4.718618009049168,
        "bleu": 29.07445,
        "bertscore": {
            "precision": 0.91097,
            "recall": 0.88344,
            "f1": 0.89564
        },
        "bleurt": -0.00135,
        "meteor": 0.3093626615153646,
        "nubia": {
            "semantic_relation": 3.93184,
            "contradiction": 7.63406,
            "irrelevancy": 21.41712,
            "logical_agreement": 70.94882,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.47454,
            "nubia_score": 0.68584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.75,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.52381,
            "fmeasure": 0.61417
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.27179,
            "fmeasure": 0.32077
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.46032,
            "fmeasure": 0.54
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.46032,
            "fmeasure": 0.54
        },
        "nist": 2.588442875438538,
        "bleu": 28.64629,
        "bertscore": {
            "precision": 0.91551,
            "recall": 0.92261,
            "f1": 0.90712
        },
        "bleurt": 0.17554,
        "meteor": 0.3095567723454749,
        "nubia": {
            "semantic_relation": 4.43899,
            "contradiction": 0.27563,
            "irrelevancy": 2.08076,
            "logical_agreement": 97.64362,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.16722,
            "nubia_score": 0.71244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "mT5_small/totto_test",
        "N": 20,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.49230769230769234,
            "3": 0.8315789473684211
        },
        "rouge1": {
            "precision": 0.82113,
            "recall": 0.78622,
            "fmeasure": 0.79587
        },
        "rouge2": {
            "precision": 0.65482,
            "recall": 0.63262,
            "fmeasure": 0.63596
        },
        "rougeL": {
            "precision": 0.74593,
            "recall": 0.71953,
            "fmeasure": 0.72404
        },
        "rougeLsum": {
            "precision": 0.74593,
            "recall": 0.71953,
            "fmeasure": 0.72404
        },
        "nist": 6.507652475164599,
        "bleu": 56.42714,
        "bertscore": {
            "precision": 0.95673,
            "recall": 0.94068,
            "f1": 0.94732
        },
        "bleurt": 0.43247,
        "meteor": 0.43791663754884785,
        "nubia": {
            "semantic_relation": 4.12442,
            "contradiction": 19.26216,
            "irrelevancy": 10.8359,
            "logical_agreement": 69.90194,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.46869,
            "nubia_score": 0.72008
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.5,
            "3": 0.8194444444444444
        },
        "rouge1": {
            "precision": 0.78143,
            "recall": 0.79487,
            "fmeasure": 0.78397
        },
        "rouge2": {
            "precision": 0.57638,
            "recall": 0.59968,
            "fmeasure": 0.58389
        },
        "rougeL": {
            "precision": 0.68242,
            "recall": 0.69614,
            "fmeasure": 0.68587
        },
        "rougeLsum": {
            "precision": 0.68242,
            "recall": 0.69614,
            "fmeasure": 0.68587
        },
        "nist": 5.850771093749913,
        "bleu": 58.02123,
        "bertscore": {
            "precision": 0.93405,
            "recall": 0.94119,
            "f1": 0.93574
        },
        "bleurt": 0.37217,
        "meteor": 0.44704874907316033,
        "nubia": {
            "semantic_relation": 4.18121,
            "contradiction": 20.97264,
            "irrelevancy": 30.09763,
            "logical_agreement": 48.92973,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.2423,
            "nubia_score": 0.75086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.42857,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "nist": 2.0172250009178354,
        "bleu": 28.99784,
        "bertscore": {
            "precision": 0.92112,
            "recall": 0.95213,
            "f1": 0.93637
        },
        "bleurt": 0.80447,
        "meteor": 0.39919645893271766,
        "nubia": {
            "semantic_relation": 4.95423,
            "contradiction": 0.18035,
            "irrelevancy": 0.98149,
            "logical_agreement": 98.83816,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.51735,
            "nubia_score": 0.97849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.16666666666666666,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.6773,
            "recall": 0.57151,
            "fmeasure": 0.61503
        },
        "rouge2": {
            "precision": 0.44198,
            "recall": 0.35152,
            "fmeasure": 0.38809
        },
        "rougeL": {
            "precision": 0.58435,
            "recall": 0.50354,
            "fmeasure": 0.53517
        },
        "rougeLsum": {
            "precision": 0.58435,
            "recall": 0.50354,
            "fmeasure": 0.53517
        },
        "nist": 3.624499690723126,
        "bleu": 25.13079,
        "bertscore": {
            "precision": 0.93048,
            "recall": 0.90487,
            "f1": 0.91524
        },
        "bleurt": 0.12913,
        "meteor": 0.2664573642658899,
        "nubia": {
            "semantic_relation": 3.84198,
            "contradiction": 10.81682,
            "irrelevancy": 33.46078,
            "logical_agreement": 55.7224,
            "grammar_ref": 4.84918,
            "grammar_hyp": 4.97175,
            "nubia_score": 0.57573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "mT5_small/totto_test",
        "N": 103,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18902439024390244,
            "2": 0.4612794612794613,
            "3": 0.7597864768683275
        },
        "rouge1": {
            "precision": 0.75837,
            "recall": 0.71821,
            "fmeasure": 0.72421
        },
        "rouge2": {
            "precision": 0.53449,
            "recall": 0.50919,
            "fmeasure": 0.51121
        },
        "rougeL": {
            "precision": 0.6657,
            "recall": 0.63619,
            "fmeasure": 0.63814
        },
        "rougeLsum": {
            "precision": 0.6657,
            "recall": 0.63619,
            "fmeasure": 0.63814
        },
        "nist": 7.568862273059046,
        "bleu": 47.96675,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.91828,
            "f1": 0.92161
        },
        "bleurt": 0.25172,
        "meteor": 0.38444742062194864,
        "nubia": {
            "semantic_relation": 4.10419,
            "contradiction": 13.62024,
            "irrelevancy": 21.97106,
            "logical_agreement": 64.4087,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.58335,
            "nubia_score": 0.70357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.2,
            "3": 0.8620689655172413
        },
        "rouge1": {
            "precision": 0.75518,
            "recall": 0.8469,
            "fmeasure": 0.794
        },
        "rouge2": {
            "precision": 0.60969,
            "recall": 0.69308,
            "fmeasure": 0.64359
        },
        "rougeL": {
            "precision": 0.75518,
            "recall": 0.8469,
            "fmeasure": 0.794
        },
        "rougeLsum": {
            "precision": 0.75518,
            "recall": 0.8469,
            "fmeasure": 0.794
        },
        "nist": 3.9692497674441545,
        "bleu": 52.67748,
        "bertscore": {
            "precision": 0.9477,
            "recall": 0.96297,
            "f1": 0.95514
        },
        "bleurt": 0.29478,
        "meteor": 0.5425120065844531,
        "nubia": {
            "semantic_relation": 4.25278,
            "contradiction": 0.56479,
            "irrelevancy": 53.27747,
            "logical_agreement": 46.15774,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.4531,
            "nubia_score": 0.76199
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.4,
            "3": 0.7714285714285715
        },
        "rouge1": {
            "precision": 0.73589,
            "recall": 0.71255,
            "fmeasure": 0.72088
        },
        "rouge2": {
            "precision": 0.59029,
            "recall": 0.56189,
            "fmeasure": 0.57202
        },
        "rougeL": {
            "precision": 0.64947,
            "recall": 0.64633,
            "fmeasure": 0.64543
        },
        "rougeLsum": {
            "precision": 0.64947,
            "recall": 0.64633,
            "fmeasure": 0.64543
        },
        "nist": 4.255509950983309,
        "bleu": 48.51545,
        "bertscore": {
            "precision": 0.92583,
            "recall": 0.9239,
            "f1": 0.92443
        },
        "bleurt": 0.08753,
        "meteor": 0.39092268398355634,
        "nubia": {
            "semantic_relation": 3.73574,
            "contradiction": 3.1642,
            "irrelevancy": 35.15424,
            "logical_agreement": 61.68157,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.13708,
            "nubia_score": 0.58251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "mT5_small/totto_test",
        "N": 16,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3170731707317073,
            "3": 0.8432432432432433
        },
        "rouge1": {
            "precision": 0.81315,
            "recall": 0.78925,
            "fmeasure": 0.79578
        },
        "rouge2": {
            "precision": 0.57682,
            "recall": 0.57125,
            "fmeasure": 0.56929
        },
        "rougeL": {
            "precision": 0.72577,
            "recall": 0.70543,
            "fmeasure": 0.71056
        },
        "rougeLsum": {
            "precision": 0.72577,
            "recall": 0.70543,
            "fmeasure": 0.71056
        },
        "nist": 6.636770823809136,
        "bleu": 53.6746,
        "bertscore": {
            "precision": 0.95045,
            "recall": 0.95214,
            "f1": 0.95074
        },
        "bleurt": 0.46299,
        "meteor": 0.4259434248657742,
        "nubia": {
            "semantic_relation": 4.43156,
            "contradiction": 1.61228,
            "irrelevancy": 26.9742,
            "logical_agreement": 71.41351,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.385,
            "nubia_score": 0.8192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "mT5_small/totto_test",
        "N": 105,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17630057803468208,
            "2": 0.3622291021671827,
            "3": 0.6634408602150538
        },
        "rouge1": {
            "precision": 0.67663,
            "recall": 0.59426,
            "fmeasure": 0.6102
        },
        "rouge2": {
            "precision": 0.41827,
            "recall": 0.37199,
            "fmeasure": 0.37916
        },
        "rougeL": {
            "precision": 0.57513,
            "recall": 0.50861,
            "fmeasure": 0.51942
        },
        "rougeLsum": {
            "precision": 0.57513,
            "recall": 0.50861,
            "fmeasure": 0.51942
        },
        "nist": 6.307810213890779,
        "bleu": 36.01799,
        "bertscore": {
            "precision": 0.9003,
            "recall": 0.88614,
            "f1": 0.89155
        },
        "bleurt": 0.05753,
        "meteor": 0.33493601802620493,
        "nubia": {
            "semantic_relation": 3.46927,
            "contradiction": 15.93348,
            "irrelevancy": 30.3851,
            "logical_agreement": 53.68142,
            "grammar_ref": 4.94529,
            "grammar_hyp": 5.13164,
            "nubia_score": 0.56251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.5483870967741935,
            "3": 0.5961538461538461
        },
        "rouge1": {
            "precision": 0.65809,
            "recall": 0.67445,
            "fmeasure": 0.651
        },
        "rouge2": {
            "precision": 0.41859,
            "recall": 0.44957,
            "fmeasure": 0.42303
        },
        "rougeL": {
            "precision": 0.56676,
            "recall": 0.6061,
            "fmeasure": 0.57018
        },
        "rougeLsum": {
            "precision": 0.56676,
            "recall": 0.6061,
            "fmeasure": 0.57018
        },
        "nist": 4.796658059394364,
        "bleu": 32.84669,
        "bertscore": {
            "precision": 0.89812,
            "recall": 0.90797,
            "f1": 0.89808
        },
        "bleurt": 0.09472,
        "meteor": 0.3543407790985093,
        "nubia": {
            "semantic_relation": 3.85897,
            "contradiction": 19.28824,
            "irrelevancy": 48.0272,
            "logical_agreement": 32.68457,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.59906,
            "nubia_score": 0.64007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.13636363636363635,
            "3": 0.6914893617021277
        },
        "rouge1": {
            "precision": 0.73298,
            "recall": 0.61716,
            "fmeasure": 0.6624
        },
        "rouge2": {
            "precision": 0.47202,
            "recall": 0.40893,
            "fmeasure": 0.43424
        },
        "rougeL": {
            "precision": 0.62555,
            "recall": 0.53233,
            "fmeasure": 0.56855
        },
        "rougeLsum": {
            "precision": 0.62555,
            "recall": 0.53233,
            "fmeasure": 0.56855
        },
        "nist": 4.143865207625224,
        "bleu": 38.95238,
        "bertscore": {
            "precision": 0.92668,
            "recall": 0.90096,
            "f1": 0.91127
        },
        "bleurt": 0.10452,
        "meteor": 0.34609324721670975,
        "nubia": {
            "semantic_relation": 3.49038,
            "contradiction": 32.54,
            "irrelevancy": 22.57454,
            "logical_agreement": 44.88545,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.9435,
            "nubia_score": 0.51509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2830188679245283,
            "2": 0.4594594594594595,
            "3": 0.6190476190476191
        },
        "rouge1": {
            "precision": 0.54737,
            "recall": 0.53312,
            "fmeasure": 0.53185
        },
        "rouge2": {
            "precision": 0.29097,
            "recall": 0.25177,
            "fmeasure": 0.26303
        },
        "rougeL": {
            "precision": 0.42143,
            "recall": 0.40375,
            "fmeasure": 0.40631
        },
        "rougeLsum": {
            "precision": 0.42143,
            "recall": 0.40375,
            "fmeasure": 0.40631
        },
        "nist": 4.1708491632477624,
        "bleu": 22.18713,
        "bertscore": {
            "precision": 0.89568,
            "recall": 0.88699,
            "f1": 0.89008
        },
        "bleurt": -0.09064,
        "meteor": 0.29689908035377677,
        "nubia": {
            "semantic_relation": 3.78148,
            "contradiction": 10.17696,
            "irrelevancy": 66.58001,
            "logical_agreement": 23.24303,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.739,
            "nubia_score": 0.58581
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.2,
            "3": 0.8701298701298701
        },
        "rouge1": {
            "precision": 0.84288,
            "recall": 0.8072,
            "fmeasure": 0.81744
        },
        "rouge2": {
            "precision": 0.5938,
            "recall": 0.60532,
            "fmeasure": 0.59198
        },
        "rougeL": {
            "precision": 0.7142,
            "recall": 0.72277,
            "fmeasure": 0.71066
        },
        "rougeLsum": {
            "precision": 0.7142,
            "recall": 0.72277,
            "fmeasure": 0.71066
        },
        "nist": 5.586903151373691,
        "bleu": 46.17864,
        "bertscore": {
            "precision": 0.94101,
            "recall": 0.94381,
            "f1": 0.93924
        },
        "bleurt": 0.40676,
        "meteor": 0.43698651553087914,
        "nubia": {
            "semantic_relation": 4.365,
            "contradiction": 0.39517,
            "irrelevancy": 29.3508,
            "logical_agreement": 70.25403,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.90832,
            "nubia_score": 0.78818
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.6571428571428571,
            "3": 0.5652173913043478
        },
        "rouge1": {
            "precision": 0.71034,
            "recall": 0.54526,
            "fmeasure": 0.59791
        },
        "rouge2": {
            "precision": 0.44997,
            "recall": 0.30876,
            "fmeasure": 0.35098
        },
        "rougeL": {
            "precision": 0.60054,
            "recall": 0.45804,
            "fmeasure": 0.50329
        },
        "rougeLsum": {
            "precision": 0.60054,
            "recall": 0.45804,
            "fmeasure": 0.50329
        },
        "nist": 3.5722155462117096,
        "bleu": 32.68957,
        "bertscore": {
            "precision": 0.91816,
            "recall": 0.87511,
            "f1": 0.89459
        },
        "bleurt": -0.03187,
        "meteor": 0.28076083726211776,
        "nubia": {
            "semantic_relation": 3.77927,
            "contradiction": 43.11496,
            "irrelevancy": 10.24938,
            "logical_agreement": 46.63566,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.96617,
            "nubia_score": 0.54698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.69444,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.32727,
            "fmeasure": 0.35
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "nist": 0.8465369049159016,
        "bleu": 13.39142,
        "bertscore": {
            "precision": 0.8987,
            "recall": 0.87459,
            "f1": 0.88648
        },
        "bleurt": 0.0163,
        "meteor": 0.3199127132252423,
        "nubia": {
            "semantic_relation": 3.69862,
            "contradiction": 0.17343,
            "irrelevancy": 33.70499,
            "logical_agreement": 66.12158,
            "grammar_ref": 6.47099,
            "grammar_hyp": 7.75407,
            "nubia_score": 0.53949
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "mT5_small/totto_test",
        "N": 19,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1323529411764706,
            "2": 0.42857142857142855,
            "3": 0.7109826589595376
        },
        "rouge1": {
            "precision": 0.65679,
            "recall": 0.64165,
            "fmeasure": 0.62898
        },
        "rouge2": {
            "precision": 0.40978,
            "recall": 0.40245,
            "fmeasure": 0.3933
        },
        "rougeL": {
            "precision": 0.56506,
            "recall": 0.55537,
            "fmeasure": 0.54305
        },
        "rougeLsum": {
            "precision": 0.56506,
            "recall": 0.55537,
            "fmeasure": 0.54305
        },
        "nist": 4.85024436504391,
        "bleu": 33.69761,
        "bertscore": {
            "precision": 0.8809,
            "recall": 0.89047,
            "f1": 0.88247
        },
        "bleurt": 0.05065,
        "meteor": 0.31099129390818164,
        "nubia": {
            "semantic_relation": 3.88706,
            "contradiction": 14.63557,
            "irrelevancy": 28.60733,
            "logical_agreement": 56.7571,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.63282,
            "nubia_score": 0.61391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "nist": 0.9472807507835431,
        "bleu": 47.87975,
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        },
        "bleurt": 0.78138,
        "meteor": 0.4180407844493463,
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "mT5_small/totto_test",
        "N": 80,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19491525423728814,
            "2": 0.36619718309859156,
            "3": 0.7036625971143174
        },
        "rouge1": {
            "precision": 0.7455,
            "recall": 0.66907,
            "fmeasure": 0.68858
        },
        "rouge2": {
            "precision": 0.48634,
            "recall": 0.42763,
            "fmeasure": 0.44396
        },
        "rougeL": {
            "precision": 0.65572,
            "recall": 0.59002,
            "fmeasure": 0.60617
        },
        "rougeLsum": {
            "precision": 0.65572,
            "recall": 0.59002,
            "fmeasure": 0.60617
        },
        "nist": 6.725304460983307,
        "bleu": 38.0791,
        "bertscore": {
            "precision": 0.92155,
            "recall": 0.90692,
            "f1": 0.9121
        },
        "bleurt": 0.17542,
        "meteor": 0.3537140012541812,
        "nubia": {
            "semantic_relation": 4.0341,
            "contradiction": 12.2668,
            "irrelevancy": 25.31927,
            "logical_agreement": 62.41393,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.97618,
            "nubia_score": 0.65316
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_small/totto_test",
        "N": 61,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.39819004524886875,
            "3": 0.6722338204592901
        },
        "rouge1": {
            "precision": 0.66886,
            "recall": 0.63043,
            "fmeasure": 0.63625
        },
        "rouge2": {
            "precision": 0.39568,
            "recall": 0.37254,
            "fmeasure": 0.37746
        },
        "rougeL": {
            "precision": 0.54816,
            "recall": 0.51202,
            "fmeasure": 0.51839
        },
        "rougeLsum": {
            "precision": 0.54816,
            "recall": 0.51202,
            "fmeasure": 0.51839
        },
        "nist": 6.452684641118356,
        "bleu": 37.11908,
        "bertscore": {
            "precision": 0.90546,
            "recall": 0.89186,
            "f1": 0.89719
        },
        "bleurt": 0.04232,
        "meteor": 0.33115594720955965,
        "nubia": {
            "semantic_relation": 3.6778,
            "contradiction": 21.2235,
            "irrelevancy": 28.65392,
            "logical_agreement": 50.12257,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.11547,
            "nubia_score": 0.59368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.09090909090909091,
            "3": 0.8611111111111112
        },
        "rouge1": {
            "precision": 0.67129,
            "recall": 0.69121,
            "fmeasure": 0.67746
        },
        "rouge2": {
            "precision": 0.42917,
            "recall": 0.42684,
            "fmeasure": 0.427
        },
        "rougeL": {
            "precision": 0.59448,
            "recall": 0.61163,
            "fmeasure": 0.60028
        },
        "rougeLsum": {
            "precision": 0.59448,
            "recall": 0.61163,
            "fmeasure": 0.60028
        },
        "nist": 3.692659656967409,
        "bleu": 29.06498,
        "bertscore": {
            "precision": 0.90752,
            "recall": 0.92482,
            "f1": 0.91543
        },
        "bleurt": 0.23555,
        "meteor": 0.37081906155977923,
        "nubia": {
            "semantic_relation": 4.42674,
            "contradiction": 0.37651,
            "irrelevancy": 47.36472,
            "logical_agreement": 52.25877,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.06159,
            "nubia_score": 0.8107
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.79258,
            "recall": 0.84938,
            "fmeasure": 0.81517
        },
        "rouge2": {
            "precision": 0.52361,
            "recall": 0.58393,
            "fmeasure": 0.549
        },
        "rougeL": {
            "precision": 0.68533,
            "recall": 0.74258,
            "fmeasure": 0.70899
        },
        "rougeLsum": {
            "precision": 0.68533,
            "recall": 0.74258,
            "fmeasure": 0.70899
        },
        "nist": 5.043828126904443,
        "bleu": 54.14495,
        "bertscore": {
            "precision": 0.93477,
            "recall": 0.94175,
            "f1": 0.93769
        },
        "bleurt": 0.31033,
        "meteor": 0.4369965912969602,
        "nubia": {
            "semantic_relation": 4.48894,
            "contradiction": 5.24072,
            "irrelevancy": 17.12081,
            "logical_agreement": 77.63847,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.52852,
            "nubia_score": 0.75501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.56,
            "3": 0.7263157894736842
        },
        "rouge1": {
            "precision": 0.81554,
            "recall": 0.72217,
            "fmeasure": 0.75477
        },
        "rouge2": {
            "precision": 0.51358,
            "recall": 0.46898,
            "fmeasure": 0.48036
        },
        "rougeL": {
            "precision": 0.68123,
            "recall": 0.61921,
            "fmeasure": 0.63894
        },
        "rougeLsum": {
            "precision": 0.68123,
            "recall": 0.61921,
            "fmeasure": 0.63894
        },
        "nist": 5.629079104568854,
        "bleu": 39.67363,
        "bertscore": {
            "precision": 0.94096,
            "recall": 0.91631,
            "f1": 0.92667
        },
        "bleurt": 0.08794,
        "meteor": 0.35223821642350184,
        "nubia": {
            "semantic_relation": 3.98423,
            "contradiction": 12.02239,
            "irrelevancy": 37.40483,
            "logical_agreement": 50.57277,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.90012,
            "nubia_score": 0.64363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "mT5_small/totto_test",
        "N": 18,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.21428571428571427,
            "3": 0.7157894736842105
        },
        "rouge1": {
            "precision": 0.69867,
            "recall": 0.67907,
            "fmeasure": 0.68075
        },
        "rouge2": {
            "precision": 0.49597,
            "recall": 0.48082,
            "fmeasure": 0.48174
        },
        "rougeL": {
            "precision": 0.62856,
            "recall": 0.61344,
            "fmeasure": 0.61404
        },
        "rougeLsum": {
            "precision": 0.62856,
            "recall": 0.61344,
            "fmeasure": 0.61404
        },
        "nist": 5.5933714499529215,
        "bleu": 44.34825,
        "bertscore": {
            "precision": 0.91183,
            "recall": 0.90482,
            "f1": 0.90715
        },
        "bleurt": 0.25293,
        "meteor": 0.37757136429540866,
        "nubia": {
            "semantic_relation": 4.02542,
            "contradiction": 3.84431,
            "irrelevancy": 41.98952,
            "logical_agreement": 54.16617,
            "grammar_ref": 5.08526,
            "grammar_hyp": 5.09768,
            "nubia_score": 0.68214
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.71717,
            "fmeasure": 0.78638
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.78333,
            "fmeasure": 0.85464
        },
        "nist": 3.7642741174382337,
        "bleu": 81.76129,
        "bertscore": {
            "precision": 0.97871,
            "recall": 0.94782,
            "f1": 0.96301
        },
        "bleurt": 0.69712,
        "meteor": 0.5064321156600579,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.96713,
            "irrelevancy": 0.64693,
            "logical_agreement": 98.38594,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.52299,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.16666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7601,
            "recall": 0.53191,
            "fmeasure": 0.60269
        },
        "rouge2": {
            "precision": 0.42647,
            "recall": 0.28519,
            "fmeasure": 0.32946
        },
        "rougeL": {
            "precision": 0.55051,
            "recall": 0.40153,
            "fmeasure": 0.45007
        },
        "rougeLsum": {
            "precision": 0.55051,
            "recall": 0.40153,
            "fmeasure": 0.45007
        },
        "nist": 2.527953650119906,
        "bleu": 14.98686,
        "bertscore": {
            "precision": 0.93668,
            "recall": 0.91399,
            "f1": 0.92383
        },
        "bleurt": 0.04718,
        "meteor": 0.2962031121568582,
        "nubia": {
            "semantic_relation": 4.39412,
            "contradiction": 1.98164,
            "irrelevancy": 55.73436,
            "logical_agreement": 42.284,
            "grammar_ref": 3.10743,
            "grammar_hyp": 4.2301,
            "nubia_score": 0.75589
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3333333333333333,
            "3": 0.8791208791208791
        },
        "rouge1": {
            "precision": 0.92023,
            "recall": 0.87797,
            "fmeasure": 0.89794
        },
        "rouge2": {
            "precision": 0.75732,
            "recall": 0.72197,
            "fmeasure": 0.73861
        },
        "rougeL": {
            "precision": 0.78398,
            "recall": 0.73543,
            "fmeasure": 0.75812
        },
        "rougeLsum": {
            "precision": 0.78398,
            "recall": 0.73543,
            "fmeasure": 0.75812
        },
        "nist": 6.4539222082413845,
        "bleu": 70.65943,
        "bertscore": {
            "precision": 0.98195,
            "recall": 0.97282,
            "f1": 0.97676
        },
        "bleurt": 0.60793,
        "meteor": 0.49612118515192033,
        "nubia": {
            "semantic_relation": 4.71708,
            "contradiction": 3.16469,
            "irrelevancy": 0.76158,
            "logical_agreement": 96.07373,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.15985,
            "nubia_score": 0.87308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.71795,
            "fmeasure": 0.5719
        },
        "rouge2": {
            "precision": 0.275,
            "recall": 0.42262,
            "fmeasure": 0.33272
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.40256,
            "fmeasure": 0.31699
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.40256,
            "fmeasure": 0.31699
        },
        "nist": 2.5766812288998513,
        "bleu": 27.409,
        "bertscore": {
            "precision": 0.82891,
            "recall": 0.85893,
            "f1": 0.84011
        },
        "bleurt": -0.10604,
        "meteor": 0.4164788794038261,
        "nubia": {
            "semantic_relation": 3.473,
            "contradiction": 0.09043,
            "irrelevancy": 99.77856,
            "logical_agreement": 0.13101,
            "grammar_ref": 4.56931,
            "grammar_hyp": 2.80482,
            "nubia_score": 0.76144
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6923076923076923,
            "3": 0.8148148148148148
        },
        "rouge1": {
            "precision": 0.78384,
            "recall": 0.76201,
            "fmeasure": 0.77098
        },
        "rouge2": {
            "precision": 0.55434,
            "recall": 0.53969,
            "fmeasure": 0.54539
        },
        "rougeL": {
            "precision": 0.7431,
            "recall": 0.72512,
            "fmeasure": 0.73227
        },
        "rougeLsum": {
            "precision": 0.7431,
            "recall": 0.72512,
            "fmeasure": 0.73227
        },
        "nist": 4.411110212466699,
        "bleu": 47.54693,
        "bertscore": {
            "precision": 0.93032,
            "recall": 0.9234,
            "f1": 0.92655
        },
        "bleurt": 0.42549,
        "meteor": 0.415514655515779,
        "nubia": {
            "semantic_relation": 4.23837,
            "contradiction": 0.34213,
            "irrelevancy": 40.21969,
            "logical_agreement": 59.43818,
            "grammar_ref": 4.97796,
            "grammar_hyp": 4.86758,
            "nubia_score": 0.72932
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.4473684210526316
        },
        "rouge1": {
            "precision": 0.54688,
            "recall": 0.43869,
            "fmeasure": 0.4864
        },
        "rouge2": {
            "precision": 0.28853,
            "recall": 0.2284,
            "fmeasure": 0.25462
        },
        "rougeL": {
            "precision": 0.46875,
            "recall": 0.37741,
            "fmeasure": 0.4178
        },
        "rougeLsum": {
            "precision": 0.46875,
            "recall": 0.37741,
            "fmeasure": 0.4178
        },
        "nist": 3.425200925913205,
        "bleu": 31.43046,
        "bertscore": {
            "precision": 0.9104,
            "recall": 0.86102,
            "f1": 0.88495
        },
        "bleurt": -0.21109,
        "meteor": 0.2506853467709944,
        "nubia": {
            "semantic_relation": 3.47343,
            "contradiction": 25.96499,
            "irrelevancy": 45.64418,
            "logical_agreement": 28.39083,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.6109,
            "nubia_score": 0.4172
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_small/totto_test",
        "N": 40,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1643835616438356,
            "2": 0.38461538461538464,
            "3": 0.7065217391304348
        },
        "rouge1": {
            "precision": 0.6929,
            "recall": 0.64381,
            "fmeasure": 0.65593
        },
        "rouge2": {
            "precision": 0.4434,
            "recall": 0.41323,
            "fmeasure": 0.41657
        },
        "rougeL": {
            "precision": 0.55866,
            "recall": 0.53105,
            "fmeasure": 0.53012
        },
        "rougeLsum": {
            "precision": 0.55866,
            "recall": 0.53105,
            "fmeasure": 0.53012
        },
        "nist": 6.227411613353078,
        "bleu": 34.88952,
        "bertscore": {
            "precision": 0.90639,
            "recall": 0.8951,
            "f1": 0.89867
        },
        "bleurt": 0.05488,
        "meteor": 0.3358365447968069,
        "nubia": {
            "semantic_relation": 3.64783,
            "contradiction": 19.52749,
            "irrelevancy": 25.14831,
            "logical_agreement": 55.3242,
            "grammar_ref": 4.29053,
            "grammar_hyp": 3.98835,
            "nubia_score": 0.61175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.7666666666666667,
            "3": 0.8166666666666667
        },
        "rouge1": {
            "precision": 0.85174,
            "recall": 0.76799,
            "fmeasure": 0.79709
        },
        "rouge2": {
            "precision": 0.58798,
            "recall": 0.53229,
            "fmeasure": 0.54978
        },
        "rougeL": {
            "precision": 0.68403,
            "recall": 0.62264,
            "fmeasure": 0.64492
        },
        "rougeLsum": {
            "precision": 0.68403,
            "recall": 0.62264,
            "fmeasure": 0.64492
        },
        "nist": 5.557234257011779,
        "bleu": 49.45995,
        "bertscore": {
            "precision": 0.9532,
            "recall": 0.9332,
            "f1": 0.93962
        },
        "bleurt": 0.34591,
        "meteor": 0.42457919708547054,
        "nubia": {
            "semantic_relation": 4.128,
            "contradiction": 18.24175,
            "irrelevancy": 18.63043,
            "logical_agreement": 63.12782,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.41671,
            "nubia_score": 0.67534
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "mT5_small/totto_test",
        "N": 25,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.46875,
            "3": 0.7347670250896058
        },
        "rouge1": {
            "precision": 0.77831,
            "recall": 0.7366,
            "fmeasure": 0.74836
        },
        "rouge2": {
            "precision": 0.53463,
            "recall": 0.50722,
            "fmeasure": 0.51337
        },
        "rougeL": {
            "precision": 0.6617,
            "recall": 0.62487,
            "fmeasure": 0.63421
        },
        "rougeLsum": {
            "precision": 0.6617,
            "recall": 0.62487,
            "fmeasure": 0.63421
        },
        "nist": 6.331306689426427,
        "bleu": 43.3539,
        "bertscore": {
            "precision": 0.92643,
            "recall": 0.91968,
            "f1": 0.92054
        },
        "bleurt": 0.23821,
        "meteor": 0.3835566902327058,
        "nubia": {
            "semantic_relation": 4.16025,
            "contradiction": 10.15396,
            "irrelevancy": 26.93207,
            "logical_agreement": 62.91397,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.91326,
            "nubia_score": 0.70864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.70955,
            "fmeasure": 0.71572
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.40414,
            "fmeasure": 0.40784
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "nist": 2.3557006939344536,
        "bleu": 17.31422,
        "bertscore": {
            "precision": 0.90149,
            "recall": 0.90661,
            "f1": 0.90327
        },
        "bleurt": 0.46713,
        "meteor": 0.3449119907005969,
        "nubia": {
            "semantic_relation": 4.88508,
            "contradiction": 0.1669,
            "irrelevancy": 27.49829,
            "logical_agreement": 72.3348,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.63432,
            "nubia_score": 0.92989
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "mT5_small/totto_test",
        "N": 20,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22988505747126436,
            "2": 0.3076923076923077,
            "3": 0.7018072289156626
        },
        "rouge1": {
            "precision": 0.66705,
            "recall": 0.63296,
            "fmeasure": 0.62886
        },
        "rouge2": {
            "precision": 0.39924,
            "recall": 0.37998,
            "fmeasure": 0.37244
        },
        "rougeL": {
            "precision": 0.52392,
            "recall": 0.50238,
            "fmeasure": 0.49484
        },
        "rougeLsum": {
            "precision": 0.52392,
            "recall": 0.50238,
            "fmeasure": 0.49484
        },
        "nist": 5.527682552127681,
        "bleu": 32.99005,
        "bertscore": {
            "precision": 0.91041,
            "recall": 0.89999,
            "f1": 0.8975
        },
        "bleurt": -0.01052,
        "meteor": 0.322611195364901,
        "nubia": {
            "semantic_relation": 3.6428,
            "contradiction": 18.55906,
            "irrelevancy": 27.2666,
            "logical_agreement": 54.17434,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.10157,
            "nubia_score": 0.56591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5333333333333333,
            "3": 0.7808219178082192
        },
        "rouge1": {
            "precision": 0.73379,
            "recall": 0.74726,
            "fmeasure": 0.72529
        },
        "rouge2": {
            "precision": 0.49487,
            "recall": 0.49305,
            "fmeasure": 0.48293
        },
        "rougeL": {
            "precision": 0.59367,
            "recall": 0.60244,
            "fmeasure": 0.58568
        },
        "rougeLsum": {
            "precision": 0.59367,
            "recall": 0.60244,
            "fmeasure": 0.58568
        },
        "nist": 5.1569449287569675,
        "bleu": 39.24382,
        "bertscore": {
            "precision": 0.90185,
            "recall": 0.9256,
            "f1": 0.91229
        },
        "bleurt": 0.2557,
        "meteor": 0.3924243340522858,
        "nubia": {
            "semantic_relation": 4.24291,
            "contradiction": 10.80562,
            "irrelevancy": 41.37285,
            "logical_agreement": 47.82153,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.60075,
            "nubia_score": 0.73725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.6571428571428571
        },
        "rouge1": {
            "precision": 0.71024,
            "recall": 0.65972,
            "fmeasure": 0.68065
        },
        "rouge2": {
            "precision": 0.37626,
            "recall": 0.36193,
            "fmeasure": 0.36659
        },
        "rougeL": {
            "precision": 0.59001,
            "recall": 0.55258,
            "fmeasure": 0.56776
        },
        "rougeLsum": {
            "precision": 0.59001,
            "recall": 0.55258,
            "fmeasure": 0.56776
        },
        "nist": 4.529387517125684,
        "bleu": 29.97432,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.90014,
            "f1": 0.91308
        },
        "bleurt": 0.20578,
        "meteor": 0.32265073048258924,
        "nubia": {
            "semantic_relation": 4.21326,
            "contradiction": 10.58596,
            "irrelevancy": 24.66049,
            "logical_agreement": 64.75355,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.03472,
            "nubia_score": 0.72975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.375,
            "3": 0.8846153846153846
        },
        "rouge1": {
            "precision": 0.85112,
            "recall": 0.80476,
            "fmeasure": 0.82223
        },
        "rouge2": {
            "precision": 0.68701,
            "recall": 0.64585,
            "fmeasure": 0.66252
        },
        "rougeL": {
            "precision": 0.71867,
            "recall": 0.67712,
            "fmeasure": 0.69324
        },
        "rougeLsum": {
            "precision": 0.71867,
            "recall": 0.67712,
            "fmeasure": 0.69324
        },
        "nist": 6.184760307677529,
        "bleu": 62.73595,
        "bertscore": {
            "precision": 0.94392,
            "recall": 0.92958,
            "f1": 0.93652
        },
        "bleurt": 0.41529,
        "meteor": 0.4478815761553365,
        "nubia": {
            "semantic_relation": 4.15231,
            "contradiction": 7.60829,
            "irrelevancy": 19.97535,
            "logical_agreement": 72.41637,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.9537,
            "nubia_score": 0.71876
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "mT5_small/totto_test",
        "N": 64,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1794871794871795,
            "2": 0.46255506607929514,
            "3": 0.7146853146853147
        },
        "rouge1": {
            "precision": 0.73734,
            "recall": 0.69132,
            "fmeasure": 0.70584
        },
        "rouge2": {
            "precision": 0.46755,
            "recall": 0.44469,
            "fmeasure": 0.45113
        },
        "rougeL": {
            "precision": 0.61384,
            "recall": 0.57654,
            "fmeasure": 0.58779
        },
        "rougeLsum": {
            "precision": 0.61384,
            "recall": 0.57654,
            "fmeasure": 0.58779
        },
        "nist": 6.792335553265433,
        "bleu": 40.35626,
        "bertscore": {
            "precision": 0.92903,
            "recall": 0.91203,
            "f1": 0.91887
        },
        "bleurt": 0.21977,
        "meteor": 0.3658215476302284,
        "nubia": {
            "semantic_relation": 4.06875,
            "contradiction": 8.00186,
            "irrelevancy": 35.15589,
            "logical_agreement": 56.84225,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.6434,
            "nubia_score": 0.68935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.6176470588235294
        },
        "rouge1": {
            "precision": 0.73571,
            "recall": 0.70567,
            "fmeasure": 0.71922
        },
        "rouge2": {
            "precision": 0.49978,
            "recall": 0.46188,
            "fmeasure": 0.47824
        },
        "rougeL": {
            "precision": 0.58571,
            "recall": 0.5584,
            "fmeasure": 0.57072
        },
        "rougeLsum": {
            "precision": 0.58571,
            "recall": 0.5584,
            "fmeasure": 0.57072
        },
        "nist": 3.3859976428068,
        "bleu": 30.43804,
        "bertscore": {
            "precision": 0.90958,
            "recall": 0.92464,
            "f1": 0.91675
        },
        "bleurt": 0.42142,
        "meteor": 0.3365676713581205,
        "nubia": {
            "semantic_relation": 4.51251,
            "contradiction": 0.24847,
            "irrelevancy": 33.56166,
            "logical_agreement": 66.18987,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.17931,
            "nubia_score": 0.87879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "mT5_small/totto_test",
        "N": 17,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.36470588235294116,
            "3": 0.6994535519125683
        },
        "rouge1": {
            "precision": 0.73689,
            "recall": 0.69971,
            "fmeasure": 0.70611
        },
        "rouge2": {
            "precision": 0.52983,
            "recall": 0.50489,
            "fmeasure": 0.50746
        },
        "rougeL": {
            "precision": 0.6479,
            "recall": 0.61344,
            "fmeasure": 0.61881
        },
        "rougeLsum": {
            "precision": 0.6479,
            "recall": 0.61344,
            "fmeasure": 0.61881
        },
        "nist": 5.415617834524366,
        "bleu": 41.43827,
        "bertscore": {
            "precision": 0.92715,
            "recall": 0.92027,
            "f1": 0.92241
        },
        "bleurt": 0.14515,
        "meteor": 0.3766954892166416,
        "nubia": {
            "semantic_relation": 3.95301,
            "contradiction": 14.72461,
            "irrelevancy": 33.70403,
            "logical_agreement": 51.57136,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.35805,
            "nubia_score": 0.64788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.47619,
            "fmeasure": 0.4878
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.25,
            "fmeasure": 0.25641
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.42857,
            "fmeasure": 0.43902
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.42857,
            "fmeasure": 0.43902
        },
        "nist": 1.9574844290468605,
        "bleu": 15.01306,
        "bertscore": {
            "precision": 0.88355,
            "recall": 0.85413,
            "f1": 0.86859
        },
        "bleurt": -0.09342,
        "meteor": 0.2711725096199139,
        "nubia": {
            "semantic_relation": 2.82157,
            "contradiction": 99.41706,
            "irrelevancy": 0.3141,
            "logical_agreement": 0.26884,
            "grammar_ref": 3.42286,
            "grammar_hyp": 3.8514,
            "nubia_score": 0.36458
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "mT5_small/totto_test",
        "N": 150,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16706443914081145,
            "2": 0.2756183745583039,
            "3": 0.7943071965628357
        },
        "rouge1": {
            "precision": 0.8156,
            "recall": 0.76652,
            "fmeasure": 0.78383
        },
        "rouge2": {
            "precision": 0.57247,
            "recall": 0.53573,
            "fmeasure": 0.54834
        },
        "rougeL": {
            "precision": 0.70355,
            "recall": 0.65601,
            "fmeasure": 0.67311
        },
        "rougeLsum": {
            "precision": 0.70355,
            "recall": 0.65601,
            "fmeasure": 0.67311
        },
        "nist": 8.14132832618657,
        "bleu": 48.25599,
        "bertscore": {
            "precision": 0.94157,
            "recall": 0.93446,
            "f1": 0.93695
        },
        "bleurt": 0.39049,
        "meteor": 0.4082884272784095,
        "nubia": {
            "semantic_relation": 4.43803,
            "contradiction": 6.89637,
            "irrelevancy": 18.34782,
            "logical_agreement": 74.75581,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.65479,
            "nubia_score": 0.79437
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "mT5_small/totto_test",
        "N": 12,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5714285714285714,
            "3": 0.7608695652173914
        },
        "rouge1": {
            "precision": 0.71544,
            "recall": 0.72568,
            "fmeasure": 0.70969
        },
        "rouge2": {
            "precision": 0.52252,
            "recall": 0.50029,
            "fmeasure": 0.50163
        },
        "rougeL": {
            "precision": 0.61672,
            "recall": 0.61734,
            "fmeasure": 0.6083
        },
        "rougeLsum": {
            "precision": 0.61672,
            "recall": 0.61734,
            "fmeasure": 0.6083
        },
        "nist": 4.934850541386242,
        "bleu": 40.36619,
        "bertscore": {
            "precision": 0.91379,
            "recall": 0.91268,
            "f1": 0.91024
        },
        "bleurt": 0.23234,
        "meteor": 0.3775351049933723,
        "nubia": {
            "semantic_relation": 4.16668,
            "contradiction": 14.37581,
            "irrelevancy": 18.93769,
            "logical_agreement": 66.6865,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.47207,
            "nubia_score": 0.71117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.68627,
            "recall": 0.85348,
            "fmeasure": 0.76057
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.46154,
            "fmeasure": 0.40066
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.57143,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.57143,
            "fmeasure": 0.51613
        },
        "nist": 3.2033521556852773,
        "bleu": 21.84182,
        "bertscore": {
            "precision": 0.91147,
            "recall": 0.93501,
            "f1": 0.91864
        },
        "bleurt": 0.5048,
        "meteor": 0.4290109944388497,
        "nubia": {
            "semantic_relation": 4.99919,
            "contradiction": 0.23968,
            "irrelevancy": 71.11973,
            "logical_agreement": 28.64059,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.42185,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.38095238095238093,
            "3": 0.6777777777777778
        },
        "rouge1": {
            "precision": 0.72211,
            "recall": 0.70459,
            "fmeasure": 0.69875
        },
        "rouge2": {
            "precision": 0.52815,
            "recall": 0.50888,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.62996,
            "recall": 0.61313,
            "fmeasure": 0.61699
        },
        "rougeLsum": {
            "precision": 0.62996,
            "recall": 0.61313,
            "fmeasure": 0.61699
        },
        "nist": 4.939123407296178,
        "bleu": 40.47386,
        "bertscore": {
            "precision": 0.92489,
            "recall": 0.917,
            "f1": 0.91906
        },
        "bleurt": 0.1762,
        "meteor": 0.3597465726970159,
        "nubia": {
            "semantic_relation": 3.80581,
            "contradiction": 31.25803,
            "irrelevancy": 32.82908,
            "logical_agreement": 35.91289,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.75331,
            "nubia_score": 0.59286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "mT5_small/totto_test",
        "N": 25,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2608695652173913,
            "2": 0.4057971014492754,
            "3": 0.7491166077738516
        },
        "rouge1": {
            "precision": 0.76625,
            "recall": 0.70065,
            "fmeasure": 0.71994
        },
        "rouge2": {
            "precision": 0.56284,
            "recall": 0.52068,
            "fmeasure": 0.53115
        },
        "rougeL": {
            "precision": 0.66932,
            "recall": 0.62688,
            "fmeasure": 0.63683
        },
        "rougeLsum": {
            "precision": 0.66932,
            "recall": 0.62688,
            "fmeasure": 0.63683
        },
        "nist": 6.498109611732133,
        "bleu": 46.44651,
        "bertscore": {
            "precision": 0.92658,
            "recall": 0.91824,
            "f1": 0.92126
        },
        "bleurt": 0.12396,
        "meteor": 0.3864802972464473,
        "nubia": {
            "semantic_relation": 3.7452,
            "contradiction": 15.13527,
            "irrelevancy": 26.16062,
            "logical_agreement": 58.70411,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.81827,
            "nubia_score": 0.59865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.41667,
            "fmeasure": 0.35714
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "nist": 1.8823529411764706,
        "bleu": 19.3453,
        "bertscore": {
            "precision": 0.88196,
            "recall": 0.89007,
            "f1": 0.886
        },
        "bleurt": 0.1139,
        "meteor": 0.3357291994814012,
        "nubia": {
            "semantic_relation": 3.633,
            "contradiction": 0.16377,
            "irrelevancy": 99.6995,
            "logical_agreement": 0.13673,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.86485,
            "nubia_score": 0.65907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.8125,
            "3": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.69313,
            "recall": 0.79131,
            "fmeasure": 0.71954
        },
        "rouge2": {
            "precision": 0.42507,
            "recall": 0.51649,
            "fmeasure": 0.45259
        },
        "rougeL": {
            "precision": 0.60596,
            "recall": 0.71711,
            "fmeasure": 0.63965
        },
        "rougeLsum": {
            "precision": 0.60596,
            "recall": 0.71711,
            "fmeasure": 0.63965
        },
        "nist": 4.32422250521216,
        "bleu": 39.70165,
        "bertscore": {
            "precision": 0.90808,
            "recall": 0.93053,
            "f1": 0.91547
        },
        "bleurt": 0.22036,
        "meteor": 0.4050192517286007,
        "nubia": {
            "semantic_relation": 3.875,
            "contradiction": 21.60228,
            "irrelevancy": 35.89991,
            "logical_agreement": 42.49781,
            "grammar_ref": 4.75156,
            "grammar_hyp": 5.01567,
            "nubia_score": 0.57939
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "mT5_small/totto_test",
        "N": 26,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19166666666666668,
            "2": 0.31092436974789917,
            "3": 0.7312775330396476
        },
        "rouge1": {
            "precision": 0.70989,
            "recall": 0.63925,
            "fmeasure": 0.65767
        },
        "rouge2": {
            "precision": 0.43231,
            "recall": 0.39217,
            "fmeasure": 0.40166
        },
        "rougeL": {
            "precision": 0.55148,
            "recall": 0.49209,
            "fmeasure": 0.50825
        },
        "rougeLsum": {
            "precision": 0.55148,
            "recall": 0.49209,
            "fmeasure": 0.50825
        },
        "nist": 6.274316981919291,
        "bleu": 35.50453,
        "bertscore": {
            "precision": 0.90942,
            "recall": 0.88992,
            "f1": 0.89801
        },
        "bleurt": 0.02452,
        "meteor": 0.33525810016467783,
        "nubia": {
            "semantic_relation": 3.48093,
            "contradiction": 22.45011,
            "irrelevancy": 29.98662,
            "logical_agreement": 47.56327,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.77684,
            "nubia_score": 0.55925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.45833,
            "fmeasure": 0.55
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.08696,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "nist": 2.270903878906555,
        "bleu": 4.34895,
        "bertscore": {
            "precision": 0.85368,
            "recall": 0.82379,
            "f1": 0.83049
        },
        "bleurt": -0.55923,
        "meteor": 0.21934397220768492,
        "nubia": {
            "semantic_relation": 3.46826,
            "contradiction": 29.7149,
            "irrelevancy": 21.49231,
            "logical_agreement": 48.79279,
            "grammar_ref": 4.791,
            "grammar_hyp": 5.22369,
            "nubia_score": 0.42803
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "mT5_small/totto_test",
        "N": 105,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.189873417721519,
            "2": 0.3305084745762712,
            "3": 0.7591801878736123
        },
        "rouge1": {
            "precision": 0.79028,
            "recall": 0.7298,
            "fmeasure": 0.74868
        },
        "rouge2": {
            "precision": 0.54147,
            "recall": 0.49646,
            "fmeasure": 0.51059
        },
        "rougeL": {
            "precision": 0.67642,
            "recall": 0.62069,
            "fmeasure": 0.63913
        },
        "rougeLsum": {
            "precision": 0.67642,
            "recall": 0.62069,
            "fmeasure": 0.63913
        },
        "nist": 7.469680954621753,
        "bleu": 44.05878,
        "bertscore": {
            "precision": 0.93419,
            "recall": 0.92534,
            "f1": 0.9289
        },
        "bleurt": 0.32493,
        "meteor": 0.38292344336557355,
        "nubia": {
            "semantic_relation": 4.35291,
            "contradiction": 7.21331,
            "irrelevancy": 23.59645,
            "logical_agreement": 69.19024,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.15324,
            "nubia_score": 0.7494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3125,
            "2": 0.4,
            "3": 0.801980198019802
        },
        "rouge1": {
            "precision": 0.78185,
            "recall": 0.81378,
            "fmeasure": 0.7738
        },
        "rouge2": {
            "precision": 0.60878,
            "recall": 0.63025,
            "fmeasure": 0.60009
        },
        "rougeL": {
            "precision": 0.68447,
            "recall": 0.74113,
            "fmeasure": 0.69146
        },
        "rougeLsum": {
            "precision": 0.68447,
            "recall": 0.74113,
            "fmeasure": 0.69146
        },
        "nist": 5.210122680723523,
        "bleu": 47.24862,
        "bertscore": {
            "precision": 0.93738,
            "recall": 0.93734,
            "f1": 0.93363
        },
        "bleurt": 0.5252,
        "meteor": 0.4281395659592423,
        "nubia": {
            "semantic_relation": 4.57507,
            "contradiction": 1.7989,
            "irrelevancy": 34.22576,
            "logical_agreement": 63.97534,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.33054,
            "nubia_score": 0.89125
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6578947368421053
        },
        "rouge1": {
            "precision": 0.69593,
            "recall": 0.63714,
            "fmeasure": 0.66311
        },
        "rouge2": {
            "precision": 0.39146,
            "recall": 0.32716,
            "fmeasure": 0.35525
        },
        "rougeL": {
            "precision": 0.66259,
            "recall": 0.6054,
            "fmeasure": 0.63064
        },
        "rougeLsum": {
            "precision": 0.66259,
            "recall": 0.6054,
            "fmeasure": 0.63064
        },
        "nist": 3.7714033797674635,
        "bleu": 29.39414,
        "bertscore": {
            "precision": 0.91235,
            "recall": 0.89154,
            "f1": 0.90138
        },
        "bleurt": 0.00864,
        "meteor": 0.325640874268591,
        "nubia": {
            "semantic_relation": 3.39374,
            "contradiction": 22.02644,
            "irrelevancy": 58.20503,
            "logical_agreement": 19.76853,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.2835,
            "nubia_score": 0.56888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "rouge1": {
            "precision": 0.79808,
            "recall": 0.73523,
            "fmeasure": 0.76426
        },
        "rouge2": {
            "precision": 0.39087,
            "recall": 0.37215,
            "fmeasure": 0.38083
        },
        "rougeL": {
            "precision": 0.76442,
            "recall": 0.67551,
            "fmeasure": 0.71407
        },
        "rougeLsum": {
            "precision": 0.76442,
            "recall": 0.67551,
            "fmeasure": 0.71407
        },
        "nist": 3.9926964647338923,
        "bleu": 38.35544,
        "bertscore": {
            "precision": 0.93591,
            "recall": 0.92508,
            "f1": 0.92944
        },
        "bleurt": 0.21028,
        "meteor": 0.38202846624701997,
        "nubia": {
            "semantic_relation": 4.34826,
            "contradiction": 2.04754,
            "irrelevancy": 4.80533,
            "logical_agreement": 93.14713,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.13054,
            "nubia_score": 0.76693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.7291666666666666
        },
        "rouge1": {
            "precision": 0.51892,
            "recall": 0.61695,
            "fmeasure": 0.5523
        },
        "rouge2": {
            "precision": 0.29236,
            "recall": 0.36833,
            "fmeasure": 0.31801
        },
        "rougeL": {
            "precision": 0.42979,
            "recall": 0.4973,
            "fmeasure": 0.45097
        },
        "rougeLsum": {
            "precision": 0.42979,
            "recall": 0.4973,
            "fmeasure": 0.45097
        },
        "nist": 3.444378683683737,
        "bleu": 26.93414,
        "bertscore": {
            "precision": 0.85537,
            "recall": 0.87701,
            "f1": 0.86527
        },
        "bleurt": -0.10867,
        "meteor": 0.35317828585673067,
        "nubia": {
            "semantic_relation": 3.62993,
            "contradiction": 7.32288,
            "irrelevancy": 70.14823,
            "logical_agreement": 22.52889,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.44153,
            "nubia_score": 0.53595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1986532337201607,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.99035,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.83462,
            "fmeasure": 0.77592
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.45278,
            "fmeasure": 0.40097
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.65874,
            "fmeasure": 0.59142
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.65874,
            "fmeasure": 0.59142
        },
        "nist": 3.225277769294053,
        "bleu": 14.88392,
        "bertscore": {
            "precision": 0.90405,
            "recall": 0.91198,
            "f1": 0.90789
        },
        "bleurt": 0.37573,
        "meteor": 0.3762260943883742,
        "nubia": {
            "semantic_relation": 4.40233,
            "contradiction": 1.73286,
            "irrelevancy": 30.79565,
            "logical_agreement": 67.47149,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.27171,
            "nubia_score": 0.74183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "mT5_small/totto_test",
        "N": 9,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22641509433962265,
            "2": 0.3673469387755102,
            "3": 0.6619718309859155
        },
        "rouge1": {
            "precision": 0.61942,
            "recall": 0.56269,
            "fmeasure": 0.57803
        },
        "rouge2": {
            "precision": 0.3177,
            "recall": 0.29493,
            "fmeasure": 0.29569
        },
        "rougeL": {
            "precision": 0.51656,
            "recall": 0.49766,
            "fmeasure": 0.49232
        },
        "rougeLsum": {
            "precision": 0.51656,
            "recall": 0.49766,
            "fmeasure": 0.49232
        },
        "nist": 4.202105801666231,
        "bleu": 23.44793,
        "bertscore": {
            "precision": 0.8778,
            "recall": 0.86906,
            "f1": 0.86925
        },
        "bleurt": -0.0265,
        "meteor": 0.28096711574949296,
        "nubia": {
            "semantic_relation": 3.32901,
            "contradiction": 19.20205,
            "irrelevancy": 35.97628,
            "logical_agreement": 44.82166,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.71432,
            "nubia_score": 0.46906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "mT5_small/totto_test",
        "N": 11,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.038461538461538464,
            "2": 0.3157894736842105,
            "3": 0.7661290322580645
        },
        "rouge1": {
            "precision": 0.81922,
            "recall": 0.75059,
            "fmeasure": 0.7768
        },
        "rouge2": {
            "precision": 0.61819,
            "recall": 0.56107,
            "fmeasure": 0.5819
        },
        "rougeL": {
            "precision": 0.72674,
            "recall": 0.67711,
            "fmeasure": 0.69175
        },
        "rougeLsum": {
            "precision": 0.72674,
            "recall": 0.67711,
            "fmeasure": 0.69175
        },
        "nist": 5.174276968376906,
        "bleu": 48.84652,
        "bertscore": {
            "precision": 0.94012,
            "recall": 0.92744,
            "f1": 0.93193
        },
        "bleurt": 0.3961,
        "meteor": 0.4008525788778329,
        "nubia": {
            "semantic_relation": 4.43741,
            "contradiction": 7.98728,
            "irrelevancy": 18.89524,
            "logical_agreement": 73.11748,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.86296,
            "nubia_score": 0.76354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.3333333333333333,
            "3": 0.9473684210526315
        },
        "rouge1": {
            "precision": 0.76865,
            "recall": 0.90848,
            "fmeasure": 0.82453
        },
        "rouge2": {
            "precision": 0.63668,
            "recall": 0.72674,
            "fmeasure": 0.67181
        },
        "rougeL": {
            "precision": 0.76865,
            "recall": 0.90848,
            "fmeasure": 0.82453
        },
        "rougeLsum": {
            "precision": 0.76865,
            "recall": 0.90848,
            "fmeasure": 0.82453
        },
        "nist": 4.71001398028334,
        "bleu": 53.26461,
        "bertscore": {
            "precision": 0.95441,
            "recall": 0.98122,
            "f1": 0.96743
        },
        "bleurt": 0.70621,
        "meteor": 0.5657337166720289,
        "nubia": {
            "semantic_relation": 4.88523,
            "contradiction": 0.31553,
            "irrelevancy": 34.61965,
            "logical_agreement": 65.06481,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.41198,
            "nubia_score": 0.82986
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.4067796610169492,
            "3": 0.6986301369863014
        },
        "rouge1": {
            "precision": 0.69054,
            "recall": 0.63952,
            "fmeasure": 0.65187
        },
        "rouge2": {
            "precision": 0.43995,
            "recall": 0.40489,
            "fmeasure": 0.4146
        },
        "rougeL": {
            "precision": 0.5369,
            "recall": 0.49807,
            "fmeasure": 0.50776
        },
        "rougeLsum": {
            "precision": 0.5369,
            "recall": 0.49807,
            "fmeasure": 0.50776
        },
        "nist": 5.48325321644476,
        "bleu": 37.81876,
        "bertscore": {
            "precision": 0.90848,
            "recall": 0.89059,
            "f1": 0.89551
        },
        "bleurt": -0.21502,
        "meteor": 0.34759000846518334,
        "nubia": {
            "semantic_relation": 3.38785,
            "contradiction": 15.01911,
            "irrelevancy": 55.82579,
            "logical_agreement": 29.15511,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.53413,
            "nubia_score": 0.48168
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.17647058823529413
        },
        "rouge1": {
            "precision": 0.19298,
            "recall": 0.13723,
            "fmeasure": 0.16039
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.19298,
            "recall": 0.13723,
            "fmeasure": 0.16039
        },
        "rougeLsum": {
            "precision": 0.19298,
            "recall": 0.13723,
            "fmeasure": 0.16039
        },
        "nist": 0.6191877230225886,
        "bleu": 3.46232,
        "bertscore": {
            "precision": 0.76954,
            "recall": 0.75293,
            "f1": 0.76114
        },
        "bleurt": -0.87448,
        "meteor": 0.09377725859068152,
        "nubia": {
            "semantic_relation": 1.24383,
            "contradiction": 45.46172,
            "irrelevancy": 46.08222,
            "logical_agreement": 8.45607,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.28827,
            "nubia_score": 0.07607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.8709677419354839,
            "3": 0.6049382716049383
        },
        "rouge1": {
            "precision": 0.78016,
            "recall": 0.64964,
            "fmeasure": 0.70181
        },
        "rouge2": {
            "precision": 0.52686,
            "recall": 0.4387,
            "fmeasure": 0.47269
        },
        "rougeL": {
            "precision": 0.66478,
            "recall": 0.55824,
            "fmeasure": 0.60092
        },
        "rougeLsum": {
            "precision": 0.66478,
            "recall": 0.55824,
            "fmeasure": 0.60092
        },
        "nist": 5.238722005183225,
        "bleu": 44.28465,
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.88835,
            "f1": 0.90522
        },
        "bleurt": 0.14264,
        "meteor": 0.3616595148844982,
        "nubia": {
            "semantic_relation": 4.17517,
            "contradiction": 7.80983,
            "irrelevancy": 21.49021,
            "logical_agreement": 70.69996,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.8236,
            "nubia_score": 0.69011
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "mT5_small/totto_test",
        "N": 79,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4320388349514563,
            "3": 0.7723840345199569
        },
        "rouge1": {
            "precision": 0.81647,
            "recall": 0.75296,
            "fmeasure": 0.77718
        },
        "rouge2": {
            "precision": 0.58127,
            "recall": 0.53924,
            "fmeasure": 0.55431
        },
        "rougeL": {
            "precision": 0.67112,
            "recall": 0.62006,
            "fmeasure": 0.6392
        },
        "rougeLsum": {
            "precision": 0.67112,
            "recall": 0.62006,
            "fmeasure": 0.6392
        },
        "nist": 7.422367709134218,
        "bleu": 43.90918,
        "bertscore": {
            "precision": 0.94296,
            "recall": 0.9321,
            "f1": 0.93633
        },
        "bleurt": 0.3948,
        "meteor": 0.39467026469762767,
        "nubia": {
            "semantic_relation": 4.39296,
            "contradiction": 9.86352,
            "irrelevancy": 19.13273,
            "logical_agreement": 71.00375,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.85268,
            "nubia_score": 0.77351
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "rouge1": {
            "precision": 0.92121,
            "recall": 0.92121,
            "fmeasure": 0.92121
        },
        "rouge2": {
            "precision": 0.65351,
            "recall": 0.67203,
            "fmeasure": 0.66228
        },
        "rougeL": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "rougeLsum": {
            "precision": 0.7053,
            "recall": 0.72955,
            "fmeasure": 0.71685
        },
        "nist": 4.997333840451075,
        "bleu": 54.47186,
        "bertscore": {
            "precision": 0.96493,
            "recall": 0.96896,
            "f1": 0.96693
        },
        "bleurt": 0.60623,
        "meteor": 0.4715439325255402,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.57754,
            "irrelevancy": 20.30422,
            "logical_agreement": 78.11823,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.10045,
            "nubia_score": 0.96457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.375,
            "3": 0.9270833333333334
        },
        "rouge1": {
            "precision": 0.85152,
            "recall": 0.86033,
            "fmeasure": 0.84863
        },
        "rouge2": {
            "precision": 0.66681,
            "recall": 0.68378,
            "fmeasure": 0.67217
        },
        "rougeL": {
            "precision": 0.7192,
            "recall": 0.73061,
            "fmeasure": 0.72087
        },
        "rougeLsum": {
            "precision": 0.7192,
            "recall": 0.73061,
            "fmeasure": 0.72087
        },
        "nist": 5.489555712797784,
        "bleu": 52.59431,
        "bertscore": {
            "precision": 0.94671,
            "recall": 0.95844,
            "f1": 0.95171
        },
        "bleurt": 0.43454,
        "meteor": 0.46739520405857965,
        "nubia": {
            "semantic_relation": 4.19565,
            "contradiction": 8.64653,
            "irrelevancy": 20.05635,
            "logical_agreement": 71.29713,
            "grammar_ref": 4.87577,
            "grammar_hyp": 4.83206,
            "nubia_score": 0.70537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8775510204081632
        },
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.8953,
            "fmeasure": 0.91529
        },
        "rouge2": {
            "precision": 0.84697,
            "recall": 0.81005,
            "fmeasure": 0.82745
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.87607,
            "fmeasure": 0.89529
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.87607,
            "fmeasure": 0.89529
        },
        "nist": 5.098867791372461,
        "bleu": 71.75009,
        "bertscore": {
            "precision": 0.97889,
            "recall": 0.96172,
            "f1": 0.97014
        },
        "bleurt": 0.78276,
        "meteor": 0.5114471865900768,
        "nubia": {
            "semantic_relation": 4.60374,
            "contradiction": 3.6752,
            "irrelevancy": 1.20217,
            "logical_agreement": 95.12263,
            "grammar_ref": 5.0449,
            "grammar_hyp": 4.96191,
            "nubia_score": 0.85146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "mT5_small/totto_test",
        "N": 131,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22546419098143236,
            "2": 0.4110576923076923,
            "3": 0.7124824684431977
        },
        "rouge1": {
            "precision": 0.75463,
            "recall": 0.68547,
            "fmeasure": 0.70681
        },
        "rouge2": {
            "precision": 0.50376,
            "recall": 0.45684,
            "fmeasure": 0.47131
        },
        "rougeL": {
            "precision": 0.64839,
            "recall": 0.58825,
            "fmeasure": 0.60687
        },
        "rougeLsum": {
            "precision": 0.64839,
            "recall": 0.58825,
            "fmeasure": 0.60687
        },
        "nist": 7.228772401565377,
        "bleu": 40.48305,
        "bertscore": {
            "precision": 0.92592,
            "recall": 0.91266,
            "f1": 0.91811
        },
        "bleurt": 0.20779,
        "meteor": 0.3603119494763806,
        "nubia": {
            "semantic_relation": 4.12832,
            "contradiction": 12.31642,
            "irrelevancy": 25.41353,
            "logical_agreement": 62.27005,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.705,
            "nubia_score": 0.69403
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.463768115942029,
            "3": 0.652542372881356
        },
        "rouge1": {
            "precision": 0.65731,
            "recall": 0.63949,
            "fmeasure": 0.61705
        },
        "rouge2": {
            "precision": 0.3893,
            "recall": 0.37746,
            "fmeasure": 0.36269
        },
        "rougeL": {
            "precision": 0.5237,
            "recall": 0.53289,
            "fmeasure": 0.50268
        },
        "rougeLsum": {
            "precision": 0.5237,
            "recall": 0.53289,
            "fmeasure": 0.50268
        },
        "nist": 5.029255037861571,
        "bleu": 33.61158,
        "bertscore": {
            "precision": 0.89356,
            "recall": 0.88251,
            "f1": 0.88688
        },
        "bleurt": 0.03004,
        "meteor": 0.32467586174368296,
        "nubia": {
            "semantic_relation": 3.50067,
            "contradiction": 25.48534,
            "irrelevancy": 30.57935,
            "logical_agreement": 43.93532,
            "grammar_ref": 4.37064,
            "grammar_hyp": 3.93268,
            "nubia_score": 0.51461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7361111111111112
        },
        "rouge1": {
            "precision": 0.78341,
            "recall": 0.73151,
            "fmeasure": 0.75575
        },
        "rouge2": {
            "precision": 0.59861,
            "recall": 0.56156,
            "fmeasure": 0.5788
        },
        "rougeL": {
            "precision": 0.65732,
            "recall": 0.61986,
            "fmeasure": 0.63746
        },
        "rougeLsum": {
            "precision": 0.65732,
            "recall": 0.61986,
            "fmeasure": 0.63746
        },
        "nist": 4.72993387570635,
        "bleu": 40.14337,
        "bertscore": {
            "precision": 0.94275,
            "recall": 0.89926,
            "f1": 0.92023
        },
        "bleurt": 0.31276,
        "meteor": 0.34117770171008793,
        "nubia": {
            "semantic_relation": 4.02329,
            "contradiction": 25.45979,
            "irrelevancy": 22.82093,
            "logical_agreement": 51.71927,
            "grammar_ref": 4.59177,
            "grammar_hyp": 3.76756,
            "nubia_score": 0.76121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.18181818181818182,
            "3": 0.9056603773584906
        },
        "rouge1": {
            "precision": 0.88481,
            "recall": 0.89339,
            "fmeasure": 0.88626
        },
        "rouge2": {
            "precision": 0.7945,
            "recall": 0.81642,
            "fmeasure": 0.80128
        },
        "rougeL": {
            "precision": 0.83815,
            "recall": 0.84739,
            "fmeasure": 0.83959
        },
        "rougeLsum": {
            "precision": 0.83815,
            "recall": 0.84739,
            "fmeasure": 0.83959
        },
        "nist": 6.22610489809925,
        "bleu": 74.84197,
        "bertscore": {
            "precision": 0.97028,
            "recall": 0.96862,
            "f1": 0.96917
        },
        "bleurt": 0.72561,
        "meteor": 0.525316008026377,
        "nubia": {
            "semantic_relation": 4.77676,
            "contradiction": 0.40826,
            "irrelevancy": 19.7057,
            "logical_agreement": 79.88603,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.02301,
            "nubia_score": 0.908
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.55882,
            "recall": 0.7033,
            "fmeasure": 0.62258
        },
        "rouge2": {
            "precision": 0.40625,
            "recall": 0.51923,
            "fmeasure": 0.45567
        },
        "rougeL": {
            "precision": 0.55882,
            "recall": 0.7033,
            "fmeasure": 0.62258
        },
        "rougeLsum": {
            "precision": 0.55882,
            "recall": 0.7033,
            "fmeasure": 0.62258
        },
        "nist": 2.333500282148517,
        "bleu": 25.33655,
        "bertscore": {
            "precision": 0.91556,
            "recall": 0.95246,
            "f1": 0.93364
        },
        "bleurt": 0.3353,
        "meteor": 0.3176549132246505,
        "nubia": {
            "semantic_relation": 2.80814,
            "contradiction": 67.38909,
            "irrelevancy": 31.54633,
            "logical_agreement": 1.06458,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.1787,
            "nubia_score": 0.42706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.63853,
            "recall": 0.62476,
            "fmeasure": 0.62769
        },
        "rouge2": {
            "precision": 0.34487,
            "recall": 0.31548,
            "fmeasure": 0.32738
        },
        "rougeL": {
            "precision": 0.5119,
            "recall": 0.49006,
            "fmeasure": 0.49778
        },
        "rougeLsum": {
            "precision": 0.5119,
            "recall": 0.49006,
            "fmeasure": 0.49778
        },
        "nist": 3.489200037696561,
        "bleu": 47.37545,
        "bertscore": {
            "precision": 0.92391,
            "recall": 0.91795,
            "f1": 0.91918
        },
        "bleurt": 0.28223,
        "meteor": 0.3999759274650358,
        "nubia": {
            "semantic_relation": 4.22827,
            "contradiction": 0.36232,
            "irrelevancy": 4.46076,
            "logical_agreement": 95.17692,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.9476,
            "nubia_score": 0.80618
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "mT5_small/totto_test",
        "N": 14,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.17647058823529413,
            "3": 0.4714828897338403
        },
        "rouge1": {
            "precision": 0.547,
            "recall": 0.45466,
            "fmeasure": 0.47707
        },
        "rouge2": {
            "precision": 0.23513,
            "recall": 0.19136,
            "fmeasure": 0.20112
        },
        "rougeL": {
            "precision": 0.40417,
            "recall": 0.35471,
            "fmeasure": 0.35981
        },
        "rougeLsum": {
            "precision": 0.40417,
            "recall": 0.35471,
            "fmeasure": 0.35981
        },
        "nist": 3.8107370622330485,
        "bleu": 15.26037,
        "bertscore": {
            "precision": 0.86312,
            "recall": 0.83787,
            "f1": 0.84813
        },
        "bleurt": -0.27726,
        "meteor": 0.2267928392186174,
        "nubia": {
            "semantic_relation": 3.182,
            "contradiction": 21.31438,
            "irrelevancy": 39.02407,
            "logical_agreement": 39.66155,
            "grammar_ref": 3.91022,
            "grammar_hyp": 3.89879,
            "nubia_score": 0.40832
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.15789473684210525,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.5412,
            "recall": 0.39902,
            "fmeasure": 0.43749
        },
        "rouge2": {
            "precision": 0.28227,
            "recall": 0.20647,
            "fmeasure": 0.22457
        },
        "rougeL": {
            "precision": 0.49907,
            "recall": 0.36206,
            "fmeasure": 0.3982
        },
        "rougeLsum": {
            "precision": 0.49907,
            "recall": 0.36206,
            "fmeasure": 0.3982
        },
        "nist": 2.3021608706273056,
        "bleu": 36.26977,
        "bertscore": {
            "precision": 0.85467,
            "recall": 0.83429,
            "f1": 0.83615
        },
        "bleurt": -0.13039,
        "meteor": 0.25702065772607363,
        "nubia": {
            "semantic_relation": 3.45851,
            "contradiction": 32.14723,
            "irrelevancy": 21.89207,
            "logical_agreement": 45.96071,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.61502,
            "nubia_score": 0.48846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "nist": 4.673642355475211,
        "bleu": 78.56293,
        "bertscore": {
            "precision": 0.97641,
            "recall": 0.96546,
            "f1": 0.96962
        },
        "bleurt": 0.6799,
        "meteor": 0.5124329313818176,
        "nubia": {
            "semantic_relation": 4.7361,
            "contradiction": 0.20205,
            "irrelevancy": 0.47436,
            "logical_agreement": 99.32359,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.27871,
            "nubia_score": 0.91305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7333333333333333,
            "3": 0.7878787878787878
        },
        "rouge1": {
            "precision": 0.77388,
            "recall": 0.74179,
            "fmeasure": 0.74122
        },
        "rouge2": {
            "precision": 0.55345,
            "recall": 0.53814,
            "fmeasure": 0.5349
        },
        "rougeL": {
            "precision": 0.74055,
            "recall": 0.72096,
            "fmeasure": 0.71558
        },
        "rougeLsum": {
            "precision": 0.74055,
            "recall": 0.72096,
            "fmeasure": 0.71558
        },
        "nist": 4.790112700430741,
        "bleu": 50.91403,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.92557,
            "f1": 0.92815
        },
        "bleurt": 0.07136,
        "meteor": 0.4368490729173513,
        "nubia": {
            "semantic_relation": 3.91291,
            "contradiction": 5.44637,
            "irrelevancy": 38.25604,
            "logical_agreement": 56.29758,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.25442,
            "nubia_score": 0.61096
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.4,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.66947,
            "recall": 0.73644,
            "fmeasure": 0.6895
        },
        "rouge2": {
            "precision": 0.37814,
            "recall": 0.42459,
            "fmeasure": 0.39253
        },
        "rougeL": {
            "precision": 0.61013,
            "recall": 0.67163,
            "fmeasure": 0.62884
        },
        "rougeLsum": {
            "precision": 0.61013,
            "recall": 0.67163,
            "fmeasure": 0.62884
        },
        "nist": 4.608594295242637,
        "bleu": 37.00763,
        "bertscore": {
            "precision": 0.92069,
            "recall": 0.9339,
            "f1": 0.92049
        },
        "bleurt": 0.2161,
        "meteor": 0.3999629762999293,
        "nubia": {
            "semantic_relation": 3.95219,
            "contradiction": 6.63838,
            "irrelevancy": 44.50403,
            "logical_agreement": 48.8576,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.36333,
            "nubia_score": 0.69311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.83685,
            "recall": 0.72254,
            "fmeasure": 0.75779
        },
        "rouge2": {
            "precision": 0.61438,
            "recall": 0.55053,
            "fmeasure": 0.56865
        },
        "rougeL": {
            "precision": 0.76269,
            "recall": 0.66152,
            "fmeasure": 0.69229
        },
        "rougeLsum": {
            "precision": 0.76269,
            "recall": 0.66152,
            "fmeasure": 0.69229
        },
        "nist": 4.061921022018364,
        "bleu": 43.71614,
        "bertscore": {
            "precision": 0.9565,
            "recall": 0.93151,
            "f1": 0.94337
        },
        "bleurt": 0.21576,
        "meteor": 0.37605116991868964,
        "nubia": {
            "semantic_relation": 4.01115,
            "contradiction": 20.71522,
            "irrelevancy": 7.30349,
            "logical_agreement": 71.98129,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.55642,
            "nubia_score": 0.65511
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.5555555555555556,
            "3": 0.5846153846153846
        },
        "rouge1": {
            "precision": 0.65073,
            "recall": 0.62646,
            "fmeasure": 0.62376
        },
        "rouge2": {
            "precision": 0.39571,
            "recall": 0.37706,
            "fmeasure": 0.3779
        },
        "rougeL": {
            "precision": 0.53981,
            "recall": 0.52442,
            "fmeasure": 0.52094
        },
        "rougeLsum": {
            "precision": 0.53981,
            "recall": 0.52442,
            "fmeasure": 0.52094
        },
        "nist": 4.048714192856721,
        "bleu": 24.67075,
        "bertscore": {
            "precision": 0.9106,
            "recall": 0.90646,
            "f1": 0.90763
        },
        "bleurt": 0.17581,
        "meteor": 0.30174998683637305,
        "nubia": {
            "semantic_relation": 4.17129,
            "contradiction": 4.3785,
            "irrelevancy": 33.01684,
            "logical_agreement": 62.60466,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.13154,
            "nubia_score": 0.7232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.35714285714285715,
            "3": 0.7419354838709677
        },
        "rouge1": {
            "precision": 0.8283,
            "recall": 0.6932,
            "fmeasure": 0.74323
        },
        "rouge2": {
            "precision": 0.61035,
            "recall": 0.50856,
            "fmeasure": 0.54468
        },
        "rougeL": {
            "precision": 0.77701,
            "recall": 0.64807,
            "fmeasure": 0.69542
        },
        "rougeLsum": {
            "precision": 0.77701,
            "recall": 0.64807,
            "fmeasure": 0.69542
        },
        "nist": 3.4650381488268014,
        "bleu": 38.52731,
        "bertscore": {
            "precision": 0.94105,
            "recall": 0.92234,
            "f1": 0.92927
        },
        "bleurt": 0.33189,
        "meteor": 0.35691641983484457,
        "nubia": {
            "semantic_relation": 4.36586,
            "contradiction": 0.5557,
            "irrelevancy": 29.88631,
            "logical_agreement": 69.558,
            "grammar_ref": 4.09757,
            "grammar_hyp": 3.90223,
            "nubia_score": 0.88326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.8846153846153846
        },
        "rouge1": {
            "precision": 0.8913,
            "recall": 0.90316,
            "fmeasure": 0.8971
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.79221,
            "fmeasure": 0.78999
        },
        "rougeL": {
            "precision": 0.71739,
            "recall": 0.72398,
            "fmeasure": 0.72061
        },
        "rougeLsum": {
            "precision": 0.71739,
            "recall": 0.72398,
            "fmeasure": 0.72061
        },
        "nist": 4.776653570136549,
        "bleu": 63.66735,
        "bertscore": {
            "precision": 0.95318,
            "recall": 0.94591,
            "f1": 0.94754
        },
        "bleurt": 0.46489,
        "meteor": 0.46862368306251756,
        "nubia": {
            "semantic_relation": 4.42339,
            "contradiction": 4.03166,
            "irrelevancy": 4.63729,
            "logical_agreement": 91.33105,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.4519,
            "nubia_score": 0.78452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.8518518518518519
        },
        "rouge1": {
            "precision": 0.84661,
            "recall": 0.80416,
            "fmeasure": 0.81529
        },
        "rouge2": {
            "precision": 0.72649,
            "recall": 0.67598,
            "fmeasure": 0.69535
        },
        "rougeL": {
            "precision": 0.82101,
            "recall": 0.77576,
            "fmeasure": 0.78982
        },
        "rougeLsum": {
            "precision": 0.82101,
            "recall": 0.77576,
            "fmeasure": 0.78982
        },
        "nist": 5.039549369703854,
        "bleu": 60.62046,
        "bertscore": {
            "precision": 0.95937,
            "recall": 0.9491,
            "f1": 0.95321
        },
        "bleurt": 0.61267,
        "meteor": 0.45812222447468215,
        "nubia": {
            "semantic_relation": 4.42813,
            "contradiction": 11.82755,
            "irrelevancy": 22.32666,
            "logical_agreement": 65.84579,
            "grammar_ref": 5.07225,
            "grammar_hyp": 5.06299,
            "nubia_score": 0.82552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.97619,
            "recall": 0.65212,
            "fmeasure": 0.76786
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.5641,
            "fmeasure": 0.64912
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.67857,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.67857,
            "fmeasure": 0.7619
        },
        "nist": 2.4664693496825034,
        "bleu": 56.29148,
        "bertscore": {
            "precision": 0.96953,
            "recall": 0.90018,
            "f1": 0.9326
        },
        "bleurt": 0.04188,
        "meteor": 0.3891032873785887,
        "nubia": {
            "semantic_relation": 3.91139,
            "contradiction": 42.02988,
            "irrelevancy": 17.80229,
            "logical_agreement": 40.16783,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.95183,
            "nubia_score": 0.59281
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "mT5_small/totto_test",
        "N": 26,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19540229885057472,
            "2": 0.5268817204301075,
            "3": 0.6909871244635193
        },
        "rouge1": {
            "precision": 0.73022,
            "recall": 0.68549,
            "fmeasure": 0.68642
        },
        "rouge2": {
            "precision": 0.47238,
            "recall": 0.44114,
            "fmeasure": 0.44183
        },
        "rougeL": {
            "precision": 0.6136,
            "recall": 0.58008,
            "fmeasure": 0.57931
        },
        "rougeLsum": {
            "precision": 0.6136,
            "recall": 0.58008,
            "fmeasure": 0.57931
        },
        "nist": 5.554988114058704,
        "bleu": 37.93253,
        "bertscore": {
            "precision": 0.90915,
            "recall": 0.90486,
            "f1": 0.9056
        },
        "bleurt": 0.04964,
        "meteor": 0.3488502948512481,
        "nubia": {
            "semantic_relation": 3.78185,
            "contradiction": 5.1754,
            "irrelevancy": 43.71975,
            "logical_agreement": 51.10485,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.83866,
            "nubia_score": 0.60448
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "mT5_small/totto_test",
        "N": 114,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23733333333333334,
            "2": 0.458128078817734,
            "3": 0.7555358724534986
        },
        "rouge1": {
            "precision": 0.72929,
            "recall": 0.69437,
            "fmeasure": 0.69876
        },
        "rouge2": {
            "precision": 0.47172,
            "recall": 0.45551,
            "fmeasure": 0.45483
        },
        "rougeL": {
            "precision": 0.60016,
            "recall": 0.57551,
            "fmeasure": 0.57619
        },
        "rougeLsum": {
            "precision": 0.60016,
            "recall": 0.57551,
            "fmeasure": 0.57619
        },
        "nist": 7.230968446553921,
        "bleu": 39.34949,
        "bertscore": {
            "precision": 0.91872,
            "recall": 0.90908,
            "f1": 0.91244
        },
        "bleurt": 0.19892,
        "meteor": 0.3679362137332677,
        "nubia": {
            "semantic_relation": 4.14321,
            "contradiction": 9.35087,
            "irrelevancy": 31.02226,
            "logical_agreement": 59.62687,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.81943,
            "nubia_score": 0.69642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.72703,
            "recall": 0.71471,
            "fmeasure": 0.70983
        },
        "rouge2": {
            "precision": 0.42078,
            "recall": 0.41852,
            "fmeasure": 0.41148
        },
        "rougeL": {
            "precision": 0.61211,
            "recall": 0.59402,
            "fmeasure": 0.59184
        },
        "rougeLsum": {
            "precision": 0.61211,
            "recall": 0.59402,
            "fmeasure": 0.59184
        },
        "nist": 4.916760126900333,
        "bleu": 42.94283,
        "bertscore": {
            "precision": 0.91196,
            "recall": 0.90769,
            "f1": 0.90879
        },
        "bleurt": 0.02667,
        "meteor": 0.3985330158016417,
        "nubia": {
            "semantic_relation": 4.15623,
            "contradiction": 38.08281,
            "irrelevancy": 3.74652,
            "logical_agreement": 58.17067,
            "grammar_ref": 4.90076,
            "grammar_hyp": 5.03091,
            "nubia_score": 0.68311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13043478260869565,
            "2": 0.2692307692307692,
            "3": 0.7596153846153846
        },
        "rouge1": {
            "precision": 0.75575,
            "recall": 0.67887,
            "fmeasure": 0.70184
        },
        "rouge2": {
            "precision": 0.46785,
            "recall": 0.42878,
            "fmeasure": 0.44084
        },
        "rougeL": {
            "precision": 0.58442,
            "recall": 0.52358,
            "fmeasure": 0.54211
        },
        "rougeLsum": {
            "precision": 0.58442,
            "recall": 0.52358,
            "fmeasure": 0.54211
        },
        "nist": 4.65759746331265,
        "bleu": 34.51011,
        "bertscore": {
            "precision": 0.93434,
            "recall": 0.92019,
            "f1": 0.92659
        },
        "bleurt": 0.26659,
        "meteor": 0.34266168790261753,
        "nubia": {
            "semantic_relation": 4.2502,
            "contradiction": 16.75872,
            "irrelevancy": 15.49324,
            "logical_agreement": 67.74804,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.84665,
            "nubia_score": 0.70571
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7857142857142857,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.77646,
            "recall": 0.77219,
            "fmeasure": 0.76301
        },
        "rouge2": {
            "precision": 0.48965,
            "recall": 0.47463,
            "fmeasure": 0.47418
        },
        "rougeL": {
            "precision": 0.61243,
            "recall": 0.60765,
            "fmeasure": 0.60089
        },
        "rougeLsum": {
            "precision": 0.61243,
            "recall": 0.60765,
            "fmeasure": 0.60089
        },
        "nist": 4.222206013797819,
        "bleu": 38.25062,
        "bertscore": {
            "precision": 0.92507,
            "recall": 0.93498,
            "f1": 0.92977
        },
        "bleurt": 0.46452,
        "meteor": 0.3928079548378857,
        "nubia": {
            "semantic_relation": 4.17867,
            "contradiction": 22.25474,
            "irrelevancy": 32.91895,
            "logical_agreement": 44.8263,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.39488,
            "nubia_score": 0.74497
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.5714285714285714,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.73877,
            "recall": 0.69381,
            "fmeasure": 0.69406
        },
        "rouge2": {
            "precision": 0.54722,
            "recall": 0.49301,
            "fmeasure": 0.50289
        },
        "rougeL": {
            "precision": 0.70343,
            "recall": 0.66751,
            "fmeasure": 0.66249
        },
        "rougeLsum": {
            "precision": 0.70343,
            "recall": 0.66751,
            "fmeasure": 0.66249
        },
        "nist": 3.89240672086596,
        "bleu": 46.89376,
        "bertscore": {
            "precision": 0.90517,
            "recall": 0.89295,
            "f1": 0.89549
        },
        "bleurt": -0.06088,
        "meteor": 0.3597483852912541,
        "nubia": {
            "semantic_relation": 3.63186,
            "contradiction": 26.7201,
            "irrelevancy": 71.39707,
            "logical_agreement": 1.88283,
            "grammar_ref": 5.36601,
            "grammar_hyp": 5.34173,
            "nubia_score": 0.50423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12,
            "2": 0.9,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.83091,
            "recall": 0.76044,
            "fmeasure": 0.79267
        },
        "rouge2": {
            "precision": 0.58395,
            "recall": 0.53897,
            "fmeasure": 0.55925
        },
        "rougeL": {
            "precision": 0.603,
            "recall": 0.63276,
            "fmeasure": 0.61031
        },
        "rougeLsum": {
            "precision": 0.603,
            "recall": 0.63276,
            "fmeasure": 0.61031
        },
        "nist": 5.552083689039866,
        "bleu": 51.86709,
        "bertscore": {
            "precision": 0.94942,
            "recall": 0.94395,
            "f1": 0.94622
        },
        "bleurt": 0.29871,
        "meteor": 0.4361529740498436,
        "nubia": {
            "semantic_relation": 3.84477,
            "contradiction": 23.36548,
            "irrelevancy": 49.45027,
            "logical_agreement": 27.18425,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.61621,
            "nubia_score": 0.56705
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.40741,
            "fmeasure": 0.49383
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.22549,
            "fmeasure": 0.24667
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.39886,
            "fmeasure": 0.41751
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.39886,
            "fmeasure": 0.41751
        },
        "nist": 2.4148024097777,
        "bleu": 23.73681,
        "bertscore": {
            "precision": 0.88937,
            "recall": 0.84173,
            "f1": 0.85344
        },
        "bleurt": -0.29853,
        "meteor": 0.24842823293162028,
        "nubia": {
            "semantic_relation": 2.50929,
            "contradiction": 0.48634,
            "irrelevancy": 66.15629,
            "logical_agreement": 33.35737,
            "grammar_ref": 4.13721,
            "grammar_hyp": 4.30493,
            "nubia_score": 0.27585
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5166666666666667,
            "3": 0.6195652173913043
        },
        "rouge1": {
            "precision": 0.61217,
            "recall": 0.58074,
            "fmeasure": 0.58735
        },
        "rouge2": {
            "precision": 0.36341,
            "recall": 0.36979,
            "fmeasure": 0.36287
        },
        "rougeL": {
            "precision": 0.53927,
            "recall": 0.5105,
            "fmeasure": 0.5174
        },
        "rougeLsum": {
            "precision": 0.53927,
            "recall": 0.5105,
            "fmeasure": 0.5174
        },
        "nist": 4.548612248666546,
        "bleu": 32.34864,
        "bertscore": {
            "precision": 0.9146,
            "recall": 0.86958,
            "f1": 0.89083
        },
        "bleurt": 0.00461,
        "meteor": 0.2970674752677412,
        "nubia": {
            "semantic_relation": 3.05642,
            "contradiction": 20.20968,
            "irrelevancy": 47.37669,
            "logical_agreement": 32.41363,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.11823,
            "nubia_score": 0.46114
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.8809523809523809
        },
        "rouge1": {
            "precision": 0.73472,
            "recall": 0.83031,
            "fmeasure": 0.77589
        },
        "rouge2": {
            "precision": 0.62032,
            "recall": 0.67879,
            "fmeasure": 0.64455
        },
        "rougeL": {
            "precision": 0.70417,
            "recall": 0.79169,
            "fmeasure": 0.74184
        },
        "rougeLsum": {
            "precision": 0.70417,
            "recall": 0.79169,
            "fmeasure": 0.74184
        },
        "nist": 4.981919236337605,
        "bleu": 64.7022,
        "bertscore": {
            "precision": 0.93917,
            "recall": 0.94971,
            "f1": 0.94406
        },
        "bleurt": 0.45211,
        "meteor": 0.46395565086326057,
        "nubia": {
            "semantic_relation": 4.54113,
            "contradiction": 0.20915,
            "irrelevancy": 66.08061,
            "logical_agreement": 33.71024,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.78575,
            "nubia_score": 0.8944
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.3870967741935484,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.65069,
            "recall": 0.61907,
            "fmeasure": 0.63206
        },
        "rouge2": {
            "precision": 0.42203,
            "recall": 0.39339,
            "fmeasure": 0.40556
        },
        "rougeL": {
            "precision": 0.48271,
            "recall": 0.47334,
            "fmeasure": 0.47406
        },
        "rougeLsum": {
            "precision": 0.48271,
            "recall": 0.47334,
            "fmeasure": 0.47406
        },
        "nist": 3.2635911066099355,
        "bleu": 23.05407,
        "bertscore": {
            "precision": 0.89847,
            "recall": 0.86972,
            "f1": 0.88375
        },
        "bleurt": -0.08215,
        "meteor": 0.27660770566727316,
        "nubia": {
            "semantic_relation": 4.03733,
            "contradiction": 3.75743,
            "irrelevancy": 73.53559,
            "logical_agreement": 22.70698,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.13903,
            "nubia_score": 0.75441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.6912,
            "fmeasure": 0.70247
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.45079,
            "fmeasure": 0.45854
        },
        "rougeL": {
            "precision": 0.60317,
            "recall": 0.58442,
            "fmeasure": 0.59358
        },
        "rougeLsum": {
            "precision": 0.60317,
            "recall": 0.58442,
            "fmeasure": 0.59358
        },
        "nist": 2.9804995803553926,
        "bleu": 28.26169,
        "bertscore": {
            "precision": 0.89629,
            "recall": 0.90813,
            "f1": 0.89865
        },
        "bleurt": -0.12168,
        "meteor": 0.3583089144448012,
        "nubia": {
            "semantic_relation": 3.996,
            "contradiction": 0.16359,
            "irrelevancy": 67.63615,
            "logical_agreement": 32.20026,
            "grammar_ref": 4.70322,
            "grammar_hyp": 4.9406,
            "nubia_score": 0.61904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.9047619047619048
        },
        "rouge1": {
            "precision": 0.84838,
            "recall": 0.86343,
            "fmeasure": 0.85546
        },
        "rouge2": {
            "precision": 0.72745,
            "recall": 0.75359,
            "fmeasure": 0.73971
        },
        "rougeL": {
            "precision": 0.80208,
            "recall": 0.82986,
            "fmeasure": 0.81516
        },
        "rougeLsum": {
            "precision": 0.80208,
            "recall": 0.82986,
            "fmeasure": 0.81516
        },
        "nist": 4.345055612249425,
        "bleu": 61.7749,
        "bertscore": {
            "precision": 0.9414,
            "recall": 0.96042,
            "f1": 0.94605
        },
        "bleurt": 0.32651,
        "meteor": 0.5087752667439124,
        "nubia": {
            "semantic_relation": 3.51164,
            "contradiction": 50.01,
            "irrelevancy": 47.77096,
            "logical_agreement": 2.21904,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.45372,
            "nubia_score": 0.62831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.56085,
            "fmeasure": 0.50774
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.71667,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.71667,
            "fmeasure": 0.65497
        },
        "nist": 3.033201102543045,
        "bleu": 40.89601,
        "bertscore": {
            "precision": 0.93367,
            "recall": 0.96286,
            "f1": 0.94738
        },
        "bleurt": 0.49042,
        "meteor": 0.4090889580327028,
        "nubia": {
            "semantic_relation": 4.32461,
            "contradiction": 0.30577,
            "irrelevancy": 16.74637,
            "logical_agreement": 82.94786,
            "grammar_ref": 5.68329,
            "grammar_hyp": 4.87638,
            "nubia_score": 0.81762
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3939393939393939,
            "2": 0.3611111111111111,
            "3": 0.6548672566371682
        },
        "rouge1": {
            "precision": 0.63704,
            "recall": 0.58667,
            "fmeasure": 0.60563
        },
        "rouge2": {
            "precision": 0.48181,
            "recall": 0.43129,
            "fmeasure": 0.45215
        },
        "rougeL": {
            "precision": 0.59098,
            "recall": 0.54815,
            "fmeasure": 0.56307
        },
        "rougeLsum": {
            "precision": 0.59098,
            "recall": 0.54815,
            "fmeasure": 0.56307
        },
        "nist": 4.13115004073732,
        "bleu": 34.27476,
        "bertscore": {
            "precision": 0.8886,
            "recall": 0.88898,
            "f1": 0.88775
        },
        "bleurt": 0.04131,
        "meteor": 0.33461736866368375,
        "nubia": {
            "semantic_relation": 3.17522,
            "contradiction": 25.43767,
            "irrelevancy": 33.46875,
            "logical_agreement": 41.09359,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.08113,
            "nubia_score": 0.58205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8064516129032258
        },
        "rouge1": {
            "precision": 0.86508,
            "recall": 0.65652,
            "fmeasure": 0.73962
        },
        "rouge2": {
            "precision": 0.47083,
            "recall": 0.39147,
            "fmeasure": 0.42535
        },
        "rougeL": {
            "precision": 0.69841,
            "recall": 0.55139,
            "fmeasure": 0.61154
        },
        "rougeLsum": {
            "precision": 0.69841,
            "recall": 0.55139,
            "fmeasure": 0.61154
        },
        "nist": 4.6824956888014055,
        "bleu": 65.45011,
        "bertscore": {
            "precision": 0.93427,
            "recall": 0.88194,
            "f1": 0.90461
        },
        "bleurt": 0.07916,
        "meteor": 0.380889563870334,
        "nubia": {
            "semantic_relation": 3.37172,
            "contradiction": 0.6094,
            "irrelevancy": 0.90751,
            "logical_agreement": 98.48309,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.03546,
            "nubia_score": 0.55097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2857142857142857,
            "3": 0.84375
        },
        "rouge1": {
            "precision": 0.81926,
            "recall": 0.87084,
            "fmeasure": 0.82417
        },
        "rouge2": {
            "precision": 0.6479,
            "recall": 0.66843,
            "fmeasure": 0.64917
        },
        "rougeL": {
            "precision": 0.65259,
            "recall": 0.69026,
            "fmeasure": 0.65478
        },
        "rougeLsum": {
            "precision": 0.65259,
            "recall": 0.69026,
            "fmeasure": 0.65478
        },
        "nist": 5.244963667924285,
        "bleu": 54.44468,
        "bertscore": {
            "precision": 0.94291,
            "recall": 0.95624,
            "f1": 0.94841
        },
        "bleurt": 0.51773,
        "meteor": 0.4557107152347817,
        "nubia": {
            "semantic_relation": 4.42798,
            "contradiction": 0.38302,
            "irrelevancy": 29.95454,
            "logical_agreement": 69.66245,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.51171,
            "nubia_score": 0.86817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "mT5_small/totto_test",
        "N": 39,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12781954887218044,
            "2": 0.5608465608465608,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.75976,
            "recall": 0.64387,
            "fmeasure": 0.68777
        },
        "rouge2": {
            "precision": 0.51832,
            "recall": 0.44096,
            "fmeasure": 0.46883
        },
        "rougeL": {
            "precision": 0.64885,
            "recall": 0.5579,
            "fmeasure": 0.59189
        },
        "rougeLsum": {
            "precision": 0.64885,
            "recall": 0.5579,
            "fmeasure": 0.59189
        },
        "nist": 6.2824645100337095,
        "bleu": 40.35156,
        "bertscore": {
            "precision": 0.92909,
            "recall": 0.91028,
            "f1": 0.91846
        },
        "bleurt": 0.27904,
        "meteor": 0.3612547627809174,
        "nubia": {
            "semantic_relation": 4.03212,
            "contradiction": 11.91542,
            "irrelevancy": 22.1552,
            "logical_agreement": 65.92938,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.35674,
            "nubia_score": 0.67648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.28205,
            "fmeasure": 0.28205
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.40476,
            "fmeasure": 0.40476
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.40476,
            "fmeasure": 0.40476
        },
        "nist": 3.2269354504553975,
        "bleu": 14.9808,
        "bertscore": {
            "precision": 0.92568,
            "recall": 0.91791,
            "f1": 0.92178
        },
        "bleurt": 0.35443,
        "meteor": 0.3588008192671194,
        "nubia": {
            "semantic_relation": 4.40223,
            "contradiction": 0.309,
            "irrelevancy": 7.34621,
            "logical_agreement": 92.34479,
            "grammar_ref": 5.70189,
            "grammar_hyp": 4.59214,
            "nubia_score": 0.8843
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5384615384615384,
            "3": 0.7666666666666667
        },
        "rouge1": {
            "precision": 0.66749,
            "recall": 0.74142,
            "fmeasure": 0.69973
        },
        "rouge2": {
            "precision": 0.42368,
            "recall": 0.48313,
            "fmeasure": 0.44915
        },
        "rougeL": {
            "precision": 0.5129,
            "recall": 0.58963,
            "fmeasure": 0.54626
        },
        "rougeLsum": {
            "precision": 0.5129,
            "recall": 0.58963,
            "fmeasure": 0.54626
        },
        "nist": 4.629962433879578,
        "bleu": 45.9845,
        "bertscore": {
            "precision": 0.90228,
            "recall": 0.93284,
            "f1": 0.91318
        },
        "bleurt": 0.2889,
        "meteor": 0.4178892534243149,
        "nubia": {
            "semantic_relation": 3.95854,
            "contradiction": 32.39063,
            "irrelevancy": 27.72052,
            "logical_agreement": 39.88885,
            "grammar_ref": 4.38609,
            "grammar_hyp": 3.71786,
            "nubia_score": 0.69579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.67582,
            "fmeasure": 0.63547
        },
        "rouge2": {
            "precision": 0.19048,
            "recall": 0.23737,
            "fmeasure": 0.21128
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.64957,
            "fmeasure": 0.58554
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.64957,
            "fmeasure": 0.58554
        },
        "nist": 2.580405999253558,
        "bleu": 19.83544,
        "bertscore": {
            "precision": 0.8979,
            "recall": 0.90132,
            "f1": 0.89961
        },
        "bleurt": 0.02055,
        "meteor": 0.36045240799426387,
        "nubia": {
            "semantic_relation": 3.5999,
            "contradiction": 40.84375,
            "irrelevancy": 17.94178,
            "logical_agreement": 41.21447,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.51383,
            "nubia_score": 0.52448
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.625
        },
        "rouge1": {
            "precision": 0.23913,
            "recall": 0.6125,
            "fmeasure": 0.34311
        },
        "rouge2": {
            "precision": 0.06818,
            "recall": 0.18254,
            "fmeasure": 0.099
        },
        "rougeL": {
            "precision": 0.13043,
            "recall": 0.3375,
            "fmeasure": 0.18768
        },
        "rougeLsum": {
            "precision": 0.13043,
            "recall": 0.3375,
            "fmeasure": 0.18768
        },
        "nist": 1.0310863704308706,
        "bleu": 4.89986,
        "bertscore": {
            "precision": 0.74505,
            "recall": 0.87279,
            "f1": 0.80097
        },
        "bleurt": -0.16094,
        "meteor": 0.2582635731240694,
        "nubia": {
            "semantic_relation": 3.74479,
            "contradiction": 0.28114,
            "irrelevancy": 79.45057,
            "logical_agreement": 20.26828,
            "grammar_ref": 6.57359,
            "grammar_hyp": 4.30861,
            "nubia_score": 0.17277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7391304347826086
        },
        "rouge1": {
            "precision": 0.55882,
            "recall": 0.54286,
            "fmeasure": 0.55072
        },
        "rouge2": {
            "precision": 0.20202,
            "recall": 0.19608,
            "fmeasure": 0.199
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.45714,
            "fmeasure": 0.46377
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.45714,
            "fmeasure": 0.46377
        },
        "nist": 2.819289397674124,
        "bleu": 8.252,
        "bertscore": {
            "precision": 0.9013,
            "recall": 0.89034,
            "f1": 0.89331
        },
        "bleurt": -0.10773,
        "meteor": 0.3289079653897614,
        "nubia": {
            "semantic_relation": 3.54155,
            "contradiction": 79.15455,
            "irrelevancy": 13.15141,
            "logical_agreement": 7.69405,
            "grammar_ref": 5.19058,
            "grammar_hyp": 4.63764,
            "nubia_score": 0.59444
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.23809523809523808,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.6186,
            "recall": 0.57036,
            "fmeasure": 0.58535
        },
        "rouge2": {
            "precision": 0.38828,
            "recall": 0.34451,
            "fmeasure": 0.36083
        },
        "rougeL": {
            "precision": 0.49963,
            "recall": 0.46358,
            "fmeasure": 0.47477
        },
        "rougeLsum": {
            "precision": 0.49963,
            "recall": 0.46358,
            "fmeasure": 0.47477
        },
        "nist": 3.0848823953685836,
        "bleu": 19.00945,
        "bertscore": {
            "precision": 0.88078,
            "recall": 0.86785,
            "f1": 0.87372
        },
        "bleurt": 0.03626,
        "meteor": 0.24350548870552316,
        "nubia": {
            "semantic_relation": 3.44399,
            "contradiction": 9.2495,
            "irrelevancy": 38.06291,
            "logical_agreement": 52.68758,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.46119,
            "nubia_score": 0.66982
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.36363636363636365,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.52024,
            "recall": 0.52961,
            "fmeasure": 0.50401
        },
        "rouge2": {
            "precision": 0.28514,
            "recall": 0.27874,
            "fmeasure": 0.2712
        },
        "rougeL": {
            "precision": 0.45278,
            "recall": 0.45627,
            "fmeasure": 0.43714
        },
        "rougeLsum": {
            "precision": 0.45278,
            "recall": 0.45627,
            "fmeasure": 0.43714
        },
        "nist": 3.423960893091975,
        "bleu": 21.03368,
        "bertscore": {
            "precision": 0.86756,
            "recall": 0.87538,
            "f1": 0.86969
        },
        "bleurt": -0.25947,
        "meteor": 0.2633974827793646,
        "nubia": {
            "semantic_relation": 2.97603,
            "contradiction": 47.3535,
            "irrelevancy": 40.53197,
            "logical_agreement": 12.11452,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.27009,
            "nubia_score": 0.41966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.5625,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.75979,
            "recall": 0.74059,
            "fmeasure": 0.74525
        },
        "rouge2": {
            "precision": 0.60829,
            "recall": 0.57585,
            "fmeasure": 0.5875
        },
        "rougeL": {
            "precision": 0.7192,
            "recall": 0.68099,
            "fmeasure": 0.69569
        },
        "rougeLsum": {
            "precision": 0.7192,
            "recall": 0.68099,
            "fmeasure": 0.69569
        },
        "nist": 4.784501615678186,
        "bleu": 50.25097,
        "bertscore": {
            "precision": 0.9413,
            "recall": 0.9281,
            "f1": 0.93015
        },
        "bleurt": 0.32648,
        "meteor": 0.42862204153240135,
        "nubia": {
            "semantic_relation": 3.93877,
            "contradiction": 28.32467,
            "irrelevancy": 17.59467,
            "logical_agreement": 54.08066,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.12957,
            "nubia_score": 0.6855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.25,
            "3": 0.7571428571428571
        },
        "rouge1": {
            "precision": 0.82626,
            "recall": 0.71265,
            "fmeasure": 0.76132
        },
        "rouge2": {
            "precision": 0.65391,
            "recall": 0.55097,
            "fmeasure": 0.59189
        },
        "rougeL": {
            "precision": 0.7223,
            "recall": 0.62311,
            "fmeasure": 0.66452
        },
        "rougeLsum": {
            "precision": 0.7223,
            "recall": 0.62311,
            "fmeasure": 0.66452
        },
        "nist": 4.7385322661990035,
        "bleu": 48.26044,
        "bertscore": {
            "precision": 0.93139,
            "recall": 0.92024,
            "f1": 0.92404
        },
        "bleurt": 0.30447,
        "meteor": 0.39141967028542013,
        "nubia": {
            "semantic_relation": 4.27638,
            "contradiction": 1.25046,
            "irrelevancy": 22.78557,
            "logical_agreement": 75.96396,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.69813,
            "nubia_score": 0.7418
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.28125,
            "3": 0.4691358024691358
        },
        "rouge1": {
            "precision": 0.50337,
            "recall": 0.45026,
            "fmeasure": 0.4538
        },
        "rouge2": {
            "precision": 0.2406,
            "recall": 0.22086,
            "fmeasure": 0.21947
        },
        "rougeL": {
            "precision": 0.38178,
            "recall": 0.34689,
            "fmeasure": 0.3443
        },
        "rougeLsum": {
            "precision": 0.38178,
            "recall": 0.34689,
            "fmeasure": 0.3443
        },
        "nist": 3.1795818316003013,
        "bleu": 17.92183,
        "bertscore": {
            "precision": 0.86303,
            "recall": 0.84761,
            "f1": 0.85264
        },
        "bleurt": -0.15297,
        "meteor": 0.24002211920410735,
        "nubia": {
            "semantic_relation": 3.14606,
            "contradiction": 24.96328,
            "irrelevancy": 23.43082,
            "logical_agreement": 51.60589,
            "grammar_ref": 4.13756,
            "grammar_hyp": 3.19868,
            "nubia_score": 0.53036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 1.0,
            "3": 0.8444444444444444
        },
        "rouge1": {
            "precision": 0.68547,
            "recall": 0.80024,
            "fmeasure": 0.72302
        },
        "rouge2": {
            "precision": 0.48621,
            "recall": 0.58176,
            "fmeasure": 0.51601
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.70477,
            "fmeasure": 0.62698
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.70477,
            "fmeasure": 0.62698
        },
        "nist": 4.246379311958227,
        "bleu": 39.65518,
        "bertscore": {
            "precision": 0.91572,
            "recall": 0.94265,
            "f1": 0.92459
        },
        "bleurt": 0.30201,
        "meteor": 0.43806322419115673,
        "nubia": {
            "semantic_relation": 4.14788,
            "contradiction": 18.47891,
            "irrelevancy": 34.7041,
            "logical_agreement": 46.81699,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.29866,
            "nubia_score": 0.70507
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.60248,
            "recall": 0.53964,
            "fmeasure": 0.56453
        },
        "rouge2": {
            "precision": 0.30396,
            "recall": 0.29129,
            "fmeasure": 0.29574
        },
        "rougeL": {
            "precision": 0.5026,
            "recall": 0.45278,
            "fmeasure": 0.47227
        },
        "rougeLsum": {
            "precision": 0.5026,
            "recall": 0.45278,
            "fmeasure": 0.47227
        },
        "nist": 2.6668901096232673,
        "bleu": 12.99047,
        "bertscore": {
            "precision": 0.87445,
            "recall": 0.83826,
            "f1": 0.8542
        },
        "bleurt": -0.02601,
        "meteor": 0.21689932410138327,
        "nubia": {
            "semantic_relation": 3.01896,
            "contradiction": 56.74981,
            "irrelevancy": 24.96831,
            "logical_agreement": 18.28188,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.30291,
            "nubia_score": 0.42181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "mT5_small/totto_test",
        "N": 13,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.45098039215686275,
            "3": 0.7723577235772358
        },
        "rouge1": {
            "precision": 0.69404,
            "recall": 0.69372,
            "fmeasure": 0.68424
        },
        "rouge2": {
            "precision": 0.45388,
            "recall": 0.4566,
            "fmeasure": 0.45012
        },
        "rougeL": {
            "precision": 0.55634,
            "recall": 0.57496,
            "fmeasure": 0.55819
        },
        "rougeLsum": {
            "precision": 0.55634,
            "recall": 0.57496,
            "fmeasure": 0.55819
        },
        "nist": 5.433464244333404,
        "bleu": 41.41083,
        "bertscore": {
            "precision": 0.89424,
            "recall": 0.89553,
            "f1": 0.89278
        },
        "bleurt": 0.05894,
        "meteor": 0.37047173094834684,
        "nubia": {
            "semantic_relation": 4.15367,
            "contradiction": 0.41297,
            "irrelevancy": 44.56982,
            "logical_agreement": 55.01722,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.80506,
            "nubia_score": 0.72431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "nist": 3.6451714496047405,
        "bleu": 55.83948,
        "bertscore": {
            "precision": 0.94907,
            "recall": 0.93812,
            "f1": 0.94353
        },
        "bleurt": 0.67063,
        "meteor": 0.4336185492206869,
        "nubia": {
            "semantic_relation": 4.99771,
            "contradiction": 0.25029,
            "irrelevancy": 0.44471,
            "logical_agreement": 99.30501,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.0976,
            "nubia_score": 0.99587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5609756097560976,
            "2": 0.5714285714285714,
            "3": 0.7916666666666666
        },
        "rouge1": {
            "precision": 0.68842,
            "recall": 0.72233,
            "fmeasure": 0.69755
        },
        "rouge2": {
            "precision": 0.46726,
            "recall": 0.51531,
            "fmeasure": 0.47923
        },
        "rougeL": {
            "precision": 0.57592,
            "recall": 0.60317,
            "fmeasure": 0.58316
        },
        "rougeLsum": {
            "precision": 0.57592,
            "recall": 0.60317,
            "fmeasure": 0.58316
        },
        "nist": 5.106486315574228,
        "bleu": 45.41393,
        "bertscore": {
            "precision": 0.92667,
            "recall": 0.93167,
            "f1": 0.92605
        },
        "bleurt": 0.05415,
        "meteor": 0.43291865136463664,
        "nubia": {
            "semantic_relation": 3.595,
            "contradiction": 30.20063,
            "irrelevancy": 33.15377,
            "logical_agreement": 36.6456,
            "grammar_ref": 5.12618,
            "grammar_hyp": 5.14155,
            "nubia_score": 0.50943
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.49762,
            "fmeasure": 0.48519
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.18718,
            "fmeasure": 0.1873
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.38571,
            "fmeasure": 0.37778
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.38571,
            "fmeasure": 0.37778
        },
        "nist": 2.22020357119417,
        "bleu": 15.64516,
        "bertscore": {
            "precision": 0.87452,
            "recall": 0.9087,
            "f1": 0.89128
        },
        "bleurt": 0.27614,
        "meteor": 0.27218306812058696,
        "nubia": {
            "semantic_relation": 3.71386,
            "contradiction": 2.35336,
            "irrelevancy": 97.03017,
            "logical_agreement": 0.61647,
            "grammar_ref": 4.03834,
            "grammar_hyp": 3.32364,
            "nubia_score": 0.66337
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.85205,
            "fmeasure": 0.81257
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.575,
            "fmeasure": 0.5471
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.74153,
            "fmeasure": 0.64646
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.74153,
            "fmeasure": 0.64646
        },
        "nist": 4.289021035981256,
        "bleu": 39.20906,
        "bertscore": {
            "precision": 0.93265,
            "recall": 0.92998,
            "f1": 0.93127
        },
        "bleurt": 0.33672,
        "meteor": 0.45753496644158825,
        "nubia": {
            "semantic_relation": 4.64249,
            "contradiction": 4.93295,
            "irrelevancy": 47.69744,
            "logical_agreement": 47.36962,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.2539,
            "nubia_score": 0.82976
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "mT5_small/totto_test",
        "N": 162,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15749235474006115,
            "2": 0.3167420814479638,
            "3": 0.7349014621741895
        },
        "rouge1": {
            "precision": 0.75225,
            "recall": 0.69506,
            "fmeasure": 0.70965
        },
        "rouge2": {
            "precision": 0.49309,
            "recall": 0.45187,
            "fmeasure": 0.4623
        },
        "rougeL": {
            "precision": 0.64313,
            "recall": 0.59297,
            "fmeasure": 0.60534
        },
        "rougeLsum": {
            "precision": 0.64313,
            "recall": 0.59297,
            "fmeasure": 0.60534
        },
        "nist": 7.084955768878579,
        "bleu": 40.7309,
        "bertscore": {
            "precision": 0.92666,
            "recall": 0.91671,
            "f1": 0.91969
        },
        "bleurt": 0.24784,
        "meteor": 0.3726046085397624,
        "nubia": {
            "semantic_relation": 4.01459,
            "contradiction": 26.88917,
            "irrelevancy": 21.1795,
            "logical_agreement": 51.93133,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.61514,
            "nubia_score": 0.66536
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8813559322033898
        },
        "rouge1": {
            "precision": 0.88648,
            "recall": 0.89298,
            "fmeasure": 0.88939
        },
        "rouge2": {
            "precision": 0.76089,
            "recall": 0.76565,
            "fmeasure": 0.76296
        },
        "rougeL": {
            "precision": 0.88648,
            "recall": 0.89298,
            "fmeasure": 0.88939
        },
        "rougeLsum": {
            "precision": 0.88648,
            "recall": 0.89298,
            "fmeasure": 0.88939
        },
        "nist": 5.348904229147412,
        "bleu": 66.34415,
        "bertscore": {
            "precision": 0.98639,
            "recall": 0.98354,
            "f1": 0.98494
        },
        "bleurt": 0.81073,
        "meteor": 0.5013096526668773,
        "nubia": {
            "semantic_relation": 4.55155,
            "contradiction": 0.48586,
            "irrelevancy": 0.80211,
            "logical_agreement": 98.71204,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.85366,
            "nubia_score": 0.82956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "nist": 2.55922317558127,
        "bleu": 34.46073,
        "bertscore": {
            "precision": 0.86572,
            "recall": 0.90337,
            "f1": 0.88414
        },
        "bleurt": -0.01097,
        "meteor": 0.3946343248134507,
        "nubia": {
            "semantic_relation": 4.24922,
            "contradiction": 0.08815,
            "irrelevancy": 99.71957,
            "logical_agreement": 0.19227,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.57605,
            "nubia_score": 0.87191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.125,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.65242,
            "recall": 0.62887,
            "fmeasure": 0.61603
        },
        "rouge2": {
            "precision": 0.46528,
            "recall": 0.42756,
            "fmeasure": 0.43456
        },
        "rougeL": {
            "precision": 0.52279,
            "recall": 0.54279,
            "fmeasure": 0.5126
        },
        "rougeLsum": {
            "precision": 0.52279,
            "recall": 0.54279,
            "fmeasure": 0.5126
        },
        "nist": 3.5292346388187483,
        "bleu": 29.44814,
        "bertscore": {
            "precision": 0.89408,
            "recall": 0.90246,
            "f1": 0.89115
        },
        "bleurt": -0.30278,
        "meteor": 0.30599628268823004,
        "nubia": {
            "semantic_relation": 3.2697,
            "contradiction": 73.08718,
            "irrelevancy": 19.90462,
            "logical_agreement": 7.0082,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.80602,
            "nubia_score": 0.32569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6037735849056604
        },
        "rouge1": {
            "precision": 0.77076,
            "recall": 0.70423,
            "fmeasure": 0.72503
        },
        "rouge2": {
            "precision": 0.55026,
            "recall": 0.52972,
            "fmeasure": 0.5341
        },
        "rougeL": {
            "precision": 0.67836,
            "recall": 0.641,
            "fmeasure": 0.65157
        },
        "rougeLsum": {
            "precision": 0.67836,
            "recall": 0.641,
            "fmeasure": 0.65157
        },
        "nist": 3.4064520727607097,
        "bleu": 36.85359,
        "bertscore": {
            "precision": 0.92994,
            "recall": 0.90191,
            "f1": 0.9149
        },
        "bleurt": 0.30305,
        "meteor": 0.3293528652053645,
        "nubia": {
            "semantic_relation": 3.86592,
            "contradiction": 28.06738,
            "irrelevancy": 25.25344,
            "logical_agreement": 46.67918,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.41663,
            "nubia_score": 0.59002
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.16666666666666666,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.82963,
            "recall": 0.62747,
            "fmeasure": 0.70802
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.47354,
            "fmeasure": 0.53943
        },
        "rougeL": {
            "precision": 0.82963,
            "recall": 0.62747,
            "fmeasure": 0.70802
        },
        "rougeLsum": {
            "precision": 0.82963,
            "recall": 0.62747,
            "fmeasure": 0.70802
        },
        "nist": 2.3019005787122517,
        "bleu": 41.7198,
        "bertscore": {
            "precision": 0.94582,
            "recall": 0.90017,
            "f1": 0.92233
        },
        "bleurt": 0.19249,
        "meteor": 0.33132140274271,
        "nubia": {
            "semantic_relation": 3.47597,
            "contradiction": 13.82293,
            "irrelevancy": 21.34112,
            "logical_agreement": 64.83595,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.67669,
            "nubia_score": 0.47509
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30434782608695654,
            "2": 0.5925925925925926,
            "3": 0.7789473684210526
        },
        "rouge1": {
            "precision": 0.77751,
            "recall": 0.72069,
            "fmeasure": 0.72391
        },
        "rouge2": {
            "precision": 0.55064,
            "recall": 0.47811,
            "fmeasure": 0.49885
        },
        "rougeL": {
            "precision": 0.67348,
            "recall": 0.60454,
            "fmeasure": 0.61914
        },
        "rougeLsum": {
            "precision": 0.67348,
            "recall": 0.60454,
            "fmeasure": 0.61914
        },
        "nist": 5.590228396219168,
        "bleu": 49.88424,
        "bertscore": {
            "precision": 0.93158,
            "recall": 0.91676,
            "f1": 0.9229
        },
        "bleurt": 0.26868,
        "meteor": 0.39677784613399586,
        "nubia": {
            "semantic_relation": 4.24841,
            "contradiction": 0.52816,
            "irrelevancy": 37.17437,
            "logical_agreement": 62.29747,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.38818,
            "nubia_score": 0.70802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.2,
            "3": 0.55
        },
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.62546,
            "fmeasure": 0.56997
        },
        "rouge2": {
            "precision": 0.32082,
            "recall": 0.34789,
            "fmeasure": 0.328
        },
        "rougeL": {
            "precision": 0.50694,
            "recall": 0.55944,
            "fmeasure": 0.5239
        },
        "rougeLsum": {
            "precision": 0.50694,
            "recall": 0.55944,
            "fmeasure": 0.5239
        },
        "nist": 3.440129865666256,
        "bleu": 30.27401,
        "bertscore": {
            "precision": 0.92248,
            "recall": 0.89415,
            "f1": 0.90809
        },
        "bleurt": 0.13733,
        "meteor": 0.32101323837439233,
        "nubia": {
            "semantic_relation": 4.16833,
            "contradiction": 11.68962,
            "irrelevancy": 13.0003,
            "logical_agreement": 75.31008,
            "grammar_ref": 5.35082,
            "grammar_hyp": 3.67754,
            "nubia_score": 0.94906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.8666666666666667,
            "3": 0.48484848484848486
        },
        "rouge1": {
            "precision": 0.65735,
            "recall": 0.57646,
            "fmeasure": 0.60481
        },
        "rouge2": {
            "precision": 0.37063,
            "recall": 0.29874,
            "fmeasure": 0.32531
        },
        "rougeL": {
            "precision": 0.6092,
            "recall": 0.52427,
            "fmeasure": 0.55495
        },
        "rougeLsum": {
            "precision": 0.6092,
            "recall": 0.52427,
            "fmeasure": 0.55495
        },
        "nist": 3.406633661259476,
        "bleu": 23.53354,
        "bertscore": {
            "precision": 0.90788,
            "recall": 0.90051,
            "f1": 0.90389
        },
        "bleurt": 0.12988,
        "meteor": 0.2837123837834092,
        "nubia": {
            "semantic_relation": 3.68235,
            "contradiction": 4.78065,
            "irrelevancy": 58.04179,
            "logical_agreement": 37.17756,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.11663,
            "nubia_score": 0.57837
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.08333333333333333,
            "3": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.32909,
            "fmeasure": 0.46999
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.13056,
            "fmeasure": 0.19067
        },
        "rougeL": {
            "precision": 0.62745,
            "recall": 0.24072,
            "fmeasure": 0.34775
        },
        "rougeLsum": {
            "precision": 0.62745,
            "recall": 0.24072,
            "fmeasure": 0.34775
        },
        "nist": 0.13011124749010777,
        "bleu": 5.76481,
        "bertscore": {
            "precision": 0.88836,
            "recall": 0.80721,
            "f1": 0.84542
        },
        "bleurt": -0.67907,
        "meteor": 0.1547759723940581,
        "nubia": {
            "semantic_relation": 3.28083,
            "contradiction": 1.5315,
            "irrelevancy": 98.08329,
            "logical_agreement": 0.3852,
            "grammar_ref": 4.78179,
            "grammar_hyp": 5.10061,
            "nubia_score": 0.20012
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.23809523809523808,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.5752,
            "recall": 0.50601,
            "fmeasure": 0.53627
        },
        "rouge2": {
            "precision": 0.31096,
            "recall": 0.2645,
            "fmeasure": 0.28477
        },
        "rougeL": {
            "precision": 0.44702,
            "recall": 0.39606,
            "fmeasure": 0.41836
        },
        "rougeLsum": {
            "precision": 0.44702,
            "recall": 0.39606,
            "fmeasure": 0.41836
        },
        "nist": 3.1694287203069194,
        "bleu": 26.25414,
        "bertscore": {
            "precision": 0.8904,
            "recall": 0.87432,
            "f1": 0.88176
        },
        "bleurt": -0.3484,
        "meteor": 0.26465935382056605,
        "nubia": {
            "semantic_relation": 2.98982,
            "contradiction": 89.10039,
            "irrelevancy": 8.45764,
            "logical_agreement": 2.44196,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.76998,
            "nubia_score": 0.38768
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3181818181818182,
            "3": 0.49122807017543857
        },
        "rouge1": {
            "precision": 0.6105,
            "recall": 0.45783,
            "fmeasure": 0.47786
        },
        "rouge2": {
            "precision": 0.35836,
            "recall": 0.29667,
            "fmeasure": 0.2919
        },
        "rougeL": {
            "precision": 0.60633,
            "recall": 0.45475,
            "fmeasure": 0.47431
        },
        "rougeLsum": {
            "precision": 0.60633,
            "recall": 0.45475,
            "fmeasure": 0.47431
        },
        "nist": 2.7726983928762095,
        "bleu": 28.34846,
        "bertscore": {
            "precision": 0.85736,
            "recall": 0.84762,
            "f1": 0.8458
        },
        "bleurt": -0.46198,
        "meteor": 0.25519757692009304,
        "nubia": {
            "semantic_relation": 3.05498,
            "contradiction": 6.6448,
            "irrelevancy": 25.19972,
            "logical_agreement": 68.15548,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.93085,
            "nubia_score": 0.32698
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.4444444444444444,
            "3": 0.7681159420289855
        },
        "rouge1": {
            "precision": 0.77272,
            "recall": 0.73639,
            "fmeasure": 0.74114
        },
        "rouge2": {
            "precision": 0.55463,
            "recall": 0.52686,
            "fmeasure": 0.53111
        },
        "rougeL": {
            "precision": 0.61448,
            "recall": 0.60545,
            "fmeasure": 0.60116
        },
        "rougeLsum": {
            "precision": 0.61448,
            "recall": 0.60545,
            "fmeasure": 0.60116
        },
        "nist": 5.044910373225721,
        "bleu": 44.70153,
        "bertscore": {
            "precision": 0.92209,
            "recall": 0.9092,
            "f1": 0.91476
        },
        "bleurt": 0.25648,
        "meteor": 0.40155842605249825,
        "nubia": {
            "semantic_relation": 4.19215,
            "contradiction": 21.16899,
            "irrelevancy": 23.81682,
            "logical_agreement": 55.01419,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.05003,
            "nubia_score": 0.70093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6984126984126984
        },
        "rouge1": {
            "precision": 0.67688,
            "recall": 0.67608,
            "fmeasure": 0.66376
        },
        "rouge2": {
            "precision": 0.43997,
            "recall": 0.44612,
            "fmeasure": 0.4338
        },
        "rougeL": {
            "precision": 0.54789,
            "recall": 0.52598,
            "fmeasure": 0.52526
        },
        "rougeLsum": {
            "precision": 0.54789,
            "recall": 0.52598,
            "fmeasure": 0.52526
        },
        "nist": 4.044414714120617,
        "bleu": 37.25071,
        "bertscore": {
            "precision": 0.92298,
            "recall": 0.89432,
            "f1": 0.9078
        },
        "bleurt": 0.23708,
        "meteor": 0.36051666179973957,
        "nubia": {
            "semantic_relation": 4.00455,
            "contradiction": 7.45,
            "irrelevancy": 11.7014,
            "logical_agreement": 80.8486,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.41342,
            "nubia_score": 0.72819
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.5294117647058824,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.70556,
            "recall": 0.82143,
            "fmeasure": 0.73648
        },
        "rouge2": {
            "precision": 0.53021,
            "recall": 0.59362,
            "fmeasure": 0.53912
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.74074,
            "fmeasure": 0.66256
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.74074,
            "fmeasure": 0.66256
        },
        "nist": 4.24417066669908,
        "bleu": 41.8565,
        "bertscore": {
            "precision": 0.8901,
            "recall": 0.93398,
            "f1": 0.90791
        },
        "bleurt": 0.24013,
        "meteor": 0.3532417592086352,
        "nubia": {
            "semantic_relation": 3.77478,
            "contradiction": 11.15936,
            "irrelevancy": 51.75395,
            "logical_agreement": 37.08668,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.67651,
            "nubia_score": 0.66197
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 1.00634,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8679245283018868
        },
        "rouge1": {
            "precision": 0.92517,
            "recall": 0.86018,
            "fmeasure": 0.88689
        },
        "rouge2": {
            "precision": 0.84186,
            "recall": 0.79491,
            "fmeasure": 0.81381
        },
        "rougeL": {
            "precision": 0.87399,
            "recall": 0.82199,
            "fmeasure": 0.8434
        },
        "rougeLsum": {
            "precision": 0.87399,
            "recall": 0.82199,
            "fmeasure": 0.8434
        },
        "nist": 6.0729659352503775,
        "bleu": 69.92686,
        "bertscore": {
            "precision": 0.9684,
            "recall": 0.95079,
            "f1": 0.95887
        },
        "bleurt": 0.56065,
        "meteor": 0.48593145329507453,
        "nubia": {
            "semantic_relation": 4.38518,
            "contradiction": 2.47457,
            "irrelevancy": 17.5402,
            "logical_agreement": 79.98522,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.26656,
            "nubia_score": 0.76183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.93333,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "nist": 4.2252432046274455,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.70774,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.88076,
            "contradiction": 0.60152,
            "irrelevancy": 0.50659,
            "logical_agreement": 98.89189,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.56087,
            "nubia_score": 0.92103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.78065,
            "recall": 0.81601,
            "fmeasure": 0.78359
        },
        "rouge2": {
            "precision": 0.59193,
            "recall": 0.59436,
            "fmeasure": 0.58017
        },
        "rougeL": {
            "precision": 0.78065,
            "recall": 0.81601,
            "fmeasure": 0.78359
        },
        "rougeLsum": {
            "precision": 0.78065,
            "recall": 0.81601,
            "fmeasure": 0.78359
        },
        "nist": 4.20838013019552,
        "bleu": 52.56863,
        "bertscore": {
            "precision": 0.94937,
            "recall": 0.94576,
            "f1": 0.94578
        },
        "bleurt": 0.42236,
        "meteor": 0.487809942368858,
        "nubia": {
            "semantic_relation": 4.42515,
            "contradiction": 0.51814,
            "irrelevancy": 47.03393,
            "logical_agreement": 52.44793,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.78503,
            "nubia_score": 0.80955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.625,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.67063,
            "fmeasure": 0.5119
        },
        "rouge2": {
            "precision": 0.19444,
            "recall": 0.29327,
            "fmeasure": 0.23201
        },
        "rougeL": {
            "precision": 0.34211,
            "recall": 0.54365,
            "fmeasure": 0.41558
        },
        "rougeLsum": {
            "precision": 0.34211,
            "recall": 0.54365,
            "fmeasure": 0.41558
        },
        "nist": 2.2875205854110097,
        "bleu": 29.06515,
        "bertscore": {
            "precision": 0.85583,
            "recall": 0.89231,
            "f1": 0.87369
        },
        "bleurt": 0.3147,
        "meteor": 0.3416940245885725,
        "nubia": {
            "semantic_relation": 3.3347,
            "contradiction": 33.55361,
            "irrelevancy": 64.77954,
            "logical_agreement": 1.66685,
            "grammar_ref": 5.58883,
            "grammar_hyp": 3.50338,
            "nubia_score": 0.59394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "nist": 4.433288378057127,
        "bleu": 78.39204,
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        },
        "bleurt": 0.61374,
        "meteor": 0.5347033086663171,
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "mT5_small/totto_test",
        "N": 36,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28205128205128205,
            "2": 0.4632352941176471,
            "3": 0.7010050251256281
        },
        "rouge1": {
            "precision": 0.69942,
            "recall": 0.65872,
            "fmeasure": 0.66674
        },
        "rouge2": {
            "precision": 0.42435,
            "recall": 0.39849,
            "fmeasure": 0.40358
        },
        "rougeL": {
            "precision": 0.58949,
            "recall": 0.55804,
            "fmeasure": 0.56266
        },
        "rougeLsum": {
            "precision": 0.58949,
            "recall": 0.55804,
            "fmeasure": 0.56266
        },
        "nist": 5.932948444009119,
        "bleu": 33.33119,
        "bertscore": {
            "precision": 0.91669,
            "recall": 0.90768,
            "f1": 0.91089
        },
        "bleurt": 0.19233,
        "meteor": 0.3417449815863432,
        "nubia": {
            "semantic_relation": 4.06295,
            "contradiction": 20.39886,
            "irrelevancy": 25.08964,
            "logical_agreement": 54.51151,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.69248,
            "nubia_score": 0.69409
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25,
            "3": 0.6883116883116883
        },
        "rouge1": {
            "precision": 0.83746,
            "recall": 0.71034,
            "fmeasure": 0.76498
        },
        "rouge2": {
            "precision": 0.64315,
            "recall": 0.55313,
            "fmeasure": 0.5916
        },
        "rougeL": {
            "precision": 0.66331,
            "recall": 0.58853,
            "fmeasure": 0.61995
        },
        "rougeLsum": {
            "precision": 0.66331,
            "recall": 0.58853,
            "fmeasure": 0.61995
        },
        "nist": 4.910981125138128,
        "bleu": 49.1444,
        "bertscore": {
            "precision": 0.96216,
            "recall": 0.92781,
            "f1": 0.94373
        },
        "bleurt": 0.39941,
        "meteor": 0.372266945174862,
        "nubia": {
            "semantic_relation": 4.18039,
            "contradiction": 20.61962,
            "irrelevancy": 7.97042,
            "logical_agreement": 71.40995,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.67057,
            "nubia_score": 0.76752
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.25,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.72327,
            "recall": 0.68389,
            "fmeasure": 0.70085
        },
        "rouge2": {
            "precision": 0.42963,
            "recall": 0.40544,
            "fmeasure": 0.4157
        },
        "rougeL": {
            "precision": 0.61077,
            "recall": 0.57523,
            "fmeasure": 0.59046
        },
        "rougeLsum": {
            "precision": 0.61077,
            "recall": 0.57523,
            "fmeasure": 0.59046
        },
        "nist": 4.6891726308014015,
        "bleu": 36.85247,
        "bertscore": {
            "precision": 0.92818,
            "recall": 0.92352,
            "f1": 0.92521
        },
        "bleurt": 0.15124,
        "meteor": 0.3658658296656912,
        "nubia": {
            "semantic_relation": 4.36318,
            "contradiction": 29.50252,
            "irrelevancy": 15.43549,
            "logical_agreement": 55.06199,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.21875,
            "nubia_score": 0.76441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "rouge1": {
            "precision": 0.50794,
            "recall": 0.49428,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.15657,
            "fmeasure": 0.15288
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.29748,
            "fmeasure": 0.29091
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.29748,
            "fmeasure": 0.29091
        },
        "nist": 2.377446822850725,
        "bleu": 9.61984,
        "bertscore": {
            "precision": 0.83669,
            "recall": 0.82091,
            "f1": 0.82406
        },
        "bleurt": -0.48603,
        "meteor": 0.25725618119346727,
        "nubia": {
            "semantic_relation": 3.53113,
            "contradiction": 16.57129,
            "irrelevancy": 6.33929,
            "logical_agreement": 77.08941,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.39896,
            "nubia_score": 0.48594
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.5625
        },
        "rouge1": {
            "precision": 0.56548,
            "recall": 0.65146,
            "fmeasure": 0.60363
        },
        "rouge2": {
            "precision": 0.28322,
            "recall": 0.32925,
            "fmeasure": 0.30347
        },
        "rougeL": {
            "precision": 0.45635,
            "recall": 0.53439,
            "fmeasure": 0.49084
        },
        "rougeLsum": {
            "precision": 0.45635,
            "recall": 0.53439,
            "fmeasure": 0.49084
        },
        "nist": 3.292086655312334,
        "bleu": 16.94357,
        "bertscore": {
            "precision": 0.8372,
            "recall": 0.87986,
            "f1": 0.8576
        },
        "bleurt": -0.43549,
        "meteor": 0.31568817620067985,
        "nubia": {
            "semantic_relation": 2.72378,
            "contradiction": 48.13257,
            "irrelevancy": 29.96247,
            "logical_agreement": 21.90495,
            "grammar_ref": 4.76014,
            "grammar_hyp": 5.25593,
            "nubia_score": 0.37103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6756756756756757
        },
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.66304,
            "fmeasure": 0.70111
        },
        "rouge2": {
            "precision": 0.55926,
            "recall": 0.48953,
            "fmeasure": 0.51606
        },
        "rougeL": {
            "precision": 0.57407,
            "recall": 0.49308,
            "fmeasure": 0.52478
        },
        "rougeLsum": {
            "precision": 0.57407,
            "recall": 0.49308,
            "fmeasure": 0.52478
        },
        "nist": 3.4977064598605008,
        "bleu": 31.35991,
        "bertscore": {
            "precision": 0.9034,
            "recall": 0.87724,
            "f1": 0.88996
        },
        "bleurt": -0.03926,
        "meteor": 0.34265505521789,
        "nubia": {
            "semantic_relation": 3.77092,
            "contradiction": 9.08364,
            "irrelevancy": 4.96592,
            "logical_agreement": 85.95044,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.91174,
            "nubia_score": 0.59054
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.27273,
            "fmeasure": 0.24
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.41667,
            "fmeasure": 0.37037
        },
        "nist": 1.5684210940655061,
        "bleu": 11.25133,
        "bertscore": {
            "precision": 0.84205,
            "recall": 0.8351,
            "f1": 0.83856
        },
        "bleurt": 0.46301,
        "meteor": 0.30820423707448286,
        "nubia": {
            "semantic_relation": 4.36974,
            "contradiction": 0.57031,
            "irrelevancy": 92.05643,
            "logical_agreement": 7.37326,
            "grammar_ref": 5.68739,
            "grammar_hyp": 3.82267,
            "nubia_score": 0.865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.92
        },
        "rouge1": {
            "precision": 0.90891,
            "recall": 0.87979,
            "fmeasure": 0.8938
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.62368,
            "fmeasure": 0.63099
        },
        "rougeL": {
            "precision": 0.75101,
            "recall": 0.73217,
            "fmeasure": 0.74124
        },
        "rougeLsum": {
            "precision": 0.75101,
            "recall": 0.73217,
            "fmeasure": 0.74124
        },
        "nist": 4.541788519032162,
        "bleu": 45.09404,
        "bertscore": {
            "precision": 0.96366,
            "recall": 0.95893,
            "f1": 0.96122
        },
        "bleurt": 0.52901,
        "meteor": 0.4195948919197832,
        "nubia": {
            "semantic_relation": 4.70136,
            "contradiction": 0.19278,
            "irrelevancy": 0.49962,
            "logical_agreement": 99.3076,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.63211,
            "nubia_score": 0.90598
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7368421052631579
        },
        "rouge1": {
            "precision": 0.67374,
            "recall": 0.79167,
            "fmeasure": 0.71973
        },
        "rouge2": {
            "precision": 0.42381,
            "recall": 0.53266,
            "fmeasure": 0.46653
        },
        "rougeL": {
            "precision": 0.67374,
            "recall": 0.79167,
            "fmeasure": 0.71973
        },
        "rougeLsum": {
            "precision": 0.67374,
            "recall": 0.79167,
            "fmeasure": 0.71973
        },
        "nist": 3.3368418347081557,
        "bleu": 36.74445,
        "bertscore": {
            "precision": 0.90875,
            "recall": 0.94936,
            "f1": 0.92735
        },
        "bleurt": 0.69542,
        "meteor": 0.42779153167429507,
        "nubia": {
            "semantic_relation": 4.21198,
            "contradiction": 1.72288,
            "irrelevancy": 50.28485,
            "logical_agreement": 47.99227,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.12321,
            "nubia_score": 0.71728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.82609,
            "recall": 0.98333,
            "fmeasure": 0.89775
        },
        "rouge2": {
            "precision": 0.71212,
            "recall": 0.85575,
            "fmeasure": 0.77724
        },
        "rougeL": {
            "precision": 0.82609,
            "recall": 0.98333,
            "fmeasure": 0.89775
        },
        "rougeLsum": {
            "precision": 0.82609,
            "recall": 0.98333,
            "fmeasure": 0.89775
        },
        "nist": 3.947868915844048,
        "bleu": 64.85614,
        "bertscore": {
            "precision": 0.94949,
            "recall": 0.98791,
            "f1": 0.96395
        },
        "bleurt": 0.2939,
        "meteor": 0.5432190103540754,
        "nubia": {
            "semantic_relation": 4.04947,
            "contradiction": 14.94484,
            "irrelevancy": 79.57433,
            "logical_agreement": 5.48084,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.96407,
            "nubia_score": 0.66174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.56923,
            "recall": 0.71282,
            "fmeasure": 0.62591
        },
        "rouge2": {
            "precision": 0.33135,
            "recall": 0.41468,
            "fmeasure": 0.36162
        },
        "rougeL": {
            "precision": 0.56923,
            "recall": 0.69444,
            "fmeasure": 0.61617
        },
        "rougeLsum": {
            "precision": 0.56923,
            "recall": 0.69444,
            "fmeasure": 0.61617
        },
        "nist": 2.9744805253178197,
        "bleu": 33.86373,
        "bertscore": {
            "precision": 0.9073,
            "recall": 0.88849,
            "f1": 0.89761
        },
        "bleurt": 0.39294,
        "meteor": 0.37745858159910817,
        "nubia": {
            "semantic_relation": 4.62904,
            "contradiction": 3.15177,
            "irrelevancy": 22.01462,
            "logical_agreement": 74.8336,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.04001,
            "nubia_score": 0.79992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.58824,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.1875,
            "fmeasure": 0.17647
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.41176,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.41176,
            "fmeasure": 0.38889
        },
        "nist": 1.8535537339287333,
        "bleu": 14.29615,
        "bertscore": {
            "precision": 0.8925,
            "recall": 0.88,
            "f1": 0.88621
        },
        "bleurt": -0.00534,
        "meteor": 0.2843430625601941,
        "nubia": {
            "semantic_relation": 4.23331,
            "contradiction": 2.02071,
            "irrelevancy": 59.63967,
            "logical_agreement": 38.33961,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.27683,
            "nubia_score": 0.82975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.50789957099271,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.89367,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.8,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.70657,
            "recall": 0.67893,
            "fmeasure": 0.68326
        },
        "rouge2": {
            "precision": 0.43759,
            "recall": 0.44881,
            "fmeasure": 0.43838
        },
        "rougeL": {
            "precision": 0.59392,
            "recall": 0.57911,
            "fmeasure": 0.57952
        },
        "rougeLsum": {
            "precision": 0.59392,
            "recall": 0.57911,
            "fmeasure": 0.57952
        },
        "nist": 4.312167979713266,
        "bleu": 29.91349,
        "bertscore": {
            "precision": 0.90885,
            "recall": 0.89346,
            "f1": 0.90064
        },
        "bleurt": 0.00588,
        "meteor": 0.3307836534276985,
        "nubia": {
            "semantic_relation": 3.93919,
            "contradiction": 21.91076,
            "irrelevancy": 50.07402,
            "logical_agreement": 28.01522,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.46768,
            "nubia_score": 0.63251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3125,
            "2": 0.875,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.6554,
            "recall": 0.6927,
            "fmeasure": 0.6521
        },
        "rouge2": {
            "precision": 0.42558,
            "recall": 0.45225,
            "fmeasure": 0.42798
        },
        "rougeL": {
            "precision": 0.58984,
            "recall": 0.64245,
            "fmeasure": 0.59618
        },
        "rougeLsum": {
            "precision": 0.58984,
            "recall": 0.64245,
            "fmeasure": 0.59618
        },
        "nist": 4.359293705315883,
        "bleu": 42.55621,
        "bertscore": {
            "precision": 0.90573,
            "recall": 0.90846,
            "f1": 0.90322
        },
        "bleurt": 0.09435,
        "meteor": 0.36575741104113135,
        "nubia": {
            "semantic_relation": 3.72637,
            "contradiction": 26.14186,
            "irrelevancy": 29.34852,
            "logical_agreement": 44.50962,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.08592,
            "nubia_score": 0.64537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6071428571428571
        },
        "rouge1": {
            "precision": 0.73958,
            "recall": 0.67359,
            "fmeasure": 0.70124
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.47665,
            "fmeasure": 0.48998
        },
        "rougeL": {
            "precision": 0.71181,
            "recall": 0.65215,
            "fmeasure": 0.67705
        },
        "rougeLsum": {
            "precision": 0.71181,
            "recall": 0.65215,
            "fmeasure": 0.67705
        },
        "nist": 3.5493819320387896,
        "bleu": 31.88433,
        "bertscore": {
            "precision": 0.91956,
            "recall": 0.91351,
            "f1": 0.91602
        },
        "bleurt": 0.27704,
        "meteor": 0.36198886154405746,
        "nubia": {
            "semantic_relation": 3.32264,
            "contradiction": 47.16041,
            "irrelevancy": 5.7768,
            "logical_agreement": 47.06279,
            "grammar_ref": 3.82725,
            "grammar_hyp": 3.67989,
            "nubia_score": 0.52875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "nist": 2.1055161915432032,
        "bleu": 41.11336,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        },
        "bleurt": 0.18287,
        "meteor": 0.4231469901582543,
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.7083333333333334,
            "3": 0.6086956521739131
        },
        "rouge1": {
            "precision": 0.67602,
            "recall": 0.63606,
            "fmeasure": 0.63077
        },
        "rouge2": {
            "precision": 0.33593,
            "recall": 0.31676,
            "fmeasure": 0.31314
        },
        "rougeL": {
            "precision": 0.44852,
            "recall": 0.43679,
            "fmeasure": 0.42575
        },
        "rougeLsum": {
            "precision": 0.44852,
            "recall": 0.43679,
            "fmeasure": 0.42575
        },
        "nist": 4.42610283517227,
        "bleu": 26.60213,
        "bertscore": {
            "precision": 0.90807,
            "recall": 0.89798,
            "f1": 0.90195
        },
        "bleurt": 0.14016,
        "meteor": 0.3267124291494539,
        "nubia": {
            "semantic_relation": 3.94281,
            "contradiction": 15.60082,
            "irrelevancy": 35.98602,
            "logical_agreement": 48.41315,
            "grammar_ref": 5.09695,
            "grammar_hyp": 5.02748,
            "nubia_score": 0.617
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "nist": 4.01117167855772,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.77386,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "mT5_small/totto_test",
        "N": 36,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32456140350877194,
            "2": 0.5094339622641509,
            "3": 0.7448680351906158
        },
        "rouge1": {
            "precision": 0.74674,
            "recall": 0.74195,
            "fmeasure": 0.73533
        },
        "rouge2": {
            "precision": 0.53355,
            "recall": 0.53015,
            "fmeasure": 0.52593
        },
        "rougeL": {
            "precision": 0.64834,
            "recall": 0.6518,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.64834,
            "recall": 0.6518,
            "fmeasure": 0.64242
        },
        "nist": 6.4893304089206545,
        "bleu": 46.99831,
        "bertscore": {
            "precision": 0.93387,
            "recall": 0.93335,
            "f1": 0.93219
        },
        "bleurt": 0.36482,
        "meteor": 0.42109715874885334,
        "nubia": {
            "semantic_relation": 4.07963,
            "contradiction": 5.0806,
            "irrelevancy": 37.35168,
            "logical_agreement": 57.56773,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.87233,
            "nubia_score": 0.75973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "nist": 4.957404396518136,
        "bleu": 76.5665,
        "bertscore": {
            "precision": 0.97017,
            "recall": 0.97746,
            "f1": 0.97378
        },
        "bleurt": 0.64742,
        "meteor": 0.5609348411263468,
        "nubia": {
            "semantic_relation": 4.53811,
            "contradiction": 0.50213,
            "irrelevancy": 48.32052,
            "logical_agreement": 51.17736,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.8389,
            "nubia_score": 0.83775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "rouge1": {
            "precision": 0.975,
            "recall": 0.92643,
            "fmeasure": 0.94807
        },
        "rouge2": {
            "precision": 0.89425,
            "recall": 0.86591,
            "fmeasure": 0.87912
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "nist": 5.370638223410693,
        "bleu": 74.31053,
        "bertscore": {
            "precision": 0.98748,
            "recall": 0.98115,
            "f1": 0.98304
        },
        "bleurt": 0.7087,
        "meteor": 0.5559131802200744,
        "nubia": {
            "semantic_relation": 4.80972,
            "contradiction": 0.2607,
            "irrelevancy": 8.77328,
            "logical_agreement": 90.96602,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.03931,
            "nubia_score": 0.94183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.125,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.85897,
            "recall": 0.71044,
            "fmeasure": 0.77598
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.52109,
            "fmeasure": 0.57258
        },
        "rougeL": {
            "precision": 0.75897,
            "recall": 0.62205,
            "fmeasure": 0.68219
        },
        "rougeLsum": {
            "precision": 0.75897,
            "recall": 0.62205,
            "fmeasure": 0.68219
        },
        "nist": 3.8382688674746035,
        "bleu": 39.10764,
        "bertscore": {
            "precision": 0.93382,
            "recall": 0.91212,
            "f1": 0.92273
        },
        "bleurt": 0.34518,
        "meteor": 0.41264069876067605,
        "nubia": {
            "semantic_relation": 4.54357,
            "contradiction": 0.45011,
            "irrelevancy": 0.59437,
            "logical_agreement": 98.95552,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.8377,
            "nubia_score": 0.83151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.72464,
            "recall": 0.82038,
            "fmeasure": 0.76912
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.59048,
            "fmeasure": 0.567
        },
        "rougeL": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "rougeLsum": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "nist": 3.5097612095823987,
        "bleu": 49.50861,
        "bertscore": {
            "precision": 0.93974,
            "recall": 0.94781,
            "f1": 0.94376
        },
        "bleurt": 0.27975,
        "meteor": 0.4157895527996179,
        "nubia": {
            "semantic_relation": 4.65637,
            "contradiction": 0.18187,
            "irrelevancy": 2.47575,
            "logical_agreement": 97.34238,
            "grammar_ref": 5.09304,
            "grammar_hyp": 3.94671,
            "nubia_score": 0.99239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.75379,
            "fmeasure": 0.73863
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.51111,
            "fmeasure": 0.50075
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.60985,
            "fmeasure": 0.60132
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.60985,
            "fmeasure": 0.60132
        },
        "nist": 4.078296621424891,
        "bleu": 51.91538,
        "bertscore": {
            "precision": 0.97534,
            "recall": 0.96047,
            "f1": 0.96785
        },
        "bleurt": -0.02466,
        "meteor": 0.4366408472451301,
        "nubia": {
            "semantic_relation": 3.79509,
            "contradiction": 0.13389,
            "irrelevancy": 66.07809,
            "logical_agreement": 33.78802,
            "grammar_ref": 5.84412,
            "grammar_hyp": 5.12381,
            "nubia_score": 0.61941
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.28571,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52941
        },
        "nist": 2.0019550008653875,
        "bleu": 18.57506,
        "bertscore": {
            "precision": 0.87716,
            "recall": 0.92831,
            "f1": 0.90201
        },
        "bleurt": -0.35562,
        "meteor": 0.29699850622335516,
        "nubia": {
            "semantic_relation": 4.23584,
            "contradiction": 2.99435,
            "irrelevancy": 94.85057,
            "logical_agreement": 2.15509,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.5922,
            "nubia_score": 0.5627
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.875,
            "fmeasure": 0.84848
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.94118,
            "fmeasure": 0.91429
        },
        "nist": 4.294710659132164,
        "bleu": 75.90995,
        "bertscore": {
            "precision": 0.9789,
            "recall": 0.98281,
            "f1": 0.98085
        },
        "bleurt": 0.71585,
        "meteor": 0.5246933677048612,
        "nubia": {
            "semantic_relation": 3.77559,
            "contradiction": 97.22461,
            "irrelevancy": 2.18277,
            "logical_agreement": 0.59262,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.15402,
            "nubia_score": 0.54204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.83701,
            "fmeasure": 0.88834
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.69583,
            "fmeasure": 0.72792
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80637,
            "fmeasure": 0.85304
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80637,
            "fmeasure": 0.85304
        },
        "nist": 3.7338989030772027,
        "bleu": 62.2841,
        "bertscore": {
            "precision": 0.98117,
            "recall": 0.946,
            "f1": 0.96292
        },
        "bleurt": 0.58425,
        "meteor": 0.4381754705733862,
        "nubia": {
            "semantic_relation": 4.24143,
            "contradiction": 0.51254,
            "irrelevancy": 0.5776,
            "logical_agreement": 98.90986,
            "grammar_ref": 5.04945,
            "grammar_hyp": 5.37724,
            "nubia_score": 0.73259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.79365,
            "recall": 0.84737,
            "fmeasure": 0.81951
        },
        "rouge2": {
            "precision": 0.48333,
            "recall": 0.51754,
            "fmeasure": 0.49978
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.62105,
            "fmeasure": 0.59512
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.62105,
            "fmeasure": 0.59512
        },
        "nist": 4.252539641443471,
        "bleu": 49.34495,
        "bertscore": {
            "precision": 0.91792,
            "recall": 0.92557,
            "f1": 0.92173
        },
        "bleurt": 0.39739,
        "meteor": 0.43448864925119,
        "nubia": {
            "semantic_relation": 4.55532,
            "contradiction": 0.12416,
            "irrelevancy": 1.61873,
            "logical_agreement": 98.25712,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.52605,
            "nubia_score": 0.92695
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5384615384615384,
            "3": 0.64
        },
        "rouge1": {
            "precision": 0.84683,
            "recall": 0.69493,
            "fmeasure": 0.76225
        },
        "rouge2": {
            "precision": 0.63248,
            "recall": 0.50366,
            "fmeasure": 0.55978
        },
        "rougeL": {
            "precision": 0.75952,
            "recall": 0.6243,
            "fmeasure": 0.68389
        },
        "rougeLsum": {
            "precision": 0.75952,
            "recall": 0.6243,
            "fmeasure": 0.68389
        },
        "nist": 3.8605201516250998,
        "bleu": 40.62798,
        "bertscore": {
            "precision": 0.9434,
            "recall": 0.91166,
            "f1": 0.92696
        },
        "bleurt": 0.33499,
        "meteor": 0.3910996554668364,
        "nubia": {
            "semantic_relation": 4.25579,
            "contradiction": 0.27159,
            "irrelevancy": 21.49546,
            "logical_agreement": 78.23295,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.80265,
            "nubia_score": 0.87657
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54762,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "nist": 2.9487445430153727,
        "bleu": 51.31108,
        "bertscore": {
            "precision": 0.98804,
            "recall": 0.97187,
            "f1": 0.97989
        },
        "bleurt": 0.59368,
        "meteor": 0.4561301812414779,
        "nubia": {
            "semantic_relation": 4.91614,
            "contradiction": 0.68707,
            "irrelevancy": 0.60509,
            "logical_agreement": 98.70784,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.87586,
            "nubia_score": 0.87589
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.746268656716418
        },
        "rouge1": {
            "precision": 0.82652,
            "recall": 0.73331,
            "fmeasure": 0.76639
        },
        "rouge2": {
            "precision": 0.48755,
            "recall": 0.4247,
            "fmeasure": 0.44692
        },
        "rougeL": {
            "precision": 0.63686,
            "recall": 0.5764,
            "fmeasure": 0.59693
        },
        "rougeLsum": {
            "precision": 0.63686,
            "recall": 0.5764,
            "fmeasure": 0.59693
        },
        "nist": 4.474502605438825,
        "bleu": 34.38432,
        "bertscore": {
            "precision": 0.92586,
            "recall": 0.90007,
            "f1": 0.91206
        },
        "bleurt": 0.17288,
        "meteor": 0.3768026064535923,
        "nubia": {
            "semantic_relation": 4.2634,
            "contradiction": 15.34358,
            "irrelevancy": 32.57518,
            "logical_agreement": 52.08124,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.51441,
            "nubia_score": 0.70411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "rouge1": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.76914,
            "fmeasure": 0.69726
        },
        "rougeL": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "rougeLsum": {
            "precision": 0.75897,
            "recall": 0.89899,
            "fmeasure": 0.82222
        },
        "nist": 4.631713151157583,
        "bleu": 68.81482,
        "bertscore": {
            "precision": 0.96205,
            "recall": 0.96897,
            "f1": 0.96534
        },
        "bleurt": 0.72192,
        "meteor": 0.5331911546685959,
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 1.81656,
            "irrelevancy": 1.78451,
            "logical_agreement": 96.39893,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.43929,
            "nubia_score": 0.9916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "nist": 2.9898332363522426,
        "bleu": 61.0195,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "bleurt": 0.83294,
        "meteor": 0.5064321156600579,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.73333,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "nist": 2.976285626467086,
        "bleu": 36.85784,
        "bertscore": {
            "precision": 0.92322,
            "recall": 0.97435,
            "f1": 0.94278
        },
        "bleurt": 0.64612,
        "meteor": 0.46374702811495583,
        "nubia": {
            "semantic_relation": 4.198,
            "contradiction": 0.33325,
            "irrelevancy": 37.84348,
            "logical_agreement": 61.82327,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.2572,
            "nubia_score": 0.75969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5714285714285714,
            "3": 0.6818181818181818
        },
        "rouge1": {
            "precision": 0.74291,
            "recall": 0.58388,
            "fmeasure": 0.6494
        },
        "rouge2": {
            "precision": 0.36581,
            "recall": 0.29697,
            "fmeasure": 0.32515
        },
        "rougeL": {
            "precision": 0.56575,
            "recall": 0.45725,
            "fmeasure": 0.50186
        },
        "rougeLsum": {
            "precision": 0.56575,
            "recall": 0.45725,
            "fmeasure": 0.50186
        },
        "nist": 4.186120687895143,
        "bleu": 34.71478,
        "bertscore": {
            "precision": 0.90077,
            "recall": 0.87819,
            "f1": 0.8893
        },
        "bleurt": 0.23976,
        "meteor": 0.3188562823280731,
        "nubia": {
            "semantic_relation": 4.1214,
            "contradiction": 0.37383,
            "irrelevancy": 21.89826,
            "logical_agreement": 77.72791,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.75036,
            "nubia_score": 0.68669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.17647058823529413,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.83835,
            "recall": 0.73818,
            "fmeasure": 0.78313
        },
        "rouge2": {
            "precision": 0.48295,
            "recall": 0.42939,
            "fmeasure": 0.45338
        },
        "rougeL": {
            "precision": 0.50647,
            "recall": 0.44838,
            "fmeasure": 0.47437
        },
        "rougeLsum": {
            "precision": 0.50647,
            "recall": 0.44838,
            "fmeasure": 0.47437
        },
        "nist": 3.528363531954547,
        "bleu": 27.30299,
        "bertscore": {
            "precision": 0.92922,
            "recall": 0.92054,
            "f1": 0.92411
        },
        "bleurt": 0.18758,
        "meteor": 0.3728942203905602,
        "nubia": {
            "semantic_relation": 4.51454,
            "contradiction": 0.45923,
            "irrelevancy": 2.5722,
            "logical_agreement": 96.96857,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.71871,
            "nubia_score": 0.79056
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.13333333333333333,
            "3": 0.7878787878787878
        },
        "rouge1": {
            "precision": 0.72644,
            "recall": 0.67357,
            "fmeasure": 0.6953
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.46649,
            "fmeasure": 0.48089
        },
        "rougeL": {
            "precision": 0.62874,
            "recall": 0.58486,
            "fmeasure": 0.60392
        },
        "rougeLsum": {
            "precision": 0.62874,
            "recall": 0.58486,
            "fmeasure": 0.60392
        },
        "nist": 4.156576761507237,
        "bleu": 33.3195,
        "bertscore": {
            "precision": 0.91778,
            "recall": 0.91404,
            "f1": 0.9154
        },
        "bleurt": 0.2105,
        "meteor": 0.3933065368554157,
        "nubia": {
            "semantic_relation": 4.01674,
            "contradiction": 45.83266,
            "irrelevancy": 1.69162,
            "logical_agreement": 52.47572,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.52779,
            "nubia_score": 0.70222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3333333333333333,
            "3": 0.95
        },
        "rouge1": {
            "precision": 0.60985,
            "recall": 0.64369,
            "fmeasure": 0.619
        },
        "rouge2": {
            "precision": 0.43561,
            "recall": 0.50766,
            "fmeasure": 0.46536
        },
        "rougeL": {
            "precision": 0.56124,
            "recall": 0.63655,
            "fmeasure": 0.59178
        },
        "rougeLsum": {
            "precision": 0.56124,
            "recall": 0.63655,
            "fmeasure": 0.59178
        },
        "nist": 3.64565293738262,
        "bleu": 42.4524,
        "bertscore": {
            "precision": 0.90075,
            "recall": 0.89602,
            "f1": 0.89832
        },
        "bleurt": 0.15016,
        "meteor": 0.3340716774893997,
        "nubia": {
            "semantic_relation": 4.18595,
            "contradiction": 22.75508,
            "irrelevancy": 14.06083,
            "logical_agreement": 63.18409,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.24229,
            "nubia_score": 0.69306
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.4166666666666667,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.63757,
            "recall": 0.6652,
            "fmeasure": 0.63189
        },
        "rouge2": {
            "precision": 0.37738,
            "recall": 0.4082,
            "fmeasure": 0.3763
        },
        "rougeL": {
            "precision": 0.49365,
            "recall": 0.51564,
            "fmeasure": 0.49055
        },
        "rougeLsum": {
            "precision": 0.49365,
            "recall": 0.51564,
            "fmeasure": 0.49055
        },
        "nist": 4.12011588945655,
        "bleu": 39.21499,
        "bertscore": {
            "precision": 0.90036,
            "recall": 0.9285,
            "f1": 0.91392
        },
        "bleurt": 0.04963,
        "meteor": 0.38699558368857156,
        "nubia": {
            "semantic_relation": 4.114,
            "contradiction": 10.47069,
            "irrelevancy": 52.88885,
            "logical_agreement": 36.64046,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.11182,
            "nubia_score": 0.68544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.79382,
            "recall": 0.77528,
            "fmeasure": 0.76675
        },
        "rouge2": {
            "precision": 0.54861,
            "recall": 0.49207,
            "fmeasure": 0.51419
        },
        "rougeL": {
            "precision": 0.66964,
            "recall": 0.62797,
            "fmeasure": 0.63356
        },
        "rougeLsum": {
            "precision": 0.66964,
            "recall": 0.62797,
            "fmeasure": 0.63356
        },
        "nist": 5.006180353735267,
        "bleu": 43.46575,
        "bertscore": {
            "precision": 0.93968,
            "recall": 0.91809,
            "f1": 0.92322
        },
        "bleurt": 0.15043,
        "meteor": 0.38720551965833166,
        "nubia": {
            "semantic_relation": 4.10154,
            "contradiction": 0.24769,
            "irrelevancy": 55.60081,
            "logical_agreement": 44.1515,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.29634,
            "nubia_score": 0.75572
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "nist": 2.6330370023236713,
        "bleu": 42.95749,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        },
        "bleurt": 0.45492,
        "meteor": 0.42350497485471644,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.6428571428571429,
            "3": 0.7971014492753623
        },
        "rouge1": {
            "precision": 0.75385,
            "recall": 0.79557,
            "fmeasure": 0.76244
        },
        "rouge2": {
            "precision": 0.54482,
            "recall": 0.57602,
            "fmeasure": 0.55279
        },
        "rougeL": {
            "precision": 0.64842,
            "recall": 0.68102,
            "fmeasure": 0.65589
        },
        "rougeLsum": {
            "precision": 0.64842,
            "recall": 0.68102,
            "fmeasure": 0.65589
        },
        "nist": 4.86642892459811,
        "bleu": 42.65705,
        "bertscore": {
            "precision": 0.9255,
            "recall": 0.93636,
            "f1": 0.92719
        },
        "bleurt": 0.26664,
        "meteor": 0.40450365826692875,
        "nubia": {
            "semantic_relation": 3.93964,
            "contradiction": 0.46535,
            "irrelevancy": 70.62526,
            "logical_agreement": 28.90939,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.48739,
            "nubia_score": 0.65718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3888888888888889,
            "3": 0.8034188034188035
        },
        "rouge1": {
            "precision": 0.81266,
            "recall": 0.74828,
            "fmeasure": 0.77263
        },
        "rouge2": {
            "precision": 0.58778,
            "recall": 0.55093,
            "fmeasure": 0.56386
        },
        "rougeL": {
            "precision": 0.6406,
            "recall": 0.59166,
            "fmeasure": 0.61039
        },
        "rougeLsum": {
            "precision": 0.6406,
            "recall": 0.59166,
            "fmeasure": 0.61039
        },
        "nist": 5.433713992641697,
        "bleu": 42.47636,
        "bertscore": {
            "precision": 0.94117,
            "recall": 0.92555,
            "f1": 0.93205
        },
        "bleurt": 0.34297,
        "meteor": 0.4122180757110643,
        "nubia": {
            "semantic_relation": 4.38421,
            "contradiction": 20.36871,
            "irrelevancy": 17.13217,
            "logical_agreement": 62.49912,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.27191,
            "nubia_score": 0.77895
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.42857,
            "fmeasure": 0.50311
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.04545,
            "fmeasure": 0.05263
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.30952,
            "fmeasure": 0.36439
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.30952,
            "fmeasure": 0.36439
        },
        "nist": 1.1693836834268005,
        "bleu": 7.20021,
        "bertscore": {
            "precision": 0.86634,
            "recall": 0.86058,
            "f1": 0.86345
        },
        "bleurt": 0.12478,
        "meteor": 0.17291671696345584,
        "nubia": {
            "semantic_relation": 3.81393,
            "contradiction": 3.05012,
            "irrelevancy": 26.59932,
            "logical_agreement": 70.35055,
            "grammar_ref": 5.74657,
            "grammar_hyp": 5.68625,
            "nubia_score": 0.53637
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.84455,
            "fmeasure": 0.9019
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.73333,
            "fmeasure": 0.78484
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "nist": 4.770721208389991,
        "bleu": 80.52254,
        "bertscore": {
            "precision": 0.99811,
            "recall": 0.98882,
            "f1": 0.99345
        },
        "bleurt": 0.74939,
        "meteor": 0.5469432736955866,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11768,
            "irrelevancy": 0.47514,
            "logical_agreement": 99.40718,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.71917,
            "nubia_score": 0.98117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.77576,
            "fmeasure": 0.65778
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.61111,
            "fmeasure": 0.50856
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.77576,
            "fmeasure": 0.65778
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.77576,
            "fmeasure": 0.65778
        },
        "nist": 1.5316760499465438,
        "bleu": 15.31682,
        "bertscore": {
            "precision": 0.82517,
            "recall": 0.92155,
            "f1": 0.87011
        },
        "bleurt": -0.33996,
        "meteor": 0.3349081713394097,
        "nubia": {
            "semantic_relation": 3.37705,
            "contradiction": 6.44991,
            "irrelevancy": 93.01753,
            "logical_agreement": 0.53257,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.36285,
            "nubia_score": 0.4266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 4.251192788981044,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.64779,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "nist": 4.018549068142959,
        "bleu": 69.85342,
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        },
        "bleurt": 0.6035,
        "meteor": 0.5255759325753065,
        "nubia": {
            "semantic_relation": 4.40194,
            "contradiction": 0.18499,
            "irrelevancy": 63.6692,
            "logical_agreement": 36.14582,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.41374,
            "nubia_score": 0.97573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.31818,
            "recall": 0.53472,
            "fmeasure": 0.39732
        },
        "rouge2": {
            "precision": 0.04762,
            "recall": 0.08283,
            "fmeasure": 0.06019
        },
        "rougeL": {
            "precision": 0.18182,
            "recall": 0.30556,
            "fmeasure": 0.22704
        },
        "rougeLsum": {
            "precision": 0.18182,
            "recall": 0.30556,
            "fmeasure": 0.22704
        },
        "nist": 1.3460270239980732,
        "bleu": 7.48389,
        "bertscore": {
            "precision": 0.77966,
            "recall": 0.8296,
            "f1": 0.79648
        },
        "bleurt": -0.51531,
        "meteor": 0.19770895456426135,
        "nubia": {
            "semantic_relation": 3.91973,
            "contradiction": 19.54938,
            "irrelevancy": 63.16411,
            "logical_agreement": 17.28651,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.63424,
            "nubia_score": 0.63466
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.16666666666666666
        },
        "rouge1": {
            "precision": 0.30769,
            "recall": 0.36364,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.12857,
            "fmeasure": 0.10048
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.36364,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.36364,
            "fmeasure": 0.33333
        },
        "nist": 0.9248449920180403,
        "bleu": 3.7165,
        "bertscore": {
            "precision": 0.73345,
            "recall": 0.81554,
            "f1": 0.77095
        },
        "bleurt": -0.66203,
        "meteor": 0.13675213675213674,
        "nubia": {
            "semantic_relation": 3.28078,
            "contradiction": 0.08322,
            "irrelevancy": 99.63574,
            "logical_agreement": 0.28105,
            "grammar_ref": 4.68733,
            "grammar_hyp": 5.0344,
            "nubia_score": 0.45775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "rouge1": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "rouge2": {
            "precision": 0.60317,
            "recall": 0.64534,
            "fmeasure": 0.61455
        },
        "rougeL": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "rougeLsum": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "nist": 3.9004951693840617,
        "bleu": 46.69799,
        "bertscore": {
            "precision": 0.91441,
            "recall": 0.9571,
            "f1": 0.93334
        },
        "bleurt": 0.50812,
        "meteor": 0.47042596572174444,
        "nubia": {
            "semantic_relation": 4.57249,
            "contradiction": 0.39657,
            "irrelevancy": 33.5888,
            "logical_agreement": 66.01463,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.99344,
            "nubia_score": 0.90706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "nist": 2.8936441277848375,
        "bleu": 100.0,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        },
        "bleurt": 0.55466,
        "meteor": 0.9652173913043478,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.23076923076923078,
            "3": 0.8809523809523809
        },
        "rouge1": {
            "precision": 0.89795,
            "recall": 0.85016,
            "fmeasure": 0.87
        },
        "rouge2": {
            "precision": 0.75132,
            "recall": 0.7256,
            "fmeasure": 0.73599
        },
        "rougeL": {
            "precision": 0.82388,
            "recall": 0.78829,
            "fmeasure": 0.80297
        },
        "rougeLsum": {
            "precision": 0.82388,
            "recall": 0.78829,
            "fmeasure": 0.80297
        },
        "nist": 5.3132192948505,
        "bleu": 65.87549,
        "bertscore": {
            "precision": 0.98024,
            "recall": 0.97733,
            "f1": 0.97872
        },
        "bleurt": 0.67197,
        "meteor": 0.49987651537202415,
        "nubia": {
            "semantic_relation": 4.59411,
            "contradiction": 16.59923,
            "irrelevancy": 0.75398,
            "logical_agreement": 82.64679,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.02143,
            "nubia_score": 0.89956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "mT5_small/totto_test",
        "N": 15,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2978723404255319,
            "2": 0.37037037037037035,
            "3": 0.8774193548387097
        },
        "rouge1": {
            "precision": 0.81272,
            "recall": 0.80144,
            "fmeasure": 0.80278
        },
        "rouge2": {
            "precision": 0.63132,
            "recall": 0.60773,
            "fmeasure": 0.61449
        },
        "rougeL": {
            "precision": 0.74551,
            "recall": 0.73663,
            "fmeasure": 0.7373
        },
        "rougeLsum": {
            "precision": 0.74551,
            "recall": 0.73663,
            "fmeasure": 0.7373
        },
        "nist": 6.7214439817162495,
        "bleu": 56.44132,
        "bertscore": {
            "precision": 0.9641,
            "recall": 0.96177,
            "f1": 0.96073
        },
        "bleurt": 0.3623,
        "meteor": 0.46895779232136237,
        "nubia": {
            "semantic_relation": 4.47921,
            "contradiction": 10.70245,
            "irrelevancy": 28.70478,
            "logical_agreement": 60.59277,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.64177,
            "nubia_score": 0.81623
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "nist": 3.0286497677077553,
        "bleu": 70.16879,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        },
        "bleurt": 0.76221,
        "meteor": 0.5613051214200641,
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "nist": 2.7910011142063147,
        "bleu": 33.40891,
        "bertscore": {
            "precision": 0.96668,
            "recall": 0.9373,
            "f1": 0.95176
        },
        "bleurt": 0.50996,
        "meteor": 0.424582730950162,
        "nubia": {
            "semantic_relation": 4.98459,
            "contradiction": 0.13212,
            "irrelevancy": 0.41925,
            "logical_agreement": 99.44863,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.453,
            "nubia_score": 0.98464
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "nist": 2.1681907449941207,
        "bleu": 41.12176,
        "bertscore": {
            "precision": 0.90421,
            "recall": 0.93059,
            "f1": 0.91721
        },
        "bleurt": 0.38768,
        "meteor": 0.40391483707176334,
        "nubia": {
            "semantic_relation": 3.04215,
            "contradiction": 28.68807,
            "irrelevancy": 70.46279,
            "logical_agreement": 0.84915,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.99907,
            "nubia_score": 0.47879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.490498678107601,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.92254,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.0,
            "3": 0.7916666666666666
        },
        "rouge1": {
            "precision": 0.63099,
            "recall": 0.73529,
            "fmeasure": 0.67635
        },
        "rouge2": {
            "precision": 0.43869,
            "recall": 0.5125,
            "fmeasure": 0.46991
        },
        "rougeL": {
            "precision": 0.60983,
            "recall": 0.72341,
            "fmeasure": 0.65734
        },
        "rougeLsum": {
            "precision": 0.60983,
            "recall": 0.72341,
            "fmeasure": 0.65734
        },
        "nist": 3.8754917236120674,
        "bleu": 48.18312,
        "bertscore": {
            "precision": 0.92473,
            "recall": 0.94738,
            "f1": 0.93584
        },
        "bleurt": 0.29044,
        "meteor": 0.4210509624084002,
        "nubia": {
            "semantic_relation": 3.9333,
            "contradiction": 33.75756,
            "irrelevancy": 38.52056,
            "logical_agreement": 27.72188,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.14081,
            "nubia_score": 0.66744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "mT5_small/totto_test",
        "N": 10,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4583333333333333,
            "2": 0.6538461538461539,
            "3": 0.926605504587156
        },
        "rouge1": {
            "precision": 0.8741,
            "recall": 0.88699,
            "fmeasure": 0.87661
        },
        "rouge2": {
            "precision": 0.70548,
            "recall": 0.72547,
            "fmeasure": 0.71274
        },
        "rougeL": {
            "precision": 0.71801,
            "recall": 0.73212,
            "fmeasure": 0.72243
        },
        "rougeLsum": {
            "precision": 0.71801,
            "recall": 0.73212,
            "fmeasure": 0.72243
        },
        "nist": 6.796668239977826,
        "bleu": 69.64226,
        "bertscore": {
            "precision": 0.96458,
            "recall": 0.96436,
            "f1": 0.96301
        },
        "bleurt": 0.53344,
        "meteor": 0.5096356333637825,
        "nubia": {
            "semantic_relation": 4.40828,
            "contradiction": 15.80927,
            "irrelevancy": 19.91916,
            "logical_agreement": 64.27156,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.83191,
            "nubia_score": 0.79192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.46875,
            "recall": 0.39565,
            "fmeasure": 0.42432
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.16234,
            "fmeasure": 0.17707
        },
        "rougeL": {
            "precision": 0.40625,
            "recall": 0.34058,
            "fmeasure": 0.36642
        },
        "rougeLsum": {
            "precision": 0.40625,
            "recall": 0.34058,
            "fmeasure": 0.36642
        },
        "nist": 1.9758654858981657,
        "bleu": 12.56245,
        "bertscore": {
            "precision": 0.85668,
            "recall": 0.81645,
            "f1": 0.83608
        },
        "bleurt": -0.47644,
        "meteor": 0.2144554360903116,
        "nubia": {
            "semantic_relation": 3.62444,
            "contradiction": 2.42641,
            "irrelevancy": 92.5317,
            "logical_agreement": 5.04188,
            "grammar_ref": 5.51157,
            "grammar_hyp": 6.30864,
            "nubia_score": 0.42256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6111111111111112,
            "3": 0.6956521739130435
        },
        "rouge1": {
            "precision": 0.66101,
            "recall": 0.65141,
            "fmeasure": 0.63639
        },
        "rouge2": {
            "precision": 0.3636,
            "recall": 0.33517,
            "fmeasure": 0.33903
        },
        "rougeL": {
            "precision": 0.5878,
            "recall": 0.58454,
            "fmeasure": 0.56694
        },
        "rougeLsum": {
            "precision": 0.5878,
            "recall": 0.58454,
            "fmeasure": 0.56694
        },
        "nist": 3.7683541495986117,
        "bleu": 30.05616,
        "bertscore": {
            "precision": 0.90782,
            "recall": 0.91728,
            "f1": 0.90856
        },
        "bleurt": 0.10083,
        "meteor": 0.3549935270951217,
        "nubia": {
            "semantic_relation": 3.72111,
            "contradiction": 3.60284,
            "irrelevancy": 28.8785,
            "logical_agreement": 67.51866,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.16439,
            "nubia_score": 0.61678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.59028,
            "fmeasure": 0.60662
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.26786,
            "fmeasure": 0.27619
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.53472,
            "fmeasure": 0.54779
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.53472,
            "fmeasure": 0.54779
        },
        "nist": 2.403337745184905,
        "bleu": 23.3569,
        "bertscore": {
            "precision": 0.89154,
            "recall": 0.86262,
            "f1": 0.87684
        },
        "bleurt": 0.26509,
        "meteor": 0.3366834622183792,
        "nubia": {
            "semantic_relation": 4.45145,
            "contradiction": 2.44769,
            "irrelevancy": 1.60238,
            "logical_agreement": 95.94994,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.78364,
            "nubia_score": 0.61808
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.3333333333333333,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.98485,
            "recall": 0.79419,
            "fmeasure": 0.86691
        },
        "rouge2": {
            "precision": 0.81667,
            "recall": 0.67727,
            "fmeasure": 0.72843
        },
        "rougeL": {
            "precision": 0.98485,
            "recall": 0.79419,
            "fmeasure": 0.86691
        },
        "rougeLsum": {
            "precision": 0.98485,
            "recall": 0.79419,
            "fmeasure": 0.86691
        },
        "nist": 4.057324873900548,
        "bleu": 70.86735,
        "bertscore": {
            "precision": 0.91798,
            "recall": 0.89729,
            "f1": 0.90719
        },
        "bleurt": 0.36918,
        "meteor": 0.4785176508588214,
        "nubia": {
            "semantic_relation": 4.35806,
            "contradiction": 1.60602,
            "irrelevancy": 0.79712,
            "logical_agreement": 97.59687,
            "grammar_ref": 5.62679,
            "grammar_hyp": 6.36962,
            "nubia_score": 0.67796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.54346,
            "recall": 0.60339,
            "fmeasure": 0.56296
        },
        "rouge2": {
            "precision": 0.20665,
            "recall": 0.25948,
            "fmeasure": 0.2237
        },
        "rougeL": {
            "precision": 0.43954,
            "recall": 0.53119,
            "fmeasure": 0.47025
        },
        "rougeLsum": {
            "precision": 0.43954,
            "recall": 0.53119,
            "fmeasure": 0.47025
        },
        "nist": 3.3635665736121867,
        "bleu": 16.06877,
        "bertscore": {
            "precision": 0.81842,
            "recall": 0.86635,
            "f1": 0.83701
        },
        "bleurt": 0.00087,
        "meteor": 0.31824060254627906,
        "nubia": {
            "semantic_relation": 3.5163,
            "contradiction": 6.10861,
            "irrelevancy": 44.77624,
            "logical_agreement": 49.11515,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.79997,
            "nubia_score": 0.47221
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.64286,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.20513,
            "fmeasure": 0.23188
        },
        "rougeL": {
            "precision": 0.48485,
            "recall": 0.38095,
            "fmeasure": 0.42667
        },
        "rougeLsum": {
            "precision": 0.48485,
            "recall": 0.38095,
            "fmeasure": 0.42667
        },
        "nist": 2.3537576767547965,
        "bleu": 10.25419,
        "bertscore": {
            "precision": 0.89617,
            "recall": 0.87155,
            "f1": 0.88369
        },
        "bleurt": 0.22978,
        "meteor": 0.3209527643222527,
        "nubia": {
            "semantic_relation": 4.51168,
            "contradiction": 1.25798,
            "irrelevancy": 3.79392,
            "logical_agreement": 94.9481,
            "grammar_ref": 4.18993,
            "grammar_hyp": 5.83574,
            "nubia_score": 0.61649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.91667,
            "fmeasure": 0.82175
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.53535,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.78571,
            "fmeasure": 0.78075
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.78571,
            "fmeasure": 0.78075
        },
        "nist": 3.8543874856721767,
        "bleu": 60.34149,
        "bertscore": {
            "precision": 0.97608,
            "recall": 0.95123,
            "f1": 0.96349
        },
        "bleurt": 0.43544,
        "meteor": 0.899773682508891,
        "nubia": {
            "semantic_relation": 4.79531,
            "contradiction": 0.50956,
            "irrelevancy": 57.78384,
            "logical_agreement": 41.7066,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.04123,
            "nubia_score": 0.85349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.6086956521739131
        },
        "rouge1": {
            "precision": 0.69034,
            "recall": 0.61916,
            "fmeasure": 0.64023
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.22906,
            "fmeasure": 0.22638
        },
        "rougeL": {
            "precision": 0.44602,
            "recall": 0.50525,
            "fmeasure": 0.45231
        },
        "rougeLsum": {
            "precision": 0.44602,
            "recall": 0.50525,
            "fmeasure": 0.45231
        },
        "nist": 3.0478124355566547,
        "bleu": 13.02601,
        "bertscore": {
            "precision": 0.89145,
            "recall": 0.90844,
            "f1": 0.89769
        },
        "bleurt": 0.04756,
        "meteor": 0.3142068887304069,
        "nubia": {
            "semantic_relation": 3.83069,
            "contradiction": 0.20422,
            "irrelevancy": 70.35637,
            "logical_agreement": 29.43941,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.38604,
            "nubia_score": 0.60734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "rouge2": {
            "precision": 0.65625,
            "recall": 0.65696,
            "fmeasure": 0.6529
        },
        "rougeL": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "rougeLsum": {
            "precision": 0.80015,
            "recall": 0.8127,
            "fmeasure": 0.80261
        },
        "nist": 4.717064442054546,
        "bleu": 66.49127,
        "bertscore": {
            "precision": 0.97169,
            "recall": 0.95625,
            "f1": 0.95576
        },
        "bleurt": 0.60358,
        "meteor": 0.45150508987937693,
        "nubia": {
            "semantic_relation": 3.46431,
            "contradiction": 50.81687,
            "irrelevancy": 0.8388,
            "logical_agreement": 48.34432,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.01015,
            "nubia_score": 0.54185
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.6530437207411035,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.9828,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.18181818181818182,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.65,
            "recall": 0.49209,
            "fmeasure": 0.55604
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.24048,
            "fmeasure": 0.27773
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.4489,
            "fmeasure": 0.50406
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.4489,
            "fmeasure": 0.50406
        },
        "nist": 2.268586780837686,
        "bleu": 8.1022,
        "bertscore": {
            "precision": 0.89968,
            "recall": 0.87634,
            "f1": 0.88528
        },
        "bleurt": 0.07103,
        "meteor": 0.3042895806923726,
        "nubia": {
            "semantic_relation": 3.49257,
            "contradiction": 0.85021,
            "irrelevancy": 42.97098,
            "logical_agreement": 56.17881,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.52035,
            "nubia_score": 0.51679
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.67816,
            "recall": 0.77017,
            "fmeasure": 0.70962
        },
        "rouge2": {
            "precision": 0.42641,
            "recall": 0.48737,
            "fmeasure": 0.44624
        },
        "rougeL": {
            "precision": 0.48611,
            "recall": 0.54752,
            "fmeasure": 0.50598
        },
        "rougeLsum": {
            "precision": 0.48611,
            "recall": 0.54752,
            "fmeasure": 0.50598
        },
        "nist": 4.043682320078224,
        "bleu": 34.64727,
        "bertscore": {
            "precision": 0.9065,
            "recall": 0.91865,
            "f1": 0.90772
        },
        "bleurt": 0.15537,
        "meteor": 0.4041494781683084,
        "nubia": {
            "semantic_relation": 4.08266,
            "contradiction": 44.43087,
            "irrelevancy": 2.37423,
            "logical_agreement": 53.1949,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.66873,
            "nubia_score": 0.61841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.5263157894736842,
            "3": 0.5370370370370371
        },
        "rouge1": {
            "precision": 0.61843,
            "recall": 0.57352,
            "fmeasure": 0.56317
        },
        "rouge2": {
            "precision": 0.27466,
            "recall": 0.24494,
            "fmeasure": 0.24587
        },
        "rougeL": {
            "precision": 0.44777,
            "recall": 0.42916,
            "fmeasure": 0.41487
        },
        "rougeLsum": {
            "precision": 0.44777,
            "recall": 0.42916,
            "fmeasure": 0.41487
        },
        "nist": 3.989152995842667,
        "bleu": 24.17781,
        "bertscore": {
            "precision": 0.86512,
            "recall": 0.84211,
            "f1": 0.85158
        },
        "bleurt": -0.27497,
        "meteor": 0.27798062551591934,
        "nubia": {
            "semantic_relation": 3.40101,
            "contradiction": 42.75115,
            "irrelevancy": 30.51606,
            "logical_agreement": 26.73279,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.0198,
            "nubia_score": 0.50387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.77778,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.84211,
            "fmeasure": 0.86486
        },
        "nist": 3.147436368698301,
        "bleu": 51.10997,
        "bertscore": {
            "precision": 0.94038,
            "recall": 0.92784,
            "f1": 0.93407
        },
        "bleurt": 0.39218,
        "meteor": 0.4193552855930098,
        "nubia": {
            "semantic_relation": 3.90734,
            "contradiction": 11.05613,
            "irrelevancy": 85.79769,
            "logical_agreement": 3.14618,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.90573,
            "nubia_score": 0.51475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.28,
            "3": 0.8840579710144928
        },
        "rouge1": {
            "precision": 0.70807,
            "recall": 0.67889,
            "fmeasure": 0.68653
        },
        "rouge2": {
            "precision": 0.42635,
            "recall": 0.43366,
            "fmeasure": 0.42568
        },
        "rougeL": {
            "precision": 0.60295,
            "recall": 0.55339,
            "fmeasure": 0.57088
        },
        "rougeLsum": {
            "precision": 0.60295,
            "recall": 0.55339,
            "fmeasure": 0.57088
        },
        "nist": 5.221445404970172,
        "bleu": 43.03606,
        "bertscore": {
            "precision": 0.90381,
            "recall": 0.91327,
            "f1": 0.90535
        },
        "bleurt": -0.06527,
        "meteor": 0.37507266158207214,
        "nubia": {
            "semantic_relation": 3.56262,
            "contradiction": 7.48142,
            "irrelevancy": 38.52702,
            "logical_agreement": 53.99156,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.89589,
            "nubia_score": 0.54351
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "mT5_small/totto_test",
        "N": 110,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20634920634920634,
            "2": 0.4960212201591512,
            "3": 0.7462264150943396
        },
        "rouge1": {
            "precision": 0.7547,
            "recall": 0.69216,
            "fmeasure": 0.70534
        },
        "rouge2": {
            "precision": 0.50554,
            "recall": 0.46715,
            "fmeasure": 0.47376
        },
        "rougeL": {
            "precision": 0.65073,
            "recall": 0.59939,
            "fmeasure": 0.60917
        },
        "rougeLsum": {
            "precision": 0.65073,
            "recall": 0.59939,
            "fmeasure": 0.60917
        },
        "nist": 7.287269393376619,
        "bleu": 42.32305,
        "bertscore": {
            "precision": 0.9277,
            "recall": 0.91504,
            "f1": 0.91925
        },
        "bleurt": 0.18848,
        "meteor": 0.370808084186216,
        "nubia": {
            "semantic_relation": 4.02859,
            "contradiction": 14.60962,
            "irrelevancy": 25.82097,
            "logical_agreement": 59.56941,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.92446,
            "nubia_score": 0.66508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.25
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.32479,
            "fmeasure": 0.43636
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.07937,
            "fmeasure": 0.10741
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.29402,
            "fmeasure": 0.38788
        },
        "nist": 0.22125202633764687,
        "bleu": 4.42014,
        "bertscore": {
            "precision": 0.84326,
            "recall": 0.76332,
            "f1": 0.8013
        },
        "bleurt": -0.86803,
        "meteor": 0.14078298802960232,
        "nubia": {
            "semantic_relation": 2.77856,
            "contradiction": 5.43097,
            "irrelevancy": 30.9441,
            "logical_agreement": 63.62493,
            "grammar_ref": 4.61776,
            "grammar_hyp": 5.17462,
            "nubia_score": 0.22176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.65783,
            "recall": 0.49974,
            "fmeasure": 0.5557
        },
        "rouge2": {
            "precision": 0.41212,
            "recall": 0.32621,
            "fmeasure": 0.35751
        },
        "rougeL": {
            "precision": 0.65783,
            "recall": 0.49974,
            "fmeasure": 0.5557
        },
        "rougeLsum": {
            "precision": 0.65783,
            "recall": 0.49974,
            "fmeasure": 0.5557
        },
        "nist": 2.4179656869106485,
        "bleu": 32.74132,
        "bertscore": {
            "precision": 0.92276,
            "recall": 0.90437,
            "f1": 0.91275
        },
        "bleurt": -0.04101,
        "meteor": 0.2818325310861648,
        "nubia": {
            "semantic_relation": 3.68769,
            "contradiction": 20.12931,
            "irrelevancy": 50.95124,
            "logical_agreement": 28.91944,
            "grammar_ref": 5.06451,
            "grammar_hyp": 5.33486,
            "nubia_score": 0.59761
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.63619,
            "fmeasure": 0.51414
        },
        "rouge2": {
            "precision": 0.21739,
            "recall": 0.33217,
            "fmeasure": 0.25926
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.32505,
            "fmeasure": 0.26054
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.32505,
            "fmeasure": 0.26054
        },
        "nist": 2.3168893666253565,
        "bleu": 9.61984,
        "bertscore": {
            "precision": 0.81666,
            "recall": 0.86394,
            "f1": 0.83423
        },
        "bleurt": -0.24894,
        "meteor": 0.30992761797159807,
        "nubia": {
            "semantic_relation": 3.53703,
            "contradiction": 0.18988,
            "irrelevancy": 92.42128,
            "logical_agreement": 7.38883,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.52909,
            "nubia_score": 0.6088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.70536,
            "recall": 0.61975,
            "fmeasure": 0.65796
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.36966,
            "fmeasure": 0.38522
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.54034,
            "fmeasure": 0.57015
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.54034,
            "fmeasure": 0.57015
        },
        "nist": 4.074897044453666,
        "bleu": 40.47949,
        "bertscore": {
            "precision": 0.93266,
            "recall": 0.9222,
            "f1": 0.92719
        },
        "bleurt": 0.5226,
        "meteor": 0.39756302938096794,
        "nubia": {
            "semantic_relation": 4.14107,
            "contradiction": 48.48783,
            "irrelevancy": 0.84358,
            "logical_agreement": 50.66859,
            "grammar_ref": 4.56502,
            "grammar_hyp": 4.98324,
            "nubia_score": 0.69562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.59777,
            "fmeasure": 0.65133
        },
        "rouge2": {
            "precision": 0.36074,
            "recall": 0.31111,
            "fmeasure": 0.32972
        },
        "rougeL": {
            "precision": 0.39444,
            "recall": 0.3403,
            "fmeasure": 0.3616
        },
        "rougeLsum": {
            "precision": 0.39444,
            "recall": 0.3403,
            "fmeasure": 0.3616
        },
        "nist": 4.011824337755834,
        "bleu": 33.00507,
        "bertscore": {
            "precision": 0.8745,
            "recall": 0.84409,
            "f1": 0.85867
        },
        "bleurt": -0.13844,
        "meteor": 0.3202392086521521,
        "nubia": {
            "semantic_relation": 3.77719,
            "contradiction": 0.44879,
            "irrelevancy": 6.87543,
            "logical_agreement": 92.67577,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.75298,
            "nubia_score": 0.63681
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.73684,
            "recall": 1.0,
            "fmeasure": 0.84848
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.92857,
            "fmeasure": 0.78788
        },
        "nist": 2.60283922618523,
        "bleu": 45.83034,
        "bertscore": {
            "precision": 0.91731,
            "recall": 0.96154,
            "f1": 0.9389
        },
        "bleurt": 0.33762,
        "meteor": 0.4840606541446009,
        "nubia": {
            "semantic_relation": 3.8007,
            "contradiction": 0.15758,
            "irrelevancy": 99.74505,
            "logical_agreement": 0.09738,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.7782,
            "nubia_score": 0.71692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.07692307692307693,
            "3": 0.7317073170731707
        },
        "rouge1": {
            "precision": 0.69592,
            "recall": 0.63256,
            "fmeasure": 0.65017
        },
        "rouge2": {
            "precision": 0.37051,
            "recall": 0.36534,
            "fmeasure": 0.36252
        },
        "rougeL": {
            "precision": 0.56489,
            "recall": 0.56677,
            "fmeasure": 0.55959
        },
        "rougeLsum": {
            "precision": 0.56489,
            "recall": 0.56677,
            "fmeasure": 0.55959
        },
        "nist": 3.489646176998106,
        "bleu": 28.43152,
        "bertscore": {
            "precision": 0.91198,
            "recall": 0.88177,
            "f1": 0.8936
        },
        "bleurt": 0.06302,
        "meteor": 0.30471774592256035,
        "nubia": {
            "semantic_relation": 3.95124,
            "contradiction": 0.303,
            "irrelevancy": 33.83076,
            "logical_agreement": 65.86624,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.18794,
            "nubia_score": 0.66631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44048,
            "fmeasure": 0.36594
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.14444,
            "fmeasure": 0.12063
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.2619,
            "fmeasure": 0.22464
        },
        "nist": 1.2671131093267114,
        "bleu": 5.65304,
        "bertscore": {
            "precision": 0.71649,
            "recall": 0.77892,
            "f1": 0.71421
        },
        "bleurt": -0.16926,
        "meteor": 0.24704253628256037,
        "nubia": {
            "semantic_relation": 3.33196,
            "contradiction": 0.33125,
            "irrelevancy": 82.65665,
            "logical_agreement": 17.0121,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.6716,
            "nubia_score": 0.40817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40179,
            "fmeasure": 0.36397
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "nist": 1.2349851365001359,
        "bleu": 16.78446,
        "bertscore": {
            "precision": 0.85831,
            "recall": 0.87683,
            "f1": 0.86747
        },
        "bleurt": 0.52303,
        "meteor": 0.27858768568166986,
        "nubia": {
            "semantic_relation": 4.2029,
            "contradiction": 7.06447,
            "irrelevancy": 12.79331,
            "logical_agreement": 80.14222,
            "grammar_ref": 4.73918,
            "grammar_hyp": 4.01995,
            "nubia_score": 0.76232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "rouge2": {
            "precision": 0.6641,
            "recall": 0.80833,
            "fmeasure": 0.71905
        },
        "rougeL": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "rougeLsum": {
            "precision": 0.78175,
            "recall": 0.92037,
            "fmeasure": 0.83816
        },
        "nist": 3.7374922733925366,
        "bleu": 68.0971,
        "bertscore": {
            "precision": 0.93427,
            "recall": 0.95632,
            "f1": 0.94502
        },
        "bleurt": 0.22485,
        "meteor": 0.5682213889075267,
        "nubia": {
            "semantic_relation": 4.57648,
            "contradiction": 6.95906,
            "irrelevancy": 38.1223,
            "logical_agreement": 54.91864,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.24021,
            "nubia_score": 0.83489
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.7333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.41182,
            "recall": 0.71065,
            "fmeasure": 0.51624
        },
        "rouge2": {
            "precision": 0.27083,
            "recall": 0.4652,
            "fmeasure": 0.33933
        },
        "rougeL": {
            "precision": 0.3983,
            "recall": 0.68113,
            "fmeasure": 0.49771
        },
        "rougeLsum": {
            "precision": 0.3983,
            "recall": 0.68113,
            "fmeasure": 0.49771
        },
        "nist": 1.7809502259295327,
        "bleu": 14.20815,
        "bertscore": {
            "precision": 0.86544,
            "recall": 0.93305,
            "f1": 0.89766
        },
        "bleurt": 0.27306,
        "meteor": 0.33357455678447295,
        "nubia": {
            "semantic_relation": 4.17434,
            "contradiction": 0.84832,
            "irrelevancy": 37.24844,
            "logical_agreement": 61.90324,
            "grammar_ref": 4.46901,
            "grammar_hyp": 2.9498,
            "nubia_score": 0.59081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.84175,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "nist": 2.3648189689631285,
        "bleu": 10.88697,
        "bertscore": {
            "precision": 0.87464,
            "recall": 0.91728,
            "f1": 0.89545
        },
        "bleurt": -0.38963,
        "meteor": 0.37885739133291024,
        "nubia": {
            "semantic_relation": 4.05623,
            "contradiction": 3.3209,
            "irrelevancy": 92.48141,
            "logical_agreement": 4.19768,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.98883,
            "nubia_score": 0.50759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.85
        },
        "rouge1": {
            "precision": 0.68505,
            "recall": 0.87273,
            "fmeasure": 0.76728
        },
        "rouge2": {
            "precision": 0.40625,
            "recall": 0.58572,
            "fmeasure": 0.47742
        },
        "rougeL": {
            "precision": 0.49387,
            "recall": 0.70167,
            "fmeasure": 0.57706
        },
        "rougeLsum": {
            "precision": 0.49387,
            "recall": 0.70167,
            "fmeasure": 0.57706
        },
        "nist": 3.254259256036712,
        "bleu": 18.59724,
        "bertscore": {
            "precision": 0.90761,
            "recall": 0.93627,
            "f1": 0.91881
        },
        "bleurt": 0.31695,
        "meteor": 0.42053572769532177,
        "nubia": {
            "semantic_relation": 4.58234,
            "contradiction": 19.62458,
            "irrelevancy": 18.32503,
            "logical_agreement": 62.05038,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.97886,
            "nubia_score": 0.79063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.53333,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.53333,
            "fmeasure": 0.53333
        },
        "nist": 3.055782062394915,
        "bleu": 39.31752,
        "bertscore": {
            "precision": 0.92052,
            "recall": 0.91267,
            "f1": 0.91658
        },
        "bleurt": 0.17177,
        "meteor": 0.3784026912762234,
        "nubia": {
            "semantic_relation": 3.95986,
            "contradiction": 0.12994,
            "irrelevancy": 1.59288,
            "logical_agreement": 98.27718,
            "grammar_ref": 4.08392,
            "grammar_hyp": 4.11066,
            "nubia_score": 0.73654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.47674,
            "fmeasure": 0.57821
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.31313,
            "fmeasure": 0.37235
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.438,
            "fmeasure": 0.52703
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.438,
            "fmeasure": 0.52703
        },
        "nist": 2.4717278568707313,
        "bleu": 25.62149,
        "bertscore": {
            "precision": 0.92628,
            "recall": 0.86032,
            "f1": 0.89208
        },
        "bleurt": 0.00663,
        "meteor": 0.2667540001968566,
        "nubia": {
            "semantic_relation": 3.49895,
            "contradiction": 89.76286,
            "irrelevancy": 8.21905,
            "logical_agreement": 2.01809,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.69979,
            "nubia_score": 0.4371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.64935,
            "fmeasure": 0.68364
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.78333,
            "fmeasure": 0.82407
        },
        "nist": 3.8107815848368243,
        "bleu": 71.38958,
        "bertscore": {
            "precision": 0.98905,
            "recall": 0.98905,
            "f1": 0.98905
        },
        "bleurt": 0.61973,
        "meteor": 0.9233576642335767,
        "nubia": {
            "semantic_relation": 4.6448,
            "contradiction": 0.52652,
            "irrelevancy": 0.67281,
            "logical_agreement": 98.80067,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.73563,
            "nubia_score": 0.8067
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.87277,
            "recall": 0.8022,
            "fmeasure": 0.83372
        },
        "rouge2": {
            "precision": 0.75978,
            "recall": 0.70055,
            "fmeasure": 0.72678
        },
        "rougeL": {
            "precision": 0.86027,
            "recall": 0.79084,
            "fmeasure": 0.82182
        },
        "rougeLsum": {
            "precision": 0.86027,
            "recall": 0.79084,
            "fmeasure": 0.82182
        },
        "nist": 4.088049868383423,
        "bleu": 53.86707,
        "bertscore": {
            "precision": 0.96152,
            "recall": 0.95392,
            "f1": 0.95768
        },
        "bleurt": 0.66119,
        "meteor": 0.4203940047431396,
        "nubia": {
            "semantic_relation": 4.115,
            "contradiction": 46.01821,
            "irrelevancy": 1.52967,
            "logical_agreement": 52.45212,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.10445,
            "nubia_score": 0.72282
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.80359,
            "recall": 0.76389,
            "fmeasure": 0.76615
        },
        "rouge2": {
            "precision": 0.58056,
            "recall": 0.56665,
            "fmeasure": 0.55942
        },
        "rougeL": {
            "precision": 0.74299,
            "recall": 0.70093,
            "fmeasure": 0.7045
        },
        "rougeLsum": {
            "precision": 0.74299,
            "recall": 0.70093,
            "fmeasure": 0.7045
        },
        "nist": 3.3547323588780236,
        "bleu": 45.23142,
        "bertscore": {
            "precision": 0.92618,
            "recall": 0.92996,
            "f1": 0.92698
        },
        "bleurt": 0.03708,
        "meteor": 0.43344884871904366,
        "nubia": {
            "semantic_relation": 3.94465,
            "contradiction": 0.6548,
            "irrelevancy": 57.9879,
            "logical_agreement": 41.35731,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.9824,
            "nubia_score": 0.5918
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.4375
        },
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.54127,
            "fmeasure": 0.5594
        },
        "rouge2": {
            "precision": 0.2037,
            "recall": 0.18596,
            "fmeasure": 0.1944
        },
        "rougeL": {
            "precision": 0.35088,
            "recall": 0.32222,
            "fmeasure": 0.3359
        },
        "rougeLsum": {
            "precision": 0.35088,
            "recall": 0.32222,
            "fmeasure": 0.3359
        },
        "nist": 2.492717953532228,
        "bleu": 10.81301,
        "bertscore": {
            "precision": 0.81863,
            "recall": 0.81171,
            "f1": 0.81516
        },
        "bleurt": -0.41438,
        "meteor": 0.27939134102431173,
        "nubia": {
            "semantic_relation": 3.64729,
            "contradiction": 0.091,
            "irrelevancy": 99.76063,
            "logical_agreement": 0.14837,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.74501,
            "nubia_score": 0.52973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.09090909090909091,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.56975,
            "fmeasure": 0.60949
        },
        "rouge2": {
            "precision": 0.54667,
            "recall": 0.47009,
            "fmeasure": 0.50143
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.56142,
            "fmeasure": 0.59939
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.56142,
            "fmeasure": 0.59939
        },
        "nist": 2.389425636181642,
        "bleu": 45.87949,
        "bertscore": {
            "precision": 0.93932,
            "recall": 0.86215,
            "f1": 0.89908
        },
        "bleurt": -0.07303,
        "meteor": 0.3140982621064453,
        "nubia": {
            "semantic_relation": 2.53711,
            "contradiction": 98.53676,
            "irrelevancy": 0.65147,
            "logical_agreement": 0.81177,
            "grammar_ref": 3.4256,
            "grammar_hyp": 2.72732,
            "nubia_score": 0.30449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.34119,
            "fmeasure": 0.46358
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.2674,
            "fmeasure": 0.36918
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.29854,
            "fmeasure": 0.40564
        },
        "nist": 0.19432195860366142,
        "bleu": 17.92681,
        "bertscore": {
            "precision": 0.87739,
            "recall": 0.81951,
            "f1": 0.84746
        },
        "bleurt": -0.29666,
        "meteor": 0.2526845694782849,
        "nubia": {
            "semantic_relation": 3.33397,
            "contradiction": 5.86135,
            "irrelevancy": 1.66517,
            "logical_agreement": 92.47349,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.6356,
            "nubia_score": 0.31744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5615,
            "fmeasure": 0.52387
        },
        "rouge2": {
            "precision": 0.20513,
            "recall": 0.24444,
            "fmeasure": 0.22153
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.32576,
            "fmeasure": 0.30222
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.32576,
            "fmeasure": 0.30222
        },
        "nist": 2.5247307087219455,
        "bleu": 9.12008,
        "bertscore": {
            "precision": 0.85712,
            "recall": 0.89798,
            "f1": 0.87632
        },
        "bleurt": -0.18596,
        "meteor": 0.323011202200837,
        "nubia": {
            "semantic_relation": 3.85213,
            "contradiction": 0.38405,
            "irrelevancy": 98.9316,
            "logical_agreement": 0.68435,
            "grammar_ref": 4.84054,
            "grammar_hyp": 5.79467,
            "nubia_score": 0.47187
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.52564,
            "fmeasure": 0.57556
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.51282,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.51282,
            "fmeasure": 0.55556
        },
        "nist": 2.0800184486222952,
        "bleu": 22.49927,
        "bertscore": {
            "precision": 0.90999,
            "recall": 0.87479,
            "f1": 0.89204
        },
        "bleurt": -0.29798,
        "meteor": 0.27382337313381716,
        "nubia": {
            "semantic_relation": 3.06182,
            "contradiction": 0.79139,
            "irrelevancy": 98.7086,
            "logical_agreement": 0.50001,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.05827,
            "nubia_score": 0.34303
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "mT5_small/totto_test",
        "N": 8,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.34615384615384615,
            "2": 0.6486486486486487,
            "3": 0.6712328767123288
        },
        "rouge1": {
            "precision": 0.79042,
            "recall": 0.6558,
            "fmeasure": 0.69283
        },
        "rouge2": {
            "precision": 0.57194,
            "recall": 0.48399,
            "fmeasure": 0.50658
        },
        "rougeL": {
            "precision": 0.73661,
            "recall": 0.60816,
            "fmeasure": 0.63861
        },
        "rougeLsum": {
            "precision": 0.73661,
            "recall": 0.60816,
            "fmeasure": 0.63861
        },
        "nist": 3.992937382763322,
        "bleu": 43.1545,
        "bertscore": {
            "precision": 0.91072,
            "recall": 0.88833,
            "f1": 0.89776
        },
        "bleurt": -0.03797,
        "meteor": 0.341977491048397,
        "nubia": {
            "semantic_relation": 3.413,
            "contradiction": 40.33477,
            "irrelevancy": 26.79938,
            "logical_agreement": 32.86585,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.40336,
            "nubia_score": 0.4963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.83502,
            "fmeasure": 0.6771
        },
        "rouge2": {
            "precision": 0.25641,
            "recall": 0.41667,
            "fmeasure": 0.31746
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.62963,
            "fmeasure": 0.49275
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.62963,
            "fmeasure": 0.49275
        },
        "nist": 2.7063492194507752,
        "bleu": 19.25161,
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.92889,
            "f1": 0.92173
        },
        "bleurt": 0.37168,
        "meteor": 0.32532669468973185,
        "nubia": {
            "semantic_relation": 4.50656,
            "contradiction": 0.29677,
            "irrelevancy": 81.06517,
            "logical_agreement": 18.63806,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.18054,
            "nubia_score": 0.78016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 3.282100621995838,
        "bleu": 63.40466,
        "bertscore": {
            "precision": 0.97368,
            "recall": 0.98391,
            "f1": 0.97877
        },
        "bleurt": 0.59174,
        "meteor": 0.49956437727591835,
        "nubia": {
            "semantic_relation": 4.44341,
            "contradiction": 53.77061,
            "irrelevancy": 38.83098,
            "logical_agreement": 7.39841,
            "grammar_ref": 5.3705,
            "grammar_hyp": 4.99775,
            "nubia_score": 0.66513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "nist": 4.306797170061882,
        "bleu": 69.04427,
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        },
        "bleurt": 0.47554,
        "meteor": 0.5500501807094148,
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rouge2": {
            "precision": 0.63158,
            "recall": 0.63158,
            "fmeasure": 0.63158
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "nist": 3.0294084695357357,
        "bleu": 46.50755,
        "bertscore": {
            "precision": 0.89426,
            "recall": 0.87293,
            "f1": 0.8775
        },
        "bleurt": 0.15682,
        "meteor": 0.3820628495120413,
        "nubia": {
            "semantic_relation": 3.67592,
            "contradiction": 0.09612,
            "irrelevancy": 98.91132,
            "logical_agreement": 0.99257,
            "grammar_ref": 3.95052,
            "grammar_hyp": 3.25097,
            "nubia_score": 0.76614
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.8963,
            "fmeasure": 0.8807
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "nist": 3.354997429774719,
        "bleu": 71.70327,
        "bertscore": {
            "precision": 0.97182,
            "recall": 0.98396,
            "f1": 0.97747
        },
        "bleurt": 0.72235,
        "meteor": 0.5423794259791352,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23544,
            "irrelevancy": 0.46592,
            "logical_agreement": 99.29864,
            "grammar_ref": 5.07856,
            "grammar_hyp": 4.58636,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.25,
            "3": 0.5172413793103449
        },
        "rouge1": {
            "precision": 0.43734,
            "recall": 0.48145,
            "fmeasure": 0.45323
        },
        "rouge2": {
            "precision": 0.16528,
            "recall": 0.23504,
            "fmeasure": 0.19361
        },
        "rougeL": {
            "precision": 0.37821,
            "recall": 0.40934,
            "fmeasure": 0.38878
        },
        "rougeLsum": {
            "precision": 0.37821,
            "recall": 0.40934,
            "fmeasure": 0.38878
        },
        "nist": 2.378471299222892,
        "bleu": 17.81527,
        "bertscore": {
            "precision": 0.83194,
            "recall": 0.84714,
            "f1": 0.83482
        },
        "bleurt": -0.14708,
        "meteor": 0.23128452772485703,
        "nubia": {
            "semantic_relation": 3.37841,
            "contradiction": 33.29991,
            "irrelevancy": 34.13664,
            "logical_agreement": 32.56346,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.38747,
            "nubia_score": 0.54524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.7608695652173914
        },
        "rouge1": {
            "precision": 0.73968,
            "recall": 0.75037,
            "fmeasure": 0.74474
        },
        "rouge2": {
            "precision": 0.58205,
            "recall": 0.58745,
            "fmeasure": 0.5846
        },
        "rougeL": {
            "precision": 0.7254,
            "recall": 0.73608,
            "fmeasure": 0.73045
        },
        "rougeLsum": {
            "precision": 0.7254,
            "recall": 0.73608,
            "fmeasure": 0.73045
        },
        "nist": 3.9543942925253943,
        "bleu": 44.25906,
        "bertscore": {
            "precision": 0.90884,
            "recall": 0.91948,
            "f1": 0.91372
        },
        "bleurt": 0.21379,
        "meteor": 0.3998706375895962,
        "nubia": {
            "semantic_relation": 3.76336,
            "contradiction": 20.12779,
            "irrelevancy": 23.27645,
            "logical_agreement": 56.59576,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.71878,
            "nubia_score": 0.70563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.79808,
            "recall": 0.78419,
            "fmeasure": 0.79072
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.53175,
            "fmeasure": 0.54637
        },
        "rougeL": {
            "precision": 0.75962,
            "recall": 0.74573,
            "fmeasure": 0.75226
        },
        "rougeLsum": {
            "precision": 0.75962,
            "recall": 0.74573,
            "fmeasure": 0.75226
        },
        "nist": 3.7425710735278708,
        "bleu": 36.62917,
        "bertscore": {
            "precision": 0.93896,
            "recall": 0.92532,
            "f1": 0.92916
        },
        "bleurt": 0.37329,
        "meteor": 0.45020311024396964,
        "nubia": {
            "semantic_relation": 4.48523,
            "contradiction": 0.63009,
            "irrelevancy": 33.88453,
            "logical_agreement": 65.48539,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.49755,
            "nubia_score": 0.79292
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "nist": 0.6179519972810469,
        "bleu": 30.67489,
        "bertscore": {
            "precision": 0.97564,
            "recall": 0.89184,
            "f1": 0.93186
        },
        "bleurt": 0.26056,
        "meteor": 0.4466946348571188,
        "nubia": {
            "semantic_relation": 4.15284,
            "contradiction": 0.35397,
            "irrelevancy": 0.51105,
            "logical_agreement": 99.13498,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.8924,
            "nubia_score": 0.88513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.62714,
            "fmeasure": 0.71197
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.46032,
            "fmeasure": 0.53011
        },
        "rougeL": {
            "precision": 0.80392,
            "recall": 0.60277,
            "fmeasure": 0.68889
        },
        "rougeLsum": {
            "precision": 0.80392,
            "recall": 0.60277,
            "fmeasure": 0.68889
        },
        "nist": 2.029998654650492,
        "bleu": 36.71749,
        "bertscore": {
            "precision": 0.93261,
            "recall": 0.9023,
            "f1": 0.9172
        },
        "bleurt": 0.25918,
        "meteor": 0.36073545005012414,
        "nubia": {
            "semantic_relation": 4.18867,
            "contradiction": 80.36043,
            "irrelevancy": 5.27783,
            "logical_agreement": 14.36173,
            "grammar_ref": 3.0511,
            "grammar_hyp": 3.25592,
            "nubia_score": 0.75997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.423065265165703,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.94038,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.8055555555555556
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.76612,
            "fmeasure": 0.82706
        },
        "rouge2": {
            "precision": 0.85823,
            "recall": 0.68056,
            "fmeasure": 0.72957
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.7475,
            "fmeasure": 0.80882
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.7475,
            "fmeasure": 0.80882
        },
        "nist": 4.0250079089993696,
        "bleu": 69.06189,
        "bertscore": {
            "precision": 0.98589,
            "recall": 0.95141,
            "f1": 0.96793
        },
        "bleurt": 0.52945,
        "meteor": 0.48781575241517827,
        "nubia": {
            "semantic_relation": 4.65497,
            "contradiction": 0.61813,
            "irrelevancy": 6.94662,
            "logical_agreement": 92.43525,
            "grammar_ref": 4.5734,
            "grammar_hyp": 5.43366,
            "nubia_score": 0.81481
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.30952,
            "fmeasure": 0.37798
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.14286,
            "recall": 0.09127,
            "fmeasure": 0.11012
        },
        "rougeLsum": {
            "precision": 0.14286,
            "recall": 0.09127,
            "fmeasure": 0.11012
        },
        "nist": 0.6313012927725296,
        "bleu": 5.36763,
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.85558,
            "f1": 0.86714
        },
        "bleurt": -0.34277,
        "meteor": 0.11691022964509397,
        "nubia": {
            "semantic_relation": 3.05977,
            "contradiction": 5.36346,
            "irrelevancy": 25.93902,
            "logical_agreement": 68.69752,
            "grammar_ref": 5.77141,
            "grammar_hyp": 6.70338,
            "nubia_score": 0.24783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.71429,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.42308,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.39153,
            "fmeasure": 0.34119
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.39153,
            "fmeasure": 0.34119
        },
        "nist": 3.0615363598565533,
        "bleu": 20.36612,
        "bertscore": {
            "precision": 0.86766,
            "recall": 0.88954,
            "f1": 0.87068
        },
        "bleurt": -0.81641,
        "meteor": 0.3706057722587009,
        "nubia": {
            "semantic_relation": 3.20139,
            "contradiction": 2.28219,
            "irrelevancy": 97.53961,
            "logical_agreement": 0.17819,
            "grammar_ref": 6.35753,
            "grammar_hyp": 7.30634,
            "nubia_score": 0.26126
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6451612903225806
        },
        "rouge1": {
            "precision": 0.66935,
            "recall": 0.70539,
            "fmeasure": 0.67036
        },
        "rouge2": {
            "precision": 0.51785,
            "recall": 0.4899,
            "fmeasure": 0.49762
        },
        "rougeL": {
            "precision": 0.64036,
            "recall": 0.64815,
            "fmeasure": 0.63189
        },
        "rougeLsum": {
            "precision": 0.64036,
            "recall": 0.64815,
            "fmeasure": 0.63189
        },
        "nist": 2.959737121560293,
        "bleu": 30.45825,
        "bertscore": {
            "precision": 0.90202,
            "recall": 0.91697,
            "f1": 0.90868
        },
        "bleurt": 0.331,
        "meteor": 0.3705653356591323,
        "nubia": {
            "semantic_relation": 4.31085,
            "contradiction": 3.81182,
            "irrelevancy": 10.18595,
            "logical_agreement": 86.00224,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.27053,
            "nubia_score": 0.64842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8095238095238095
        },
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.71131,
            "fmeasure": 0.78846
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.52518,
            "fmeasure": 0.56259
        },
        "rougeL": {
            "precision": 0.70085,
            "recall": 0.59768,
            "fmeasure": 0.63745
        },
        "rougeLsum": {
            "precision": 0.70085,
            "recall": 0.59768,
            "fmeasure": 0.63745
        },
        "nist": 3.6641893389970934,
        "bleu": 49.72215,
        "bertscore": {
            "precision": 0.97019,
            "recall": 0.93599,
            "f1": 0.95259
        },
        "bleurt": 0.47709,
        "meteor": 0.38787866751573935,
        "nubia": {
            "semantic_relation": 4.34985,
            "contradiction": 0.43247,
            "irrelevancy": 0.60689,
            "logical_agreement": 98.96065,
            "grammar_ref": 5.26806,
            "grammar_hyp": 5.02809,
            "nubia_score": 0.77043
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.25,
            "3": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44035,
            "fmeasure": 0.37939
        },
        "rouge2": {
            "precision": 0.08,
            "recall": 0.10526,
            "fmeasure": 0.09091
        },
        "rougeL": {
            "precision": 0.26923,
            "recall": 0.35,
            "fmeasure": 0.30435
        },
        "rougeLsum": {
            "precision": 0.26923,
            "recall": 0.35,
            "fmeasure": 0.30435
        },
        "nist": 1.9204614797416555,
        "bleu": 5.11438,
        "bertscore": {
            "precision": 0.77602,
            "recall": 0.80374,
            "f1": 0.78725
        },
        "bleurt": -0.50829,
        "meteor": 0.20823082080341515,
        "nubia": {
            "semantic_relation": 2.62119,
            "contradiction": 95.86554,
            "irrelevancy": 1.80632,
            "logical_agreement": 2.32814,
            "grammar_ref": 5.26752,
            "grammar_hyp": 3.63669,
            "nubia_score": 0.4782
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.28409,
            "fmeasure": 0.34792
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.43478,
            "fmeasure": 0.57143
        },
        "nist": 1.1611528151260602,
        "bleu": 31.55118,
        "bertscore": {
            "precision": 0.96949,
            "recall": 0.90853,
            "f1": 0.93049
        },
        "bleurt": 0.22867,
        "meteor": 0.3080289252406045,
        "nubia": {
            "semantic_relation": 3.82183,
            "contradiction": 33.80952,
            "irrelevancy": 2.2444,
            "logical_agreement": 63.94608,
            "grammar_ref": 4.20692,
            "grammar_hyp": 5.10487,
            "nubia_score": 0.47024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "rouge1": {
            "precision": 0.72,
            "recall": 0.75,
            "fmeasure": 0.73469
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.46377,
            "fmeasure": 0.4539
        },
        "rougeL": {
            "precision": 0.58667,
            "recall": 0.61111,
            "fmeasure": 0.59864
        },
        "rougeLsum": {
            "precision": 0.58667,
            "recall": 0.61111,
            "fmeasure": 0.59864
        },
        "nist": 4.4459300056842554,
        "bleu": 38.40974,
        "bertscore": {
            "precision": 0.91844,
            "recall": 0.91003,
            "f1": 0.91421
        },
        "bleurt": 0.25552,
        "meteor": 0.32474750087377086,
        "nubia": {
            "semantic_relation": 4.45604,
            "contradiction": 1.43658,
            "irrelevancy": 95.56464,
            "logical_agreement": 2.99878,
            "grammar_ref": 3.8277,
            "grammar_hyp": 2.96598,
            "nubia_score": 0.94387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "nist": 4.090634124990776,
        "bleu": 76.11606,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "bleurt": 0.48581,
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4782608695652174,
            "3": 0.5882352941176471
        },
        "rouge1": {
            "precision": 0.49528,
            "recall": 0.60613,
            "fmeasure": 0.53701
        },
        "rouge2": {
            "precision": 0.22531,
            "recall": 0.30579,
            "fmeasure": 0.25361
        },
        "rougeL": {
            "precision": 0.42015,
            "recall": 0.51043,
            "fmeasure": 0.45417
        },
        "rougeLsum": {
            "precision": 0.42015,
            "recall": 0.51043,
            "fmeasure": 0.45417
        },
        "nist": 2.891992483253483,
        "bleu": 16.87428,
        "bertscore": {
            "precision": 0.84398,
            "recall": 0.86181,
            "f1": 0.85079
        },
        "bleurt": -0.03337,
        "meteor": 0.23994962515617463,
        "nubia": {
            "semantic_relation": 3.35131,
            "contradiction": 6.52528,
            "irrelevancy": 62.95425,
            "logical_agreement": 30.52047,
            "grammar_ref": 4.61531,
            "grammar_hyp": 3.8868,
            "nubia_score": 0.57883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8260869565217391
        },
        "rouge1": {
            "precision": 0.81723,
            "recall": 0.78263,
            "fmeasure": 0.7978
        },
        "rouge2": {
            "precision": 0.66502,
            "recall": 0.63173,
            "fmeasure": 0.64614
        },
        "rougeL": {
            "precision": 0.76961,
            "recall": 0.73368,
            "fmeasure": 0.7494
        },
        "rougeLsum": {
            "precision": 0.76961,
            "recall": 0.73368,
            "fmeasure": 0.7494
        },
        "nist": 5.425389780148621,
        "bleu": 66.95645,
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.94936,
            "f1": 0.95175
        },
        "bleurt": 0.43831,
        "meteor": 0.4615234511201746,
        "nubia": {
            "semantic_relation": 4.38093,
            "contradiction": 25.12037,
            "irrelevancy": 0.66521,
            "logical_agreement": 74.21442,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.27716,
            "nubia_score": 0.83929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "nist": 2.7109047337507373,
        "bleu": 53.10725,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        },
        "bleurt": 0.22576,
        "meteor": 0.5033950705050299,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 4.3764992953429935,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.91462,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7037,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.76667,
            "fmeasure": 0.77193
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.76667,
            "fmeasure": 0.77193
        },
        "nist": 3.923549743383573,
        "bleu": 68.14154,
        "bertscore": {
            "precision": 0.96383,
            "recall": 0.95023,
            "f1": 0.95687
        },
        "bleurt": 0.66684,
        "meteor": 0.48383703309871473,
        "nubia": {
            "semantic_relation": 4.61187,
            "contradiction": 0.42729,
            "irrelevancy": 5.39194,
            "logical_agreement": 94.18077,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.90122,
            "nubia_score": 0.84762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.0,
            "3": 0.6944444444444444
        },
        "rouge1": {
            "precision": 0.61162,
            "recall": 0.54767,
            "fmeasure": 0.57171
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.26914,
            "fmeasure": 0.27914
        },
        "rougeL": {
            "precision": 0.43946,
            "recall": 0.40369,
            "fmeasure": 0.41583
        },
        "rougeLsum": {
            "precision": 0.43946,
            "recall": 0.40369,
            "fmeasure": 0.41583
        },
        "nist": 2.8559667794594117,
        "bleu": 17.28292,
        "bertscore": {
            "precision": 0.90278,
            "recall": 0.8729,
            "f1": 0.88673
        },
        "bleurt": 0.06076,
        "meteor": 0.3352910063892891,
        "nubia": {
            "semantic_relation": 4.11207,
            "contradiction": 0.84278,
            "irrelevancy": 15.38754,
            "logical_agreement": 83.76968,
            "grammar_ref": 4.73268,
            "grammar_hyp": 5.41616,
            "nubia_score": 0.63924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.4,
            "3": 0.56
        },
        "rouge1": {
            "precision": 0.91558,
            "recall": 0.58806,
            "fmeasure": 0.71264
        },
        "rouge2": {
            "precision": 0.52222,
            "recall": 0.31779,
            "fmeasure": 0.39245
        },
        "rougeL": {
            "precision": 0.58442,
            "recall": 0.39412,
            "fmeasure": 0.46799
        },
        "rougeLsum": {
            "precision": 0.58442,
            "recall": 0.39412,
            "fmeasure": 0.46799
        },
        "nist": 1.0366313759034123,
        "bleu": 13.38126,
        "bertscore": {
            "precision": 0.90939,
            "recall": 0.82282,
            "f1": 0.85521
        },
        "bleurt": 0.09843,
        "meteor": 0.2823130669255903,
        "nubia": {
            "semantic_relation": 3.90064,
            "contradiction": 0.40143,
            "irrelevancy": 0.49795,
            "logical_agreement": 99.10062,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.58913,
            "nubia_score": 0.6585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "rouge1": {
            "precision": 0.51667,
            "recall": 0.48077,
            "fmeasure": 0.48901
        },
        "rouge2": {
            "precision": 0.30903,
            "recall": 0.24466,
            "fmeasure": 0.2702
        },
        "rougeL": {
            "precision": 0.48725,
            "recall": 0.44231,
            "fmeasure": 0.45568
        },
        "rougeLsum": {
            "precision": 0.48725,
            "recall": 0.44231,
            "fmeasure": 0.45568
        },
        "nist": 2.4483571539609854,
        "bleu": 19.56475,
        "bertscore": {
            "precision": 0.85428,
            "recall": 0.84259,
            "f1": 0.84815
        },
        "bleurt": -0.40046,
        "meteor": 0.27839879730039707,
        "nubia": {
            "semantic_relation": 3.43146,
            "contradiction": 0.07503,
            "irrelevancy": 99.24542,
            "logical_agreement": 0.67955,
            "grammar_ref": 4.47266,
            "grammar_hyp": 4.09475,
            "nubia_score": 0.55988
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.66249,
            "fmeasure": 0.70955
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.37593,
            "fmeasure": 0.40414
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.61153,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.61153,
            "fmeasure": 0.65497
        },
        "nist": 2.9952271887957482,
        "bleu": 19.22324,
        "bertscore": {
            "precision": 0.91453,
            "recall": 0.90212,
            "f1": 0.90828
        },
        "bleurt": 0.05296,
        "meteor": 0.3486971558069454,
        "nubia": {
            "semantic_relation": 3.8939,
            "contradiction": 0.52642,
            "irrelevancy": 50.71396,
            "logical_agreement": 48.75962,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.10604,
            "nubia_score": 0.67152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.1699250014423126,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.99428,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "nist": 3.5579098675041347,
        "bleu": 73.48889,
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        },
        "bleurt": 0.54425,
        "meteor": 0.9384615384615386,
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.87329,
            "fmeasure": 0.88088
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.63508,
            "fmeasure": 0.6409
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.70955,
            "fmeasure": 0.71572
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.70955,
            "fmeasure": 0.71572
        },
        "nist": 3.9302432198125357,
        "bleu": 49.377,
        "bertscore": {
            "precision": 0.98154,
            "recall": 0.98154,
            "f1": 0.98154
        },
        "bleurt": 0.72768,
        "meteor": 0.5503896226161639,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.13677,
            "irrelevancy": 0.4447,
            "logical_agreement": 99.41854,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.69212,
            "nubia_score": 0.98656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.72365,
            "fmeasure": 0.72311
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.34722,
            "fmeasure": 0.37162
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "nist": 2.8204580279315103,
        "bleu": 48.32698,
        "bertscore": {
            "precision": 0.93117,
            "recall": 0.90925,
            "f1": 0.92008
        },
        "bleurt": 0.43562,
        "meteor": 0.37194330680678134,
        "nubia": {
            "semantic_relation": 4.58758,
            "contradiction": 0.13568,
            "irrelevancy": 0.81852,
            "logical_agreement": 99.0458,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.82569,
            "nubia_score": 0.87078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.37778,
            "fmeasure": 0.3121
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.10438,
            "fmeasure": 0.08464
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.37778,
            "fmeasure": 0.3121
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.37778,
            "fmeasure": 0.3121
        },
        "nist": 0.9340000908077821,
        "bleu": 3.7165,
        "bertscore": {
            "precision": 0.7949,
            "recall": 0.81432,
            "f1": 0.80449
        },
        "bleurt": -0.1664,
        "meteor": 0.20838560322744382,
        "nubia": {
            "semantic_relation": 3.19724,
            "contradiction": 0.14107,
            "irrelevancy": 99.7519,
            "logical_agreement": 0.10703,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.54669,
            "nubia_score": 0.40354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7857142857142857
        },
        "rouge1": {
            "precision": 0.75439,
            "recall": 0.675,
            "fmeasure": 0.71119
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.2479,
            "fmeasure": 0.26148
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.44444,
            "fmeasure": 0.42879
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.44444,
            "fmeasure": 0.42879
        },
        "nist": 3.67676243131574,
        "bleu": 12.5054,
        "bertscore": {
            "precision": 0.86951,
            "recall": 0.87723,
            "f1": 0.86694
        },
        "bleurt": -0.15397,
        "meteor": 0.3551387173625372,
        "nubia": {
            "semantic_relation": 4.00807,
            "contradiction": 56.48274,
            "irrelevancy": 38.31168,
            "logical_agreement": 5.20559,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.49972,
            "nubia_score": 0.63048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.618,
            "recall": 0.63694,
            "fmeasure": 0.59547
        },
        "rouge2": {
            "precision": 0.30524,
            "recall": 0.31656,
            "fmeasure": 0.28652
        },
        "rougeL": {
            "precision": 0.51576,
            "recall": 0.53547,
            "fmeasure": 0.49567
        },
        "rougeLsum": {
            "precision": 0.51576,
            "recall": 0.53547,
            "fmeasure": 0.49567
        },
        "nist": 2.740697150137998,
        "bleu": 7.95504,
        "bertscore": {
            "precision": 0.85943,
            "recall": 0.85185,
            "f1": 0.85381
        },
        "bleurt": -0.12458,
        "meteor": 0.28336585994389746,
        "nubia": {
            "semantic_relation": 3.41421,
            "contradiction": 10.15519,
            "irrelevancy": 30.85848,
            "logical_agreement": 58.98633,
            "grammar_ref": 3.73262,
            "grammar_hyp": 3.80894,
            "nubia_score": 0.52209
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.47857,
            "fmeasure": 0.54615
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.21703,
            "fmeasure": 0.25181
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.34048,
            "fmeasure": 0.38923
        },
        "nist": 3.0006339511684827,
        "bleu": 34.55764,
        "bertscore": {
            "precision": 0.92493,
            "recall": 0.90004,
            "f1": 0.91232
        },
        "bleurt": 0.23778,
        "meteor": 0.37056685299787695,
        "nubia": {
            "semantic_relation": 4.06878,
            "contradiction": 72.51704,
            "irrelevancy": 10.46826,
            "logical_agreement": 17.0147,
            "grammar_ref": 4.95834,
            "grammar_hyp": 5.30912,
            "nubia_score": 0.55376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "rouge1": {
            "precision": 0.67831,
            "recall": 0.7579,
            "fmeasure": 0.68975
        },
        "rouge2": {
            "precision": 0.40248,
            "recall": 0.46539,
            "fmeasure": 0.42014
        },
        "rougeL": {
            "precision": 0.60539,
            "recall": 0.69309,
            "fmeasure": 0.6261
        },
        "rougeLsum": {
            "precision": 0.60539,
            "recall": 0.69309,
            "fmeasure": 0.6261
        },
        "nist": 4.412923781565901,
        "bleu": 43.96276,
        "bertscore": {
            "precision": 0.90021,
            "recall": 0.91075,
            "f1": 0.90353
        },
        "bleurt": 0.40006,
        "meteor": 0.3860004036442326,
        "nubia": {
            "semantic_relation": 4.38101,
            "contradiction": 24.74336,
            "irrelevancy": 21.09056,
            "logical_agreement": 54.16608,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.4766,
            "nubia_score": 0.70514
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.67544,
            "recall": 0.6489,
            "fmeasure": 0.66176
        },
        "rouge2": {
            "precision": 0.4246,
            "recall": 0.41111,
            "fmeasure": 0.41762
        },
        "rougeL": {
            "precision": 0.51754,
            "recall": 0.49671,
            "fmeasure": 0.50679
        },
        "rougeLsum": {
            "precision": 0.51754,
            "recall": 0.49671,
            "fmeasure": 0.50679
        },
        "nist": 3.4240768897848066,
        "bleu": 37.92759,
        "bertscore": {
            "precision": 0.89609,
            "recall": 0.86498,
            "f1": 0.8796
        },
        "bleurt": 0.01114,
        "meteor": 0.32754847096162426,
        "nubia": {
            "semantic_relation": 3.31611,
            "contradiction": 0.26524,
            "irrelevancy": 40.94534,
            "logical_agreement": 58.78942,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.33433,
            "nubia_score": 0.51546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.65302,
            "fmeasure": 0.74196
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.38681,
            "fmeasure": 0.44167
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "nist": 2.27669746579841,
        "bleu": 33.92072,
        "bertscore": {
            "precision": 0.96929,
            "recall": 0.94456,
            "f1": 0.95676
        },
        "bleurt": 0.36837,
        "meteor": 0.41664419714148093,
        "nubia": {
            "semantic_relation": 4.84412,
            "contradiction": 0.57963,
            "irrelevancy": 0.83691,
            "logical_agreement": 98.58346,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.92275,
            "nubia_score": 0.93636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.44106,
            "fmeasure": 0.53549
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.28109,
            "fmeasure": 0.34316
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.32077,
            "fmeasure": 0.38945
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.32077,
            "fmeasure": 0.38945
        },
        "nist": 1.5248051278932206,
        "bleu": 28.1982,
        "bertscore": {
            "precision": 0.93562,
            "recall": 0.89079,
            "f1": 0.91266
        },
        "bleurt": 0.09427,
        "meteor": 0.2878104291239948,
        "nubia": {
            "semantic_relation": 3.80334,
            "contradiction": 20.08543,
            "irrelevancy": 2.42006,
            "logical_agreement": 77.4945,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.88779,
            "nubia_score": 0.58631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.8254,
            "fmeasure": 0.83844
        },
        "rouge2": {
            "precision": 0.7619,
            "recall": 0.73077,
            "fmeasure": 0.73929
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.8254,
            "fmeasure": 0.83844
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.8254,
            "fmeasure": 0.83844
        },
        "nist": 3.8250304508508277,
        "bleu": 76.24659,
        "bertscore": {
            "precision": 0.97942,
            "recall": 0.98571,
            "f1": 0.98255
        },
        "bleurt": 0.46131,
        "meteor": 0.5423090198415988,
        "nubia": {
            "semantic_relation": 4.01668,
            "contradiction": 0.22497,
            "irrelevancy": 0.47594,
            "logical_agreement": 99.2991,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.60383,
            "nubia_score": 0.74713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.45635,
            "fmeasure": 0.51348
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.25,
            "fmeasure": 0.27778
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.31944,
            "fmeasure": 0.35944
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.31944,
            "fmeasure": 0.35944
        },
        "nist": 1.578527034136064,
        "bleu": 8.56594,
        "bertscore": {
            "precision": 0.85646,
            "recall": 0.83091,
            "f1": 0.84287
        },
        "bleurt": -0.38404,
        "meteor": 0.24946771767473147,
        "nubia": {
            "semantic_relation": 3.43191,
            "contradiction": 3.50224,
            "irrelevancy": 87.14665,
            "logical_agreement": 9.35111,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.12294,
            "nubia_score": 0.40673
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.60185,
            "fmeasure": 0.61275
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.31746,
            "fmeasure": 0.34524
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.39167,
            "fmeasure": 0.4213
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.39167,
            "fmeasure": 0.4213
        },
        "nist": 2.3141418982197526,
        "bleu": 20.90067,
        "bertscore": {
            "precision": 0.85502,
            "recall": 0.83782,
            "f1": 0.84633
        },
        "bleurt": -0.76478,
        "meteor": 0.2742108970502077,
        "nubia": {
            "semantic_relation": 3.01932,
            "contradiction": 12.77311,
            "irrelevancy": 52.71214,
            "logical_agreement": 34.51475,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.66343,
            "nubia_score": 0.26267
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "nist": 2.786695492161276,
        "bleu": 32.64971,
        "bertscore": {
            "precision": 0.95819,
            "recall": 0.9622,
            "f1": 0.96019
        },
        "bleurt": 0.75303,
        "meteor": 0.4713546341303103,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29062,
            "irrelevancy": 0.42341,
            "logical_agreement": 99.28596,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.67848,
            "nubia_score": 0.99142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.4,
            "3": 0.6956521739130435
        },
        "rouge1": {
            "precision": 0.55671,
            "recall": 0.65409,
            "fmeasure": 0.59101
        },
        "rouge2": {
            "precision": 0.24402,
            "recall": 0.32118,
            "fmeasure": 0.27229
        },
        "rougeL": {
            "precision": 0.39738,
            "recall": 0.58303,
            "fmeasure": 0.46113
        },
        "rougeLsum": {
            "precision": 0.39738,
            "recall": 0.58303,
            "fmeasure": 0.46113
        },
        "nist": 3.8945015411640074,
        "bleu": 19.93805,
        "bertscore": {
            "precision": 0.8722,
            "recall": 0.93151,
            "f1": 0.89624
        },
        "bleurt": 0.20521,
        "meteor": 0.3409645962678813,
        "nubia": {
            "semantic_relation": 4.35602,
            "contradiction": 0.21594,
            "irrelevancy": 80.72671,
            "logical_agreement": 19.05735,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.68931,
            "nubia_score": 0.82474
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "rouge2": {
            "precision": 0.74713,
            "recall": 0.69167,
            "fmeasure": 0.71816
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.67025,
            "fmeasure": 0.69512
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.67025,
            "fmeasure": 0.69512
        },
        "nist": 5.021921524891575,
        "bleu": 60.89818,
        "bertscore": {
            "precision": 0.97773,
            "recall": 0.94954,
            "f1": 0.96343
        },
        "bleurt": 0.49108,
        "meteor": 0.4766358108004548,
        "nubia": {
            "semantic_relation": 3.78031,
            "contradiction": 0.1349,
            "irrelevancy": 0.64404,
            "logical_agreement": 99.22106,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.29238,
            "nubia_score": 0.71048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.6333333333333333
        },
        "rouge1": {
            "precision": 0.80719,
            "recall": 0.65529,
            "fmeasure": 0.71889
        },
        "rouge2": {
            "precision": 0.46429,
            "recall": 0.37342,
            "fmeasure": 0.41161
        },
        "rougeL": {
            "precision": 0.68431,
            "recall": 0.56058,
            "fmeasure": 0.61301
        },
        "rougeLsum": {
            "precision": 0.68431,
            "recall": 0.56058,
            "fmeasure": 0.61301
        },
        "nist": 3.013105535613936,
        "bleu": 18.38536,
        "bertscore": {
            "precision": 0.92384,
            "recall": 0.89532,
            "f1": 0.9028
        },
        "bleurt": 0.05337,
        "meteor": 0.28835460848674066,
        "nubia": {
            "semantic_relation": 4.18684,
            "contradiction": 1.85583,
            "irrelevancy": 43.73479,
            "logical_agreement": 54.40937,
            "grammar_ref": 4.16263,
            "grammar_hyp": 3.9673,
            "nubia_score": 0.73975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.6153846153846154,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.89205,
            "recall": 0.72298,
            "fmeasure": 0.79672
        },
        "rouge2": {
            "precision": 0.66905,
            "recall": 0.53409,
            "fmeasure": 0.592
        },
        "rougeL": {
            "precision": 0.8608,
            "recall": 0.69798,
            "fmeasure": 0.76894
        },
        "rougeLsum": {
            "precision": 0.8608,
            "recall": 0.69798,
            "fmeasure": 0.76894
        },
        "nist": 2.4571356409042977,
        "bleu": 48.99944,
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.91164,
            "f1": 0.91883
        },
        "bleurt": 0.01271,
        "meteor": 0.4055708409963595,
        "nubia": {
            "semantic_relation": 3.83831,
            "contradiction": 56.59016,
            "irrelevancy": 17.12766,
            "logical_agreement": 26.28218,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.67891,
            "nubia_score": 0.53029
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.89744,
            "recall": 0.94872,
            "fmeasure": 0.92094
        },
        "rouge2": {
            "precision": 0.80556,
            "recall": 0.91667,
            "fmeasure": 0.85606
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.92308,
            "fmeasure": 0.86752
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.92308,
            "fmeasure": 0.86752
        },
        "nist": 5.091289366370446,
        "bleu": 93.65138,
        "bertscore": {
            "precision": 0.95443,
            "recall": 0.9742,
            "f1": 0.94874
        },
        "bleurt": 0.39679,
        "meteor": 0.6100257941925625,
        "nubia": {
            "semantic_relation": 4.85505,
            "contradiction": 0.75098,
            "irrelevancy": 42.36888,
            "logical_agreement": 56.88014,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.28441,
            "nubia_score": 0.93135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.66826,
            "fmeasure": 0.7018
        },
        "rouge2": {
            "precision": 0.58824,
            "recall": 0.5291,
            "fmeasure": 0.55639
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.54705,
            "fmeasure": 0.59279
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.54705,
            "fmeasure": 0.59279
        },
        "nist": 4.092460335968241,
        "bleu": 48.62027,
        "bertscore": {
            "precision": 0.95734,
            "recall": 0.9379,
            "f1": 0.94752
        },
        "bleurt": 0.48074,
        "meteor": 0.4072890642119206,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.76433,
            "irrelevancy": 3.87462,
            "logical_agreement": 93.36105,
            "grammar_ref": 3.4928,
            "grammar_hyp": 4.31481,
            "nubia_score": 0.92602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.62281,
            "fmeasure": 0.54583
        },
        "rouge2": {
            "precision": 0.26061,
            "recall": 0.38917,
            "fmeasure": 0.31042
        },
        "rougeL": {
            "precision": 0.46875,
            "recall": 0.59485,
            "fmeasure": 0.51637
        },
        "rougeLsum": {
            "precision": 0.46875,
            "recall": 0.59485,
            "fmeasure": 0.51637
        },
        "nist": 2.1713012729623213,
        "bleu": 14.1478,
        "bertscore": {
            "precision": 0.86135,
            "recall": 0.89198,
            "f1": 0.87578
        },
        "bleurt": -0.13992,
        "meteor": 0.26482972342281486,
        "nubia": {
            "semantic_relation": 3.38956,
            "contradiction": 0.83484,
            "irrelevancy": 71.78527,
            "logical_agreement": 27.37989,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.46028,
            "nubia_score": 0.47291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.82164,
            "fmeasure": 0.87126
        },
        "rouge2": {
            "precision": 0.74603,
            "recall": 0.66361,
            "fmeasure": 0.69986
        },
        "rougeL": {
            "precision": 0.75556,
            "recall": 0.67622,
            "fmeasure": 0.71143
        },
        "rougeLsum": {
            "precision": 0.75556,
            "recall": 0.67622,
            "fmeasure": 0.71143
        },
        "nist": 4.671852119565929,
        "bleu": 58.91835,
        "bertscore": {
            "precision": 0.97093,
            "recall": 0.95548,
            "f1": 0.96266
        },
        "bleurt": 0.66291,
        "meteor": 0.4834268364575855,
        "nubia": {
            "semantic_relation": 4.65275,
            "contradiction": 3.96401,
            "irrelevancy": 29.31024,
            "logical_agreement": 66.72575,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.15314,
            "nubia_score": 0.81077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.7
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.74176,
            "fmeasure": 0.78462
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4391,
            "fmeasure": 0.46739
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66758,
            "fmeasure": 0.70615
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66758,
            "fmeasure": 0.70615
        },
        "nist": 3.5365094621786812,
        "bleu": 43.76004,
        "bertscore": {
            "precision": 0.96489,
            "recall": 0.93288,
            "f1": 0.94861
        },
        "bleurt": 0.25916,
        "meteor": 0.39010844864076505,
        "nubia": {
            "semantic_relation": 3.90939,
            "contradiction": 7.59503,
            "irrelevancy": 46.05359,
            "logical_agreement": 46.35138,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.59658,
            "nubia_score": 0.54474
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.55,
            "3": 0.7407407407407407
        },
        "rouge1": {
            "precision": 0.65313,
            "recall": 0.68487,
            "fmeasure": 0.66176
        },
        "rouge2": {
            "precision": 0.41511,
            "recall": 0.44099,
            "fmeasure": 0.4203
        },
        "rougeL": {
            "precision": 0.57261,
            "recall": 0.60121,
            "fmeasure": 0.58049
        },
        "rougeLsum": {
            "precision": 0.57261,
            "recall": 0.60121,
            "fmeasure": 0.58049
        },
        "nist": 4.014561264128624,
        "bleu": 34.88663,
        "bertscore": {
            "precision": 0.89166,
            "recall": 0.90223,
            "f1": 0.89683
        },
        "bleurt": 0.07749,
        "meteor": 0.35952400062127526,
        "nubia": {
            "semantic_relation": 3.19358,
            "contradiction": 33.13552,
            "irrelevancy": 40.58969,
            "logical_agreement": 26.27478,
            "grammar_ref": 4.43752,
            "grammar_hyp": 3.81235,
            "nubia_score": 0.5471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8666666666666667
        },
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.82372,
            "fmeasure": 0.89054
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.62727,
            "fmeasure": 0.68975
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.71902,
            "fmeasure": 0.77822
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.71902,
            "fmeasure": 0.77822
        },
        "nist": 3.415091667033954,
        "bleu": 53.84228,
        "bertscore": {
            "precision": 0.97058,
            "recall": 0.92591,
            "f1": 0.94765
        },
        "bleurt": 0.27416,
        "meteor": 0.4233150945010734,
        "nubia": {
            "semantic_relation": 4.16491,
            "contradiction": 0.44484,
            "irrelevancy": 16.61307,
            "logical_agreement": 82.94209,
            "grammar_ref": 5.09196,
            "grammar_hyp": 5.19132,
            "nubia_score": 0.71936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.375
        },
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.2803,
            "fmeasure": 0.32543
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.19318,
            "fmeasure": 0.22134
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.19318,
            "fmeasure": 0.22134
        },
        "nist": 1.0658620505066725,
        "bleu": 4.47668,
        "bertscore": {
            "precision": 0.85966,
            "recall": 0.7994,
            "f1": 0.82844
        },
        "bleurt": -0.29012,
        "meteor": 0.16481774960380347,
        "nubia": {
            "semantic_relation": 3.34076,
            "contradiction": 1.01048,
            "irrelevancy": 48.67258,
            "logical_agreement": 50.31694,
            "grammar_ref": 4.87259,
            "grammar_hyp": 4.90074,
            "nubia_score": 0.42717
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9
        },
        "rouge1": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.57576,
            "fmeasure": 0.46914
        },
        "rougeL": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.56863,
            "recall": 0.80556,
            "fmeasure": 0.66667
        },
        "nist": 2.2752605244252586,
        "bleu": 35.75297,
        "bertscore": {
            "precision": 0.85978,
            "recall": 0.93321,
            "f1": 0.89499
        },
        "bleurt": -0.07345,
        "meteor": 0.4491223499501472,
        "nubia": {
            "semantic_relation": 3.96907,
            "contradiction": 0.39,
            "irrelevancy": 98.44399,
            "logical_agreement": 1.16602,
            "grammar_ref": 5.64121,
            "grammar_hyp": 4.40132,
            "nubia_score": 0.74842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.8387096774193549
        },
        "rouge1": {
            "precision": 0.79475,
            "recall": 0.81491,
            "fmeasure": 0.80293
        },
        "rouge2": {
            "precision": 0.61064,
            "recall": 0.65011,
            "fmeasure": 0.6282
        },
        "rougeL": {
            "precision": 0.6713,
            "recall": 0.70409,
            "fmeasure": 0.68613
        },
        "rougeLsum": {
            "precision": 0.6713,
            "recall": 0.70409,
            "fmeasure": 0.68613
        },
        "nist": 4.458270935810255,
        "bleu": 57.26013,
        "bertscore": {
            "precision": 0.94133,
            "recall": 0.93965,
            "f1": 0.94041
        },
        "bleurt": 0.0874,
        "meteor": 0.40330012200691356,
        "nubia": {
            "semantic_relation": 4.04984,
            "contradiction": 1.09525,
            "irrelevancy": 74.45551,
            "logical_agreement": 24.44924,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.98072,
            "nubia_score": 0.68195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.2
        },
        "rouge1": {
            "precision": 0.48718,
            "recall": 0.38562,
            "fmeasure": 0.43016
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.25758,
            "fmeasure": 0.27743
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.30065,
            "fmeasure": 0.30222
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.30065,
            "fmeasure": 0.30222
        },
        "nist": 2.030906461788843,
        "bleu": 22.24247,
        "bertscore": {
            "precision": 0.83489,
            "recall": 0.83058,
            "f1": 0.82855
        },
        "bleurt": -0.43115,
        "meteor": 0.22257616922961143,
        "nubia": {
            "semantic_relation": 1.85428,
            "contradiction": 59.80369,
            "irrelevancy": 34.65379,
            "logical_agreement": 5.54252,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.52966,
            "nubia_score": 0.13704
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.6363636363636364,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.5641,
            "recall": 0.6029,
            "fmeasure": 0.58263
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.16813,
            "fmeasure": 0.14842
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.37333,
            "fmeasure": 0.35124
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.37333,
            "fmeasure": 0.35124
        },
        "nist": 3.061450498057023,
        "bleu": 13.18178,
        "bertscore": {
            "precision": 0.85557,
            "recall": 0.85454,
            "f1": 0.85118
        },
        "bleurt": -0.39948,
        "meteor": 0.26577350440621755,
        "nubia": {
            "semantic_relation": 2.32534,
            "contradiction": 22.24851,
            "irrelevancy": 32.51548,
            "logical_agreement": 45.236,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.1762,
            "nubia_score": 0.36567
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8333333333333334,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.43089,
            "recall": 0.66239,
            "fmeasure": 0.5221
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.39487,
            "fmeasure": 0.30614
        },
        "rougeL": {
            "precision": 0.38211,
            "recall": 0.58737,
            "fmeasure": 0.46298
        },
        "rougeLsum": {
            "precision": 0.38211,
            "recall": 0.58737,
            "fmeasure": 0.46298
        },
        "nist": 1.9386007614603342,
        "bleu": 20.85254,
        "bertscore": {
            "precision": 0.87756,
            "recall": 0.88853,
            "f1": 0.883
        },
        "bleurt": -0.34177,
        "meteor": 0.3214198699791849,
        "nubia": {
            "semantic_relation": 3.22238,
            "contradiction": 72.13196,
            "irrelevancy": 16.95367,
            "logical_agreement": 10.91437,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.91814,
            "nubia_score": 0.34269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.90455,
            "fmeasure": 0.84387
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.73889,
            "fmeasure": 0.68333
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.85909,
            "fmeasure": 0.8004
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.85909,
            "fmeasure": 0.8004
        },
        "nist": 2.809389582235585,
        "bleu": 34.17233,
        "bertscore": {
            "precision": 0.9632,
            "recall": 0.98391,
            "f1": 0.97344
        },
        "bleurt": 0.74135,
        "meteor": 0.9051319272478866,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.09688,
            "irrelevancy": 0.99384,
            "logical_agreement": 98.90928,
            "grammar_ref": 5.30755,
            "grammar_hyp": 4.73856,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.5,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.64599,
            "recall": 0.7,
            "fmeasure": 0.66774
        },
        "rouge2": {
            "precision": 0.46914,
            "recall": 0.49811,
            "fmeasure": 0.48007
        },
        "rougeL": {
            "precision": 0.57686,
            "recall": 0.62222,
            "fmeasure": 0.59408
        },
        "rougeLsum": {
            "precision": 0.57686,
            "recall": 0.62222,
            "fmeasure": 0.59408
        },
        "nist": 3.1366798703217635,
        "bleu": 34.19901,
        "bertscore": {
            "precision": 0.89897,
            "recall": 0.90704,
            "f1": 0.90268
        },
        "bleurt": 0.0966,
        "meteor": 0.33252178500505053,
        "nubia": {
            "semantic_relation": 3.91887,
            "contradiction": 27.00051,
            "irrelevancy": 40.43794,
            "logical_agreement": 32.56155,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.36198,
            "nubia_score": 0.66276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.17647058823529413,
            "3": 0.35714285714285715
        },
        "rouge1": {
            "precision": 0.83889,
            "recall": 0.29926,
            "fmeasure": 0.4362
        },
        "rouge2": {
            "precision": 0.41111,
            "recall": 0.09898,
            "fmeasure": 0.15421
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.21593,
            "fmeasure": 0.31856
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.21593,
            "fmeasure": 0.31856
        },
        "nist": 0.031294537038350695,
        "bleu": 6.54604,
        "bertscore": {
            "precision": 0.87856,
            "recall": 0.77923,
            "f1": 0.81643
        },
        "bleurt": -0.45249,
        "meteor": 0.14940929682046947,
        "nubia": {
            "semantic_relation": 3.54563,
            "contradiction": 1.40416,
            "irrelevancy": 5.75598,
            "logical_agreement": 92.83986,
            "grammar_ref": 3.63495,
            "grammar_hyp": 5.71281,
            "nubia_score": 0.29788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.65132,
            "fmeasure": 0.71111
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.5037,
            "fmeasure": 0.553
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.65132,
            "fmeasure": 0.71111
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.65132,
            "fmeasure": 0.71111
        },
        "nist": 2.705271763174047,
        "bleu": 48.15674,
        "bertscore": {
            "precision": 0.93712,
            "recall": 0.89294,
            "f1": 0.91433
        },
        "bleurt": 0.06495,
        "meteor": 0.3639900072199973,
        "nubia": {
            "semantic_relation": 4.28137,
            "contradiction": 0.584,
            "irrelevancy": 0.69786,
            "logical_agreement": 98.71814,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.29087,
            "nubia_score": 0.79731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.49944
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.28718,
            "fmeasure": 0.28608
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.46875,
            "fmeasure": 0.46719
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.46875,
            "fmeasure": 0.46719
        },
        "nist": 1.915221389464583,
        "bleu": 21.02369,
        "bertscore": {
            "precision": 0.89332,
            "recall": 0.8954,
            "f1": 0.89185
        },
        "bleurt": 0.27562,
        "meteor": 0.3266287424398572,
        "nubia": {
            "semantic_relation": 4.00181,
            "contradiction": 34.92852,
            "irrelevancy": 16.55577,
            "logical_agreement": 48.5157,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.30575,
            "nubia_score": 0.74414
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "nist": 2.4156844010247407,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.6432,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.6374,
            "contradiction": 0.2158,
            "irrelevancy": 0.51722,
            "logical_agreement": 99.26698,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.20485,
            "nubia_score": 0.86208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.6875
        },
        "rouge1": {
            "precision": 0.59412,
            "recall": 0.69863,
            "fmeasure": 0.63372
        },
        "rouge2": {
            "precision": 0.40296,
            "recall": 0.46814,
            "fmeasure": 0.42762
        },
        "rougeL": {
            "precision": 0.46471,
            "recall": 0.55992,
            "fmeasure": 0.50203
        },
        "rougeLsum": {
            "precision": 0.46471,
            "recall": 0.55992,
            "fmeasure": 0.50203
        },
        "nist": 3.8883763216002984,
        "bleu": 36.68236,
        "bertscore": {
            "precision": 0.88323,
            "recall": 0.91478,
            "f1": 0.89871
        },
        "bleurt": -0.10888,
        "meteor": 0.3361114248286325,
        "nubia": {
            "semantic_relation": 4.01655,
            "contradiction": 22.33119,
            "irrelevancy": 60.23363,
            "logical_agreement": 17.43518,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.26799,
            "nubia_score": 0.75169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.74306,
            "recall": 0.75,
            "fmeasure": 0.73647
        },
        "rouge2": {
            "precision": 0.58075,
            "recall": 0.62809,
            "fmeasure": 0.59363
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.65887,
            "fmeasure": 0.63353
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.65887,
            "fmeasure": 0.63353
        },
        "nist": 4.1575695951685985,
        "bleu": 33.56154,
        "bertscore": {
            "precision": 0.91947,
            "recall": 0.9167,
            "f1": 0.91808
        },
        "bleurt": 0.14293,
        "meteor": 0.33446587602616523,
        "nubia": {
            "semantic_relation": 4.30668,
            "contradiction": 0.17289,
            "irrelevancy": 77.69066,
            "logical_agreement": 22.13645,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.54191,
            "nubia_score": 0.83269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.25874,
            "fmeasure": 0.30576
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.47619,
            "fmeasure": 0.52479
        },
        "nist": 1.6585348934394,
        "bleu": 15.8271,
        "bertscore": {
            "precision": 0.92893,
            "recall": 0.88062,
            "f1": 0.90125
        },
        "bleurt": 0.19228,
        "meteor": 0.27004591964226465,
        "nubia": {
            "semantic_relation": 3.59812,
            "contradiction": 8.1895,
            "irrelevancy": 23.07297,
            "logical_agreement": 68.73753,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.92066,
            "nubia_score": 0.39465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "mT5_small/totto_test",
        "N": 158,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24911660777385158,
            "2": 0.4189723320158103,
            "3": 0.7194740137758296
        },
        "rouge1": {
            "precision": 0.73627,
            "recall": 0.68668,
            "fmeasure": 0.69712
        },
        "rouge2": {
            "precision": 0.48074,
            "recall": 0.44655,
            "fmeasure": 0.45438
        },
        "rougeL": {
            "precision": 0.62274,
            "recall": 0.58683,
            "fmeasure": 0.5933
        },
        "rougeLsum": {
            "precision": 0.62274,
            "recall": 0.58683,
            "fmeasure": 0.5933
        },
        "nist": 7.40989002562333,
        "bleu": 40.53092,
        "bertscore": {
            "precision": 0.92164,
            "recall": 0.91075,
            "f1": 0.91429
        },
        "bleurt": 0.19476,
        "meteor": 0.36732525735603927,
        "nubia": {
            "semantic_relation": 4.03779,
            "contradiction": 9.64751,
            "irrelevancy": 30.62067,
            "logical_agreement": 59.73182,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.58483,
            "nubia_score": 0.69947
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.5303,
            "recall": 0.74444,
            "fmeasure": 0.61925
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.37778,
            "fmeasure": 0.32479
        },
        "rougeL": {
            "precision": 0.43939,
            "recall": 0.55088,
            "fmeasure": 0.48737
        },
        "rougeLsum": {
            "precision": 0.43939,
            "recall": 0.55088,
            "fmeasure": 0.48737
        },
        "nist": 2.6184248310714358,
        "bleu": 21.23347,
        "bertscore": {
            "precision": 0.88309,
            "recall": 0.86777,
            "f1": 0.87079
        },
        "bleurt": 0.19602,
        "meteor": 0.33229861132468347,
        "nubia": {
            "semantic_relation": 3.82195,
            "contradiction": 1.01124,
            "irrelevancy": 52.89103,
            "logical_agreement": 46.09773,
            "grammar_ref": 5.46955,
            "grammar_hyp": 3.78147,
            "nubia_score": 0.75061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "nist": 3.8535769082186824,
        "bleu": 76.74162,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        },
        "bleurt": 0.39021,
        "meteor": 0.5426177315437225,
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.31313,
            "fmeasure": 0.37193
        },
        "rouge2": {
            "precision": 0.09524,
            "recall": 0.06061,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.26515,
            "fmeasure": 0.31053
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.26515,
            "fmeasure": 0.31053
        },
        "nist": 1.183562716012046,
        "bleu": 10.21685,
        "bertscore": {
            "precision": 0.90298,
            "recall": 0.8448,
            "f1": 0.87134
        },
        "bleurt": -0.33676,
        "meteor": 0.19452587142679487,
        "nubia": {
            "semantic_relation": 4.04718,
            "contradiction": 1.04552,
            "irrelevancy": 55.20324,
            "logical_agreement": 43.75125,
            "grammar_ref": 4.53537,
            "grammar_hyp": 5.69678,
            "nubia_score": 0.51321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.95,
            "recall": 0.72159,
            "fmeasure": 0.81319
        },
        "rouge2": {
            "precision": 0.7963,
            "recall": 0.6,
            "fmeasure": 0.67763
        },
        "rougeL": {
            "precision": 0.78333,
            "recall": 0.61269,
            "fmeasure": 0.68193
        },
        "rougeLsum": {
            "precision": 0.78333,
            "recall": 0.61269,
            "fmeasure": 0.68193
        },
        "nist": 3.1181790796138436,
        "bleu": 48.71345,
        "bertscore": {
            "precision": 0.94021,
            "recall": 0.89916,
            "f1": 0.91921
        },
        "bleurt": 0.35007,
        "meteor": 0.369160021838795,
        "nubia": {
            "semantic_relation": 4.73157,
            "contradiction": 0.17328,
            "irrelevancy": 16.90895,
            "logical_agreement": 82.91777,
            "grammar_ref": 4.70595,
            "grammar_hyp": 6.50389,
            "nubia_score": 0.66452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "nist": 1.629358976048761,
        "bleu": 9.42516,
        "bertscore": {
            "precision": 0.89807,
            "recall": 0.87333,
            "f1": 0.88468
        },
        "bleurt": 0.22483,
        "meteor": 0.20248556899341844,
        "nubia": {
            "semantic_relation": 3.80351,
            "contradiction": 1.62983,
            "irrelevancy": 1.66872,
            "logical_agreement": 96.70145,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.68543,
            "nubia_score": 0.65747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.87879,
            "fmeasure": 0.87879
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.53333,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.78788,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.78788,
            "fmeasure": 0.78788
        },
        "nist": 3.6909379535219213,
        "bleu": 55.20582,
        "bertscore": {
            "precision": 0.97555,
            "recall": 0.96089,
            "f1": 0.96816
        },
        "bleurt": 0.56975,
        "meteor": 0.47229158568017576,
        "nubia": {
            "semantic_relation": 4.9379,
            "contradiction": 0.37274,
            "irrelevancy": 0.6688,
            "logical_agreement": 98.95846,
            "grammar_ref": 4.98843,
            "grammar_hyp": 4.97872,
            "nubia_score": 0.94952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "nist": 3.7446507581081168,
        "bleu": 68.6589,
        "bertscore": {
            "precision": 0.96582,
            "recall": 0.92293,
            "f1": 0.93315
        },
        "bleurt": 0.43863,
        "meteor": 0.41036442483055713,
        "nubia": {
            "semantic_relation": 4.31728,
            "contradiction": 0.57385,
            "irrelevancy": 33.76928,
            "logical_agreement": 65.65687,
            "grammar_ref": 4.00353,
            "grammar_hyp": 4.65252,
            "nubia_score": 0.72783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.3157894736842105
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.31357,
            "fmeasure": 0.40784
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.14069,
            "fmeasure": 0.18561
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.17918,
            "fmeasure": 0.23305
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.17918,
            "fmeasure": 0.23305
        },
        "nist": 0.22049851324314484,
        "bleu": 3.72881,
        "bertscore": {
            "precision": 0.8999,
            "recall": 0.79355,
            "f1": 0.84338
        },
        "bleurt": -0.08733,
        "meteor": 0.17324846130648894,
        "nubia": {
            "semantic_relation": 3.83775,
            "contradiction": 1.61359,
            "irrelevancy": 1.8094,
            "logical_agreement": 96.57701,
            "grammar_ref": 4.34096,
            "grammar_hyp": 6.5316,
            "nubia_score": 0.36463
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.6,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.6,
            "fmeasure": 0.46154
        },
        "nist": 0.9942163464312139,
        "bleu": 13.06511,
        "bertscore": {
            "precision": 0.84997,
            "recall": 0.91997,
            "f1": 0.88359
        },
        "bleurt": 0.33895,
        "meteor": 0.35602707728372085,
        "nubia": {
            "semantic_relation": 4.3363,
            "contradiction": 0.10349,
            "irrelevancy": 99.77726,
            "logical_agreement": 0.11925,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.91872,
            "nubia_score": 0.97367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.7619047619047619
        },
        "rouge1": {
            "precision": 0.546,
            "recall": 0.59142,
            "fmeasure": 0.56172
        },
        "rouge2": {
            "precision": 0.34495,
            "recall": 0.37967,
            "fmeasure": 0.35735
        },
        "rougeL": {
            "precision": 0.41613,
            "recall": 0.46714,
            "fmeasure": 0.43533
        },
        "rougeLsum": {
            "precision": 0.41613,
            "recall": 0.46714,
            "fmeasure": 0.43533
        },
        "nist": 3.584344298768121,
        "bleu": 31.52799,
        "bertscore": {
            "precision": 0.90489,
            "recall": 0.89389,
            "f1": 0.8993
        },
        "bleurt": -0.29339,
        "meteor": 0.3367229591389075,
        "nubia": {
            "semantic_relation": 3.62177,
            "contradiction": 48.20087,
            "irrelevancy": 26.40469,
            "logical_agreement": 25.39444,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.36738,
            "nubia_score": 0.56608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.8181818181818182,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.75992,
            "fmeasure": 0.77301
        },
        "rouge2": {
            "precision": 0.64951,
            "recall": 0.56502,
            "fmeasure": 0.58233
        },
        "rougeL": {
            "precision": 0.68519,
            "recall": 0.61706,
            "fmeasure": 0.62878
        },
        "rougeLsum": {
            "precision": 0.68519,
            "recall": 0.61706,
            "fmeasure": 0.62878
        },
        "nist": 5.114874802890064,
        "bleu": 70.20429,
        "bertscore": {
            "precision": 0.95511,
            "recall": 0.9371,
            "f1": 0.94596
        },
        "bleurt": 0.18724,
        "meteor": 0.4292826988313254,
        "nubia": {
            "semantic_relation": 4.00769,
            "contradiction": 3.55044,
            "irrelevancy": 60.66513,
            "logical_agreement": 35.78442,
            "grammar_ref": 4.3679,
            "grammar_hyp": 3.87702,
            "nubia_score": 0.74545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.78632,
            "fmeasure": 0.79321
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.48039,
            "fmeasure": 0.51556
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.70085,
            "fmeasure": 0.74691
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.70085,
            "fmeasure": 0.74691
        },
        "nist": 3.8901901409883304,
        "bleu": 59.9782,
        "bertscore": {
            "precision": 0.94309,
            "recall": 0.94455,
            "f1": 0.93994
        },
        "bleurt": -0.14496,
        "meteor": 0.4042814223028806,
        "nubia": {
            "semantic_relation": 4.04864,
            "contradiction": 2.69761,
            "irrelevancy": 93.43712,
            "logical_agreement": 3.86527,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.5015,
            "nubia_score": 0.56762
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.125
        },
        "rouge1": {
            "precision": 0.18182,
            "recall": 0.22222,
            "fmeasure": 0.2
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.18182,
            "recall": 0.22222,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.18182,
            "recall": 0.22222,
            "fmeasure": 0.2
        },
        "nist": 0.8193426110996872,
        "bleu": 4.45688,
        "bertscore": {
            "precision": 0.82071,
            "recall": 0.80129,
            "f1": 0.80998
        },
        "bleurt": -0.19467,
        "meteor": 0.07692307692307693,
        "nubia": {
            "semantic_relation": 2.06585,
            "contradiction": 38.89581,
            "irrelevancy": 49.89076,
            "logical_agreement": 11.21344,
            "grammar_ref": 5.49813,
            "grammar_hyp": 6.19126,
            "nubia_score": 0.11636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.48148,
            "fmeasure": 0.57206
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.20903,
            "fmeasure": 0.25031
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.35354,
            "fmeasure": 0.40359
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.35354,
            "fmeasure": 0.40359
        },
        "nist": 1.6965593944902075,
        "bleu": 6.12212,
        "bertscore": {
            "precision": 0.93168,
            "recall": 0.88186,
            "f1": 0.90543
        },
        "bleurt": 0.11917,
        "meteor": 0.3035844547167411,
        "nubia": {
            "semantic_relation": 3.95083,
            "contradiction": 0.27634,
            "irrelevancy": 32.75292,
            "logical_agreement": 66.97073,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.94987,
            "nubia_score": 0.68103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2857142857142857,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.63889,
            "fmeasure": 0.6746
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.43421,
            "fmeasure": 0.46212
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.38056,
            "fmeasure": 0.40177
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.38056,
            "fmeasure": 0.40177
        },
        "nist": 4.1019485408757985,
        "bleu": 42.36963,
        "bertscore": {
            "precision": 0.92598,
            "recall": 0.90934,
            "f1": 0.90879
        },
        "bleurt": 0.2372,
        "meteor": 0.3527144162410664,
        "nubia": {
            "semantic_relation": 4.42954,
            "contradiction": 37.88347,
            "irrelevancy": 4.80889,
            "logical_agreement": 57.30764,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.45089,
            "nubia_score": 0.72573
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "mT5_small/totto_test",
        "N": 35,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.5288461538461539,
            "3": 0.8184438040345822
        },
        "rouge1": {
            "precision": 0.8126,
            "recall": 0.78744,
            "fmeasure": 0.79635
        },
        "rouge2": {
            "precision": 0.58587,
            "recall": 0.57176,
            "fmeasure": 0.57611
        },
        "rougeL": {
            "precision": 0.69727,
            "recall": 0.68351,
            "fmeasure": 0.68715
        },
        "rougeLsum": {
            "precision": 0.69727,
            "recall": 0.68351,
            "fmeasure": 0.68715
        },
        "nist": 6.729840503953407,
        "bleu": 51.73374,
        "bertscore": {
            "precision": 0.94771,
            "recall": 0.94388,
            "f1": 0.94509
        },
        "bleurt": 0.48322,
        "meteor": 0.4304744330287957,
        "nubia": {
            "semantic_relation": 4.31132,
            "contradiction": 7.73215,
            "irrelevancy": 17.41656,
            "logical_agreement": 74.85129,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.02636,
            "nubia_score": 0.82099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3
        },
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.27273,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.1,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.27273,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.27273,
            "fmeasure": 0.33333
        },
        "nist": 0.6192383692936545,
        "bleu": 13.39801,
        "bertscore": {
            "precision": 0.7834,
            "recall": 0.73555,
            "f1": 0.75872
        },
        "bleurt": -1.41257,
        "meteor": 0.15597376719096342,
        "nubia": {
            "semantic_relation": 2.63564,
            "contradiction": 1.69765,
            "irrelevancy": 61.06403,
            "logical_agreement": 37.23833,
            "grammar_ref": 4.59968,
            "grammar_hyp": 6.17154,
            "nubia_score": 0.16743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6842105263157895
        },
        "rouge1": {
            "precision": 0.59375,
            "recall": 0.64377,
            "fmeasure": 0.60326
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.34524,
            "fmeasure": 0.30476
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.46684,
            "fmeasure": 0.44108
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.46684,
            "fmeasure": 0.44108
        },
        "nist": 2.7647694659360442,
        "bleu": 17.5833,
        "bertscore": {
            "precision": 0.90565,
            "recall": 0.87299,
            "f1": 0.88759
        },
        "bleurt": 0.15565,
        "meteor": 0.33748776946153836,
        "nubia": {
            "semantic_relation": 4.08163,
            "contradiction": 0.33143,
            "irrelevancy": 8.64727,
            "logical_agreement": 91.0213,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.00332,
            "nubia_score": 0.65508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.44118,
            "recall": 0.70346,
            "fmeasure": 0.54221
        },
        "rouge2": {
            "precision": 0.28283,
            "recall": 0.60952,
            "fmeasure": 0.38432
        },
        "rougeL": {
            "precision": 0.38235,
            "recall": 0.78413,
            "fmeasure": 0.51132
        },
        "rougeLsum": {
            "precision": 0.38235,
            "recall": 0.78413,
            "fmeasure": 0.51132
        },
        "nist": 2.264891631921443,
        "bleu": 24.75304,
        "bertscore": {
            "precision": 0.80963,
            "recall": 0.92379,
            "f1": 0.84955
        },
        "bleurt": 0.001,
        "meteor": 0.35733974697445886,
        "nubia": {
            "semantic_relation": 2.91824,
            "contradiction": 99.1058,
            "irrelevancy": 0.61416,
            "logical_agreement": 0.28005,
            "grammar_ref": 3.44293,
            "grammar_hyp": 2.65246,
            "nubia_score": 0.46083
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.68843,
            "fmeasure": 0.72304
        },
        "rouge2": {
            "precision": 0.51389,
            "recall": 0.42526,
            "fmeasure": 0.46032
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.56343,
            "fmeasure": 0.60539
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.56343,
            "fmeasure": 0.60539
        },
        "nist": 3.035692374520041,
        "bleu": 33.01008,
        "bertscore": {
            "precision": 0.93446,
            "recall": 0.91841,
            "f1": 0.92601
        },
        "bleurt": 0.30415,
        "meteor": 0.37872611767369513,
        "nubia": {
            "semantic_relation": 4.51789,
            "contradiction": 1.45965,
            "irrelevancy": 8.19003,
            "logical_agreement": 90.35032,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.76915,
            "nubia_score": 0.67446
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.27928,
            "recall": 0.73889,
            "fmeasure": 0.4045
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.53333,
            "fmeasure": 0.27362
        },
        "rougeL": {
            "precision": 0.25225,
            "recall": 0.68687,
            "fmeasure": 0.36752
        },
        "rougeLsum": {
            "precision": 0.25225,
            "recall": 0.68687,
            "fmeasure": 0.36752
        },
        "nist": 1.635037321788437,
        "bleu": 19.37413,
        "bertscore": {
            "precision": 0.75899,
            "recall": 0.88192,
            "f1": 0.81585
        },
        "bleurt": -0.45759,
        "meteor": 0.31560246452784213,
        "nubia": {
            "semantic_relation": 3.66284,
            "contradiction": 0.74652,
            "irrelevancy": 95.49326,
            "logical_agreement": 3.76022,
            "grammar_ref": 5.20931,
            "grammar_hyp": 3.68928,
            "nubia_score": 0.18508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.39338,
            "fmeasure": 0.40375
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.09647,
            "fmeasure": 0.10258
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.24265,
            "fmeasure": 0.25065
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.24265,
            "fmeasure": 0.25065
        },
        "nist": 2.071711898934263,
        "bleu": 6.8094,
        "bertscore": {
            "precision": 0.87818,
            "recall": 0.83166,
            "f1": 0.84414
        },
        "bleurt": -0.08266,
        "meteor": 0.19546703452734573,
        "nubia": {
            "semantic_relation": 3.08513,
            "contradiction": 31.41769,
            "irrelevancy": 4.44536,
            "logical_agreement": 64.13695,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.14895,
            "nubia_score": 0.47937
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.85714,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.5,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.85714,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.85714,
            "fmeasure": 0.57143
        },
        "nist": 1.2857142857142858,
        "bleu": 8.88918,
        "bertscore": {
            "precision": 0.83294,
            "recall": 0.93221,
            "f1": 0.87978
        },
        "bleurt": 0.5556,
        "meteor": 0.42176019493755473,
        "nubia": {
            "semantic_relation": 4.47468,
            "contradiction": 0.15037,
            "irrelevancy": 55.38741,
            "logical_agreement": 44.46223,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.49917,
            "nubia_score": 0.91585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.84259,
            "fmeasure": 0.7942
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.45238,
            "fmeasure": 0.43519
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.71852,
            "fmeasure": 0.69744
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.71852,
            "fmeasure": 0.69744
        },
        "nist": 3.9956462056763953,
        "bleu": 22.65258,
        "bertscore": {
            "precision": 0.94593,
            "recall": 0.96686,
            "f1": 0.95627
        },
        "bleurt": 0.63187,
        "meteor": 0.4623158007404865,
        "nubia": {
            "semantic_relation": 4.43585,
            "contradiction": 0.2491,
            "irrelevancy": 1.08405,
            "logical_agreement": 98.66685,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.63852,
            "nubia_score": 0.89639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "nist": 1.7990385038524417,
        "bleu": 20.16495,
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        },
        "bleurt": 0.49066,
        "meteor": 0.861811391223156,
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.0,
            "3": 0.84
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.82167,
            "fmeasure": 0.83758
        },
        "rouge2": {
            "precision": 0.68333,
            "recall": 0.66374,
            "fmeasure": 0.67249
        },
        "rougeL": {
            "precision": 0.74603,
            "recall": 0.74,
            "fmeasure": 0.74231
        },
        "rougeLsum": {
            "precision": 0.74603,
            "recall": 0.74,
            "fmeasure": 0.74231
        },
        "nist": 4.820978252384935,
        "bleu": 61.16926,
        "bertscore": {
            "precision": 0.94693,
            "recall": 0.93188,
            "f1": 0.93613
        },
        "bleurt": 0.40997,
        "meteor": 0.4115370026874791,
        "nubia": {
            "semantic_relation": 4.48993,
            "contradiction": 1.5721,
            "irrelevancy": 31.57622,
            "logical_agreement": 66.85167,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.27712,
            "nubia_score": 0.86097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "nist": 2.456435556800404,
        "bleu": 50.0,
        "bertscore": {
            "precision": 0.97618,
            "recall": 0.98533,
            "f1": 0.98073
        },
        "bleurt": 0.83889,
        "meteor": 0.5277006683854432,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.1828,
            "irrelevancy": 0.64042,
            "logical_agreement": 98.17678,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.57266,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 1.0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.68889,
            "fmeasure": 0.72503
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.45503,
            "fmeasure": 0.49333
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.61111,
            "fmeasure": 0.64534
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.61111,
            "fmeasure": 0.64534
        },
        "nist": 4.095309635649086,
        "bleu": 73.15255,
        "bertscore": {
            "precision": 0.95757,
            "recall": 0.90264,
            "f1": 0.92929
        },
        "bleurt": 0.15542,
        "meteor": 0.45798217746719627,
        "nubia": {
            "semantic_relation": 4.10919,
            "contradiction": 0.86157,
            "irrelevancy": 35.98343,
            "logical_agreement": 63.155,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.83866,
            "nubia_score": 0.5336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "nist": 1.2775418301849517,
        "bleu": 11.33958,
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        },
        "bleurt": -0.04695,
        "meteor": 0.31127891035349853,
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.6444444444444445
        },
        "rouge1": {
            "precision": 0.73022,
            "recall": 0.61819,
            "fmeasure": 0.66073
        },
        "rouge2": {
            "precision": 0.39898,
            "recall": 0.36067,
            "fmeasure": 0.37754
        },
        "rougeL": {
            "precision": 0.6734,
            "recall": 0.56385,
            "fmeasure": 0.60517
        },
        "rougeLsum": {
            "precision": 0.6734,
            "recall": 0.56385,
            "fmeasure": 0.60517
        },
        "nist": 3.7565596530370153,
        "bleu": 38.48978,
        "bertscore": {
            "precision": 0.91031,
            "recall": 0.86577,
            "f1": 0.88694
        },
        "bleurt": 0.05445,
        "meteor": 0.3380022285330759,
        "nubia": {
            "semantic_relation": 3.93173,
            "contradiction": 2.97278,
            "irrelevancy": 16.31767,
            "logical_agreement": 80.70955,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.64708,
            "nubia_score": 0.58263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25,
            "fmeasure": 0.26667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "nist": 2.113355981086958,
        "bleu": 13.35434,
        "bertscore": {
            "precision": 0.91789,
            "recall": 0.90364,
            "f1": 0.91071
        },
        "bleurt": 0.14202,
        "meteor": 0.26557509739080626,
        "nubia": {
            "semantic_relation": 4.01781,
            "contradiction": 0.34119,
            "irrelevancy": 96.06696,
            "logical_agreement": 3.59185,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.52262,
            "nubia_score": 0.85465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.22222,
            "fmeasure": 0.22222
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.22222,
            "fmeasure": 0.22222
        },
        "nist": 1.6609765125767406,
        "bleu": 8.18219,
        "bertscore": {
            "precision": 0.75033,
            "recall": 0.75746,
            "f1": 0.75388
        },
        "bleurt": -0.55591,
        "meteor": 0.2242933024914006,
        "nubia": {
            "semantic_relation": 4.11673,
            "contradiction": 0.45505,
            "irrelevancy": 91.62734,
            "logical_agreement": 7.91762,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.23293,
            "nubia_score": 0.62783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.4,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.83333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.58974,
            "fmeasure": 0.46465
        },
        "rougeL": {
            "precision": 0.50794,
            "recall": 0.7619,
            "fmeasure": 0.60952
        },
        "rougeLsum": {
            "precision": 0.50794,
            "recall": 0.7619,
            "fmeasure": 0.60952
        },
        "nist": 3.7659689449553917,
        "bleu": 40.90527,
        "bertscore": {
            "precision": 0.82337,
            "recall": 0.91342,
            "f1": 0.86077
        },
        "bleurt": 0.0249,
        "meteor": 0.4073432482682585,
        "nubia": {
            "semantic_relation": 3.32053,
            "contradiction": 0.23382,
            "irrelevancy": 99.27779,
            "logical_agreement": 0.48838,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.65514,
            "nubia_score": 0.58132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.868421052631579
        },
        "rouge1": {
            "precision": 0.8747,
            "recall": 0.77749,
            "fmeasure": 0.80563
        },
        "rouge2": {
            "precision": 0.64806,
            "recall": 0.56387,
            "fmeasure": 0.58734
        },
        "rougeL": {
            "precision": 0.78143,
            "recall": 0.67998,
            "fmeasure": 0.71229
        },
        "rougeLsum": {
            "precision": 0.78143,
            "recall": 0.67998,
            "fmeasure": 0.71229
        },
        "nist": 4.941118884212299,
        "bleu": 50.72831,
        "bertscore": {
            "precision": 0.95844,
            "recall": 0.93292,
            "f1": 0.94433
        },
        "bleurt": 0.01101,
        "meteor": 0.4410321822428069,
        "nubia": {
            "semantic_relation": 4.34925,
            "contradiction": 0.68805,
            "irrelevancy": 36.08499,
            "logical_agreement": 63.22697,
            "grammar_ref": 5.76985,
            "grammar_hyp": 6.42547,
            "nubia_score": 0.6357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5454545454545454,
            "3": 0.43243243243243246
        },
        "rouge1": {
            "precision": 0.61005,
            "recall": 0.58864,
            "fmeasure": 0.59247
        },
        "rouge2": {
            "precision": 0.39823,
            "recall": 0.40087,
            "fmeasure": 0.3958
        },
        "rougeL": {
            "precision": 0.47088,
            "recall": 0.45375,
            "fmeasure": 0.45868
        },
        "rougeLsum": {
            "precision": 0.47088,
            "recall": 0.45375,
            "fmeasure": 0.45868
        },
        "nist": 3.46744660746745,
        "bleu": 24.62648,
        "bertscore": {
            "precision": 0.88941,
            "recall": 0.87326,
            "f1": 0.88105
        },
        "bleurt": 0.13902,
        "meteor": 0.2743841496649074,
        "nubia": {
            "semantic_relation": 3.18559,
            "contradiction": 50.85259,
            "irrelevancy": 4.50488,
            "logical_agreement": 44.64253,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.93473,
            "nubia_score": 0.47851
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.91071,
            "fmeasure": 0.86413
        },
        "rougeL": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rougeLsum": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "nist": 4.026196058544812,
        "bleu": 69.0167,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.99714,
            "f1": 0.99064
        },
        "bleurt": 0.81116,
        "meteor": 0.6108178404694528,
        "nubia": {
            "semantic_relation": 4.96299,
            "contradiction": 0.14795,
            "irrelevancy": 3.49378,
            "logical_agreement": 96.35828,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.07239,
            "nubia_score": 0.98909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.55,
            "2": 0.6666666666666666,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.70895,
            "recall": 0.8068,
            "fmeasure": 0.75037
        },
        "rouge2": {
            "precision": 0.5204,
            "recall": 0.57473,
            "fmeasure": 0.54207
        },
        "rougeL": {
            "precision": 0.57258,
            "recall": 0.66511,
            "fmeasure": 0.61138
        },
        "rougeLsum": {
            "precision": 0.57258,
            "recall": 0.66511,
            "fmeasure": 0.61138
        },
        "nist": 4.7264176935517295,
        "bleu": 51.91975,
        "bertscore": {
            "precision": 0.91494,
            "recall": 0.91925,
            "f1": 0.91256
        },
        "bleurt": -0.09408,
        "meteor": 0.4157298322362467,
        "nubia": {
            "semantic_relation": 4.16905,
            "contradiction": 2.85203,
            "irrelevancy": 77.50958,
            "logical_agreement": 19.63839,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.08388,
            "nubia_score": 0.74184
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "nist": 2.8646054890616752,
        "bleu": 42.50281,
        "bertscore": {
            "precision": 0.96145,
            "recall": 0.96696,
            "f1": 0.9642
        },
        "bleurt": 0.68139,
        "meteor": 0.48351570164972274,
        "nubia": {
            "semantic_relation": 4.6542,
            "contradiction": 0.23542,
            "irrelevancy": 4.26769,
            "logical_agreement": 95.49688,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.03878,
            "nubia_score": 0.87015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.79798
        },
        "rouge2": {
            "precision": 0.58974,
            "recall": 0.92593,
            "fmeasure": 0.71818
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.79798
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.79798
        },
        "nist": 2.228972500528848,
        "bleu": 20.03636,
        "bertscore": {
            "precision": 0.90932,
            "recall": 0.95264,
            "f1": 0.91334
        },
        "bleurt": 0.33487,
        "meteor": 0.5119868093563041,
        "nubia": {
            "semantic_relation": 4.26481,
            "contradiction": 0.13491,
            "irrelevancy": 61.38936,
            "logical_agreement": 38.47573,
            "grammar_ref": 3.90726,
            "grammar_hyp": 3.22521,
            "nubia_score": 0.77596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "nist": 2.8441645853579183,
        "bleu": 44.5345,
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        },
        "bleurt": 0.30287,
        "meteor": 0.4505163353501177,
        "nubia": {
            "semantic_relation": 4.22765,
            "contradiction": 0.25393,
            "irrelevancy": 86.02728,
            "logical_agreement": 13.71879,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31451,
            "nubia_score": 0.76427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364,
            "3": 0.9444444444444444
        },
        "rouge1": {
            "precision": 0.65247,
            "recall": 0.75532,
            "fmeasure": 0.69082
        },
        "rouge2": {
            "precision": 0.48932,
            "recall": 0.60859,
            "fmeasure": 0.52606
        },
        "rougeL": {
            "precision": 0.53519,
            "recall": 0.62228,
            "fmeasure": 0.56113
        },
        "rougeLsum": {
            "precision": 0.53519,
            "recall": 0.62228,
            "fmeasure": 0.56113
        },
        "nist": 3.211730825091681,
        "bleu": 39.2706,
        "bertscore": {
            "precision": 0.95433,
            "recall": 0.95149,
            "f1": 0.95133
        },
        "bleurt": 0.41548,
        "meteor": 0.44638746455383743,
        "nubia": {
            "semantic_relation": 4.41903,
            "contradiction": 44.61341,
            "irrelevancy": 16.27101,
            "logical_agreement": 39.11557,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.4381,
            "nubia_score": 0.80926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.83333,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.46061,
            "fmeasure": 0.35238
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "nist": 2.9211152056479777,
        "bleu": 13.9508,
        "bertscore": {
            "precision": 0.85844,
            "recall": 0.91708,
            "f1": 0.87512
        },
        "bleurt": 0.06204,
        "meteor": 0.42919650333815856,
        "nubia": {
            "semantic_relation": 4.41335,
            "contradiction": 3.46921,
            "irrelevancy": 67.46956,
            "logical_agreement": 29.06123,
            "grammar_ref": 5.75818,
            "grammar_hyp": 4.95052,
            "nubia_score": 0.7923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "mT5_small/totto_test",
        "N": 79,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20242914979757085,
            "2": 0.45652173913043476,
            "3": 0.7747440273037542
        },
        "rouge1": {
            "precision": 0.74492,
            "recall": 0.73321,
            "fmeasure": 0.7277
        },
        "rouge2": {
            "precision": 0.52493,
            "recall": 0.5193,
            "fmeasure": 0.51521
        },
        "rougeL": {
            "precision": 0.65449,
            "recall": 0.64665,
            "fmeasure": 0.64135
        },
        "rougeLsum": {
            "precision": 0.65449,
            "recall": 0.64665,
            "fmeasure": 0.64135
        },
        "nist": 7.108959848764126,
        "bleu": 47.27321,
        "bertscore": {
            "precision": 0.92448,
            "recall": 0.92513,
            "f1": 0.92239
        },
        "bleurt": 0.25183,
        "meteor": 0.3809515997104454,
        "nubia": {
            "semantic_relation": 4.04557,
            "contradiction": 15.52657,
            "irrelevancy": 30.50407,
            "logical_agreement": 53.96936,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.39279,
            "nubia_score": 0.69406
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.9130434782608695
        },
        "rouge1": {
            "precision": 0.90385,
            "recall": 0.94118,
            "fmeasure": 0.9219
        },
        "rouge2": {
            "precision": 0.80964,
            "recall": 0.84375,
            "fmeasure": 0.82609
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.85294,
            "fmeasure": 0.83619
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.85294,
            "fmeasure": 0.83619
        },
        "nist": 4.855802667460798,
        "bleu": 74.35215,
        "bertscore": {
            "precision": 0.98768,
            "recall": 0.98506,
            "f1": 0.98637
        },
        "bleurt": 0.54511,
        "meteor": 0.5417165526027626,
        "nubia": {
            "semantic_relation": 4.78337,
            "contradiction": 7.62317,
            "irrelevancy": 34.34426,
            "logical_agreement": 58.03257,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.33339,
            "nubia_score": 0.87192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "rouge1": {
            "precision": 0.54001,
            "recall": 0.61838,
            "fmeasure": 0.56904
        },
        "rouge2": {
            "precision": 0.26014,
            "recall": 0.29303,
            "fmeasure": 0.27214
        },
        "rougeL": {
            "precision": 0.38955,
            "recall": 0.43484,
            "fmeasure": 0.40585
        },
        "rougeLsum": {
            "precision": 0.38955,
            "recall": 0.43484,
            "fmeasure": 0.40585
        },
        "nist": 2.9556580622371844,
        "bleu": 13.80413,
        "bertscore": {
            "precision": 0.89439,
            "recall": 0.9024,
            "f1": 0.89697
        },
        "bleurt": -0.04504,
        "meteor": 0.2904124459316316,
        "nubia": {
            "semantic_relation": 3.76307,
            "contradiction": 4.81704,
            "irrelevancy": 67.28891,
            "logical_agreement": 27.89405,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.36244,
            "nubia_score": 0.59323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "mT5_small/totto_test",
        "N": 6,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.45,
            "3": 0.7741935483870968
        },
        "rouge1": {
            "precision": 0.86314,
            "recall": 0.83167,
            "fmeasure": 0.83011
        },
        "rouge2": {
            "precision": 0.66222,
            "recall": 0.63796,
            "fmeasure": 0.63947
        },
        "rougeL": {
            "precision": 0.78256,
            "recall": 0.76821,
            "fmeasure": 0.7621
        },
        "rougeLsum": {
            "precision": 0.78256,
            "recall": 0.76821,
            "fmeasure": 0.7621
        },
        "nist": 5.077578466853739,
        "bleu": 48.24459,
        "bertscore": {
            "precision": 0.9409,
            "recall": 0.93067,
            "f1": 0.93501
        },
        "bleurt": 0.31014,
        "meteor": 0.4382862582633088,
        "nubia": {
            "semantic_relation": 4.47762,
            "contradiction": 3.02087,
            "irrelevancy": 25.05593,
            "logical_agreement": 71.9232,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.47352,
            "nubia_score": 0.81361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "mT5_small/totto_test",
        "N": 4,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.2222222222222222,
            "3": 0.3793103448275862
        },
        "rouge1": {
            "precision": 0.5643,
            "recall": 0.34257,
            "fmeasure": 0.40272
        },
        "rouge2": {
            "precision": 0.21767,
            "recall": 0.1139,
            "fmeasure": 0.14337
        },
        "rougeL": {
            "precision": 0.40577,
            "recall": 0.29499,
            "fmeasure": 0.33493
        },
        "rougeLsum": {
            "precision": 0.40577,
            "recall": 0.29499,
            "fmeasure": 0.33493
        },
        "nist": 2.1385705424957377,
        "bleu": 7.13046,
        "bertscore": {
            "precision": 0.85327,
            "recall": 0.81364,
            "f1": 0.82599
        },
        "bleurt": -0.36057,
        "meteor": 0.18346771615723245,
        "nubia": {
            "semantic_relation": 3.69249,
            "contradiction": 26.97478,
            "irrelevancy": 13.84564,
            "logical_agreement": 59.17957,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.36938,
            "nubia_score": 0.50931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.67402,
            "fmeasure": 0.75019
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.45694,
            "fmeasure": 0.51235
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.61275,
            "fmeasure": 0.68199
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.61275,
            "fmeasure": 0.68199
        },
        "nist": 2.803136096693226,
        "bleu": 44.6401,
        "bertscore": {
            "precision": 0.94325,
            "recall": 0.90199,
            "f1": 0.92216
        },
        "bleurt": 0.17617,
        "meteor": 0.37363815877832,
        "nubia": {
            "semantic_relation": 3.59877,
            "contradiction": 7.00675,
            "irrelevancy": 3.13876,
            "logical_agreement": 89.85448,
            "grammar_ref": 4.86284,
            "grammar_hyp": 4.98381,
            "nubia_score": 0.50355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.6,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.57333,
            "recall": 0.4272,
            "fmeasure": 0.48836
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.1619,
            "fmeasure": 0.18688
        },
        "rougeL": {
            "precision": 0.32,
            "recall": 0.2728,
            "fmeasure": 0.2945
        },
        "rougeLsum": {
            "precision": 0.32,
            "recall": 0.2728,
            "fmeasure": 0.2945
        },
        "nist": 2.858367449383249,
        "bleu": 8.54916,
        "bertscore": {
            "precision": 0.87193,
            "recall": 0.80568,
            "f1": 0.8375
        },
        "bleurt": -0.54906,
        "meteor": 0.22202176057669376,
        "nubia": {
            "semantic_relation": 2.55222,
            "contradiction": 1.61315,
            "irrelevancy": 18.3729,
            "logical_agreement": 80.01395,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.32921,
            "nubia_score": 0.40572
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.46377,
            "recall": 0.88889,
            "fmeasure": 0.60952
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.72727,
            "fmeasure": 0.48485
        },
        "rougeL": {
            "precision": 0.43478,
            "recall": 0.83333,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.43478,
            "recall": 0.83333,
            "fmeasure": 0.57143
        },
        "nist": 2.0502213234723485,
        "bleu": 32.2679,
        "bertscore": {
            "precision": 0.80708,
            "recall": 0.92305,
            "f1": 0.86118
        },
        "bleurt": 0.13185,
        "meteor": 0.43696518201996026,
        "nubia": {
            "semantic_relation": 3.48996,
            "contradiction": 3.38343,
            "irrelevancy": 96.21675,
            "logical_agreement": 0.39982,
            "grammar_ref": 5.08958,
            "grammar_hyp": 3.14005,
            "nubia_score": 0.52778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.76768,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.55152,
            "fmeasure": 0.53247
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.76768,
            "fmeasure": 0.74396
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.76768,
            "fmeasure": 0.74396
        },
        "nist": 3.2440306735011815,
        "bleu": 31.70233,
        "bertscore": {
            "precision": 0.97279,
            "recall": 0.97919,
            "f1": 0.97598
        },
        "bleurt": 0.56166,
        "meteor": 0.4540407414051586,
        "nubia": {
            "semantic_relation": 4.89641,
            "contradiction": 0.46553,
            "irrelevancy": 0.91809,
            "logical_agreement": 98.61638,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.26045,
            "nubia_score": 0.92703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.6666666666666666,
            "3": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.9,
            "recall": 0.57647,
            "fmeasure": 0.70222
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.32143,
            "fmeasure": 0.40696
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.53072,
            "fmeasure": 0.65778
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.53072,
            "fmeasure": 0.65778
        },
        "nist": 1.9362043792791752,
        "bleu": 24.5039,
        "bertscore": {
            "precision": 0.9183,
            "recall": 0.81025,
            "f1": 0.8609
        },
        "bleurt": -0.43195,
        "meteor": 0.2478307558257328,
        "nubia": {
            "semantic_relation": 3.42809,
            "contradiction": 1.41527,
            "irrelevancy": 5.6045,
            "logical_agreement": 92.98023,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.06357,
            "nubia_score": 0.45311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.64683,
            "recall": 0.65101,
            "fmeasure": 0.64063
        },
        "rouge2": {
            "precision": 0.36014,
            "recall": 0.35664,
            "fmeasure": 0.35158
        },
        "rougeL": {
            "precision": 0.56548,
            "recall": 0.52117,
            "fmeasure": 0.53952
        },
        "rougeLsum": {
            "precision": 0.56548,
            "recall": 0.52117,
            "fmeasure": 0.53952
        },
        "nist": 3.172377185327152,
        "bleu": 28.85597,
        "bertscore": {
            "precision": 0.90176,
            "recall": 0.91932,
            "f1": 0.90987
        },
        "bleurt": 0.2814,
        "meteor": 0.33125148541857224,
        "nubia": {
            "semantic_relation": 3.75085,
            "contradiction": 43.90554,
            "irrelevancy": 53.11509,
            "logical_agreement": 2.97937,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.98279,
            "nubia_score": 0.64264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.67379,
            "fmeasure": 0.74561
        },
        "rouge2": {
            "precision": 0.77381,
            "recall": 0.5058,
            "fmeasure": 0.59326
        },
        "rougeL": {
            "precision": 0.89583,
            "recall": 0.67379,
            "fmeasure": 0.74561
        },
        "rougeLsum": {
            "precision": 0.89583,
            "recall": 0.67379,
            "fmeasure": 0.74561
        },
        "nist": 1.3206161201058846,
        "bleu": 41.94966,
        "bertscore": {
            "precision": 0.92059,
            "recall": 0.88573,
            "f1": 0.90101
        },
        "bleurt": -0.00647,
        "meteor": 0.4317992438550579,
        "nubia": {
            "semantic_relation": 4.42949,
            "contradiction": 19.22155,
            "irrelevancy": 18.77487,
            "logical_agreement": 62.00359,
            "grammar_ref": 4.07172,
            "grammar_hyp": 5.2536,
            "nubia_score": 0.68954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "nist": 3.0881978509745025,
        "bleu": 68.94026,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        },
        "bleurt": 0.64449,
        "meteor": 0.81809314801268,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.25,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.55152,
            "fmeasure": 0.64052
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.36147,
            "fmeasure": 0.45657
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.48599,
            "fmeasure": 0.56649
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.48599,
            "fmeasure": 0.56649
        },
        "nist": 1.6270859002229454,
        "bleu": 40.43844,
        "bertscore": {
            "precision": 0.92644,
            "recall": 0.85844,
            "f1": 0.88341
        },
        "bleurt": -0.14917,
        "meteor": 0.31140354672402926,
        "nubia": {
            "semantic_relation": 3.28871,
            "contradiction": 0.13857,
            "irrelevancy": 96.26158,
            "logical_agreement": 3.59985,
            "grammar_ref": 4.44297,
            "grammar_hyp": 3.93115,
            "nubia_score": 0.46882
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.37821,
            "fmeasure": 0.41905
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54342,
            "fmeasure": 0.59753
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54342,
            "fmeasure": 0.59753
        },
        "nist": 3.353520501612051,
        "bleu": 35.84892,
        "bertscore": {
            "precision": 0.916,
            "recall": 0.87322,
            "f1": 0.88581
        },
        "bleurt": -0.06378,
        "meteor": 0.3424658391974671,
        "nubia": {
            "semantic_relation": 3.94575,
            "contradiction": 23.38666,
            "irrelevancy": 70.32109,
            "logical_agreement": 6.29225,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.3626,
            "nubia_score": 0.6368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.57143,
            "fmeasure": 0.48485
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.46154,
            "fmeasure": 0.3871
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.57143,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.57143,
            "fmeasure": 0.48485
        },
        "nist": 1.6526917594067516,
        "bleu": 19.80316,
        "bertscore": {
            "precision": 0.81908,
            "recall": 0.88012,
            "f1": 0.8485
        },
        "bleurt": -0.30289,
        "meteor": 0.32318180438504585,
        "nubia": {
            "semantic_relation": 2.33633,
            "contradiction": 74.6297,
            "irrelevancy": 24.2582,
            "logical_agreement": 1.1121,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.05052,
            "nubia_score": 0.24026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.69615,
            "fmeasure": 0.50606
        },
        "rouge2": {
            "precision": 0.10526,
            "recall": 0.19444,
            "fmeasure": 0.13594
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.44231,
            "fmeasure": 0.31818
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.44231,
            "fmeasure": 0.31818
        },
        "nist": 1.8380416676968903,
        "bleu": 9.13442,
        "bertscore": {
            "precision": 0.88183,
            "recall": 0.90212,
            "f1": 0.89186
        },
        "bleurt": -0.50818,
        "meteor": 0.30477449942938256,
        "nubia": {
            "semantic_relation": 3.3134,
            "contradiction": 21.5099,
            "irrelevancy": 77.93693,
            "logical_agreement": 0.55317,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.58094,
            "nubia_score": 0.33665
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "nist": 2.049671574886097,
        "bleu": 23.07713,
        "bertscore": {
            "precision": 0.87052,
            "recall": 0.94229,
            "f1": 0.90498
        },
        "bleurt": 0.21219,
        "meteor": 0.4220378127640017,
        "nubia": {
            "semantic_relation": 4.63878,
            "contradiction": 0.30613,
            "irrelevancy": 94.58437,
            "logical_agreement": 5.1095,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.28973,
            "nubia_score": 0.85907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.59649,
            "recall": 0.74837,
            "fmeasure": 0.6595
        },
        "rouge2": {
            "precision": 0.24074,
            "recall": 0.29924,
            "fmeasure": 0.26504
        },
        "rougeL": {
            "precision": 0.4386,
            "recall": 0.54739,
            "fmeasure": 0.48387
        },
        "rougeLsum": {
            "precision": 0.4386,
            "recall": 0.54739,
            "fmeasure": 0.48387
        },
        "nist": 2.36295617460001,
        "bleu": 9.87564,
        "bertscore": {
            "precision": 0.8924,
            "recall": 0.90812,
            "f1": 0.89106
        },
        "bleurt": -0.14396,
        "meteor": 0.3180661749731935,
        "nubia": {
            "semantic_relation": 3.64134,
            "contradiction": 5.86137,
            "irrelevancy": 93.08993,
            "logical_agreement": 1.0487,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.842,
            "nubia_score": 0.50951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.2222222222222222
        },
        "rouge1": {
            "precision": 0.2963,
            "recall": 0.17634,
            "fmeasure": 0.20702
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.03333,
            "fmeasure": 0.05263
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.09677,
            "fmeasure": 0.15
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.09677,
            "fmeasure": 0.15
        },
        "nist": 0.03525105957435651,
        "bleu": 8.6398,
        "bertscore": {
            "precision": 0.85562,
            "recall": 0.74732,
            "f1": 0.79187
        },
        "bleurt": -0.53143,
        "meteor": 0.0795092418437589,
        "nubia": {
            "semantic_relation": 1.62674,
            "contradiction": 40.42508,
            "irrelevancy": 21.67918,
            "logical_agreement": 37.89574,
            "grammar_ref": 4.34568,
            "grammar_hyp": 4.14668,
            "nubia_score": 0.12892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.42857,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "nist": 1.7141424566001497,
        "bleu": 25.21194,
        "bertscore": {
            "precision": 0.86178,
            "recall": 0.92533,
            "f1": 0.8921
        },
        "bleurt": 0.19622,
        "meteor": 0.3964096993712689,
        "nubia": {
            "semantic_relation": 4.07467,
            "contradiction": 0.09942,
            "irrelevancy": 99.76836,
            "logical_agreement": 0.13222,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.79365,
            "nubia_score": 0.82331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.43636,
            "fmeasure": 0.55639
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.54348,
            "fmeasure": 0.68514
        },
        "nist": 0.5230454028516153,
        "bleu": 20.2362,
        "bertscore": {
            "precision": 0.95762,
            "recall": 0.84624,
            "f1": 0.89849
        },
        "bleurt": 0.36014,
        "meteor": 0.3272942874634928,
        "nubia": {
            "semantic_relation": 4.42806,
            "contradiction": 0.1765,
            "irrelevancy": 0.43401,
            "logical_agreement": 99.38949,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.2568,
            "nubia_score": 0.90992
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.77273,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.68182,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.68182,
            "fmeasure": 0.7
        },
        "nist": 4.609020737243196,
        "bleu": 66.00582,
        "bertscore": {
            "precision": 0.93128,
            "recall": 0.94593,
            "f1": 0.93848
        },
        "bleurt": 0.66765,
        "meteor": 0.46445720479689445,
        "nubia": {
            "semantic_relation": 4.63412,
            "contradiction": 1.69222,
            "irrelevancy": 0.9902,
            "logical_agreement": 97.31757,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.18191,
            "nubia_score": 0.80189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.66354,
            "fmeasure": 0.72031
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.57845,
            "fmeasure": 0.61734
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.63646,
            "fmeasure": 0.6833
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.63646,
            "fmeasure": 0.6833
        },
        "nist": 1.500960348032613,
        "bleu": 44.77172,
        "bertscore": {
            "precision": 0.95031,
            "recall": 0.90864,
            "f1": 0.92846
        },
        "bleurt": 0.16721,
        "meteor": 0.3155081346683423,
        "nubia": {
            "semantic_relation": 4.05755,
            "contradiction": 0.56249,
            "irrelevancy": 2.7339,
            "logical_agreement": 96.7036,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.8679,
            "nubia_score": 0.65053
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.353995254377449,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.89781,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.40892,
            "irrelevancy": 0.54064,
            "logical_agreement": 99.05044,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.8105,
            "nubia_score": 0.99007
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "nist": 2.425622163887878,
        "bleu": 51.15078,
        "bertscore": {
            "precision": 0.99151,
            "recall": 0.95959,
            "f1": 0.97529
        },
        "bleurt": 0.50807,
        "meteor": 0.42750933026297866,
        "nubia": {
            "semantic_relation": 3.87389,
            "contradiction": 20.08697,
            "irrelevancy": 3.02677,
            "logical_agreement": 76.88626,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.80119,
            "nubia_score": 0.42085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.74444,
            "recall": 0.8105,
            "fmeasure": 0.77297
        },
        "rouge2": {
            "precision": 0.54902,
            "recall": 0.58813,
            "fmeasure": 0.56528
        },
        "rougeL": {
            "precision": 0.72593,
            "recall": 0.79296,
            "fmeasure": 0.75495
        },
        "rougeLsum": {
            "precision": 0.72593,
            "recall": 0.79296,
            "fmeasure": 0.75495
        },
        "nist": 3.8750998249010706,
        "bleu": 49.31963,
        "bertscore": {
            "precision": 0.91909,
            "recall": 0.93569,
            "f1": 0.92716
        },
        "bleurt": 0.13403,
        "meteor": 0.47116970251260853,
        "nubia": {
            "semantic_relation": 4.21468,
            "contradiction": 7.67848,
            "irrelevancy": 64.1771,
            "logical_agreement": 28.14441,
            "grammar_ref": 5.29605,
            "grammar_hyp": 5.26063,
            "nubia_score": 0.72958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "nist": 2.4929182263680483,
        "bleu": 19.43406,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94874
        },
        "bleurt": 0.5593,
        "meteor": 0.38388402914845343,
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.85,
            "recall": 0.65385,
            "fmeasure": 0.73913
        },
        "rouge2": {
            "precision": 0.57895,
            "recall": 0.44,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.46154,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.46154,
            "fmeasure": 0.52174
        },
        "nist": 2.412092609331813,
        "bleu": 29.00687,
        "bertscore": {
            "precision": 0.95354,
            "recall": 0.90076,
            "f1": 0.9264
        },
        "bleurt": 0.13997,
        "meteor": 0.3524842018052115,
        "nubia": {
            "semantic_relation": 3.84154,
            "contradiction": 19.56544,
            "irrelevancy": 2.21729,
            "logical_agreement": 78.21727,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.72497,
            "nubia_score": 0.55748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5833333333333334
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "nist": 2.3164651907465217,
        "bleu": 30.1304,
        "bertscore": {
            "precision": 0.90406,
            "recall": 0.87922,
            "f1": 0.89147
        },
        "bleurt": 0.3527,
        "meteor": 0.3839657862290567,
        "nubia": {
            "semantic_relation": 4.18831,
            "contradiction": 0.07999,
            "irrelevancy": 1.7299,
            "logical_agreement": 98.19011,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.62088,
            "nubia_score": 0.87273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.90625,
            "recall": 0.725,
            "fmeasure": 0.80556
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.63158,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.90625,
            "recall": 0.725,
            "fmeasure": 0.80556
        },
        "rougeLsum": {
            "precision": 0.90625,
            "recall": 0.725,
            "fmeasure": 0.80556
        },
        "nist": 3.3061748967107705,
        "bleu": 61.2988,
        "bertscore": {
            "precision": 0.97325,
            "recall": 0.89624,
            "f1": 0.93316
        },
        "bleurt": 0.19875,
        "meteor": 0.47220734046244783,
        "nubia": {
            "semantic_relation": 3.85016,
            "contradiction": 0.33172,
            "irrelevancy": 0.55315,
            "logical_agreement": 99.11514,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.36681,
            "nubia_score": 0.65848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.1111111111111111,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.43266,
            "fmeasure": 0.58861
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.33987,
            "fmeasure": 0.48184
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.43266,
            "fmeasure": 0.58861
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.43266,
            "fmeasure": 0.58861
        },
        "nist": 0.3946558058579736,
        "bleu": 31.9413,
        "bertscore": {
            "precision": 0.95106,
            "recall": 0.89151,
            "f1": 0.91162
        },
        "bleurt": -0.62681,
        "meteor": 0.2915254109606652,
        "nubia": {
            "semantic_relation": 3.16455,
            "contradiction": 33.4007,
            "irrelevancy": 6.07636,
            "logical_agreement": 60.52295,
            "grammar_ref": 5.24053,
            "grammar_hyp": 6.21196,
            "nubia_score": 0.29194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6
        },
        "rouge1": {
            "precision": 0.23077,
            "recall": 0.4375,
            "fmeasure": 0.30075
        },
        "rouge2": {
            "precision": 0.04167,
            "recall": 0.1,
            "fmeasure": 0.05882
        },
        "rougeL": {
            "precision": 0.15385,
            "recall": 0.29167,
            "fmeasure": 0.2005
        },
        "rougeLsum": {
            "precision": 0.15385,
            "recall": 0.29167,
            "fmeasure": 0.2005
        },
        "nist": 1.029238588006989,
        "bleu": 9.67265,
        "bertscore": {
            "precision": 0.67973,
            "recall": 0.77589,
            "f1": 0.71925
        },
        "bleurt": -0.69826,
        "meteor": 0.20592116104937308,
        "nubia": {
            "semantic_relation": 2.74396,
            "contradiction": 25.58893,
            "irrelevancy": 73.73684,
            "logical_agreement": 0.67423,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.48179,
            "nubia_score": 0.3101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.87179,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5873,
            "fmeasure": 0.61654
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.71154,
            "fmeasure": 0.74206
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.71154,
            "fmeasure": 0.74206
        },
        "nist": 0.7431521442254547,
        "bleu": 61.47882,
        "bertscore": {
            "precision": 0.96403,
            "recall": 0.96736,
            "f1": 0.9657
        },
        "bleurt": 0.21318,
        "meteor": 0.5283981486420264,
        "nubia": {
            "semantic_relation": 4.10346,
            "contradiction": 0.20912,
            "irrelevancy": 0.42988,
            "logical_agreement": 99.361,
            "grammar_ref": 4.62626,
            "grammar_hyp": 6.3024,
            "nubia_score": 0.53026
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.47059,
            "fmeasure": 0.47475
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.13056,
            "fmeasure": 0.1319
        },
        "rougeL": {
            "precision": 0.29167,
            "recall": 0.26625,
            "fmeasure": 0.27821
        },
        "rougeLsum": {
            "precision": 0.29167,
            "recall": 0.26625,
            "fmeasure": 0.27821
        },
        "nist": 2.046911654384169,
        "bleu": 10.56372,
        "bertscore": {
            "precision": 0.85988,
            "recall": 0.86993,
            "f1": 0.86488
        },
        "bleurt": -0.1633,
        "meteor": 0.2202767968954732,
        "nubia": {
            "semantic_relation": 2.1594,
            "contradiction": 3.75421,
            "irrelevancy": 91.51745,
            "logical_agreement": 4.72833,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.36402,
            "nubia_score": 0.25305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.67917,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "nist": 2.955116912262305,
        "bleu": 57.58522,
        "bertscore": {
            "precision": 0.89616,
            "recall": 0.94973,
            "f1": 0.92216
        },
        "bleurt": -0.33255,
        "meteor": 0.5139078546685881,
        "nubia": {
            "semantic_relation": 2.89108,
            "contradiction": 0.54,
            "irrelevancy": 98.75045,
            "logical_agreement": 0.70956,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.79961,
            "nubia_score": 0.34265
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.6
        },
        "rouge1": {
            "precision": 0.47727,
            "recall": 0.54412,
            "fmeasure": 0.50641
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.35417,
            "fmeasure": 0.32883
        },
        "rougeL": {
            "precision": 0.38636,
            "recall": 0.45321,
            "fmeasure": 0.4155
        },
        "rougeLsum": {
            "precision": 0.38636,
            "recall": 0.45321,
            "fmeasure": 0.4155
        },
        "nist": 2.733431817510688,
        "bleu": 16.07863,
        "bertscore": {
            "precision": 0.82089,
            "recall": 0.83917,
            "f1": 0.82989
        },
        "bleurt": -0.73092,
        "meteor": 0.3376640786430428,
        "nubia": {
            "semantic_relation": 3.28373,
            "contradiction": 0.50215,
            "irrelevancy": 99.21315,
            "logical_agreement": 0.2847,
            "grammar_ref": 3.66593,
            "grammar_hyp": 4.14459,
            "nubia_score": 0.47537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.125,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.78301,
            "fmeasure": 0.7493
        },
        "rouge2": {
            "precision": 0.57937,
            "recall": 0.62149,
            "fmeasure": 0.59215
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.65747,
            "fmeasure": 0.62131
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.65747,
            "fmeasure": 0.62131
        },
        "nist": 3.4952454733829232,
        "bleu": 52.10667,
        "bertscore": {
            "precision": 0.9511,
            "recall": 0.95658,
            "f1": 0.95382
        },
        "bleurt": 0.39088,
        "meteor": 0.47671546472707066,
        "nubia": {
            "semantic_relation": 3.80529,
            "contradiction": 0.67503,
            "irrelevancy": 0.94151,
            "logical_agreement": 98.38346,
            "grammar_ref": 4.25678,
            "grammar_hyp": 3.97674,
            "nubia_score": 0.65453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4166666666666667
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "nist": 1.5984118021130185,
        "bleu": 21.76314,
        "bertscore": {
            "precision": 0.88759,
            "recall": 0.86415,
            "f1": 0.87571
        },
        "bleurt": -0.22948,
        "meteor": 0.3343547431832232,
        "nubia": {
            "semantic_relation": 4.16544,
            "contradiction": 0.28429,
            "irrelevancy": 5.33701,
            "logical_agreement": 94.3787,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.29276,
            "nubia_score": 0.92251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.2037,
            "fmeasure": 0.23684
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.38462,
            "fmeasure": 0.47619
        },
        "nist": 0.9572871299785921,
        "bleu": 8.59132,
        "bertscore": {
            "precision": 0.92188,
            "recall": 0.85467,
            "f1": 0.88701
        },
        "bleurt": -0.26662,
        "meteor": 0.28038886196955204,
        "nubia": {
            "semantic_relation": 3.81986,
            "contradiction": 15.07903,
            "irrelevancy": 79.31522,
            "logical_agreement": 5.60576,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.82406,
            "nubia_score": 0.5347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8823529411764706
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.85354,
            "fmeasure": 0.87968
        },
        "rouge2": {
            "precision": 0.72857,
            "recall": 0.69722,
            "fmeasure": 0.71053
        },
        "rougeL": {
            "precision": 0.86364,
            "recall": 0.83232,
            "fmeasure": 0.84577
        },
        "rougeLsum": {
            "precision": 0.86364,
            "recall": 0.83232,
            "fmeasure": 0.84577
        },
        "nist": 3.9508763524245136,
        "bleu": 60.34149,
        "bertscore": {
            "precision": 0.97207,
            "recall": 0.96765,
            "f1": 0.96855
        },
        "bleurt": 0.76691,
        "meteor": 0.46658635061397613,
        "nubia": {
            "semantic_relation": 4.95917,
            "contradiction": 0.4792,
            "irrelevancy": 2.34918,
            "logical_agreement": 97.17162,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.49555,
            "nubia_score": 0.98564
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "nist": 3.6961650890339652,
        "bleu": 76.11606,
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        },
        "bleurt": 0.74566,
        "meteor": 0.5715186082473627,
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6470588235294118
        },
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.71678,
            "fmeasure": 0.75223
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.40931,
            "fmeasure": 0.42608
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.57734,
            "fmeasure": 0.60012
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.57734,
            "fmeasure": 0.60012
        },
        "nist": 3.1106486305338077,
        "bleu": 29.91308,
        "bertscore": {
            "precision": 0.90063,
            "recall": 0.90292,
            "f1": 0.90177
        },
        "bleurt": -0.13083,
        "meteor": 0.3377361787439172,
        "nubia": {
            "semantic_relation": 3.6754,
            "contradiction": 0.77128,
            "irrelevancy": 87.27983,
            "logical_agreement": 11.94889,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.71899,
            "nubia_score": 0.51959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "nist": 2.32249814589546,
        "bleu": 41.10546,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "bleurt": 0.65075,
        "meteor": 0.8569614896318238,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.48889,
            "fmeasure": 0.55282
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.0812,
            "fmeasure": 0.08959
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.30037,
            "fmeasure": 0.32889
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.30037,
            "fmeasure": 0.32889
        },
        "nist": 1.9758069132295433,
        "bleu": 8.108,
        "bertscore": {
            "precision": 0.88132,
            "recall": 0.84481,
            "f1": 0.86268
        },
        "bleurt": 0.05765,
        "meteor": 0.2893710821486708,
        "nubia": {
            "semantic_relation": 3.4522,
            "contradiction": 2.85931,
            "irrelevancy": 8.60897,
            "logical_agreement": 88.53172,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.88938,
            "nubia_score": 0.58028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.58333,
            "fmeasure": 0.54902
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "nist": 3.6924927713907505,
        "bleu": 59.23033,
        "bertscore": {
            "precision": 0.97818,
            "recall": 0.99443,
            "f1": 0.98624
        },
        "bleurt": 0.75444,
        "meteor": 0.5234779551940048,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1262,
            "irrelevancy": 5.88214,
            "logical_agreement": 93.99166,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.79772,
            "nubia_score": 0.98703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "nist": 1.8094988549899862,
        "bleu": 24.59813,
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        },
        "bleurt": 0.30353,
        "meteor": 0.3010544205973617,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2777777777777778
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.18519,
            "fmeasure": 0.27027
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.14815,
            "fmeasure": 0.21622
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.14815,
            "fmeasure": 0.21622
        },
        "nist": 0.07893581143130902,
        "bleu": 2.02597,
        "bertscore": {
            "precision": 0.89553,
            "recall": 0.75251,
            "f1": 0.81765
        },
        "bleurt": -0.49755,
        "meteor": 0.08239722127151576,
        "nubia": {
            "semantic_relation": 1.99295,
            "contradiction": 18.72454,
            "irrelevancy": 73.73763,
            "logical_agreement": 7.53784,
            "grammar_ref": 4.95946,
            "grammar_hyp": 5.48008,
            "nubia_score": 0.09235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.76471,
            "fmeasure": 0.8125
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.58824,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.58824,
            "fmeasure": 0.625
        },
        "nist": 3.442106960182977,
        "bleu": 30.95846,
        "bertscore": {
            "precision": 0.91711,
            "recall": 0.87841,
            "f1": 0.89734
        },
        "bleurt": 0.12924,
        "meteor": 0.39454839479443005,
        "nubia": {
            "semantic_relation": 3.37436,
            "contradiction": 1.02098,
            "irrelevancy": 5.88788,
            "logical_agreement": 93.09114,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.47555,
            "nubia_score": 0.44407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "nist": 3.0945894140476606,
        "bleu": 62.62845,
        "bertscore": {
            "precision": 0.96634,
            "recall": 0.98092,
            "f1": 0.97358
        },
        "bleurt": 0.79405,
        "meteor": 0.512675617900284,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37071,
            "irrelevancy": 0.70467,
            "logical_agreement": 98.92462,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.34125,
            "nubia_score": 0.98178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "rouge1": {
            "precision": 0.87729,
            "recall": 0.88828,
            "fmeasure": 0.88177
        },
        "rouge2": {
            "precision": 0.70406,
            "recall": 0.71902,
            "fmeasure": 0.71056
        },
        "rougeL": {
            "precision": 0.83883,
            "recall": 0.85165,
            "fmeasure": 0.84425
        },
        "rougeLsum": {
            "precision": 0.83883,
            "recall": 0.85165,
            "fmeasure": 0.84425
        },
        "nist": 4.297916759630754,
        "bleu": 59.36359,
        "bertscore": {
            "precision": 0.95626,
            "recall": 0.96789,
            "f1": 0.9602
        },
        "bleurt": 0.52652,
        "meteor": 0.5083614283050566,
        "nubia": {
            "semantic_relation": 4.55992,
            "contradiction": 0.18471,
            "irrelevancy": 48.96674,
            "logical_agreement": 50.84855,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.80853,
            "nubia_score": 0.81393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.75214,
            "fmeasure": 0.80808
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.625,
            "fmeasure": 0.675
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.75214,
            "fmeasure": 0.80808
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.75214,
            "fmeasure": 0.80808
        },
        "nist": 2.5991571359046515,
        "bleu": 58.14307,
        "bertscore": {
            "precision": 0.9808,
            "recall": 0.9808,
            "f1": 0.9808
        },
        "bleurt": 0.33778,
        "meteor": 0.4948400113670794,
        "nubia": {
            "semantic_relation": 4.24241,
            "contradiction": 0.72992,
            "irrelevancy": 0.55123,
            "logical_agreement": 98.71884,
            "grammar_ref": 4.45494,
            "grammar_hyp": 4.02218,
            "nubia_score": 0.79118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.8125
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.66667,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "nist": 3.73609896478902,
        "bleu": 65.25942,
        "bertscore": {
            "precision": 0.97026,
            "recall": 0.92549,
            "f1": 0.94735
        },
        "bleurt": -0.22932,
        "meteor": 0.4368767317307086,
        "nubia": {
            "semantic_relation": 3.62949,
            "contradiction": 0.23057,
            "irrelevancy": 33.2221,
            "logical_agreement": 66.54734,
            "grammar_ref": 3.23206,
            "grammar_hyp": 2.92393,
            "nubia_score": 0.7323
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.631578947368421
        },
        "rouge1": {
            "precision": 0.68254,
            "recall": 0.71895,
            "fmeasure": 0.69649
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.43018,
            "fmeasure": 0.42316
        },
        "rougeL": {
            "precision": 0.54762,
            "recall": 0.56209,
            "fmeasure": 0.55142
        },
        "rougeLsum": {
            "precision": 0.54762,
            "recall": 0.56209,
            "fmeasure": 0.55142
        },
        "nist": 2.8340026917563805,
        "bleu": 16.79822,
        "bertscore": {
            "precision": 0.89638,
            "recall": 0.86226,
            "f1": 0.87627
        },
        "bleurt": -0.22555,
        "meteor": 0.3333969785007155,
        "nubia": {
            "semantic_relation": 4.1209,
            "contradiction": 11.63428,
            "irrelevancy": 12.6432,
            "logical_agreement": 75.72252,
            "grammar_ref": 6.00658,
            "grammar_hyp": 5.26804,
            "nubia_score": 0.78435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.57273,
            "fmeasure": 0.58571
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.69697,
            "fmeasure": 0.71146
        },
        "nist": 2.7137581921247107,
        "bleu": 43.66835,
        "bertscore": {
            "precision": 0.93867,
            "recall": 0.93609,
            "f1": 0.93738
        },
        "bleurt": 0.5113,
        "meteor": 0.4201762641755536,
        "nubia": {
            "semantic_relation": 4.67757,
            "contradiction": 1.33555,
            "irrelevancy": 6.72201,
            "logical_agreement": 91.94243,
            "grammar_ref": 4.19853,
            "grammar_hyp": 5.03058,
            "nubia_score": 0.75582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "mT5_small/totto_test",
        "N": 5,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7450980392156863,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.74156,
            "recall": 0.8059,
            "fmeasure": 0.76473
        },
        "rouge2": {
            "precision": 0.56842,
            "recall": 0.61217,
            "fmeasure": 0.58286
        },
        "rougeL": {
            "precision": 0.6178,
            "recall": 0.66479,
            "fmeasure": 0.63348
        },
        "rougeLsum": {
            "precision": 0.6178,
            "recall": 0.66479,
            "fmeasure": 0.63348
        },
        "nist": 5.663286016040592,
        "bleu": 60.91669,
        "bertscore": {
            "precision": 0.93651,
            "recall": 0.94661,
            "f1": 0.93938
        },
        "bleurt": 0.12052,
        "meteor": 0.466495326680578,
        "nubia": {
            "semantic_relation": 4.10106,
            "contradiction": 26.70771,
            "irrelevancy": 34.09624,
            "logical_agreement": 39.19605,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.43533,
            "nubia_score": 0.74505
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "total_length": 1826,
        "mean_pred_length": 28.984126984126984,
        "std_pred_length": 8.433666591367674,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 48,
        "distinct-1": 0.47973713033953996,
        "vocab_size-1": 876,
        "unique-1": 699,
        "entropy-1": 8.459592285972148,
        "distinct-2": 0.9205899035734544,
        "vocab_size-2": 1623,
        "unique-2": 1549,
        "entropy-2": 10.574003463847957,
        "cond_entropy-2": 1.981274414964411,
        "distinct-3": 0.9894117647058823,
        "vocab_size-3": 1682,
        "unique-3": 1673,
        "entropy-3": 10.703216420724427,
        "cond_entropy-3": 0.132870743708884,
        "total_length-nopunct": 1640,
        "mean_pred_length-nopunct": 26.03174603174603,
        "std_pred_length-nopunct": 7.354877992509901,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5292682926829269,
        "vocab_size-1-nopunct": 868,
        "unique-1-nopunct": 698,
        "entropy-1-nopunct": 8.6685820741202,
        "distinct-2-nopunct": 0.9441978440076094,
        "vocab_size-2-nopunct": 1489,
        "unique-2-nopunct": 1435,
        "entropy-2-nopunct": 10.484737752070485,
        "cond_entropy-2-nopunct": 1.8728925522154303,
        "distinct-3-nopunct": 0.9980184940554822,
        "vocab_size-3-nopunct": 1511,
        "unique-3-nopunct": 1508,
        "entropy-3-nopunct": 10.560186478096458,
        "cond_entropy-3-nopunct": 0.08120066733484084,
        "msttr-100": 0.75222,
        "msttr-100_nopunct": 0.78875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.035918367346938776,
            "2": 0.24316939890710382,
            "3": 0.5175438596491229,
            "4": 0.7177914110429447,
            "5": 0.7904191616766467,
            "6": 0.8924731182795699,
            "7": 0.9156626506024096,
            "8": 0.9627906976744186,
            "9": 0.9770114942528736,
            "10": 0.9814814814814815
        },
        "rouge1": {
            "precision": 0.88329,
            "recall": 0.9223,
            "fmeasure": 0.89995
        },
        "rouge2": {
            "precision": 0.79567,
            "recall": 0.83158,
            "fmeasure": 0.81087
        },
        "rougeL": {
            "precision": 0.87317,
            "recall": 0.91797,
            "fmeasure": 0.89256
        },
        "rougeLsum": {
            "precision": 0.87317,
            "recall": 0.91797,
            "fmeasure": 0.89256
        },
        "nist": 11.682243787705156,
        "bleu": 87.71958,
        "bertscore": {
            "precision": 0.97054,
            "recall": 0.98047,
            "f1": 0.97405
        },
        "bleurt": 0.25366,
        "meteor": 0.569789631574028,
        "nubia": {
            "semantic_relation": 4.31481,
            "contradiction": 1.02561,
            "irrelevancy": 42.03875,
            "logical_agreement": 56.93564,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.49187,
            "nubia_score": 0.63899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.36363636363636365
        },
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.34524,
            "fmeasure": 0.39231
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.11264,
            "fmeasure": 0.12862
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.34524,
            "fmeasure": 0.39231
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.34524,
            "fmeasure": 0.39231
        },
        "nist": 2.1086971660322993,
        "bleu": 18.59153,
        "bertscore": {
            "precision": 0.89246,
            "recall": 0.85929,
            "f1": 0.87556
        },
        "bleurt": 0.20546,
        "meteor": 0.28570751500842767,
        "nubia": {
            "semantic_relation": 4.21356,
            "contradiction": 0.25518,
            "irrelevancy": 76.58471,
            "logical_agreement": 23.16011,
            "grammar_ref": 5.03823,
            "grammar_hyp": 5.37132,
            "nubia_score": 0.65788
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "total_length": 2895,
        "mean_pred_length": 16.637931034482758,
        "std_pred_length": 6.9729319247664865,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 39,
        "distinct-1": 0.44352331606217615,
        "vocab_size-1": 1284,
        "unique-1": 1002,
        "entropy-1": 8.58734946329352,
        "distinct-2": 0.8776185226019846,
        "vocab_size-2": 2388,
        "unique-2": 2251,
        "entropy-2": 11.011678275604007,
        "cond_entropy-2": 2.129935541323337,
        "distinct-3": 0.972516686297605,
        "vocab_size-3": 2477,
        "unique-3": 2436,
        "entropy-3": 11.244611840457457,
        "cond_entropy-3": 0.2512058021998219,
        "total_length-nopunct": 2570,
        "mean_pred_length-nopunct": 14.770114942528735,
        "std_pred_length-nopunct": 6.12926117207644,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.49571984435797667,
        "vocab_size-1-nopunct": 1274,
        "unique-1-nopunct": 1000,
        "entropy-1-nopunct": 8.881271264968834,
        "distinct-2-nopunct": 0.8860601001669449,
        "vocab_size-2-nopunct": 2123,
        "unique-2-nopunct": 2013,
        "entropy-2-nopunct": 10.846086552325271,
        "cond_entropy-2-nopunct": 2.103304280997529,
        "distinct-3-nopunct": 0.9810981098109811,
        "vocab_size-3-nopunct": 2180,
        "unique-3-nopunct": 2148,
        "entropy-3-nopunct": 11.076221364207886,
        "cond_entropy-3-nopunct": 0.251137010999048,
        "msttr-100": 0.72714,
        "msttr-100_nopunct": 0.7676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.040398740818468,
            "2": 0.18151815181518152,
            "3": 0.41798941798941797,
            "4": 0.5766129032258065,
            "5": 0.7027863777089783,
            "6": 0.7805970149253731,
            "7": 0.8810126582278481
        },
        "rouge1": {
            "precision": 0.88107,
            "recall": 0.8283,
            "fmeasure": 0.84362
        },
        "rouge2": {
            "precision": 0.74332,
            "recall": 0.70256,
            "fmeasure": 0.71216
        },
        "rougeL": {
            "precision": 0.84975,
            "recall": 0.79777,
            "fmeasure": 0.81302
        },
        "rougeLsum": {
            "precision": 0.84975,
            "recall": 0.79777,
            "fmeasure": 0.81302
        },
        "nist": 10.546133249686848,
        "bleu": 72.01648,
        "bertscore": {
            "precision": 0.96226,
            "recall": 0.9503,
            "f1": 0.95423
        },
        "bleurt": 0.27449,
        "meteor": 0.4833098529763591,
        "nubia": {
            "semantic_relation": 4.38005,
            "contradiction": 3.98197,
            "irrelevancy": 15.58615,
            "logical_agreement": 80.43188,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.07562,
            "nubia_score": 0.71303
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "total_length": 1229,
        "mean_pred_length": 21.189655172413794,
        "std_pred_length": 8.830700555159089,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 50,
        "distinct-1": 0.5183075671277462,
        "vocab_size-1": 637,
        "unique-1": 517,
        "entropy-1": 8.129351873858125,
        "distinct-2": 0.9291204099060631,
        "vocab_size-2": 1088,
        "unique-2": 1040,
        "entropy-2": 10.01275964167288,
        "cond_entropy-2": 1.6930448040017452,
        "distinct-3": 0.9865229110512129,
        "vocab_size-3": 1098,
        "unique-3": 1089,
        "entropy-3": 10.086797373344758,
        "cond_entropy-3": 0.08345768826834327,
        "total_length-nopunct": 1115,
        "mean_pred_length-nopunct": 19.224137931034484,
        "std_pred_length-nopunct": 8.117760654881403,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.5641255605381166,
        "vocab_size-1-nopunct": 629,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.287113468158575,
        "distinct-2-nopunct": 0.9422894985808893,
        "vocab_size-2-nopunct": 996,
        "unique-2-nopunct": 955,
        "entropy-2-nopunct": 9.904011141689475,
        "cond_entropy-2-nopunct": 1.705023988053777,
        "distinct-3-nopunct": 0.993993993993994,
        "vocab_size-3-nopunct": 993,
        "unique-3-nopunct": 987,
        "entropy-3-nopunct": 9.952328855780259,
        "cond_entropy-3-nopunct": 0.05654735787702909,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.76455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.03985932004689332,
            "2": 0.18309859154929578,
            "3": 0.4155844155844156,
            "4": 0.5769230769230769,
            "5": 0.7039106145251397,
            "6": 0.8458781362007168,
            "7": 0.8755868544600939
        },
        "rouge1": {
            "precision": 0.86044,
            "recall": 0.81167,
            "fmeasure": 0.82925
        },
        "rouge2": {
            "precision": 0.72674,
            "recall": 0.69279,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.83848,
            "recall": 0.7994,
            "fmeasure": 0.81326
        },
        "rougeLsum": {
            "precision": 0.83848,
            "recall": 0.7994,
            "fmeasure": 0.81326
        },
        "nist": 9.60839282298681,
        "bleu": 70.41914,
        "bertscore": {
            "precision": 0.95538,
            "recall": 0.94893,
            "f1": 0.95038
        },
        "bleurt": 0.21799,
        "meteor": 0.475454939393685,
        "nubia": {
            "semantic_relation": 4.37686,
            "contradiction": 4.49562,
            "irrelevancy": 17.20573,
            "logical_agreement": 78.29865,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.82004,
            "nubia_score": 0.73583
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.91304,
            "recall": 0.77778,
            "fmeasure": 0.84
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.69231,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.91304,
            "recall": 0.77778,
            "fmeasure": 0.84
        },
        "rougeLsum": {
            "precision": 0.91304,
            "recall": 0.77778,
            "fmeasure": 0.84
        },
        "nist": 3.568464718030404,
        "bleu": 63.21376,
        "bertscore": {
            "precision": 0.96444,
            "recall": 0.93739,
            "f1": 0.95037
        },
        "bleurt": 0.31648,
        "meteor": 0.49299317890620825,
        "nubia": {
            "semantic_relation": 4.21813,
            "contradiction": 0.10057,
            "irrelevancy": 6.73199,
            "logical_agreement": 93.16744,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.65312,
            "nubia_score": 0.66926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6
        },
        "rouge1": {
            "precision": 0.48148,
            "recall": 0.61111,
            "fmeasure": 0.53099
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.21481,
            "fmeasure": 0.20814
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.44444,
            "fmeasure": 0.37778
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.44444,
            "fmeasure": 0.37778
        },
        "nist": 2.1833336970919572,
        "bleu": 11.88463,
        "bertscore": {
            "precision": 0.79059,
            "recall": 0.81025,
            "f1": 0.79582
        },
        "bleurt": -0.67375,
        "meteor": 0.3201927745857165,
        "nubia": {
            "semantic_relation": 2.73535,
            "contradiction": 6.03892,
            "irrelevancy": 93.53531,
            "logical_agreement": 0.42577,
            "grammar_ref": 7.45181,
            "grammar_hyp": 6.03191,
            "nubia_score": 0.32355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.3219280948873626,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.97683,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.19231,
            "recall": 0.33333,
            "fmeasure": 0.2439
        },
        "rouge2": {
            "precision": 0.04,
            "recall": 0.07143,
            "fmeasure": 0.05128
        },
        "rougeL": {
            "precision": 0.11538,
            "recall": 0.2,
            "fmeasure": 0.14634
        },
        "rougeLsum": {
            "precision": 0.11538,
            "recall": 0.2,
            "fmeasure": 0.14634
        },
        "nist": 0.7407407407407407,
        "bleu": 3.49018,
        "bertscore": {
            "precision": 0.76032,
            "recall": 0.78671,
            "f1": 0.77249
        },
        "bleurt": -0.23495,
        "meteor": 0.11351267557834761,
        "nubia": {
            "semantic_relation": 2.51298,
            "contradiction": 0.36486,
            "irrelevancy": 99.39804,
            "logical_agreement": 0.2371,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.49952,
            "nubia_score": 0.42141
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "total_length": 469,
        "mean_pred_length": 21.318181818181817,
        "std_pred_length": 9.45509176743296,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 39,
        "distinct-1": 0.5991471215351812,
        "vocab_size-1": 281,
        "unique-1": 233,
        "entropy-1": 7.350046802481325,
        "distinct-2": 0.9395973154362416,
        "vocab_size-2": 420,
        "unique-2": 404,
        "entropy-2": 8.652510355611064,
        "cond_entropy-2": 1.1548044430346274,
        "distinct-3": 0.9929411764705882,
        "vocab_size-3": 422,
        "unique-3": 419,
        "entropy-3": 8.717201383966303,
        "cond_entropy-3": 0.07253962751425742,
        "total_length-nopunct": 425,
        "mean_pred_length-nopunct": 19.318181818181817,
        "std_pred_length-nopunct": 8.535414798656475,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.6470588235294118,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 7.4423118440073495,
        "distinct-2-nopunct": 0.9404466501240695,
        "vocab_size-2-nopunct": 379,
        "unique-2-nopunct": 365,
        "entropy-2-nopunct": 8.503222753072256,
        "cond_entropy-2-nopunct": 1.1199014689003495,
        "distinct-3-nopunct": 0.9921259842519685,
        "vocab_size-3-nopunct": 378,
        "unique-3-nopunct": 375,
        "entropy-3-nopunct": 8.557899155997289,
        "cond_entropy-3-nopunct": 0.06079475478859296,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.7675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.023333333333333334,
            "2": 0.1694915254237288,
            "3": 0.4375,
            "4": 0.4897959183673469,
            "5": 0.7027027027027027,
            "6": 0.7575757575757576,
            "7": 0.8869047619047619
        },
        "rouge1": {
            "precision": 0.87165,
            "recall": 0.79096,
            "fmeasure": 0.81786
        },
        "rouge2": {
            "precision": 0.7198,
            "recall": 0.6524,
            "fmeasure": 0.67375
        },
        "rougeL": {
            "precision": 0.84138,
            "recall": 0.76401,
            "fmeasure": 0.78828
        },
        "rougeLsum": {
            "precision": 0.84138,
            "recall": 0.76401,
            "fmeasure": 0.78828
        },
        "nist": 8.269032135732028,
        "bleu": 70.39037,
        "bertscore": {
            "precision": 0.96449,
            "recall": 0.948,
            "f1": 0.95421
        },
        "bleurt": 0.25993,
        "meteor": 0.45367347851608675,
        "nubia": {
            "semantic_relation": 4.34048,
            "contradiction": 2.37417,
            "irrelevancy": 13.48394,
            "logical_agreement": 84.14189,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.90802,
            "nubia_score": 0.714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6538461538461539
        },
        "rouge1": {
            "precision": 0.65934,
            "recall": 0.59188,
            "fmeasure": 0.58139
        },
        "rouge2": {
            "precision": 0.34936,
            "recall": 0.22845,
            "fmeasure": 0.26228
        },
        "rougeL": {
            "precision": 0.39103,
            "recall": 0.33045,
            "fmeasure": 0.33856
        },
        "rougeLsum": {
            "precision": 0.39103,
            "recall": 0.33045,
            "fmeasure": 0.33856
        },
        "nist": 2.642289227746607,
        "bleu": 10.56893,
        "bertscore": {
            "precision": 0.86871,
            "recall": 0.83969,
            "f1": 0.85292
        },
        "bleurt": -0.41265,
        "meteor": 0.23964213363247153,
        "nubia": {
            "semantic_relation": 3.59957,
            "contradiction": 26.72664,
            "irrelevancy": 4.20185,
            "logical_agreement": 69.0715,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.89433,
            "nubia_score": 0.4759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "rouge2": {
            "precision": 0.69744,
            "recall": 0.71717,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.80952,
            "fmeasure": 0.79487
        },
        "nist": 2.9569851344298357,
        "bleu": 50.958,
        "bertscore": {
            "precision": 0.94859,
            "recall": 0.96733,
            "f1": 0.95776
        },
        "bleurt": 0.33075,
        "meteor": 0.4758660771722904,
        "nubia": {
            "semantic_relation": 4.48213,
            "contradiction": 9.42646,
            "irrelevancy": 27.55344,
            "logical_agreement": 63.0201,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.57373,
            "nubia_score": 0.70952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.11396,
            "fmeasure": 0.16587
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "nist": 0.07475536180041005,
        "bleu": 16.05295,
        "bertscore": {
            "precision": 0.84317,
            "recall": 0.79349,
            "f1": 0.81758
        },
        "bleurt": -0.24864,
        "meteor": 0.1639346022909572,
        "nubia": {
            "semantic_relation": 3.11978,
            "contradiction": 6.30794,
            "irrelevancy": 35.87276,
            "logical_agreement": 57.8193,
            "grammar_ref": 3.10421,
            "grammar_hyp": 3.53142,
            "nubia_score": 0.40227
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.90556,
            "recall": 0.75377,
            "fmeasure": 0.80547
        },
        "rouge2": {
            "precision": 0.7478,
            "recall": 0.65741,
            "fmeasure": 0.68617
        },
        "rougeL": {
            "precision": 0.90556,
            "recall": 0.75377,
            "fmeasure": 0.80547
        },
        "rougeLsum": {
            "precision": 0.90556,
            "recall": 0.75377,
            "fmeasure": 0.80547
        },
        "nist": 2.875991786272648,
        "bleu": 55.41954,
        "bertscore": {
            "precision": 0.97451,
            "recall": 0.91806,
            "f1": 0.94352
        },
        "bleurt": 0.46082,
        "meteor": 0.46532944583414726,
        "nubia": {
            "semantic_relation": 4.15752,
            "contradiction": 28.49057,
            "irrelevancy": 17.26285,
            "logical_agreement": 54.24659,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.50246,
            "nubia_score": 0.70191
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.899494936611665,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 52,
        "unique-1": 45,
        "entropy-1": 5.627642470572459,
        "distinct-2": 0.9824561403508771,
        "vocab_size-2": 56,
        "unique-2": 55,
        "entropy-2": 5.797802294866491,
        "cond_entropy-2": 0.10143801504745138,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.04096547496423607,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 8.956685895029603,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.599541531706474,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.053695389231817145,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.044913547495271544,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.3333333333333333,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.8571428571428571,
            "7": 0.8571428571428571
        },
        "rouge1": {
            "precision": 0.8331,
            "recall": 0.80055,
            "fmeasure": 0.81115
        },
        "rouge2": {
            "precision": 0.59894,
            "recall": 0.57633,
            "fmeasure": 0.58275
        },
        "rougeL": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "rougeLsum": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "nist": 6.327833642685851,
        "bleu": 70.55887,
        "bertscore": {
            "precision": 0.94924,
            "recall": 0.95155,
            "f1": 0.9493
        },
        "bleurt": 0.43745,
        "meteor": 0.5290492207149786,
        "nubia": {
            "semantic_relation": 4.78249,
            "contradiction": 0.25737,
            "irrelevancy": 17.8741,
            "logical_agreement": 81.86853,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.98523,
            "nubia_score": 0.83997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.67143,
            "recall": 0.65556,
            "fmeasure": 0.66239
        },
        "rouge2": {
            "precision": 0.35185,
            "recall": 0.35185,
            "fmeasure": 0.35185
        },
        "rougeL": {
            "precision": 0.57619,
            "recall": 0.6,
            "fmeasure": 0.58718
        },
        "rougeLsum": {
            "precision": 0.57619,
            "recall": 0.6,
            "fmeasure": 0.58718
        },
        "nist": 3.5276406501426507,
        "bleu": 48.89521,
        "bertscore": {
            "precision": 0.90063,
            "recall": 0.92891,
            "f1": 0.9143
        },
        "bleurt": 0.21895,
        "meteor": 0.3720769783955144,
        "nubia": {
            "semantic_relation": 4.02496,
            "contradiction": 0.17867,
            "irrelevancy": 49.7445,
            "logical_agreement": 50.07683,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.93357,
            "nubia_score": 0.67361
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.81818,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.91667,
            "fmeasure": 0.95652
        },
        "nist": 3.569636662899469,
        "bleu": 76.11606,
        "bertscore": {
            "precision": 0.98695,
            "recall": 0.95995,
            "f1": 0.97326
        },
        "bleurt": 0.7596,
        "meteor": 0.5398895612015752,
        "nubia": {
            "semantic_relation": 4.77808,
            "contradiction": 0.93501,
            "irrelevancy": 0.60596,
            "logical_agreement": 98.45902,
            "grammar_ref": 5.00662,
            "grammar_hyp": 4.79063,
            "nubia_score": 0.88767
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "nist": 2.964645514318526,
        "bleu": 57.8357,
        "bertscore": {
            "precision": 0.97662,
            "recall": 0.96725,
            "f1": 0.97191
        },
        "bleurt": 0.28191,
        "meteor": 0.6047441855848348,
        "nubia": {
            "semantic_relation": 4.49578,
            "contradiction": 18.9933,
            "irrelevancy": 67.98386,
            "logical_agreement": 13.02284,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.59002,
            "nubia_score": 0.57415
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "total_length": 765,
        "mean_pred_length": 25.5,
        "std_pred_length": 12.2494897852931,
        "median_pred_length": 20.5,
        "min_pred_length": 10,
        "max_pred_length": 62,
        "distinct-1": 0.5228758169934641,
        "vocab_size-1": 400,
        "unique-1": 315,
        "entropy-1": 7.7479141345779245,
        "distinct-2": 0.9006802721088435,
        "vocab_size-2": 662,
        "unique-2": 612,
        "entropy-2": 9.292119772376397,
        "cond_entropy-2": 1.411305187257646,
        "distinct-3": 0.9687943262411347,
        "vocab_size-3": 683,
        "unique-3": 665,
        "entropy-3": 9.39478505011075,
        "cond_entropy-3": 0.11243041251525808,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 22.5,
        "std_pred_length-nopunct": 10.388294694831615,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.5792592592592593,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 314,
        "entropy-1-nopunct": 7.874035481019702,
        "distinct-2-nopunct": 0.9162790697674419,
        "vocab_size-2-nopunct": 591,
        "unique-2-nopunct": 551,
        "entropy-2-nopunct": 9.142622244900435,
        "cond_entropy-2-nopunct": 1.322829180664331,
        "distinct-3-nopunct": 0.9821138211382113,
        "vocab_size-3-nopunct": 604,
        "unique-3-nopunct": 593,
        "entropy-3-nopunct": 9.22867024250305,
        "cond_entropy-3-nopunct": 0.09209026290717393,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.75333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05429864253393665,
            "2": 0.18518518518518517,
            "3": 0.423728813559322,
            "4": 0.5362318840579711,
            "5": 0.6847826086956522,
            "6": 0.7922077922077922,
            "7": 0.8995433789954338
        },
        "rouge1": {
            "precision": 0.75599,
            "recall": 0.77808,
            "fmeasure": 0.75742
        },
        "rouge2": {
            "precision": 0.57802,
            "recall": 0.59968,
            "fmeasure": 0.57963
        },
        "rougeL": {
            "precision": 0.71497,
            "recall": 0.73316,
            "fmeasure": 0.71247
        },
        "rougeLsum": {
            "precision": 0.71497,
            "recall": 0.73316,
            "fmeasure": 0.71247
        },
        "nist": 8.365439137970823,
        "bleu": 61.35146,
        "bertscore": {
            "precision": 0.9339,
            "recall": 0.94248,
            "f1": 0.93509
        },
        "bleurt": 0.06242,
        "meteor": 0.46005160231837183,
        "nubia": {
            "semantic_relation": 4.28546,
            "contradiction": 3.15926,
            "irrelevancy": 20.06134,
            "logical_agreement": 76.7794,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.03198,
            "nubia_score": 0.65937
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.57937,
            "fmeasure": 0.56863
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.45833,
            "fmeasure": 0.44103
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.57937,
            "fmeasure": 0.56863
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.57937,
            "fmeasure": 0.56863
        },
        "nist": 2.4272557548496665,
        "bleu": 46.7138,
        "bertscore": {
            "precision": 0.91659,
            "recall": 0.92966,
            "f1": 0.9217
        },
        "bleurt": 0.38136,
        "meteor": 0.37610533299556836,
        "nubia": {
            "semantic_relation": 3.51769,
            "contradiction": 0.7037,
            "irrelevancy": 19.85994,
            "logical_agreement": 79.43636,
            "grammar_ref": 4.8549,
            "grammar_hyp": 5.62849,
            "nubia_score": 0.44528
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "total_length": 201,
        "mean_pred_length": 22.333333333333332,
        "std_pred_length": 8.192137151629671,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 40,
        "distinct-1": 0.6965174129353234,
        "vocab_size-1": 140,
        "unique-1": 117,
        "entropy-1": 6.709676706566791,
        "distinct-2": 0.953125,
        "vocab_size-2": 183,
        "unique-2": 178,
        "entropy-2": 7.462515755906976,
        "cond_entropy-2": 0.6289208845225606,
        "distinct-3": 0.9890710382513661,
        "vocab_size-3": 181,
        "unique-3": 179,
        "entropy-3": 7.493841914786769,
        "cond_entropy-3": 0.037348129936257246,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 19.22222222222222,
        "std_pred_length-nopunct": 5.995883361436463,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.7630057803468208,
        "vocab_size-1-nopunct": 132,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.713893852526548,
        "distinct-2-nopunct": 0.9634146341463414,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.250785083860014,
        "cond_entropy-2-nopunct": 0.5764437275285154,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 155,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.276124405274258,
        "cond_entropy-3-nopunct": 0.031538691006649994,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.81,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.07407407407407407,
            "2": 0.22727272727272727,
            "3": 0.0,
            "4": 0.9,
            "5": 0.5294117647058824,
            "6": 0.74,
            "7": 0.8412698412698413
        },
        "rouge1": {
            "precision": 0.80462,
            "recall": 0.78547,
            "fmeasure": 0.79143
        },
        "rouge2": {
            "precision": 0.63544,
            "recall": 0.61539,
            "fmeasure": 0.6222
        },
        "rougeL": {
            "precision": 0.76395,
            "recall": 0.71813,
            "fmeasure": 0.73556
        },
        "rougeLsum": {
            "precision": 0.76395,
            "recall": 0.71813,
            "fmeasure": 0.73556
        },
        "nist": 7.326651764849715,
        "bleu": 62.87757,
        "bertscore": {
            "precision": 0.93708,
            "recall": 0.92899,
            "f1": 0.93206
        },
        "bleurt": 0.0814,
        "meteor": 0.44203006012912716,
        "nubia": {
            "semantic_relation": 4.08437,
            "contradiction": 6.73853,
            "irrelevancy": 25.37322,
            "logical_agreement": 67.88825,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.13832,
            "nubia_score": 0.58441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.88889,
            "fmeasure": 0.90196
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.79167,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.85185,
            "fmeasure": 0.86275
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.85185,
            "fmeasure": 0.86275
        },
        "nist": 4.617410631462493,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.35519,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 3.54948,
            "contradiction": 0.43167,
            "irrelevancy": 0.73861,
            "logical_agreement": 98.82972,
            "grammar_ref": 3.66596,
            "grammar_hyp": 3.31211,
            "nubia_score": 0.68428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.125,
            "3": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.44444,
            "fmeasure": 0.42963
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.35714,
            "fmeasure": 0.33696
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.44444,
            "fmeasure": 0.42963
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.44444,
            "fmeasure": 0.42963
        },
        "nist": 1.6154680464647335,
        "bleu": 25.96536,
        "bertscore": {
            "precision": 0.80571,
            "recall": 0.7973,
            "f1": 0.79207
        },
        "bleurt": -0.85761,
        "meteor": 0.2621499443403637,
        "nubia": {
            "semantic_relation": 3.22927,
            "contradiction": 0.48824,
            "irrelevancy": 99.43876,
            "logical_agreement": 0.073,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.78298,
            "nubia_score": 0.27567
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.2631578947368421
        },
        "rouge1": {
            "precision": 0.45556,
            "recall": 0.41431,
            "fmeasure": 0.43333
        },
        "rouge2": {
            "precision": 0.11806,
            "recall": 0.10867,
            "fmeasure": 0.11303
        },
        "rougeL": {
            "precision": 0.42222,
            "recall": 0.39158,
            "fmeasure": 0.40591
        },
        "rougeLsum": {
            "precision": 0.42222,
            "recall": 0.39158,
            "fmeasure": 0.40591
        },
        "nist": 1.2128570606312317,
        "bleu": 5.53755,
        "bertscore": {
            "precision": 0.84046,
            "recall": 0.81423,
            "f1": 0.82431
        },
        "bleurt": -0.11363,
        "meteor": 0.1649666917604969,
        "nubia": {
            "semantic_relation": 3.75177,
            "contradiction": 0.56736,
            "irrelevancy": 72.15236,
            "logical_agreement": 27.28029,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.83591,
            "nubia_score": 0.56249
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "total_length": 1610,
        "mean_pred_length": 25.555555555555557,
        "std_pred_length": 8.874392941952898,
        "median_pred_length": 25.0,
        "min_pred_length": 7,
        "max_pred_length": 52,
        "distinct-1": 0.4745341614906832,
        "vocab_size-1": 764,
        "unique-1": 600,
        "entropy-1": 8.314270596663302,
        "distinct-2": 0.9120879120879121,
        "vocab_size-2": 1411,
        "unique-2": 1336,
        "entropy-2": 10.363740739322912,
        "cond_entropy-2": 1.8934422891487057,
        "distinct-3": 0.9838274932614556,
        "vocab_size-3": 1460,
        "unique-3": 1450,
        "entropy-3": 10.486044480376867,
        "cond_entropy-3": 0.12943686420361827,
        "total_length-nopunct": 1443,
        "mean_pred_length-nopunct": 22.904761904761905,
        "std_pred_length-nopunct": 8.029141933071422,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.5239085239085239,
        "vocab_size-1-nopunct": 756,
        "unique-1-nopunct": 599,
        "entropy-1-nopunct": 8.510495193927671,
        "distinct-2-nopunct": 0.9355072463768116,
        "vocab_size-2-nopunct": 1291,
        "unique-2-nopunct": 1230,
        "entropy-2-nopunct": 10.277511500922005,
        "cond_entropy-2-nopunct": 1.8360483979183948,
        "distinct-3-nopunct": 0.996962794229309,
        "vocab_size-3-nopunct": 1313,
        "unique-3-nopunct": 1309,
        "entropy-3-nopunct": 10.356965218715096,
        "cond_entropy-3-nopunct": 0.08404773730415059,
        "msttr-100": 0.75375,
        "msttr-100_nopunct": 0.77857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04628736740597879,
            "2": 0.19254658385093168,
            "3": 0.3829787234042553,
            "4": 0.5970149253731343,
            "5": 0.6901960784313725,
            "6": 0.7304785894206549,
            "7": 0.8452830188679246
        },
        "rouge1": {
            "precision": 0.8189,
            "recall": 0.77169,
            "fmeasure": 0.78054
        },
        "rouge2": {
            "precision": 0.6743,
            "recall": 0.6445,
            "fmeasure": 0.64597
        },
        "rougeL": {
            "precision": 0.78967,
            "recall": 0.75034,
            "fmeasure": 0.75671
        },
        "rougeLsum": {
            "precision": 0.78967,
            "recall": 0.75034,
            "fmeasure": 0.75671
        },
        "nist": 9.348790561046048,
        "bleu": 64.31126,
        "bertscore": {
            "precision": 0.94331,
            "recall": 0.93809,
            "f1": 0.93852
        },
        "bleurt": 0.09876,
        "meteor": 0.44741969043328444,
        "nubia": {
            "semantic_relation": 4.18895,
            "contradiction": 4.39617,
            "irrelevancy": 19.7717,
            "logical_agreement": 75.83213,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.85295,
            "nubia_score": 0.65243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5
        },
        "rouge1": {
            "precision": 0.37037,
            "recall": 0.51184,
            "fmeasure": 0.42969
        },
        "rouge2": {
            "precision": 0.21154,
            "recall": 0.29678,
            "fmeasure": 0.24697
        },
        "rougeL": {
            "precision": 0.31481,
            "recall": 0.43553,
            "fmeasure": 0.3654
        },
        "rougeLsum": {
            "precision": 0.31481,
            "recall": 0.43553,
            "fmeasure": 0.3654
        },
        "nist": 2.0169911970292462,
        "bleu": 13.34819,
        "bertscore": {
            "precision": 0.83685,
            "recall": 0.83228,
            "f1": 0.83456
        },
        "bleurt": -0.23782,
        "meteor": 0.22174334761344436,
        "nubia": {
            "semantic_relation": 3.10596,
            "contradiction": 32.14577,
            "irrelevancy": 51.66598,
            "logical_agreement": 16.18825,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.84208,
            "nubia_score": 0.40824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.36508,
            "fmeasure": 0.4381
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.1,
            "fmeasure": 0.12121
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.2162,
            "fmeasure": 0.268
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.2162,
            "fmeasure": 0.268
        },
        "nist": 0.8745211491328357,
        "bleu": 4.87182,
        "bertscore": {
            "precision": 0.88185,
            "recall": 0.80506,
            "f1": 0.84171
        },
        "bleurt": 0.00121,
        "meteor": 0.24334640930677373,
        "nubia": {
            "semantic_relation": 3.05343,
            "contradiction": 70.62109,
            "irrelevancy": 4.05112,
            "logical_agreement": 25.32779,
            "grammar_ref": 3.9898,
            "grammar_hyp": 5.80176,
            "nubia_score": 0.2195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.83217,
            "fmeasure": 0.8313
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.76667,
            "fmeasure": 0.76812
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83217,
            "fmeasure": 0.8313
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83217,
            "fmeasure": 0.8313
        },
        "nist": 3.672921561006742,
        "bleu": 68.12455,
        "bertscore": {
            "precision": 0.95726,
            "recall": 0.94223,
            "f1": 0.94969
        },
        "bleurt": 0.41612,
        "meteor": 0.4670651175479345,
        "nubia": {
            "semantic_relation": 3.50181,
            "contradiction": 2.48731,
            "irrelevancy": 69.24068,
            "logical_agreement": 28.27201,
            "grammar_ref": 4.75081,
            "grammar_hyp": 4.51955,
            "nubia_score": 0.49099
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.6875,
            "fmeasure": 0.57895
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.35714,
            "fmeasure": 0.29412
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.5625,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.5625,
            "fmeasure": 0.47368
        },
        "nist": 3.0065062218468457,
        "bleu": 23.46235,
        "bertscore": {
            "precision": 0.80683,
            "recall": 0.81938,
            "f1": 0.81028
        },
        "bleurt": -0.2642,
        "meteor": 0.3764062053032062,
        "nubia": {
            "semantic_relation": 3.5179,
            "contradiction": 7.93775,
            "irrelevancy": 91.42523,
            "logical_agreement": 0.63702,
            "grammar_ref": 5.57872,
            "grammar_hyp": 4.97008,
            "nubia_score": 0.42929
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "nist": 1.6042028126043453,
        "bleu": 15.6197,
        "bertscore": {
            "precision": 0.89356,
            "recall": 0.89135,
            "f1": 0.89245
        },
        "bleurt": 0.62629,
        "meteor": 0.29493026749867945,
        "nubia": {
            "semantic_relation": 4.74574,
            "contradiction": 0.29988,
            "irrelevancy": 0.49995,
            "logical_agreement": 99.20017,
            "grammar_ref": 5.72796,
            "grammar_hyp": 5.20023,
            "nubia_score": 0.96448
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "rouge1": {
            "precision": 0.66071,
            "recall": 0.4475,
            "fmeasure": 0.53139
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.28739,
            "fmeasure": 0.34987
        },
        "rougeL": {
            "precision": 0.66071,
            "recall": 0.4475,
            "fmeasure": 0.53139
        },
        "rougeLsum": {
            "precision": 0.66071,
            "recall": 0.4475,
            "fmeasure": 0.53139
        },
        "nist": 1.8827187314102658,
        "bleu": 20.25819,
        "bertscore": {
            "precision": 0.9531,
            "recall": 0.89752,
            "f1": 0.92445
        },
        "bleurt": 0.35753,
        "meteor": 0.27984061994431575,
        "nubia": {
            "semantic_relation": 3.88769,
            "contradiction": 2.90846,
            "irrelevancy": 1.52464,
            "logical_agreement": 95.5669,
            "grammar_ref": 5.01983,
            "grammar_hyp": 5.73095,
            "nubia_score": 0.53229
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "rouge1": {
            "precision": 0.56061,
            "recall": 0.51333,
            "fmeasure": 0.53546
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.20238,
            "fmeasure": 0.21164
        },
        "rougeL": {
            "precision": 0.31818,
            "recall": 0.30545,
            "fmeasure": 0.31141
        },
        "rougeLsum": {
            "precision": 0.31818,
            "recall": 0.30545,
            "fmeasure": 0.31141
        },
        "nist": 2.9886438648932097,
        "bleu": 13.70615,
        "bertscore": {
            "precision": 0.86714,
            "recall": 0.83601,
            "f1": 0.85129
        },
        "bleurt": -0.41338,
        "meteor": 0.23881186244051472,
        "nubia": {
            "semantic_relation": 3.53662,
            "contradiction": 0.14783,
            "irrelevancy": 99.44887,
            "logical_agreement": 0.4033,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.532,
            "nubia_score": 0.53537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.45455,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "nist": 2.580147666815989,
        "bleu": 23.68477,
        "bertscore": {
            "precision": 0.88184,
            "recall": 0.8798,
            "f1": 0.88082
        },
        "bleurt": -0.13252,
        "meteor": 0.43230651302778406,
        "nubia": {
            "semantic_relation": 4.39217,
            "contradiction": 7.85986,
            "irrelevancy": 66.09843,
            "logical_agreement": 26.04171,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.62726,
            "nubia_score": 0.70296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.0,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 1.00232,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55079,
            "irrelevancy": 0.53693,
            "logical_agreement": 98.91228,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.38626,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "rouge1": {
            "precision": 0.28571,
            "recall": 0.28356,
            "fmeasure": 0.28355
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07639,
            "fmeasure": 0.07632
        },
        "rougeL": {
            "precision": 0.2619,
            "recall": 0.23379,
            "fmeasure": 0.24612
        },
        "rougeLsum": {
            "precision": 0.2619,
            "recall": 0.23379,
            "fmeasure": 0.24612
        },
        "nist": 1.2896535733446404,
        "bleu": 6.60897,
        "bertscore": {
            "precision": 0.67318,
            "recall": 0.65047,
            "f1": 0.66163
        },
        "bleurt": -0.56245,
        "meteor": 0.12298666213114799,
        "nubia": {
            "semantic_relation": 1.19878,
            "contradiction": 33.61452,
            "irrelevancy": 65.59581,
            "logical_agreement": 0.78967,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.88775,
            "nubia_score": 0.09475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.63492,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.37778,
            "fmeasure": 0.42963
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.63492,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.63492,
            "fmeasure": 0.70707
        },
        "nist": 0.536327470964314,
        "bleu": 34.9833,
        "bertscore": {
            "precision": 0.91138,
            "recall": 0.90356,
            "f1": 0.90637
        },
        "bleurt": -0.31885,
        "meteor": 0.30718306239377846,
        "nubia": {
            "semantic_relation": 3.26556,
            "contradiction": 3.03512,
            "irrelevancy": 7.26103,
            "logical_agreement": 89.70385,
            "grammar_ref": 6.44614,
            "grammar_hyp": 6.34756,
            "nubia_score": 0.50743
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.4666666666666667
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.4537,
            "fmeasure": 0.44649
        },
        "rouge2": {
            "precision": 0.15833,
            "recall": 0.15278,
            "fmeasure": 0.15468
        },
        "rougeL": {
            "precision": 0.41414,
            "recall": 0.41667,
            "fmeasure": 0.41316
        },
        "rougeLsum": {
            "precision": 0.41414,
            "recall": 0.41667,
            "fmeasure": 0.41316
        },
        "nist": 1.8187340152989975,
        "bleu": 9.32047,
        "bertscore": {
            "precision": 0.84747,
            "recall": 0.82864,
            "f1": 0.83736
        },
        "bleurt": 0.06955,
        "meteor": 0.2293784692423471,
        "nubia": {
            "semantic_relation": 3.71629,
            "contradiction": 0.69883,
            "irrelevancy": 90.0706,
            "logical_agreement": 9.23057,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.79508,
            "nubia_score": 0.56138
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.62794,
            "recall": 0.62135,
            "fmeasure": 0.62281
        },
        "rouge2": {
            "precision": 0.35033,
            "recall": 0.3415,
            "fmeasure": 0.34477
        },
        "rougeL": {
            "precision": 0.40588,
            "recall": 0.40643,
            "fmeasure": 0.40497
        },
        "rougeLsum": {
            "precision": 0.40588,
            "recall": 0.40643,
            "fmeasure": 0.40497
        },
        "nist": 3.235730948431282,
        "bleu": 14.49208,
        "bertscore": {
            "precision": 0.9132,
            "recall": 0.90669,
            "f1": 0.90765
        },
        "bleurt": 0.34522,
        "meteor": 0.3698340284595038,
        "nubia": {
            "semantic_relation": 4.79072,
            "contradiction": 0.19504,
            "irrelevancy": 0.55116,
            "logical_agreement": 99.2538,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.24285,
            "nubia_score": 0.91111
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "mT5_small/totto_test",
        "N": 136,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24155844155844156,
            "2": 0.42857142857142855,
            "3": 0.7794836008374041
        },
        "rouge1": {
            "precision": 0.75025,
            "recall": 0.73467,
            "fmeasure": 0.73301
        },
        "rouge2": {
            "precision": 0.53138,
            "recall": 0.51463,
            "fmeasure": 0.51652
        },
        "rougeL": {
            "precision": 0.64831,
            "recall": 0.63593,
            "fmeasure": 0.63408
        },
        "rougeLsum": {
            "precision": 0.64831,
            "recall": 0.63593,
            "fmeasure": 0.63408
        },
        "nist": 7.632758412309822,
        "bleu": 50.34652,
        "bertscore": {
            "precision": 0.9272,
            "recall": 0.92613,
            "f1": 0.92551
        },
        "bleurt": 0.34462,
        "meteor": 0.4002629030300856,
        "nubia": {
            "semantic_relation": 4.17075,
            "contradiction": 12.87462,
            "irrelevancy": 22.89016,
            "logical_agreement": 64.23523,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.46286,
            "nubia_score": 0.73091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.75556,
            "fmeasure": 0.64957
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.55556,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.75556,
            "fmeasure": 0.64957
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.75556,
            "fmeasure": 0.64957
        },
        "nist": 1.6144014220307388,
        "bleu": 33.64932,
        "bertscore": {
            "precision": 0.87555,
            "recall": 0.92431,
            "f1": 0.89927
        },
        "bleurt": 0.23922,
        "meteor": 0.32967443976899663,
        "nubia": {
            "semantic_relation": 4.36221,
            "contradiction": 0.36008,
            "irrelevancy": 54.69292,
            "logical_agreement": 44.94699,
            "grammar_ref": 5.64952,
            "grammar_hyp": 3.96765,
            "nubia_score": 0.81012
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.44118,
            "recall": 0.5,
            "fmeasure": 0.46875
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.14286,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.26471,
            "recall": 0.3,
            "fmeasure": 0.28125
        },
        "rougeLsum": {
            "precision": 0.26471,
            "recall": 0.3,
            "fmeasure": 0.28125
        },
        "nist": 1.85752914130123,
        "bleu": 7.01289,
        "bertscore": {
            "precision": 0.82985,
            "recall": 0.86918,
            "f1": 0.84906
        },
        "bleurt": -0.79136,
        "meteor": 0.2630681275344912,
        "nubia": {
            "semantic_relation": 2.54662,
            "contradiction": 46.06952,
            "irrelevancy": 50.18437,
            "logical_agreement": 3.74611,
            "grammar_ref": 5.62728,
            "grammar_hyp": 5.55178,
            "nubia_score": 0.25317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.44444,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.25,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.44444,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.44444,
            "fmeasure": 0.57143
        },
        "nist": 0.3940620620260747,
        "bleu": 19.76561,
        "bertscore": {
            "precision": 0.9345,
            "recall": 0.873,
            "f1": 0.90271
        },
        "bleurt": 0.07282,
        "meteor": 0.27552206048367417,
        "nubia": {
            "semantic_relation": 3.87829,
            "contradiction": 2.47406,
            "irrelevancy": 1.14062,
            "logical_agreement": 96.38532,
            "grammar_ref": 5.69157,
            "grammar_hyp": 6.34386,
            "nubia_score": 0.56397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.867976246918685,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.73788,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.8,
            "recall": 0.47059,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21635,
            "fmeasure": 0.26182
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.41176,
            "fmeasure": 0.51852
        },
        "nist": 1.5281491968761907,
        "bleu": 14.12462,
        "bertscore": {
            "precision": 0.93123,
            "recall": 0.8708,
            "f1": 0.90001
        },
        "bleurt": 0.23563,
        "meteor": 0.2578583744841909,
        "nubia": {
            "semantic_relation": 3.71643,
            "contradiction": 0.39981,
            "irrelevancy": 0.6312,
            "logical_agreement": 98.96899,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.11109,
            "nubia_score": 0.55064
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.875,
            "fmeasure": 0.90476
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92593,
            "fmeasure": 0.95833
        },
        "nist": 3.1597204709350555,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.78666,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.52884,
            "irrelevancy": 0.52708,
            "logical_agreement": 98.94409,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.1854,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9285714285714286
        },
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.875,
            "fmeasure": 0.875
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "nist": 3.98560840909984,
        "bleu": 84.82199,
        "bertscore": {
            "precision": 0.99772,
            "recall": 0.99772,
            "f1": 0.99772
        },
        "bleurt": 0.80156,
        "meteor": 0.5810381480283553,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30685,
            "irrelevancy": 0.82197,
            "logical_agreement": 98.87118,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.64355,
            "nubia_score": 0.99307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.8
        },
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.91667,
            "fmeasure": 0.88462
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55,
            "fmeasure": 0.52273
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.69048,
            "fmeasure": 0.66484
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.69048,
            "fmeasure": 0.66484
        },
        "nist": 3.058235669889711,
        "bleu": 33.43702,
        "bertscore": {
            "precision": 0.93707,
            "recall": 0.93707,
            "f1": 0.93707
        },
        "bleurt": 0.60401,
        "meteor": 0.4235753564860309,
        "nubia": {
            "semantic_relation": 4.93243,
            "contradiction": 0.6056,
            "irrelevancy": 1.19093,
            "logical_agreement": 98.20347,
            "grammar_ref": 7.77345,
            "grammar_hyp": 8.03859,
            "nubia_score": 0.92812
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "nist": 2.966193015531081,
        "bleu": 72.92572,
        "bertscore": {
            "precision": 0.92453,
            "recall": 0.96298,
            "f1": 0.94336
        },
        "bleurt": 0.47074,
        "meteor": 0.5638904804662692,
        "nubia": {
            "semantic_relation": 4.41566,
            "contradiction": 0.40909,
            "irrelevancy": 93.28802,
            "logical_agreement": 6.30289,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.43146,
            "nubia_score": 0.88872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 0.5641,
            "recall": 0.65744,
            "fmeasure": 0.60714
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.23449,
            "fmeasure": 0.21585
        },
        "rougeL": {
            "precision": 0.37179,
            "recall": 0.43347,
            "fmeasure": 0.40023
        },
        "rougeLsum": {
            "precision": 0.37179,
            "recall": 0.43347,
            "fmeasure": 0.40023
        },
        "nist": 2.473077167519552,
        "bleu": 12.74081,
        "bertscore": {
            "precision": 0.8946,
            "recall": 0.90308,
            "f1": 0.89866
        },
        "bleurt": 0.13174,
        "meteor": 0.3096879137760216,
        "nubia": {
            "semantic_relation": 3.9946,
            "contradiction": 91.19733,
            "irrelevancy": 4.24966,
            "logical_agreement": 4.553,
            "grammar_ref": 3.13705,
            "grammar_hyp": 2.86856,
            "nubia_score": 0.79153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.35714285714285715,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.625,
            "recall": 0.40278,
            "fmeasure": 0.46218
        },
        "rouge2": {
            "precision": 0.37879,
            "recall": 0.19821,
            "fmeasure": 0.24382
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.39141,
            "fmeasure": 0.4495
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.39141,
            "fmeasure": 0.4495
        },
        "nist": 1.6909189255391401,
        "bleu": 10.43197,
        "bertscore": {
            "precision": 0.81374,
            "recall": 0.80429,
            "f1": 0.80567
        },
        "bleurt": -0.33401,
        "meteor": 0.2595527136161712,
        "nubia": {
            "semantic_relation": 3.60754,
            "contradiction": 9.04262,
            "irrelevancy": 34.97896,
            "logical_agreement": 55.97842,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.79246,
            "nubia_score": 0.51524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.58285,
            "fmeasure": 0.57183
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.77632,
            "fmeasure": 0.76282
        },
        "nist": 3.555099738276094,
        "bleu": 50.32882,
        "bertscore": {
            "precision": 0.96154,
            "recall": 0.96287,
            "f1": 0.9622
        },
        "bleurt": 0.6451,
        "meteor": 0.4546337124532775,
        "nubia": {
            "semantic_relation": 4.73231,
            "contradiction": 0.85937,
            "irrelevancy": 6.02969,
            "logical_agreement": 93.11094,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.43816,
            "nubia_score": 0.88032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "rouge1": {
            "precision": 0.375,
            "recall": 0.40909,
            "fmeasure": 0.3913
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.40909,
            "fmeasure": 0.3913
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.40909,
            "fmeasure": 0.3913
        },
        "nist": 1.6545980772559188,
        "bleu": 13.67441,
        "bertscore": {
            "precision": 0.80171,
            "recall": 0.79293,
            "f1": 0.79715
        },
        "bleurt": -0.89099,
        "meteor": 0.2201406296585065,
        "nubia": {
            "semantic_relation": 2.36282,
            "contradiction": 3.85085,
            "irrelevancy": 95.90411,
            "logical_agreement": 0.24504,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.34318,
            "nubia_score": 0.21369
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.72024,
            "recall": 0.45758,
            "fmeasure": 0.55853
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.27892,
            "fmeasure": 0.34444
        },
        "rougeL": {
            "precision": 0.6994,
            "recall": 0.44567,
            "fmeasure": 0.54337
        },
        "rougeLsum": {
            "precision": 0.6994,
            "recall": 0.44567,
            "fmeasure": 0.54337
        },
        "nist": 0.6046333344341738,
        "bleu": 17.12743,
        "bertscore": {
            "precision": 0.91338,
            "recall": 0.8368,
            "f1": 0.87238
        },
        "bleurt": 0.1202,
        "meteor": 0.2129679819489162,
        "nubia": {
            "semantic_relation": 3.54862,
            "contradiction": 35.60614,
            "irrelevancy": 31.18416,
            "logical_agreement": 33.2097,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.23953,
            "nubia_score": 0.4517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5454545454545454
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.46154,
            "fmeasure": 0.57143
        },
        "nist": 1.0159330244017084,
        "bleu": 13.39235,
        "bertscore": {
            "precision": 0.94408,
            "recall": 0.87436,
            "f1": 0.90788
        },
        "bleurt": 0.6125,
        "meteor": 0.29856988218120256,
        "nubia": {
            "semantic_relation": 4.93676,
            "contradiction": 8.10139,
            "irrelevancy": 1.95092,
            "logical_agreement": 89.94769,
            "grammar_ref": 3.94537,
            "grammar_hyp": 5.30195,
            "nubia_score": 0.80508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.60349,
            "fmeasure": 0.67339
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.27941,
            "fmeasure": 0.31418
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.32026,
            "fmeasure": 0.35753
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.32026,
            "fmeasure": 0.35753
        },
        "nist": 2.8284405826589563,
        "bleu": 20.85308,
        "bertscore": {
            "precision": 0.93445,
            "recall": 0.90216,
            "f1": 0.91802
        },
        "bleurt": 0.34908,
        "meteor": 0.28122388781948054,
        "nubia": {
            "semantic_relation": 4.09843,
            "contradiction": 96.84318,
            "irrelevancy": 1.61759,
            "logical_agreement": 1.53923,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.85196,
            "nubia_score": 0.59561
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "nist": 3.0088906840841796,
        "bleu": 58.33511,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "bleurt": 0.7528,
        "meteor": 0.4630505936482093,
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "nist": 2.2971962674448263,
        "bleu": 43.44371,
        "bertscore": {
            "precision": 0.90271,
            "recall": 0.8999,
            "f1": 0.9013
        },
        "bleurt": -0.19018,
        "meteor": 0.3893256160366625,
        "nubia": {
            "semantic_relation": 4.64052,
            "contradiction": 9.57268,
            "irrelevancy": 3.00448,
            "logical_agreement": 87.42284,
            "grammar_ref": 5.78237,
            "grammar_hyp": 6.30508,
            "nubia_score": 0.74142
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.87879,
            "fmeasure": 0.87464
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "nist": 4.184371848752004,
        "bleu": 100.0,
        "bertscore": {
            "precision": 0.97217,
            "recall": 0.98387,
            "f1": 0.97798
        },
        "bleurt": 0.35883,
        "meteor": 0.5991546711750068,
        "nubia": {
            "semantic_relation": 4.24308,
            "contradiction": 0.41029,
            "irrelevancy": 0.58691,
            "logical_agreement": 99.0028,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.95367,
            "nubia_score": 0.84362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.4375,
            "recall": 0.64133,
            "fmeasure": 0.50667
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.30556,
            "fmeasure": 0.23452
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.54971,
            "fmeasure": 0.43429
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.54971,
            "fmeasure": 0.43429
        },
        "nist": 2.002788887615936,
        "bleu": 10.41946,
        "bertscore": {
            "precision": 0.86462,
            "recall": 0.94246,
            "f1": 0.90186
        },
        "bleurt": 0.15186,
        "meteor": 0.4205723059373273,
        "nubia": {
            "semantic_relation": 4.28975,
            "contradiction": 94.77009,
            "irrelevancy": 4.91613,
            "logical_agreement": 0.31378,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.89269,
            "nubia_score": 0.71986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.5,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.5,
            "fmeasure": 0.51613
        },
        "nist": 3.5331108505684883,
        "bleu": 31.4154,
        "bertscore": {
            "precision": 0.94799,
            "recall": 0.93,
            "f1": 0.93891
        },
        "bleurt": 0.36339,
        "meteor": 0.4298498808481145,
        "nubia": {
            "semantic_relation": 4.74937,
            "contradiction": 0.2125,
            "irrelevancy": 33.54292,
            "logical_agreement": 66.24459,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.30333,
            "nubia_score": 0.78827
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "nist": 1.7348945401754292,
        "bleu": 20.87318,
        "bertscore": {
            "precision": 0.92746,
            "recall": 0.89328,
            "f1": 0.91005
        },
        "bleurt": 0.10409,
        "meteor": 0.29203590581911826,
        "nubia": {
            "semantic_relation": 4.40487,
            "contradiction": 1.02546,
            "irrelevancy": 0.78996,
            "logical_agreement": 98.18459,
            "grammar_ref": 5.85687,
            "grammar_hyp": 8.15675,
            "nubia_score": 0.56355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.8465578035643277,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.87565,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "rouge1": {
            "precision": 0.65152,
            "recall": 0.38876,
            "fmeasure": 0.4856
        },
        "rouge2": {
            "precision": 0.29293,
            "recall": 0.16608,
            "fmeasure": 0.21144
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.27458,
            "fmeasure": 0.34158
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.27458,
            "fmeasure": 0.34158
        },
        "nist": 0.6553494295056045,
        "bleu": 4.30271,
        "bertscore": {
            "precision": 0.88119,
            "recall": 0.83601,
            "f1": 0.85331
        },
        "bleurt": -0.1444,
        "meteor": 0.1676186572167593,
        "nubia": {
            "semantic_relation": 3.08175,
            "contradiction": 4.88763,
            "irrelevancy": 3.25742,
            "logical_agreement": 91.85495,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.73813,
            "nubia_score": 0.41377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.66138,
            "fmeasure": 0.73504
        },
        "rouge2": {
            "precision": 0.57576,
            "recall": 0.40271,
            "fmeasure": 0.47222
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.5037,
            "fmeasure": 0.62462
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.5037,
            "fmeasure": 0.62462
        },
        "nist": 2.0538826775862336,
        "bleu": 37.86812,
        "bertscore": {
            "precision": 0.94813,
            "recall": 0.88169,
            "f1": 0.9137
        },
        "bleurt": -0.04081,
        "meteor": 0.3393125630794211,
        "nubia": {
            "semantic_relation": 3.43694,
            "contradiction": 0.50575,
            "irrelevancy": 0.90767,
            "logical_agreement": 98.58658,
            "grammar_ref": 3.09217,
            "grammar_hyp": 3.13321,
            "nubia_score": 0.663
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.41071,
            "fmeasure": 0.41905
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.76852,
            "fmeasure": 0.79902
        },
        "nist": 3.505055873841853,
        "bleu": 35.45321,
        "bertscore": {
            "precision": 0.96744,
            "recall": 0.94435,
            "f1": 0.95576
        },
        "bleurt": 0.36391,
        "meteor": 0.3918255395834617,
        "nubia": {
            "semantic_relation": 4.53494,
            "contradiction": 5.98845,
            "irrelevancy": 9.34576,
            "logical_agreement": 84.66578,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.56428,
            "nubia_score": 0.59475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2,
            "3": 0.8
        },
        "rouge1": {
            "precision": 0.48485,
            "recall": 0.51587,
            "fmeasure": 0.49982
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25877,
            "fmeasure": 0.23874
        },
        "rougeL": {
            "precision": 0.30303,
            "recall": 0.35098,
            "fmeasure": 0.32479
        },
        "rougeLsum": {
            "precision": 0.30303,
            "recall": 0.35098,
            "fmeasure": 0.32479
        },
        "nist": 3.22542101766702,
        "bleu": 25.57907,
        "bertscore": {
            "precision": 0.86368,
            "recall": 0.87657,
            "f1": 0.86969
        },
        "bleurt": -0.13369,
        "meteor": 0.29091772433603025,
        "nubia": {
            "semantic_relation": 3.16694,
            "contradiction": 4.47903,
            "irrelevancy": 71.97077,
            "logical_agreement": 23.5502,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.83902,
            "nubia_score": 0.47589
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_small/totto_test",
        "N": 898,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2326416600159617,
            "2": 0.5063965884861408,
            "3": 0.7333086739411874
        },
        "rouge1": {
            "precision": 0.74386,
            "recall": 0.70079,
            "fmeasure": 0.70396
        },
        "rouge2": {
            "precision": 0.54372,
            "recall": 0.51365,
            "fmeasure": 0.51524
        },
        "rougeL": {
            "precision": 0.70276,
            "recall": 0.66563,
            "fmeasure": 0.66727
        },
        "rougeLsum": {
            "precision": 0.70276,
            "recall": 0.66563,
            "fmeasure": 0.66727
        },
        "nist": 8.444920815709562,
        "bleu": 47.54853,
        "bertscore": {
            "precision": 0.92901,
            "recall": 0.91973,
            "f1": 0.92281
        },
        "bleurt": 0.28152,
        "meteor": 0.39128305289925086,
        "nubia": {
            "semantic_relation": 4.02577,
            "contradiction": 10.17503,
            "irrelevancy": 30.0067,
            "logical_agreement": 59.81827,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.17743,
            "nubia_score": 0.68005
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.625
        },
        "rouge1": {
            "precision": 0.49333,
            "recall": 0.64141,
            "fmeasure": 0.55649
        },
        "rouge2": {
            "precision": 0.23611,
            "recall": 0.31466,
            "fmeasure": 0.2692
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.52189,
            "fmeasure": 0.45192
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.52189,
            "fmeasure": 0.45192
        },
        "nist": 2.8089738063885212,
        "bleu": 16.61866,
        "bertscore": {
            "precision": 0.90031,
            "recall": 0.89601,
            "f1": 0.89701
        },
        "bleurt": -0.24221,
        "meteor": 0.2597957719311204,
        "nubia": {
            "semantic_relation": 3.39582,
            "contradiction": 67.48683,
            "irrelevancy": 30.46117,
            "logical_agreement": 2.052,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.4522,
            "nubia_score": 0.44127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5555555555555556
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.54444,
            "fmeasure": 0.70335
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.39827,
            "fmeasure": 0.52549
        },
        "rougeL": {
            "precision": 0.95238,
            "recall": 0.52222,
            "fmeasure": 0.67305
        },
        "rougeLsum": {
            "precision": 0.95238,
            "recall": 0.52222,
            "fmeasure": 0.67305
        },
        "nist": 0.565379981524113,
        "bleu": 29.10832,
        "bertscore": {
            "precision": 0.93467,
            "recall": 0.82773,
            "f1": 0.87796
        },
        "bleurt": -0.02769,
        "meteor": 0.3283230031227706,
        "nubia": {
            "semantic_relation": 3.65986,
            "contradiction": 0.79405,
            "irrelevancy": 0.70526,
            "logical_agreement": 98.50069,
            "grammar_ref": 4.47457,
            "grammar_hyp": 6.12039,
            "nubia_score": 0.43812
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.5098,
            "fmeasure": 0.5977
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.35417,
            "fmeasure": 0.41975
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.39216,
            "fmeasure": 0.45977
        },
        "nist": 1.8200785863811701,
        "bleu": 30.25543,
        "bertscore": {
            "precision": 0.93948,
            "recall": 0.91825,
            "f1": 0.92848
        },
        "bleurt": 0.42762,
        "meteor": 0.29563020110735383,
        "nubia": {
            "semantic_relation": 4.14143,
            "contradiction": 8.46344,
            "irrelevancy": 14.96147,
            "logical_agreement": 76.57509,
            "grammar_ref": 3.28677,
            "grammar_hyp": 5.09187,
            "nubia_score": 0.55245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35294,
            "fmeasure": 0.41379
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.25,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "nist": 1.2518755231080134,
        "bleu": 19.82688,
        "bertscore": {
            "precision": 0.87412,
            "recall": 0.78643,
            "f1": 0.82796
        },
        "bleurt": -0.2294,
        "meteor": 0.22195679961878512,
        "nubia": {
            "semantic_relation": 2.37725,
            "contradiction": 70.67274,
            "irrelevancy": 28.59182,
            "logical_agreement": 0.73544,
            "grammar_ref": 4.28272,
            "grammar_hyp": 3.88229,
            "nubia_score": 0.19987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.47368421052631576,
            "3": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.62135,
            "recall": 0.5947,
            "fmeasure": 0.6059
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.3848,
            "fmeasure": 0.39855
        },
        "rougeL": {
            "precision": 0.56871,
            "recall": 0.53914,
            "fmeasure": 0.55185
        },
        "rougeLsum": {
            "precision": 0.56871,
            "recall": 0.53914,
            "fmeasure": 0.55185
        },
        "nist": 3.1243857427091917,
        "bleu": 31.39265,
        "bertscore": {
            "precision": 0.89956,
            "recall": 0.8976,
            "f1": 0.89851
        },
        "bleurt": 0.1606,
        "meteor": 0.30930395110263403,
        "nubia": {
            "semantic_relation": 4.05449,
            "contradiction": 33.29919,
            "irrelevancy": 23.98994,
            "logical_agreement": 42.71087,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.65827,
            "nubia_score": 0.61389
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "total_length": 3009,
        "mean_pred_length": 18.126506024096386,
        "std_pred_length": 7.557149082158146,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4443336656696577,
        "vocab_size-1": 1337,
        "unique-1": 1046,
        "entropy-1": 8.599009029452578,
        "distinct-2": 0.862469222652128,
        "vocab_size-2": 2452,
        "unique-2": 2308,
        "entropy-2": 11.012332562641825,
        "cond_entropy-2": 2.1489522475925877,
        "distinct-3": 0.9656331714605902,
        "vocab_size-3": 2585,
        "unique-3": 2539,
        "entropy-3": 11.291594024421833,
        "cond_entropy-3": 0.2942555590203698,
        "total_length-nopunct": 2638,
        "mean_pred_length-nopunct": 15.891566265060241,
        "std_pred_length-nopunct": 6.493763547950701,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5034116755117514,
        "vocab_size-1-nopunct": 1328,
        "unique-1-nopunct": 1046,
        "entropy-1-nopunct": 8.90997836144087,
        "distinct-2-nopunct": 0.8814724919093851,
        "vocab_size-2-nopunct": 2179,
        "unique-2-nopunct": 2069,
        "entropy-2-nopunct": 10.868189742420004,
        "cond_entropy-2-nopunct": 2.0914565694764398,
        "distinct-3-nopunct": 0.9809193408499567,
        "vocab_size-3-nopunct": 2262,
        "unique-3-nopunct": 2232,
        "entropy-3-nopunct": 11.12821988090212,
        "cond_entropy-3-nopunct": 0.2796261826660963,
        "msttr-100": 0.711,
        "msttr-100_nopunct": 0.75692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.032035485460818136,
            "2": 0.15770609318996415,
            "3": 0.40569395017793597,
            "4": 0.5879828326180258,
            "5": 0.7188940092165899,
            "6": 0.8446969696969697,
            "7": 0.9084507042253521,
            "8": 0.9389067524115756,
            "9": 0.9494949494949495,
            "10": 0.9917491749174917
        },
        "rouge1": {
            "precision": 0.89557,
            "recall": 0.92114,
            "fmeasure": 0.90385
        },
        "rouge2": {
            "precision": 0.80069,
            "recall": 0.83859,
            "fmeasure": 0.81349
        },
        "rougeL": {
            "precision": 0.88412,
            "recall": 0.9088,
            "fmeasure": 0.89203
        },
        "rougeLsum": {
            "precision": 0.88412,
            "recall": 0.9088,
            "fmeasure": 0.89203
        },
        "nist": 12.28088611061854,
        "bleu": 88.3401,
        "bertscore": {
            "precision": 0.97511,
            "recall": 0.9809,
            "f1": 0.97503
        },
        "bleurt": 0.36705,
        "meteor": 0.5564059612260167,
        "nubia": {
            "semantic_relation": 4.44542,
            "contradiction": 2.96142,
            "irrelevancy": 30.56664,
            "logical_agreement": 66.47194,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.80703,
            "nubia_score": 0.72513
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.48148,
            "fmeasure": 0.48148
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "nist": 2.638831505321384,
        "bleu": 37.06866,
        "bertscore": {
            "precision": 0.94558,
            "recall": 0.96722,
            "f1": 0.95628
        },
        "bleurt": -0.10894,
        "meteor": 0.44902503618506967,
        "nubia": {
            "semantic_relation": 4.58092,
            "contradiction": 7.04595,
            "irrelevancy": 11.07823,
            "logical_agreement": 81.87583,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.05686,
            "nubia_score": 0.73966
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "total_length": 1325,
        "mean_pred_length": 22.844827586206897,
        "std_pred_length": 8.347623498560639,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 43,
        "distinct-1": 0.5033962264150943,
        "vocab_size-1": 667,
        "unique-1": 538,
        "entropy-1": 8.133356800292473,
        "distinct-2": 0.920284135753749,
        "vocab_size-2": 1166,
        "unique-2": 1115,
        "entropy-2": 10.091692655306453,
        "cond_entropy-2": 1.7882371691042864,
        "distinct-3": 0.9867659222497932,
        "vocab_size-3": 1193,
        "unique-3": 1181,
        "entropy-3": 10.209821854311361,
        "cond_entropy-3": 0.1284678862853231,
        "total_length-nopunct": 1183,
        "mean_pred_length-nopunct": 20.396551724137932,
        "std_pred_length-nopunct": 7.542842360013516,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5562130177514792,
        "vocab_size-1-nopunct": 658,
        "unique-1-nopunct": 536,
        "entropy-1-nopunct": 8.324312779226847,
        "distinct-2-nopunct": 0.9351111111111111,
        "vocab_size-2-nopunct": 1052,
        "unique-2-nopunct": 1010,
        "entropy-2-nopunct": 9.970002939059952,
        "cond_entropy-2-nopunct": 1.7339278945785959,
        "distinct-3-nopunct": 0.9925023430178069,
        "vocab_size-3-nopunct": 1059,
        "unique-3-nopunct": 1051,
        "entropy-3-nopunct": 10.044349146860052,
        "cond_entropy-3-nopunct": 0.0833536755868592,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03829787234042553,
            "2": 0.19767441860465115,
            "3": 0.39072847682119205,
            "4": 0.5818181818181818,
            "5": 0.762962962962963,
            "6": 0.8653846153846154,
            "7": 0.9385964912280702,
            "8": 0.9659863945578231,
            "9": 0.9803921568627451,
            "10": 0.9812206572769953
        },
        "rouge1": {
            "precision": 0.90585,
            "recall": 0.92591,
            "fmeasure": 0.91293
        },
        "rouge2": {
            "precision": 0.81484,
            "recall": 0.83573,
            "fmeasure": 0.82065
        },
        "rougeL": {
            "precision": 0.89804,
            "recall": 0.91642,
            "fmeasure": 0.90392
        },
        "rougeLsum": {
            "precision": 0.89804,
            "recall": 0.91642,
            "fmeasure": 0.90392
        },
        "nist": 11.50299569537447,
        "bleu": 89.21588,
        "bertscore": {
            "precision": 0.97289,
            "recall": 0.97917,
            "f1": 0.97508
        },
        "bleurt": 0.30365,
        "meteor": 0.5584050472115804,
        "nubia": {
            "semantic_relation": 4.39667,
            "contradiction": 2.56957,
            "irrelevancy": 31.32887,
            "logical_agreement": 66.10156,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.66164,
            "nubia_score": 0.70673
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "total_length": 716,
        "mean_pred_length": 22.375,
        "std_pred_length": 8.256626126935869,
        "median_pred_length": 20.5,
        "min_pred_length": 10,
        "max_pred_length": 40,
        "distinct-1": 0.5418994413407822,
        "vocab_size-1": 388,
        "unique-1": 307,
        "entropy-1": 7.6568455536980915,
        "distinct-2": 0.9035087719298246,
        "vocab_size-2": 618,
        "unique-2": 579,
        "entropy-2": 9.181283015575788,
        "cond_entropy-2": 1.3699432961054745,
        "distinct-3": 0.9754601226993865,
        "vocab_size-3": 636,
        "unique-3": 624,
        "entropy-3": 9.295017187959996,
        "cond_entropy-3": 0.12381120302535249,
        "total_length-nopunct": 633,
        "mean_pred_length-nopunct": 19.78125,
        "std_pred_length-nopunct": 7.074312577028245,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.6003159557661928,
        "vocab_size-1-nopunct": 380,
        "unique-1-nopunct": 306,
        "entropy-1-nopunct": 7.809227702297373,
        "distinct-2-nopunct": 0.9201331114808652,
        "vocab_size-2-nopunct": 553,
        "unique-2-nopunct": 525,
        "entropy-2-nopunct": 9.031488901148345,
        "cond_entropy-2-nopunct": 1.2833739485792792,
        "distinct-3-nopunct": 0.984182776801406,
        "vocab_size-3-nopunct": 560,
        "unique-3-nopunct": 552,
        "entropy-3-nopunct": 9.119323704341568,
        "cond_entropy-3-nopunct": 0.09731008077842579,
        "msttr-100": 0.70143,
        "msttr-100_nopunct": 0.74333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.030800821355236138,
            "2": 0.22429906542056074,
            "3": 0.352112676056338,
            "4": 0.671875,
            "5": 0.7818181818181819,
            "6": 0.8970588235294118,
            "7": 0.9090909090909091,
            "8": 0.9523809523809523,
            "9": 0.9761904761904762,
            "10": 0.9758064516129032
        },
        "rouge1": {
            "precision": 0.9132,
            "recall": 0.92011,
            "fmeasure": 0.91065
        },
        "rouge2": {
            "precision": 0.81843,
            "recall": 0.82405,
            "fmeasure": 0.81486
        },
        "rougeL": {
            "precision": 0.89725,
            "recall": 0.89876,
            "fmeasure": 0.89193
        },
        "rougeLsum": {
            "precision": 0.89725,
            "recall": 0.89876,
            "fmeasure": 0.89193
        },
        "nist": 10.58497281120468,
        "bleu": 89.68873,
        "bertscore": {
            "precision": 0.97282,
            "recall": 0.97888,
            "f1": 0.97332
        },
        "bleurt": 0.30574,
        "meteor": 0.5478987842155322,
        "nubia": {
            "semantic_relation": 4.47213,
            "contradiction": 1.70122,
            "irrelevancy": 35.52548,
            "logical_agreement": 62.77331,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.53107,
            "nubia_score": 0.71866
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "total_length": 100,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.077444574328174,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.73,
        "vocab_size-1": 73,
        "unique-1": 59,
        "entropy-1": 5.92120956470983,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.5295767870076403,
        "distinct-3": 1.0,
        "vocab_size-3": 90,
        "unique-3": 90,
        "entropy-3": 6.491853096329662,
        "cond_entropy-3": -0.05578028977905097,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.883465457416738,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.5381835751275978,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.06246284125033935,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.06944444444444445,
            "2": 0.19047619047619047,
            "3": 0.375,
            "4": 0.8,
            "5": 0.5714285714285714,
            "6": 0.9230769230769231,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 0.9523809523809523
        },
        "rouge1": {
            "precision": 0.91628,
            "recall": 0.88644,
            "fmeasure": 0.89917
        },
        "rouge2": {
            "precision": 0.84142,
            "recall": 0.81355,
            "fmeasure": 0.82523
        },
        "rougeL": {
            "precision": 0.91462,
            "recall": 0.88777,
            "fmeasure": 0.89887
        },
        "rougeLsum": {
            "precision": 0.91462,
            "recall": 0.88777,
            "fmeasure": 0.89887
        },
        "nist": 7.387394098933786,
        "bleu": 79.94006,
        "bertscore": {
            "precision": 0.97636,
            "recall": 0.97764,
            "f1": 0.97515
        },
        "bleurt": 0.28754,
        "meteor": 0.5873570418510073,
        "nubia": {
            "semantic_relation": 4.30696,
            "contradiction": 0.2225,
            "irrelevancy": 36.29303,
            "logical_agreement": 63.48448,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.06985,
            "nubia_score": 0.64048
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.4
        },
        "rouge1": {
            "precision": 0.38779,
            "recall": 0.37991,
            "fmeasure": 0.37669
        },
        "rouge2": {
            "precision": 0.05556,
            "recall": 0.06881,
            "fmeasure": 0.06119
        },
        "rougeL": {
            "precision": 0.22486,
            "recall": 0.23247,
            "fmeasure": 0.22551
        },
        "rougeLsum": {
            "precision": 0.22486,
            "recall": 0.23247,
            "fmeasure": 0.22551
        },
        "nist": 1.646781380230191,
        "bleu": 3.79126,
        "bertscore": {
            "precision": 0.85004,
            "recall": 0.84333,
            "f1": 0.84415
        },
        "bleurt": -0.2211,
        "meteor": 0.21053225409055001,
        "nubia": {
            "semantic_relation": 3.53173,
            "contradiction": 31.33824,
            "irrelevancy": 49.61663,
            "logical_agreement": 19.04513,
            "grammar_ref": 4.73012,
            "grammar_hyp": 3.25202,
            "nubia_score": 0.66463
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "total_length": 707,
        "mean_pred_length": 25.25,
        "std_pred_length": 10.40132203135736,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 61,
        "distinct-1": 0.5643564356435643,
        "vocab_size-1": 399,
        "unique-1": 326,
        "entropy-1": 7.796512057379108,
        "distinct-2": 0.9160530191458026,
        "vocab_size-2": 622,
        "unique-2": 586,
        "entropy-2": 9.205205379154792,
        "cond_entropy-2": 1.2732235501073224,
        "distinct-3": 0.9769585253456221,
        "vocab_size-3": 636,
        "unique-3": 625,
        "entropy-3": 9.295792458190606,
        "cond_entropy-3": 0.0962057376880075,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 22.428571428571427,
        "std_pred_length-nopunct": 8.243736026430575,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.6226114649681529,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 325,
        "entropy-1-nopunct": 7.918355235541638,
        "distinct-2-nopunct": 0.935,
        "vocab_size-2-nopunct": 561,
        "unique-2-nopunct": 534,
        "entropy-2-nopunct": 9.073108820553864,
        "cond_entropy-2-nopunct": 1.207633717431853,
        "distinct-3-nopunct": 0.9947552447552448,
        "vocab_size-3-nopunct": 569,
        "unique-3-nopunct": 566,
        "entropy-3-nopunct": 9.149381826288932,
        "cond_entropy-3-nopunct": 0.08039866370422288,
        "msttr-100": 0.73857,
        "msttr-100_nopunct": 0.77,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.030828516377649325,
            "2": 0.1513157894736842,
            "3": 0.3815789473684211,
            "4": 0.6290322580645161,
            "5": 0.6935483870967742,
            "6": 0.8412698412698413,
            "7": 0.9259259259259259,
            "8": 0.9516129032258065,
            "9": 0.9818181818181818,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.90192,
            "recall": 0.90163,
            "fmeasure": 0.89889
        },
        "rouge2": {
            "precision": 0.8048,
            "recall": 0.82684,
            "fmeasure": 0.80817
        },
        "rougeL": {
            "precision": 0.89052,
            "recall": 0.89131,
            "fmeasure": 0.88663
        },
        "rougeLsum": {
            "precision": 0.89052,
            "recall": 0.89131,
            "fmeasure": 0.88663
        },
        "nist": 10.281240305051874,
        "bleu": 85.79686,
        "bertscore": {
            "precision": 0.97324,
            "recall": 0.97608,
            "f1": 0.97086
        },
        "bleurt": 0.21618,
        "meteor": 0.5483259055007753,
        "nubia": {
            "semantic_relation": 4.35215,
            "contradiction": 1.78183,
            "irrelevancy": 31.38879,
            "logical_agreement": 66.82937,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.84103,
            "nubia_score": 0.67022
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "total_length": 177,
        "mean_pred_length": 25.285714285714285,
        "std_pred_length": 5.8970764115857985,
        "median_pred_length": 26.0,
        "min_pred_length": 16,
        "max_pred_length": 37,
        "distinct-1": 0.711864406779661,
        "vocab_size-1": 126,
        "unique-1": 112,
        "entropy-1": 6.55690902849692,
        "distinct-2": 0.9588235294117647,
        "vocab_size-2": 163,
        "unique-2": 160,
        "entropy-2": 7.3013643009811995,
        "cond_entropy-2": 0.6663575736413744,
        "distinct-3": 1.0,
        "vocab_size-3": 163,
        "unique-3": 163,
        "entropy-3": 7.348728154231104,
        "cond_entropy-3": 0.03973309525043292,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 22.428571428571427,
        "std_pred_length-nopunct": 4.403152859263555,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7643312101910829,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.527599192282896,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.119721837318527,
        "cond_entropy-2-nopunct": 0.6279169843440561,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.159871336778397,
        "cond_entropy-3-nopunct": 0.04548990486013314,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.13636363636363635,
            "3": 0.6666666666666666,
            "4": 0.9166666666666666,
            "5": 0.9375,
            "6": 1.0,
            "7": 0.9333333333333333,
            "8": 0.96,
            "9": 1.0,
            "10": 1.0
        },
        "rouge1": {
            "precision": 0.90029,
            "recall": 0.93669,
            "fmeasure": 0.9161
        },
        "rouge2": {
            "precision": 0.82585,
            "recall": 0.87025,
            "fmeasure": 0.84483
        },
        "rougeL": {
            "precision": 0.88429,
            "recall": 0.93239,
            "fmeasure": 0.90648
        },
        "rougeLsum": {
            "precision": 0.88429,
            "recall": 0.93239,
            "fmeasure": 0.90648
        },
        "nist": 8.697797794633605,
        "bleu": 90.83084,
        "bertscore": {
            "precision": 0.98117,
            "recall": 0.98457,
            "f1": 0.98204
        },
        "bleurt": 0.30892,
        "meteor": 0.5675603785591405,
        "nubia": {
            "semantic_relation": 4.41903,
            "contradiction": 1.79989,
            "irrelevancy": 46.81649,
            "logical_agreement": 51.38362,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.53456,
            "nubia_score": 0.68224
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.60985,
            "fmeasure": 0.49138
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.38182,
            "fmeasure": 0.30199
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.60985,
            "fmeasure": 0.49138
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.60985,
            "fmeasure": 0.49138
        },
        "nist": 1.504087842848416,
        "bleu": 16.46703,
        "bertscore": {
            "precision": 0.85578,
            "recall": 0.90029,
            "f1": 0.87747
        },
        "bleurt": 0.24123,
        "meteor": 0.307214339231524,
        "nubia": {
            "semantic_relation": 4.71035,
            "contradiction": 0.32693,
            "irrelevancy": 8.85764,
            "logical_agreement": 90.81543,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.05968,
            "nubia_score": 0.87175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5384615384615384
        },
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.59074,
            "fmeasure": 0.67402
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.30857,
            "fmeasure": 0.36111
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.42963,
            "fmeasure": 0.4902
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.42963,
            "fmeasure": 0.4902
        },
        "nist": 1.8101521400462466,
        "bleu": 15.77755,
        "bertscore": {
            "precision": 0.9045,
            "recall": 0.8539,
            "f1": 0.87364
        },
        "bleurt": -0.1319,
        "meteor": 0.28143464487440667,
        "nubia": {
            "semantic_relation": 3.66751,
            "contradiction": 31.58767,
            "irrelevancy": 51.72853,
            "logical_agreement": 16.68379,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.86482,
            "nubia_score": 0.44529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8695652173913043
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "nist": 4.245299502237301,
        "bleu": 75.62326,
        "bertscore": {
            "precision": 0.98952,
            "recall": 0.93883,
            "f1": 0.96297
        },
        "bleurt": 0.54515,
        "meteor": 0.4485380253360393,
        "nubia": {
            "semantic_relation": 4.59825,
            "contradiction": 0.54689,
            "irrelevancy": 10.49459,
            "logical_agreement": 88.95852,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.17403,
            "nubia_score": 0.89531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "mT5_small/totto_test",
        "N": 111,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.42592592592592593,
            "3": 0.7581803671189146
        },
        "rouge1": {
            "precision": 0.77499,
            "recall": 0.72279,
            "fmeasure": 0.73565
        },
        "rouge2": {
            "precision": 0.54033,
            "recall": 0.4997,
            "fmeasure": 0.51131
        },
        "rougeL": {
            "precision": 0.67228,
            "recall": 0.62162,
            "fmeasure": 0.63487
        },
        "rougeLsum": {
            "precision": 0.67228,
            "recall": 0.62162,
            "fmeasure": 0.63487
        },
        "nist": 7.275528635178187,
        "bleu": 48.07774,
        "bertscore": {
            "precision": 0.934,
            "recall": 0.92257,
            "f1": 0.92662
        },
        "bleurt": 0.35509,
        "meteor": 0.390525940534493,
        "nubia": {
            "semantic_relation": 4.14467,
            "contradiction": 11.19169,
            "irrelevancy": 19.47275,
            "logical_agreement": 69.33556,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.58314,
            "nubia_score": 0.71159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666
        },
        "rouge1": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.33333,
            "fmeasure": 0.29524
        },
        "rougeL": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "rougeLsum": {
            "precision": 0.46429,
            "recall": 0.58547,
            "fmeasure": 0.51369
        },
        "nist": 2.3155368703474615,
        "bleu": 19.25161,
        "bertscore": {
            "precision": 0.86053,
            "recall": 0.87254,
            "f1": 0.85929
        },
        "bleurt": -0.09573,
        "meteor": 0.33575706334962574,
        "nubia": {
            "semantic_relation": 2.49374,
            "contradiction": 2.15752,
            "irrelevancy": 87.66731,
            "logical_agreement": 10.17517,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.41658,
            "nubia_score": 0.28689
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "mT5_small/totto_test",
        "N": 3,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7222222222222222
        },
        "rouge1": {
            "precision": 0.96667,
            "recall": 0.75152,
            "fmeasure": 0.82917
        },
        "rouge2": {
            "precision": 0.83951,
            "recall": 0.67964,
            "fmeasure": 0.73862
        },
        "rougeL": {
            "precision": 0.95556,
            "recall": 0.74646,
            "fmeasure": 0.82222
        },
        "rougeLsum": {
            "precision": 0.95556,
            "recall": 0.74646,
            "fmeasure": 0.82222
        },
        "nist": 3.138578884670237,
        "bleu": 52.11695,
        "bertscore": {
            "precision": 0.9789,
            "recall": 0.92873,
            "f1": 0.9526
        },
        "bleurt": 0.71342,
        "meteor": 0.4116799659062523,
        "nubia": {
            "semantic_relation": 4.88205,
            "contradiction": 0.40904,
            "irrelevancy": 0.52872,
            "logical_agreement": 99.06224,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.44813,
            "nubia_score": 0.94973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.16111,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.38182,
            "fmeasure": 0.41053
        },
        "nist": 1.724828456273269,
        "bleu": 11.35509,
        "bertscore": {
            "precision": 0.89773,
            "recall": 0.87974,
            "f1": 0.88864
        },
        "bleurt": 0.31472,
        "meteor": 0.23647970285015268,
        "nubia": {
            "semantic_relation": 3.19379,
            "contradiction": 77.42395,
            "irrelevancy": 15.57207,
            "logical_agreement": 7.00397,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.40419,
            "nubia_score": 0.28775
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.6923076923076923
        },
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.63971,
            "fmeasure": 0.47744
        },
        "rouge2": {
            "precision": 0.14815,
            "recall": 0.26111,
            "fmeasure": 0.189
        },
        "rougeL": {
            "precision": 0.30952,
            "recall": 0.53186,
            "fmeasure": 0.39125
        },
        "rougeLsum": {
            "precision": 0.30952,
            "recall": 0.53186,
            "fmeasure": 0.39125
        },
        "nist": 2.096907725024201,
        "bleu": 11.8119,
        "bertscore": {
            "precision": 0.85161,
            "recall": 0.9082,
            "f1": 0.87899
        },
        "bleurt": 0.19131,
        "meteor": 0.32483940263294403,
        "nubia": {
            "semantic_relation": 3.96758,
            "contradiction": 1.35603,
            "irrelevancy": 10.97905,
            "logical_agreement": 87.66492,
            "grammar_ref": 5.85115,
            "grammar_hyp": 3.92644,
            "nubia_score": 0.74016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "rouge1": {
            "precision": 0.61243,
            "recall": 0.75777,
            "fmeasure": 0.67382
        },
        "rouge2": {
            "precision": 0.3997,
            "recall": 0.51313,
            "fmeasure": 0.44481
        },
        "rougeL": {
            "precision": 0.53836,
            "recall": 0.65054,
            "fmeasure": 0.58631
        },
        "rougeLsum": {
            "precision": 0.53836,
            "recall": 0.65054,
            "fmeasure": 0.58631
        },
        "nist": 2.940595708293018,
        "bleu": 28.08338,
        "bertscore": {
            "precision": 0.84232,
            "recall": 0.92609,
            "f1": 0.88017
        },
        "bleurt": -0.38309,
        "meteor": 0.3695804929284428,
        "nubia": {
            "semantic_relation": 3.69801,
            "contradiction": 10.80568,
            "irrelevancy": 61.45637,
            "logical_agreement": 27.73794,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.38715,
            "nubia_score": 0.559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.38461538461538464
        },
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.37778,
            "fmeasure": 0.48148
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.06845,
            "fmeasure": 0.08838
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.2366,
            "fmeasure": 0.29915
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.2366,
            "fmeasure": 0.29915
        },
        "nist": 0.4762470591647922,
        "bleu": 5.70018,
        "bertscore": {
            "precision": 0.85744,
            "recall": 0.80622,
            "f1": 0.83104
        },
        "bleurt": -0.55451,
        "meteor": 0.19623811843923974,
        "nubia": {
            "semantic_relation": 3.60486,
            "contradiction": 5.83196,
            "irrelevancy": 55.85216,
            "logical_agreement": 38.31588,
            "grammar_ref": 4.4151,
            "grammar_hyp": 6.75603,
            "nubia_score": 0.27259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72418,
            "fmeasure": 0.80934
        },
        "rouge2": {
            "precision": 0.87179,
            "recall": 0.65273,
            "fmeasure": 0.71636
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.6281,
            "fmeasure": 0.67677
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.6281,
            "fmeasure": 0.67677
        },
        "nist": 2.992841091596299,
        "bleu": 52.83097,
        "bertscore": {
            "precision": 0.94366,
            "recall": 0.88947,
            "f1": 0.9148
        },
        "bleurt": 0.19466,
        "meteor": 0.4017810134021416,
        "nubia": {
            "semantic_relation": 4.29435,
            "contradiction": 23.98727,
            "irrelevancy": 5.33443,
            "logical_agreement": 70.6783,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.68972,
            "nubia_score": 0.65632
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "mT5_small/totto_test",
        "N": 48,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5,
            "3": 0.7948717948717948
        },
        "rouge1": {
            "precision": 0.79719,
            "recall": 0.76274,
            "fmeasure": 0.76873
        },
        "rouge2": {
            "precision": 0.61008,
            "recall": 0.58608,
            "fmeasure": 0.58886
        },
        "rougeL": {
            "precision": 0.73272,
            "recall": 0.69995,
            "fmeasure": 0.70635
        },
        "rougeLsum": {
            "precision": 0.73272,
            "recall": 0.69995,
            "fmeasure": 0.70635
        },
        "nist": 6.829421965661466,
        "bleu": 58.2636,
        "bertscore": {
            "precision": 0.94548,
            "recall": 0.9362,
            "f1": 0.93943
        },
        "bleurt": 0.53632,
        "meteor": 0.4236370609475593,
        "nubia": {
            "semantic_relation": 4.32835,
            "contradiction": 8.40734,
            "irrelevancy": 11.49622,
            "logical_agreement": 80.09644,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.14786,
            "nubia_score": 0.80231
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.76923,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57071
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.64957,
            "fmeasure": 0.73504
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.64957,
            "fmeasure": 0.73504
        },
        "nist": 3.6468094959587605,
        "bleu": 48.48701,
        "bertscore": {
            "precision": 0.97128,
            "recall": 0.95234,
            "f1": 0.96172
        },
        "bleurt": 0.53921,
        "meteor": 0.3983240151613566,
        "nubia": {
            "semantic_relation": 4.96091,
            "contradiction": 0.26575,
            "irrelevancy": 0.50296,
            "logical_agreement": 99.2313,
            "grammar_ref": 4.20051,
            "grammar_hyp": 5.03598,
            "nubia_score": 0.91551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80556,
            "fmeasure": 0.86141
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71667,
            "fmeasure": 0.76741
        },
        "rougeL": {
            "precision": 0.84444,
            "recall": 0.74206,
            "fmeasure": 0.78734
        },
        "rougeLsum": {
            "precision": 0.84444,
            "recall": 0.74206,
            "fmeasure": 0.78734
        },
        "nist": 3.9366334271941397,
        "bleu": 73.24968,
        "bertscore": {
            "precision": 0.98713,
            "recall": 0.97764,
            "f1": 0.98236
        },
        "bleurt": 0.3119,
        "meteor": 0.557874933754587,
        "nubia": {
            "semantic_relation": 4.16035,
            "contradiction": 0.16955,
            "irrelevancy": 33.52328,
            "logical_agreement": 66.30717,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.90891,
            "nubia_score": 0.77555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "rouge1": {
            "precision": 0.8375,
            "recall": 0.54398,
            "fmeasure": 0.64782
        },
        "rouge2": {
            "precision": 0.53968,
            "recall": 0.34557,
            "fmeasure": 0.41288
        },
        "rougeL": {
            "precision": 0.8375,
            "recall": 0.54398,
            "fmeasure": 0.64782
        },
        "rougeLsum": {
            "precision": 0.8375,
            "recall": 0.54398,
            "fmeasure": 0.64782
        },
        "nist": 1.1777806418573156,
        "bleu": 12.26069,
        "bertscore": {
            "precision": 0.93949,
            "recall": 0.87707,
            "f1": 0.90639
        },
        "bleurt": 0.4296,
        "meteor": 0.34511039936573235,
        "nubia": {
            "semantic_relation": 4.24429,
            "contradiction": 0.62807,
            "irrelevancy": 1.47692,
            "logical_agreement": 97.89501,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.50459,
            "nubia_score": 0.76202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.375
        },
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.43519,
            "fmeasure": 0.47584
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.15761,
            "fmeasure": 0.18571
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.4537,
            "fmeasure": 0.41114
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.4537,
            "fmeasure": 0.41114
        },
        "nist": 2.661459212789743,
        "bleu": 29.49071,
        "bertscore": {
            "precision": 0.90103,
            "recall": 0.89888,
            "f1": 0.85428
        },
        "bleurt": -0.07627,
        "meteor": 0.26278544300644907,
        "nubia": {
            "semantic_relation": 3.70028,
            "contradiction": 0.13955,
            "irrelevancy": 94.49347,
            "logical_agreement": 5.36698,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.80507,
            "nubia_score": 0.53769
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "nist": 4.451815875634701,
        "bleu": 69.05636,
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        },
        "bleurt": 0.78257,
        "meteor": 0.9489775258149422,
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.75
        },
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.89167,
            "fmeasure": 0.81704
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.68519,
            "fmeasure": 0.61623
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88571,
            "fmeasure": 0.79365
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88571,
            "fmeasure": 0.79365
        },
        "nist": 2.7247919309938924,
        "bleu": 31.70233,
        "bertscore": {
            "precision": 0.9795,
            "recall": 0.94676,
            "f1": 0.96285
        },
        "bleurt": 0.50277,
        "meteor": 0.4857690665088045,
        "nubia": {
            "semantic_relation": 4.83055,
            "contradiction": 0.99743,
            "irrelevancy": 53.17975,
            "logical_agreement": 45.82282,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.83718,
            "nubia_score": 0.98917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7142857142857143
        },
        "rouge1": {
            "precision": 0.75,
            "recall": 0.60606,
            "fmeasure": 0.66873
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.275,
            "fmeasure": 0.3098
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.51515,
            "fmeasure": 0.56347
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.51515,
            "fmeasure": 0.56347
        },
        "nist": 2.518434426223242,
        "bleu": 21.72186,
        "bertscore": {
            "precision": 0.88159,
            "recall": 0.84955,
            "f1": 0.86527
        },
        "bleurt": 0.42705,
        "meteor": 0.3307172749040934,
        "nubia": {
            "semantic_relation": 4.38127,
            "contradiction": 0.22773,
            "irrelevancy": 0.66301,
            "logical_agreement": 99.10926,
            "grammar_ref": 5.60099,
            "grammar_hyp": 6.24211,
            "nubia_score": 0.71579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.80855,
            "fmeasure": 0.85827
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.88988,
            "fmeasure": 0.94083
        },
        "nist": 4.0182899183808685,
        "bleu": 81.96501,
        "bertscore": {
            "precision": 0.99739,
            "recall": 0.98801,
            "f1": 0.99268
        },
        "bleurt": 0.72022,
        "meteor": 0.5534770148308852,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.48733,
            "irrelevancy": 0.52385,
            "logical_agreement": 98.98882,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.64499,
            "nubia_score": 0.95124
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.8963,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.49537,
            "fmeasure": 0.51716
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "nist": 3.7456398254417365,
        "bleu": 55.62833,
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95351,
            "f1": 0.963
        },
        "bleurt": 0.70029,
        "meteor": 0.46736318340128513,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18796,
            "irrelevancy": 0.48475,
            "logical_agreement": 99.32729,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.58474,
            "nubia_score": 0.95724
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79365,
            "fmeasure": 0.76863
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "nist": 2.763324482612094,
        "bleu": 59.69492,
        "bertscore": {
            "precision": 0.96429,
            "recall": 0.97126,
            "f1": 0.96429
        },
        "bleurt": 0.64829,
        "meteor": 0.902035682675735,
        "nubia": {
            "semantic_relation": 4.92238,
            "contradiction": 0.17593,
            "irrelevancy": 35.19794,
            "logical_agreement": 64.62613,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.71883,
            "nubia_score": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "rouge1": {
            "precision": 0.4,
            "recall": 0.5303,
            "fmeasure": 0.45584
        },
        "rouge2": {
            "precision": 0.21429,
            "recall": 0.29091,
            "fmeasure": 0.24667
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.5303,
            "fmeasure": 0.45584
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.5303,
            "fmeasure": 0.45584
        },
        "nist": 0.853759374819711,
        "bleu": 5.81664,
        "bertscore": {
            "precision": 0.78111,
            "recall": 0.84069,
            "f1": 0.80981
        },
        "bleurt": -0.31999,
        "meteor": 0.27541743040561756,
        "nubia": {
            "semantic_relation": 2.96828,
            "contradiction": 6.81595,
            "irrelevancy": 92.40988,
            "logical_agreement": 0.77417,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.52648,
            "nubia_score": 0.43493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.2857142857142857,
            "3": 0.7
        },
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.63333,
            "fmeasure": 0.62424
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.37473,
            "fmeasure": 0.3619
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.52963,
            "fmeasure": 0.51919
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.52963,
            "fmeasure": 0.51919
        },
        "nist": 2.3877730929972563,
        "bleu": 26.13023,
        "bertscore": {
            "precision": 0.93193,
            "recall": 0.91617,
            "f1": 0.92399
        },
        "bleurt": 0.3774,
        "meteor": 0.36616925205340173,
        "nubia": {
            "semantic_relation": 4.49676,
            "contradiction": 0.1704,
            "irrelevancy": 1.06342,
            "logical_agreement": 98.76618,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.80124,
            "nubia_score": 0.874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "mT5_small/totto_test",
        "N": 123,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22614840989399293,
            "2": 0.3712374581939799,
            "3": 0.7575057736720554
        },
        "rouge1": {
            "precision": 0.74585,
            "recall": 0.72736,
            "fmeasure": 0.72421
        },
        "rouge2": {
            "precision": 0.52692,
            "recall": 0.51174,
            "fmeasure": 0.511
        },
        "rougeL": {
            "precision": 0.6502,
            "recall": 0.63182,
            "fmeasure": 0.6305
        },
        "rougeLsum": {
            "precision": 0.6502,
            "recall": 0.63182,
            "fmeasure": 0.6305
        },
        "nist": 7.32640103509801,
        "bleu": 49.37398,
        "bertscore": {
            "precision": 0.92722,
            "recall": 0.92009,
            "f1": 0.92184
        },
        "bleurt": 0.32078,
        "meteor": 0.38972446648764925,
        "nubia": {
            "semantic_relation": 4.15889,
            "contradiction": 12.22439,
            "irrelevancy": 22.659,
            "logical_agreement": 65.11661,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.68917,
            "nubia_score": 0.72188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3157894736842105
        },
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.23043,
            "fmeasure": 0.29853
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.07994,
            "fmeasure": 0.10476
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.19203,
            "fmeasure": 0.24877
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.19203,
            "fmeasure": 0.24877
        },
        "nist": 0.554519805309835,
        "bleu": 6.82428,
        "bertscore": {
            "precision": 0.84461,
            "recall": 0.78994,
            "f1": 0.81636
        },
        "bleurt": -0.25191,
        "meteor": 0.15851498766512645,
        "nubia": {
            "semantic_relation": 3.49879,
            "contradiction": 18.39592,
            "irrelevancy": 12.89329,
            "logical_agreement": 68.7108,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.40895,
            "nubia_score": 0.40119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "nist": 3.886868538598291,
        "bleu": 100.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "bleurt": 0.88843,
        "meteor": 1.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2217,
            "irrelevancy": 0.43077,
            "logical_agreement": 99.34753,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.86832,
            "nubia_score": 0.98747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "mT5_small/totto_test",
        "N": 29,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.45614035087719296,
            "3": 0.8816568047337278
        },
        "rouge1": {
            "precision": 0.87405,
            "recall": 0.85608,
            "fmeasure": 0.86043
        },
        "rouge2": {
            "precision": 0.7329,
            "recall": 0.71648,
            "fmeasure": 0.72148
        },
        "rougeL": {
            "precision": 0.82222,
            "recall": 0.80701,
            "fmeasure": 0.81105
        },
        "rougeLsum": {
            "precision": 0.82222,
            "recall": 0.80701,
            "fmeasure": 0.81105
        },
        "nist": 7.347315917820068,
        "bleu": 72.45834,
        "bertscore": {
            "precision": 0.96276,
            "recall": 0.95329,
            "f1": 0.95666
        },
        "bleurt": 0.59154,
        "meteor": 0.4574593544674462,
        "nubia": {
            "semantic_relation": 4.37089,
            "contradiction": 5.94934,
            "irrelevancy": 8.15742,
            "logical_agreement": 85.89324,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.32243,
            "nubia_score": 0.8148
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "mT5_small/totto_test",
        "N": 112,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18100890207715134,
            "2": 0.42948717948717946,
            "3": 0.7401574803149606
        },
        "rouge1": {
            "precision": 0.75027,
            "recall": 0.68716,
            "fmeasure": 0.7042
        },
        "rouge2": {
            "precision": 0.50287,
            "recall": 0.45486,
            "fmeasure": 0.4696
        },
        "rougeL": {
            "precision": 0.63553,
            "recall": 0.58362,
            "fmeasure": 0.59802
        },
        "rougeLsum": {
            "precision": 0.63553,
            "recall": 0.58362,
            "fmeasure": 0.59802
        },
        "nist": 7.124003225791392,
        "bleu": 41.62088,
        "bertscore": {
            "precision": 0.91927,
            "recall": 0.90883,
            "f1": 0.91287
        },
        "bleurt": 0.21301,
        "meteor": 0.36388260642639836,
        "nubia": {
            "semantic_relation": 4.04345,
            "contradiction": 10.49914,
            "irrelevancy": 27.10934,
            "logical_agreement": 62.39152,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.76623,
            "nubia_score": 0.68654
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "mT5_small/totto_test",
        "N": 91,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2072072072072072,
            "2": 0.44360902255639095,
            "3": 0.7489495798319328
        },
        "rouge1": {
            "precision": 0.78225,
            "recall": 0.71464,
            "fmeasure": 0.73806
        },
        "rouge2": {
            "precision": 0.5599,
            "recall": 0.50923,
            "fmeasure": 0.52676
        },
        "rougeL": {
            "precision": 0.68825,
            "recall": 0.63283,
            "fmeasure": 0.65126
        },
        "rougeLsum": {
            "precision": 0.68825,
            "recall": 0.63283,
            "fmeasure": 0.65126
        },
        "nist": 7.32950622411921,
        "bleu": 49.25468,
        "bertscore": {
            "precision": 0.93268,
            "recall": 0.91715,
            "f1": 0.92362
        },
        "bleurt": 0.30394,
        "meteor": 0.3874508428311451,
        "nubia": {
            "semantic_relation": 4.08373,
            "contradiction": 8.8346,
            "irrelevancy": 20.07862,
            "logical_agreement": 71.08677,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.47203,
            "nubia_score": 0.71164
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1850,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23048327137546468,
            "2": 0.44539900725467735,
            "3": 0.765746591286997
        },
        "rouge1": {
            "precision": 0.74126,
            "recall": 0.7134,
            "fmeasure": 0.71304
        },
        "rouge2": {
            "precision": 0.53306,
            "recall": 0.5128,
            "fmeasure": 0.51242
        },
        "rougeL": {
            "precision": 0.66825,
            "recall": 0.64464,
            "fmeasure": 0.64344
        },
        "rougeLsum": {
            "precision": 0.66825,
            "recall": 0.64464,
            "fmeasure": 0.64344
        },
        "nist": 9.24732753455068,
        "bleu": 48.76828,
        "bertscore": {
            "precision": 0.92528,
            "recall": 0.91945,
            "f1": 0.92054
        },
        "bleurt": 0.28223,
        "meteor": 0.39280085130442893,
        "nubia": {
            "semantic_relation": 4.11006,
            "contradiction": 9.46327,
            "irrelevancy": 29.19053,
            "logical_agreement": 61.3462,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.74163,
            "nubia_score": 0.70667
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_small/totto_test",
        "N": 2221,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2093609865470852,
            "2": 0.4282472067039106,
            "3": 0.767092479309104
        },
        "rouge1": {
            "precision": 0.77358,
            "recall": 0.73037,
            "fmeasure": 0.74
        },
        "rouge2": {
            "precision": 0.53317,
            "recall": 0.5045,
            "fmeasure": 0.51024
        },
        "rougeL": {
            "precision": 0.66415,
            "recall": 0.63023,
            "fmeasure": 0.63659
        },
        "rougeLsum": {
            "precision": 0.66415,
            "recall": 0.63023,
            "fmeasure": 0.63659
        },
        "nist": 9.873579339114814,
        "bleu": 45.63473,
        "bertscore": {
            "precision": 0.93062,
            "recall": 0.92352,
            "f1": 0.92552
        },
        "bleurt": 0.28102,
        "meteor": 0.39307866790780605,
        "nubia": {
            "semantic_relation": 4.24348,
            "contradiction": 8.96094,
            "irrelevancy": 26.77257,
            "logical_agreement": 64.26649,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.83922,
            "nubia_score": 0.72764
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_small/totto_test",
        "N": 1369,
        "total_length": 123344,
        "mean_pred_length": 16.0187012987013,
        "std_pred_length": 6.756289104916921,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 76,
        "distinct-1": 0.17079874173044493,
        "vocab_size-1": 21067,
        "unique-1": 14419,
        "entropy-1": 9.9891988771045,
        "distinct-2": 0.5256909134931341,
        "vocab_size-2": 60793,
        "unique-2": 50370,
        "entropy-2": 14.423393108589158,
        "cond_entropy-2": 4.0348576018175795,
        "distinct-3": 0.7524920329059512,
        "vocab_size-3": 81227,
        "unique-3": 73153,
        "entropy-3": 15.744447817492025,
        "cond_entropy-3": 1.3030986353804792,
        "total_length-nopunct": 107106,
        "mean_pred_length-nopunct": 13.90987012987013,
        "std_pred_length-nopunct": 5.732199435883589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.19650626482176536,
        "vocab_size-1-nopunct": 21047,
        "unique-1-nopunct": 14415,
        "entropy-1-nopunct": 10.559916529914831,
        "distinct-2-nopunct": 0.5712029454962477,
        "vocab_size-2-nopunct": 56781,
        "unique-2-nopunct": 48149,
        "entropy-2-nopunct": 14.424294300610233,
        "cond_entropy-2-nopunct": 4.042834015329056,
        "distinct-3-nopunct": 0.7811375482520228,
        "vocab_size-3-nopunct": 71635,
        "unique-3-nopunct": 65442,
        "entropy-3-nopunct": 15.6237189365747,
        "cond_entropy-3-nopunct": 1.2901963484683723,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.76311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21475935828877005,
            "2": 0.4224285365257757,
            "3": 0.7467850027168991
        },
        "rouge1": {
            "precision": 0.75197,
            "recall": 0.70799,
            "fmeasure": 0.71789
        },
        "rouge2": {
            "precision": 0.50518,
            "recall": 0.47751,
            "fmeasure": 0.48288
        },
        "rougeL": {
            "precision": 0.63048,
            "recall": 0.59917,
            "fmeasure": 0.60436
        },
        "rougeLsum": {
            "precision": 0.63048,
            "recall": 0.59917,
            "fmeasure": 0.60436
        },
        "nist": 9.386461778141104,
        "bleu": 43.99184,
        "bertscore": {
            "precision": 0.92451,
            "recall": 0.91631,
            "f1": 0.91876
        },
        "bleurt": 0.2193,
        "meteor": 0.38227230497849835,
        "nubia": {
            "semantic_relation": 4.08901,
            "contradiction": 13.23884,
            "irrelevancy": 29.56703,
            "logical_agreement": 57.19413,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.49172,
            "nubia_score": 0.69471
        }
    },
    "totto_test": {
        "predictions_file": "mT5_small/totto_test",
        "N": 7700,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2198305565689732,
            "2": 0.42963928726640593,
            "3": 0.7449200010046969
        },
        "rouge1": {
            "precision": 0.74738,
            "recall": 0.70721,
            "fmeasure": 0.71392
        },
        "rouge2": {
            "precision": 0.51433,
            "recall": 0.48773,
            "fmeasure": 0.49149
        },
        "rougeL": {
            "precision": 0.64768,
            "recall": 0.6161,
            "fmeasure": 0.61997
        },
        "rougeLsum": {
            "precision": 0.64768,
            "recall": 0.6161,
            "fmeasure": 0.61997
        },
        "nist": 10.300335343226433,
        "bleu": 43.65339,
        "bertscore": {
            "precision": 0.92479,
            "recall": 0.91671,
            "f1": 0.91903
        },
        "bleurt": 0.23631,
        "meteor": 0.3779176388379896,
        "nubia": {
            "semantic_relation": 4.08435,
            "contradiction": 11.71024,
            "irrelevancy": 28.8519,
            "logical_agreement": 59.43786,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.67857,
            "nubia_score": 0.6934
        }
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "mT5_small/totto_challenge_test_scramble",
        "N": 378
    },
    "wiki_auto_asset_turk_val": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_val",
        "N": 20000,
        "total_length": 420810,
        "mean_pred_length": 21.0405,
        "std_pred_length": 8.714864299000874,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 76,
        "distinct-1": 0.022114493476866046,
        "vocab_size-1": 9306,
        "unique-1": 0,
        "entropy-1": 9.882511904541705,
        "distinct-2": 0.07147276764551783,
        "vocab_size-2": 28647,
        "unique-2": 0,
        "entropy-2": 14.100494655921276,
        "cond_entropy-2": 3.937999766611138,
        "distinct-3": 0.09187521336099368,
        "vocab_size-3": 34987,
        "unique-3": 0,
        "entropy-3": 14.93150844968585,
        "cond_entropy-3": 0.8482220570748878,
        "total_length-nopunct": 370870,
        "mean_pred_length-nopunct": 18.5435,
        "std_pred_length-nopunct": 7.652784313568493,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.025041119529754362,
        "vocab_size-1-nopunct": 9287,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.31398100398441,
        "distinct-2-nopunct": 0.07479978339555961,
        "vocab_size-2-nopunct": 26245,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 14.092030546008456,
        "cond_entropy-2-nopunct": 3.9464217672388124,
        "distinct-3-nopunct": 0.09399462024360021,
        "vocab_size-3-nopunct": 31100,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.851729716021556,
        "cond_entropy-3-nopunct": 0.7999550166570378,
        "msttr-100": 0.2669,
        "msttr-100_nopunct": 0.25115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_val.json",
        "local_recall": {
            "1": 0.7835121016149662
        },
        "rouge1": {
            "precision": 0.73527,
            "recall": 0.79401,
            "fmeasure": 0.75244
        },
        "rouge2": {
            "precision": 0.56044,
            "recall": 0.60315,
            "fmeasure": 0.572
        },
        "rougeL": {
            "precision": 0.69296,
            "recall": 0.74741,
            "fmeasure": 0.70886
        },
        "rougeLsum": {
            "precision": 0.69296,
            "recall": 0.74741,
            "fmeasure": 0.70886
        },
        "nist": 9.988683240139283,
        "bleu": 48.16482,
        "sari": 50.46233,
        "bertscore": {
            "precision": 0.92508,
            "recall": 0.94008,
            "f1": 0.93197
        },
        "bleurt": 0.37578,
        "meteor": 0.4313323816453825,
        "nubia": {
            "semantic_relation": 4.5041,
            "contradiction": 2.30639,
            "irrelevancy": 26.86303,
            "logical_agreement": 70.83059,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.72595,
            "nubia_score": 0.74584
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "total_length": 7860,
        "mean_pred_length": 21.894150417827298,
        "std_pred_length": 9.120972452778172,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 61,
        "distinct-1": 0.3713740458015267,
        "vocab_size-1": 2919,
        "unique-1": 2124,
        "entropy-1": 9.290508185850303,
        "distinct-2": 0.8404212771630449,
        "vocab_size-2": 6304,
        "unique-2": 5837,
        "entropy-2": 12.315126428639841,
        "cond_entropy-2": 2.78775666453281,
        "distinct-3": 0.9687762531503781,
        "vocab_size-3": 6919,
        "unique-3": 6802,
        "entropy-3": 12.706209863482327,
        "cond_entropy-3": 0.4038224981293277,
        "total_length-nopunct": 6969,
        "mean_pred_length-nopunct": 19.41225626740947,
        "std_pred_length-nopunct": 7.982394638024873,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.41698952503946046,
        "vocab_size-1-nopunct": 2906,
        "unique-1-nopunct": 2123,
        "entropy-1-nopunct": 9.636808098693828,
        "distinct-2-nopunct": 0.8644478063540091,
        "vocab_size-2-nopunct": 5714,
        "unique-2-nopunct": 5337,
        "entropy-2-nopunct": 12.23112865091686,
        "cond_entropy-2-nopunct": 2.7206886997032753,
        "distinct-3-nopunct": 0.9833626619740842,
        "vocab_size-3-nopunct": 6147,
        "unique-3-nopunct": 6066,
        "entropy-3-nopunct": 12.57329021366977,
        "cond_entropy-3-nopunct": 0.36196576729118807,
        "msttr-100": 0.72974,
        "msttr-100_nopunct": 0.76783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03436236677692025,
            "2": 0.19002695417789758,
            "3": 0.43132530120481927,
            "4": 0.6406727828746177,
            "5": 0.7526555386949925,
            "6": 0.8690140845070422,
            "7": 0.9180327868852459,
            "8": 0.9529553679131484,
            "9": 0.9661375661375662,
            "10": 0.9868217054263566
        },
        "rouge1": {
            "precision": 0.89752,
            "recall": 0.92032,
            "fmeasure": 0.90502
        },
        "rouge2": {
            "precision": 0.80505,
            "recall": 0.83496,
            "fmeasure": 0.81467
        },
        "rougeL": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "rougeLsum": {
            "precision": 0.88654,
            "recall": 0.90955,
            "fmeasure": 0.89399
        },
        "nist": 13.589369172315616,
        "bleu": 88.22733,
        "sari": 49.02756,
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.98001,
            "f1": 0.97453
        },
        "bleurt": 0.31744,
        "meteor": 0.5587553144887645,
        "nubia": {
            "semantic_relation": 4.40729,
            "contradiction": 2.29327,
            "irrelevancy": 33.60574,
            "logical_agreement": 64.10099,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70464,
            "nubia_score": 0.70017
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "total_length": 7229,
        "mean_pred_length": 20.13649025069638,
        "std_pred_length": 9.1858423186049,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.36644072485821,
        "vocab_size-1": 2649,
        "unique-1": 1933,
        "entropy-1": 9.204601060334188,
        "distinct-2": 0.845414847161572,
        "vocab_size-2": 5808,
        "unique-2": 5386,
        "entropy-2": 12.214450573848323,
        "cond_entropy-2": 2.748968289552871,
        "distinct-3": 0.9688219935493779,
        "vocab_size-3": 6308,
        "unique-3": 6196,
        "entropy-3": 12.57353139728536,
        "cond_entropy-3": 0.3748342848513119,
        "total_length-nopunct": 6456,
        "mean_pred_length-nopunct": 17.983286908077993,
        "std_pred_length-nopunct": 8.15960218755718,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4083023543990087,
        "vocab_size-1-nopunct": 2636,
        "unique-1-nopunct": 1930,
        "entropy-1-nopunct": 9.521398318728968,
        "distinct-2-nopunct": 0.8651795965228801,
        "vocab_size-2-nopunct": 5275,
        "unique-2-nopunct": 4927,
        "entropy-2-nopunct": 12.12066793495952,
        "cond_entropy-2-nopunct": 2.7348537281635985,
        "distinct-3-nopunct": 0.9811781108400139,
        "vocab_size-3-nopunct": 5630,
        "unique-3-nopunct": 5542,
        "entropy-3-nopunct": 12.445366994834446,
        "cond_entropy-3-nopunct": 0.34460054672478496,
        "msttr-100": 0.73264,
        "msttr-100_nopunct": 0.77109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04265704584040747,
            "2": 0.18773946360153257,
            "3": 0.40919037199124725,
            "4": 0.5816164817749604,
            "5": 0.6915887850467289,
            "6": 0.7783816425120773,
            "7": 0.8736158839251623
        },
        "rouge1": {
            "precision": 0.85348,
            "recall": 0.80789,
            "fmeasure": 0.81987
        },
        "rouge2": {
            "precision": 0.70936,
            "recall": 0.67588,
            "fmeasure": 0.68255
        },
        "rougeL": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "rougeLsum": {
            "precision": 0.82248,
            "recall": 0.77952,
            "fmeasure": 0.79051
        },
        "nist": 11.348324337318253,
        "bleu": 68.4974,
        "sari": 48.71872,
        "bertscore": {
            "precision": 0.95485,
            "recall": 0.94662,
            "f1": 0.94865
        },
        "bleurt": 0.21243,
        "meteor": 0.4688629598902241,
        "nubia": {
            "semantic_relation": 4.33162,
            "contradiction": 4.00834,
            "irrelevancy": 17.09194,
            "logical_agreement": 78.89971,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.98215,
            "nubia_score": 0.69949
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "total_length": 6554,
        "mean_pred_length": 18.25626740947075,
        "std_pred_length": 9.327292954936649,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 88,
        "distinct-1": 0.35855965822398533,
        "vocab_size-1": 2350,
        "unique-1": 1679,
        "entropy-1": 9.053686474064484,
        "distinct-2": 0.8269572235673931,
        "vocab_size-2": 5123,
        "unique-2": 4666,
        "entropy-2": 12.02075706292727,
        "cond_entropy-2": 2.6809461388720117,
        "distinct-3": 0.9599040438656614,
        "vocab_size-3": 5602,
        "unique-3": 5488,
        "entropy-3": 12.365804272435504,
        "cond_entropy-3": 0.36225167969499933,
        "total_length-nopunct": 5808,
        "mean_pred_length-nopunct": 16.178272980501394,
        "std_pred_length-nopunct": 8.244621869744169,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 82,
        "distinct-1-nopunct": 0.403064738292011,
        "vocab_size-1-nopunct": 2341,
        "unique-1-nopunct": 1679,
        "entropy-1-nopunct": 9.394962384901454,
        "distinct-2-nopunct": 0.8563039089741237,
        "vocab_size-2-nopunct": 4666,
        "unique-2-nopunct": 4281,
        "entropy-2-nopunct": 11.987148602784334,
        "cond_entropy-2-nopunct": 2.7311576452118316,
        "distinct-3-nopunct": 0.9803536345776032,
        "vocab_size-3-nopunct": 4990,
        "unique-3-nopunct": 4900,
        "entropy-3-nopunct": 12.272577819151287,
        "cond_entropy-3-nopunct": 0.30452086519458704,
        "msttr-100": 0.71708,
        "msttr-100_nopunct": 0.7531,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.05314009661835749,
            "2": 0.1201923076923077,
            "3": 0.18874560375146543,
            "4": 0.24220963172804533,
            "5": 0.3200531208499336,
            "6": 0.3460591133004926,
            "7": 0.4372146118721461,
            "8": 0.5158730158730159,
            "9": 0.6561151079136691
        },
        "rouge1": {
            "precision": 0.55881,
            "recall": 0.54702,
            "fmeasure": 0.53186
        },
        "rouge2": {
            "precision": 0.31923,
            "recall": 0.32491,
            "fmeasure": 0.3069
        },
        "rougeL": {
            "precision": 0.49921,
            "recall": 0.50056,
            "fmeasure": 0.48066
        },
        "rougeLsum": {
            "precision": 0.49921,
            "recall": 0.50056,
            "fmeasure": 0.48066
        },
        "nist": 6.758140400156539,
        "bleu": 27.99847,
        "sari": 39.84143,
        "bertscore": {
            "precision": 0.86789,
            "recall": 0.87105,
            "f1": 0.86465
        },
        "bleurt": -0.48792,
        "meteor": 0.2705226132230671,
        "nubia": {
            "semantic_relation": 2.89475,
            "contradiction": 20.56294,
            "irrelevancy": 45.11578,
            "logical_agreement": 34.32128,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.57671,
            "nubia_score": 0.31305
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "total_length": 6364,
        "mean_pred_length": 17.72701949860724,
        "std_pred_length": 8.307336072459673,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.38874921433060966,
        "vocab_size-1": 2474,
        "unique-1": 1891,
        "entropy-1": 9.1229438014001,
        "distinct-2": 0.8411323896752706,
        "vocab_size-2": 5051,
        "unique-2": 4664,
        "entropy-2": 12.020648294376853,
        "cond_entropy-2": 2.5925518955953653,
        "distinct-3": 0.9613885936946511,
        "vocab_size-3": 5428,
        "unique-3": 5308,
        "entropy-3": 12.338388555752903,
        "cond_entropy-3": 0.33573582412451813,
        "total_length-nopunct": 5629,
        "mean_pred_length-nopunct": 15.67966573816156,
        "std_pred_length-nopunct": 7.486322079143412,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.4373778646295967,
        "vocab_size-1-nopunct": 2462,
        "unique-1-nopunct": 1887,
        "entropy-1-nopunct": 9.481917793170823,
        "distinct-2-nopunct": 0.8633776091081594,
        "vocab_size-2-nopunct": 4550,
        "unique-2-nopunct": 4225,
        "entropy-2-nopunct": 11.938360439131621,
        "cond_entropy-2-nopunct": 2.6084869545589573,
        "distinct-3-nopunct": 0.9763795560985543,
        "vocab_size-3-nopunct": 4795,
        "unique-3-nopunct": 4698,
        "entropy-3-nopunct": 12.210618405824379,
        "cond_entropy-3-nopunct": 0.29528934940216345,
        "msttr-100": 0.72079,
        "msttr-100_nopunct": 0.76446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.04541062801932367,
            "2": 0.11057692307692307,
            "3": 0.17702227432590856,
            "4": 0.26487252124645894,
            "5": 0.34926958831341304,
            "6": 0.3645320197044335,
            "7": 0.4200913242009132,
            "8": 0.558531746031746,
            "9": 0.6683453237410072
        },
        "rouge1": {
            "precision": 0.58618,
            "recall": 0.55647,
            "fmeasure": 0.54583
        },
        "rouge2": {
            "precision": 0.37074,
            "recall": 0.3566,
            "fmeasure": 0.34483
        },
        "rougeL": {
            "precision": 0.54126,
            "recall": 0.52344,
            "fmeasure": 0.50824
        },
        "rougeLsum": {
            "precision": 0.54126,
            "recall": 0.52344,
            "fmeasure": 0.50824
        },
        "nist": 7.080369222199171,
        "bleu": 32.67673,
        "sari": 40.13787,
        "bertscore": {
            "precision": 0.855,
            "recall": 0.87264,
            "f1": 0.85817
        },
        "bleurt": -0.76135,
        "meteor": 0.27291553912722283,
        "nubia": {
            "semantic_relation": 2.97711,
            "contradiction": 17.6694,
            "irrelevancy": 42.60024,
            "logical_agreement": 39.73036,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.17022,
            "nubia_score": 0.28937
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "total_length": 6886,
        "mean_pred_length": 19.181058495821727,
        "std_pred_length": 10.414157815308412,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 69,
        "distinct-1": 0.41214057507987223,
        "vocab_size-1": 2838,
        "unique-1": 2253,
        "entropy-1": 9.344639190305573,
        "distinct-2": 0.8510801286961851,
        "vocab_size-2": 5555,
        "unique-2": 5208,
        "entropy-2": 12.114750499356054,
        "cond_entropy-2": 2.483471769241719,
        "distinct-3": 0.9586575875486382,
        "vocab_size-3": 5913,
        "unique-3": 5811,
        "entropy-3": 12.421802570843886,
        "cond_entropy-3": 0.32512207161341633,
        "total_length-nopunct": 6091,
        "mean_pred_length-nopunct": 16.96657381615599,
        "std_pred_length-nopunct": 9.159922225070597,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.4637990477754063,
        "vocab_size-1-nopunct": 2825,
        "unique-1-nopunct": 2251,
        "entropy-1-nopunct": 9.69985088259457,
        "distinct-2-nopunct": 0.8804954640614097,
        "vocab_size-2-nopunct": 5047,
        "unique-2-nopunct": 4751,
        "entropy-2-nopunct": 12.097685345822295,
        "cond_entropy-2-nopunct": 2.5337949281353533,
        "distinct-3-nopunct": 0.9826912339475153,
        "vocab_size-3-nopunct": 5280,
        "unique-3-nopunct": 5203,
        "entropy-3-nopunct": 12.354054765371929,
        "cond_entropy-3-nopunct": 0.27745683438069735,
        "msttr-100": 0.73588,
        "msttr-100_nopunct": 0.7775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.04154589371980676,
            "2": 0.10782967032967034,
            "3": 0.17584994138335286,
            "4": 0.26628895184135976,
            "5": 0.32669322709163345,
            "6": 0.3669950738916256,
            "7": 0.4817351598173516,
            "8": 0.5248015873015873,
            "9": 0.6237410071942446
        },
        "rouge1": {
            "precision": 0.53218,
            "recall": 0.53021,
            "fmeasure": 0.51298
        },
        "rouge2": {
            "precision": 0.30254,
            "recall": 0.30245,
            "fmeasure": 0.28988
        },
        "rougeL": {
            "precision": 0.4918,
            "recall": 0.49664,
            "fmeasure": 0.47579
        },
        "rougeLsum": {
            "precision": 0.4918,
            "recall": 0.49664,
            "fmeasure": 0.47579
        },
        "nist": 6.264504911923486,
        "bleu": 24.92937,
        "sari": 39.9961,
        "bertscore": {
            "precision": 0.82511,
            "recall": 0.85945,
            "f1": 0.83688
        },
        "bleurt": -1.01394,
        "meteor": 0.24919249242342154,
        "nubia": {
            "semantic_relation": 2.92054,
            "contradiction": 18.91218,
            "irrelevancy": 41.21306,
            "logical_agreement": 39.87476,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.66857,
            "nubia_score": 0.25355
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "total_length": 7271,
        "mean_pred_length": 20.25348189415042,
        "std_pred_length": 11.127512785937576,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 97,
        "distinct-1": 0.3302159262824921,
        "vocab_size-1": 2401,
        "unique-1": 1652,
        "entropy-1": 9.029978750280097,
        "distinct-2": 0.7844328703703703,
        "vocab_size-2": 5422,
        "unique-2": 4775,
        "entropy-2": 12.015700682720379,
        "cond_entropy-2": 2.7325592571336044,
        "distinct-3": 0.9241568747138715,
        "vocab_size-3": 6056,
        "unique-3": 5759,
        "entropy-3": 12.429048236955389,
        "cond_entropy-3": 0.4372988804734252,
        "total_length-nopunct": 6408,
        "mean_pred_length-nopunct": 17.84958217270195,
        "std_pred_length-nopunct": 9.597451704103907,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 72,
        "distinct-1-nopunct": 0.37297128589263423,
        "vocab_size-1-nopunct": 2390,
        "unique-1-nopunct": 1650,
        "entropy-1-nopunct": 9.35671040181374,
        "distinct-2-nopunct": 0.8130269466027442,
        "vocab_size-2-nopunct": 4918,
        "unique-2-nopunct": 4355,
        "entropy-2-nopunct": 11.99482744932696,
        "cond_entropy-2-nopunct": 2.775051830372062,
        "distinct-3-nopunct": 0.9490333919156415,
        "vocab_size-3-nopunct": 5400,
        "unique-3-nopunct": 5150,
        "entropy-3-nopunct": 12.364594845714539,
        "cond_entropy-3-nopunct": 0.39412874119516733,
        "msttr-100": 0.68681,
        "msttr-100_nopunct": 0.72469,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.04830917874396135,
            "2": 0.14697802197802198,
            "3": 0.223915592028136,
            "4": 0.31444759206798867,
            "5": 0.4116865869853918,
            "6": 0.47783251231527096,
            "7": 0.5764840182648402,
            "8": 0.6517857142857143,
            "9": 0.8086330935251799
        },
        "rouge1": {
            "precision": 0.64894,
            "recall": 0.66131,
            "fmeasure": 0.6292
        },
        "rouge2": {
            "precision": 0.46577,
            "recall": 0.48011,
            "fmeasure": 0.44789
        },
        "rougeL": {
            "precision": 0.60194,
            "recall": 0.61782,
            "fmeasure": 0.58403
        },
        "rougeLsum": {
            "precision": 0.60194,
            "recall": 0.61782,
            "fmeasure": 0.58403
        },
        "nist": 8.283352178608206,
        "bleu": 42.10103,
        "sari": 42.95527,
        "bertscore": {
            "precision": 0.9005,
            "recall": 0.90509,
            "f1": 0.89754
        },
        "bleurt": -0.27425,
        "meteor": 0.34395979018161704,
        "nubia": {
            "semantic_relation": 3.4374,
            "contradiction": 11.29695,
            "irrelevancy": 44.87411,
            "logical_agreement": 43.82894,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.19591,
            "nubia_score": 0.40282
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "total_length": 7395,
        "mean_pred_length": 20.598885793871865,
        "std_pred_length": 10.226438992574645,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 70,
        "distinct-1": 0.3452332657200811,
        "vocab_size-1": 2553,
        "unique-1": 1804,
        "entropy-1": 9.090673828385452,
        "distinct-2": 0.8148095508811825,
        "vocab_size-2": 5733,
        "unique-2": 5219,
        "entropy-2": 12.12483503528263,
        "cond_entropy-2": 2.7866662563524014,
        "distinct-3": 0.9511756776995657,
        "vocab_size-3": 6351,
        "unique-3": 6178,
        "entropy-3": 12.542666833639007,
        "cond_entropy-3": 0.42896442672606644,
        "total_length-nopunct": 6540,
        "mean_pred_length-nopunct": 18.21727019498607,
        "std_pred_length-nopunct": 9.149798378951452,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 64,
        "distinct-1-nopunct": 0.38807339449541284,
        "vocab_size-1-nopunct": 2538,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.407934048360579,
        "distinct-2-nopunct": 0.8446853259990292,
        "vocab_size-2-nopunct": 5221,
        "unique-2-nopunct": 4791,
        "entropy-2-nopunct": 12.08200371774783,
        "cond_entropy-2-nopunct": 2.8053451788418324,
        "distinct-3-nopunct": 0.9721745104774991,
        "vocab_size-3-nopunct": 5660,
        "unique-3-nopunct": 5527,
        "entropy-3-nopunct": 12.446289100164607,
        "cond_entropy-3-nopunct": 0.3862622939222544,
        "msttr-100": 0.70849,
        "msttr-100_nopunct": 0.74692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.06239388794567063,
            "2": 0.16219667943805874,
            "3": 0.2647702407002188,
            "4": 0.26148969889064977,
            "5": 0.34787123572170303,
            "6": 0.4577294685990338,
            "7": 0.6384116074837725
        },
        "rouge1": {
            "precision": 0.57641,
            "recall": 0.56156,
            "fmeasure": 0.54764
        },
        "rouge2": {
            "precision": 0.33036,
            "recall": 0.33326,
            "fmeasure": 0.31806
        },
        "rougeL": {
            "precision": 0.51268,
            "recall": 0.50541,
            "fmeasure": 0.48902
        },
        "rougeLsum": {
            "precision": 0.51268,
            "recall": 0.50541,
            "fmeasure": 0.48902
        },
        "nist": 6.648244664123772,
        "bleu": 28.7373,
        "sari": 39.16619,
        "bertscore": {
            "precision": 0.86898,
            "recall": 0.86958,
            "f1": 0.86595
        },
        "bleurt": -0.40826,
        "meteor": 0.2774635258922975,
        "nubia": {
            "semantic_relation": 3.12409,
            "contradiction": 20.28301,
            "irrelevancy": 38.83497,
            "logical_agreement": 40.88202,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.41938,
            "nubia_score": 0.36722
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "total_length": 7590,
        "mean_pred_length": 21.142061281337046,
        "std_pred_length": 10.627361919962084,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.3877470355731225,
        "vocab_size-1": 2943,
        "unique-1": 2227,
        "entropy-1": 9.371622510660398,
        "distinct-2": 0.8408242290139677,
        "vocab_size-2": 6080,
        "unique-2": 5593,
        "entropy-2": 12.266579567707652,
        "cond_entropy-2": 2.6403042058477797,
        "distinct-3": 0.9576542491268918,
        "vocab_size-3": 6581,
        "unique-3": 6417,
        "entropy-3": 12.603978280713774,
        "cond_entropy-3": 0.35350541082154063,
        "total_length-nopunct": 6734,
        "mean_pred_length-nopunct": 18.75766016713092,
        "std_pred_length-nopunct": 9.40395170218904,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.4354024354024354,
        "vocab_size-1-nopunct": 2932,
        "unique-1-nopunct": 2225,
        "entropy-1-nopunct": 9.715879892182075,
        "distinct-2-nopunct": 0.8638431372549019,
        "vocab_size-2-nopunct": 5507,
        "unique-2-nopunct": 5081,
        "entropy-2-nopunct": 12.205441891348764,
        "cond_entropy-2-nopunct": 2.6207812645280835,
        "distinct-3-nopunct": 0.9745678191489362,
        "vocab_size-3-nopunct": 5863,
        "unique-3-nopunct": 5726,
        "entropy-3-nopunct": 12.50126967681423,
        "cond_entropy-3-nopunct": 0.3157095556574053,
        "msttr-100": 0.7388,
        "msttr-100_nopunct": 0.76836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.04859932088285229,
            "2": 0.13154533844189017,
            "3": 0.27571115973741794,
            "4": 0.39461172741679873,
            "5": 0.446521287642783,
            "6": 0.5748792270531401,
            "7": 0.6685757922871325
        },
        "rouge1": {
            "precision": 0.6218,
            "recall": 0.61076,
            "fmeasure": 0.5999
        },
        "rouge2": {
            "precision": 0.41382,
            "recall": 0.41137,
            "fmeasure": 0.40202
        },
        "rougeL": {
            "precision": 0.58092,
            "recall": 0.57167,
            "fmeasure": 0.56158
        },
        "rougeLsum": {
            "precision": 0.58092,
            "recall": 0.57167,
            "fmeasure": 0.56158
        },
        "nist": 7.513362287952194,
        "bleu": 36.46132,
        "sari": 39.73321,
        "bertscore": {
            "precision": 0.86133,
            "recall": 0.87986,
            "f1": 0.86762
        },
        "bleurt": -0.67401,
        "meteor": 0.30587458416203084,
        "nubia": {
            "semantic_relation": 3.41196,
            "contradiction": 14.91212,
            "irrelevancy": 35.04893,
            "logical_agreement": 50.03895,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.15202,
            "nubia_score": 0.38329
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "total_length": 7554,
        "mean_pred_length": 21.041782729805014,
        "std_pred_length": 10.033977549156264,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 65,
        "distinct-1": 0.4180566587238549,
        "vocab_size-1": 3158,
        "unique-1": 2483,
        "entropy-1": 9.52463988284095,
        "distinct-2": 0.862404447533009,
        "vocab_size-2": 6205,
        "unique-2": 5817,
        "entropy-2": 12.336310727511691,
        "cond_entropy-2": 2.5542889985476394,
        "distinct-3": 0.9676711527208894,
        "vocab_size-3": 6615,
        "unique-3": 6498,
        "entropy-3": 12.630995739309185,
        "cond_entropy-3": 0.3040360588420944,
        "total_length-nopunct": 6707,
        "mean_pred_length-nopunct": 18.682451253481894,
        "std_pred_length-nopunct": 8.91116783015593,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.4689130758908603,
        "vocab_size-1-nopunct": 3145,
        "unique-1-nopunct": 2480,
        "entropy-1-nopunct": 9.880754996213438,
        "distinct-2-nopunct": 0.8881537492123504,
        "vocab_size-2-nopunct": 5638,
        "unique-2-nopunct": 5322,
        "entropy-2-nopunct": 12.271551838248735,
        "cond_entropy-2-nopunct": 2.505949032886642,
        "distinct-3-nopunct": 0.9836366672232426,
        "vocab_size-3-nopunct": 5891,
        "unique-3-nopunct": 5806,
        "entropy-3-nopunct": 12.513406740819473,
        "cond_entropy-3-nopunct": 0.2572756901306324,
        "msttr-100": 0.74893,
        "msttr-100_nopunct": 0.78478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.042869269949066216,
            "2": 0.13154533844189017,
            "3": 0.2603938730853392,
            "4": 0.3375594294770206,
            "5": 0.42471443406022846,
            "6": 0.5120772946859904,
            "7": 0.62122947689958
        },
        "rouge1": {
            "precision": 0.56668,
            "recall": 0.55592,
            "fmeasure": 0.54578
        },
        "rouge2": {
            "precision": 0.33571,
            "recall": 0.33952,
            "fmeasure": 0.32721
        },
        "rougeL": {
            "precision": 0.52916,
            "recall": 0.52315,
            "fmeasure": 0.51117
        },
        "rougeLsum": {
            "precision": 0.52916,
            "recall": 0.52315,
            "fmeasure": 0.51117
        },
        "nist": 6.750652254242858,
        "bleu": 28.68757,
        "sari": 40.22511,
        "bertscore": {
            "precision": 0.83015,
            "recall": 0.85979,
            "f1": 0.84174
        },
        "bleurt": -0.99572,
        "meteor": 0.26862636251626965,
        "nubia": {
            "semantic_relation": 3.22432,
            "contradiction": 16.30645,
            "irrelevancy": 36.77093,
            "logical_agreement": 46.92261,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.58234,
            "nubia_score": 0.32193
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "mT5_small/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "total_length": 8189,
        "mean_pred_length": 22.81058495821727,
        "std_pred_length": 10.43978886663085,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 62,
        "distinct-1": 0.32983270240566614,
        "vocab_size-1": 2701,
        "unique-1": 1830,
        "entropy-1": 9.201050070011249,
        "distinct-2": 0.8005108556832695,
        "vocab_size-2": 6268,
        "unique-2": 5591,
        "entropy-2": 12.236358257143786,
        "cond_entropy-2": 2.812406505127252,
        "distinct-3": 0.9390978450006693,
        "vocab_size-3": 7016,
        "unique-3": 6740,
        "entropy-3": 12.664133793055097,
        "cond_entropy-3": 0.445495770404163,
        "total_length-nopunct": 7282,
        "mean_pred_length-nopunct": 20.284122562674096,
        "std_pred_length-nopunct": 9.208059249881257,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.36899203515517714,
        "vocab_size-1-nopunct": 2687,
        "unique-1-nopunct": 1825,
        "entropy-1-nopunct": 9.505568223714198,
        "distinct-2-nopunct": 0.8283980933121479,
        "vocab_size-2-nopunct": 5735,
        "unique-2-nopunct": 5146,
        "entropy-2-nopunct": 12.217857842334363,
        "cond_entropy-2-nopunct": 2.830215533624776,
        "distinct-3-nopunct": 0.9605423522242535,
        "vocab_size-3-nopunct": 6305,
        "unique-3-nopunct": 6074,
        "entropy-3-nopunct": 12.597551955717675,
        "cond_entropy-3-nopunct": 0.396454126828495,
        "msttr-100": 0.69963,
        "msttr-100_nopunct": 0.72944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.052207130730050934,
            "2": 0.17369093231162197,
            "3": 0.3479212253829322,
            "4": 0.46275752773375595,
            "5": 0.5784008307372793,
            "6": 0.6654589371980676,
            "7": 0.7827415043909889
        },
        "rouge1": {
            "precision": 0.68179,
            "recall": 0.71342,
            "fmeasure": 0.67593
        },
        "rouge2": {
            "precision": 0.5182,
            "recall": 0.54972,
            "fmeasure": 0.51432
        },
        "rougeL": {
            "precision": 0.64667,
            "recall": 0.68057,
            "fmeasure": 0.64216
        },
        "rougeLsum": {
            "precision": 0.64667,
            "recall": 0.68057,
            "fmeasure": 0.64216
        },
        "nist": 8.63973282167082,
        "bleu": 46.82539,
        "sari": 42.1457,
        "bertscore": {
            "precision": 0.90772,
            "recall": 0.91336,
            "f1": 0.90762
        },
        "bleurt": -0.18319,
        "meteor": 0.3741548382888741,
        "nubia": {
            "semantic_relation": 3.75352,
            "contradiction": 12.82523,
            "irrelevancy": 36.61215,
            "logical_agreement": 50.56262,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.19634,
            "nubia_score": 0.48929
        }
    }
}

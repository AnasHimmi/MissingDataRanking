I work on helping computers communicate about the world around us.
There are a lot of ways to do this, and I like to focus on helping computers to talk about what they see and understand.
Given a scene like this, a modern computer-vision algorithm can tell you that there's a woman and there's a dog.
It can tell you that the woman is smiling.
It might even be able to tell you that the dog is incredibly cute.
I work on this problem thinking about how humans understand and process the world.
The thoughts, memories and stories that a scene like this might evoke for humans.
All the interconnections of related situations.
Maybe you've seen a dog like this one before, or you've spent time running on a beach like this one, and that further evokes thoughts and memories of a past vacation, past times to the beach, times spent running around with other dogs.
One of my guiding principles is that by helping computers to understand what it's like to have these experiences, to understand what we share and believe and feel, then we're in a great position to start evolving computer technology in a way that's complementary with our own experiences.
So, digging more deeply into this, a few years ago I began working on helping computers to generate human-like stories from sequences of images.
So, one day, I was working with my computer to ask it what it thought about a trip to Australia.
It took a look at the pictures, and it saw a koala.
It didn't know what the koala was, but it said it thought it was an interesting-looking creature.
Then I shared with it a sequence of images about a house burning down.
It took a look at the images and it said, "This is an amazing view! This is spectacular!"
It sent chills down my spine.
It saw a horrible, life-changing and life-destroying event and thought it was something positive.
I realized that it recognized the contrast, the reds, the yellows, and thought it was something worth remarking on positively.
And part of why it was doing this was because most of the images I had given it were positive images.
That's because people tend to share positive images when they talk about their experiences.
When was the last time you saw a selfie at a funeral?
I realized that, as I worked on improving AI task by task, dataset by dataset, that I was creating massive gaps, holes and blind spots in what it could understand.
And while doing so, I was encoding all kinds of biases.
Biases that reflect a limited viewpoint, limited to a single dataset -- biases that can reflect human biases found in the data, such as prejudice and stereotyping.
I thought back to the evolution of the technology that brought me to where I was that day -- how the first color images were calibrated against a white woman's skin, meaning that color photography was biased against black faces.
And that same bias, that same blind spot continued well into the '90s.
And the same blind spot continues even today in how well we can recognize different people's faces in facial recognition technology.
I though about the state of the art in research today, where we tend to limit our thinking to one dataset and one problem.
And that in doing so, we were creating more blind spots and biases that the AI could further amplify.
I realized then that we had to think deeply about how the technology we work on today looks in five years, in 10 years.
Humans evolve slowly, with time to correct for issues in the interaction of humans and their environment.
In contrast, artificial intelligence is evolving at an incredibly fast rate.
And that means that it really matters that we think about this carefully right now -- that we reflect on our own blind spots, our own biases, and think about how that's informing the technology we're creating and discuss what the technology of today will mean for tomorrow.
CEOs and scientists have weighed in on what they think the artificial intelligence technology of the future will be.
Stephen Hawking warns that "Artificial intelligence could end mankind."
Elon Musk warns that it's an existential risk and one of the greatest risks that we face as a civilization.
Bill Gates has made the point, "I don't understand why people aren't more concerned."
But these views -- they're part of the story.
The math, the models, the basic building blocks of artificial intelligence are something that we call access and all work with.
We have open-source tools for machine learning and intelligence that we can contribute to.
And beyond that, we can share our experience.
We can share our experiences with technology and how it concerns us and how it excites us.
We can discuss what we love.
We can communicate with foresight about the aspects of technology that could be more beneficial or could be more problematic over time.
If we all focus on opening up the discussion on AI with foresight towards the future, this will help create a general conversation and awareness about what AI is now, what it can become and all the things that we need to do in order to enable that outcome that best suits us.
We already see and know this in the technology that we use today.
We use smart phones and digital assistants and Roombas.
Are they evil?
Maybe sometimes.
Are they beneficial?
Yes, they're that, too.
And they're not all the same.
And there you already see a light shining on what the future holds.
The future continues on from what we build and create right now.
We set into motion that domino effect that carves out AI's evolutionary path.
In our time right now, we shape the AI of tomorrow.
Technology that immerses us in augmented realities bringing to life past worlds.
Technology that helps people to share their experiences when they have difficulty communicating.
Technology built on understanding the streaming visual worlds used as technology for self-driving cars.
Technology built on understanding images and generating language, evolving into technology that helps people who are visually impaired be better able to access the visual world.
And we also see how technology can lead to problems.
We have technology today that analyzes physical characteristics we're born with -- such as the color of our skin or the look of our face -- in order to determine whether or not we might be criminals or terrorists.
We have technology that crunches through our data, even data relating to our gender or our race, in order to determine whether or not we might get a loan.
All that we see now is a snapshot in the evolution of artificial intelligence.
Because where we are right now, is within a moment of that evolution.
That means that what we do now will affect what happens down the line and in the future.
If we want AI to evolve in a way that helps humans, then we need to define the goals and strategies that enable that path now.
What I'd like to see is something that fits well with humans, with our culture and with the environment.
Technology that aids and assists those of us with neurological conditions or other disabilities in order to make life equally challenging for everyone.
Technology that works regardless of your demographics or the color of your skin.
And so today, what I focus on is the technology for tomorrow and for 10 years from now.
AI can turn out in many different ways.
But in this case, it isn't a self-driving car without any destination.
This is the car that we are driving.
We choose when to speed up and when to slow down.
We choose if we need to make a turn.
We choose what the AI of the future will be.
There's a vast playing field of all the things that artificial intelligence can become.
It will become many things.
And it's up to us now, in order to figure out what we need to put in place to make sure the outcomes of artificial intelligence are the ones that will be better for all of us.
Thank you.
(Applause)
I want to ask you all to consider for a second the very simple fact that, by far, most of what we know about the universe comes to us from light.
We can stand on the Earth and look up at the night sky and see stars with our bare eyes.
The Sun burns our peripheral vision.
We see light reflected off the Moon.
And in the time since Galileo pointed that rudimentary telescope at the celestial bodies, the known universe has come to us through light, across vast eras in cosmic history.
And with all of our modern telescopes, we've been able to collect this stunning silent movie of the universe -- these series of snapshots that go all the way back to the Big Bang.
And yet, the universe is not a silent movie because the universe isn't silent.
I'd like to convince you that the universe has a soundtrack and that soundtrack is played on space itself, because space can wobble like a drum.
It can ring out a kind of recording throughout the universe of some of the most dramatic events as they unfold.
Now we'd like to be able to add to a kind of glorious visual composition that we have of the universe -- a sonic composition.
And while we've never heard the sounds from space, we really should, in the next few years, start to turn up the volume on what's going on out there.
So in this ambition to capture songs from the universe, we turn our focus to black holes and the promise they have, because black holes can bang on space-time like mallets on a drum and have a very characteristic song, which I'd like to play for you -- some of our predictions for what that song will be like.
We might one day see a shadow a black hole can cast on a very bright background, but we haven't yet.
And yet black holes may be heard even if they're not seen, and that's because they bang on space-time like a drum.
Now we owe the idea that space can ring like a drum to Albert Einstein -- to whom we owe so much.
Einstein realized that if space were empty, if the universe were empty, it would be like this picture, except for maybe without the helpful grid drawn on it.
But if we were freely falling through the space, even without this helpful grid, we might be able to paint it ourselves, because we would notice that we traveled along straight lines, undeflected straight paths through the universe.
Einstein also realized -- and this is the real meat of the matter -- that if you put energy or mass in the universe, it would curve space, and a freely falling object would pass by, let's say, the Sun and it would be deflected along the natural curves in the space.
It was Einstein's great general theory of relativity.
Now even light will be bent by those paths.
And you can be bent so much that you're caught in orbit around the Sun, as the Earth is, or the Moon around the Earth.
These are the natural curves in space.
What Einstein did not realize was that, if you took our Sun and you crushed it down to six kilometers -- so you took a million times the mass of the Earth and you crushed it to six kilometers across, you would make a black hole, an object so dense that if light veered too close, it would never escape -- a dark shadow against the universe.
But Einstein always thought black holes were a mathematical oddity.
He did not believe they existed in nature.
He thought nature would protect us from their formation.
It was decades before the term "black hole" was coined and people realized that black holes are real astrophysical objects -- in fact they're the death state of very massive stars that collapse catastrophically at the end of their lifetime.
Now our Sun will not collapse to a black hole.
It's actually not massive enough.
But if we did a little thought experiment -- as Einstein was very fond of doing -- we could imagine putting the Sun crushed down to six kilometers, and putting a tiny little Earth around it in orbit, maybe 30 kilometers outside of the black-hole sun.
And it would be self-illuminated, because now the Sun's gone, we have no other source of light -- so let's make our little Earth self-illuminated.
And you would realize you could put the Earth in a happy orbit even 30 km outside of this crushed black hole.
This crushed black hole actually would fit inside Manhattan, more or less.
It might spill off into the Hudson a little bit before it destroyed the Earth.
But basically that's what we're talking about.
We're talking about an object that you could crush down to half the square area of Manhattan.
So we move this Earth very close -- 30 kilometers outside -- and we notice it's perfectly fine orbiting around the black hole.
There's a sort of myth that black holes devour everything in the universe, but you actually have to get very close to fall in.
But what's very impressive is that, from our vantage point, we can always see the Earth.
It cannot hide behind the black hole.
The light from the Earth, some of it falls in, but some of it gets lensed around and brought back to us.
So you can't hide anything behind a black hole.
If this were Battlestar Galactica and you're fighting the Cylons, don't hide behind the black hole.
They can see you.
Now, our Sun will not collapse to a black hole -- it's not massive enough -- but there are tens of thousands of black holes in our galaxy.
And if one were to eclipse the Milky Way, this is what it would look like.
We would see a shadow of that black hole against the hundred billion stars in the Milky Way Galaxy and its luminous dust lanes.
And if we were to fall towards this black hole, we would see all of that light lensed around it, and we could even start to cross into that shadow and really not notice that anything dramatic had happened.
It would be bad if we tried to fire our rockets and get out of there because we couldn't, anymore than light can escape.
But even though the black hole is dark from the outside, it's not dark on the inside, because all of the light from the galaxy can fall in behind us.
And even though, due to a relativistic effect known as time dilation, our clocks would seem to slow down relative to galactic time, it would look as though the evolution of the galaxy had been sped up and shot at us, right before we were crushed to death by the black hole.
It would be like a near-death experience where you see the light at the end of the tunnel, but it's a total death experience.
(Laughter) And there's no way of telling anybody about the light at the end of the tunnel.
Now we've never seen a shadow like this of a black hole, but black holes can be heard, even if they're not seen.
Imagine now taking an astrophysically realistic situation -- imagine two black holes that have lived a long life together.
Maybe they started as stars and collapsed to two black holes -- each one 10 times the mass of the Sun.
So now we're going to crush them down to 60 kilometers across.
They can be spinning hundreds of times a second.
At the end of their lives, they're going around each other very near the speed of light.
So they're crossing thousands of kilometers in a fraction of a second, and as they do so, they not only curve space, but they leave behind in their wake a ringing of space, an actual wave on space-time.
Space squeezes and stretches as it emanates out from these black holes banging on the universe.
And they travel out into the cosmos at the speed of light.
This computer simulation is due to a relativity group at NASA Goddard.
It took almost 30 years for anyone in the world to crack this problem.
This was one of the groups.
It shows two black holes in orbit around each other, again, with these helpfully painted curves.
And if you can see -- it's kind of faint -- but if you can see the red waves emanating out, those are the gravitational waves.
They're literally the sounds of space ringing, and they will travel out from these black holes at the speed of light as they ring down and coalesce to one spinning, quiet black hole at the end of the day.
If you were standing near enough, your ear would resonate with the squeezing and stretching of space.
You would literally hear the sound.
Now of course, your head would be squeezed and stretched unhelpfully, so you might have trouble understanding what's going on.
But I'd like to play for you the sound that we predict.
This is from my group -- a slightly less glamorous computer modeling.
Imagine a lighter black hole falling into a very heavy black hole.
The sound you're hearing is the light black hole banging on space each time it gets close.
If it gets far away, it's a little too quiet.
But it comes in like a mallet, and it literally cracks space, wobbling it like a drum.
And we can predict what the sound will be.
We know that, as it falls in, it gets faster and it gets louder.
And eventually, we're going to hear the little guy just fall into the bigger guy.
Now I've never heard it that loud -- it's actually more dramatic.
At home it sounds kind of anticlimactic.
It's sort of like ding, ding, ding.
This is another sound from my group.
No, I'm not showing you any images, because black holes don't leave behind helpful trails of ink, and space is not painted, showing you the curves.
But if you were to float by in space on a space holiday and you heard this, you want to get moving.
(Laughter) Want to get away from the sound.
Both black holes are moving.
Both black holes are getting closer together.
In this case, they're both wobbling quite a lot.
And then they're going to merge.
Now that chirp is very characteristic of black holes merging -- that it chirps up at the end.
Now that's our prediction for what we'll see.
Luckily we're at this safe distance in Long Beach, California.
And surely, somewhere in the universe two black holes have merged.
And surely, the space around us is ringing after traveling maybe a million light years, or a million years, at the speed of light to get to us.
But the sound is too quiet for any of us to ever hear.
There are very industrious experiments being built on Earth -- one called LIGO -- which will detect deviations in the squeezing and stretching of space at less than the fraction of a nucleus of an atom over four kilometers.
It's a remarkably ambitious experiment, and it's going to be at advanced sensitivity within the next few years -- to pick this up.
There's also a mission proposed for space, which hopefully will launch in the next ten years, called LISA.
And LISA will be able to see super-massive black holes -- black holes millions or billions of times the mass of the Sun.
In this Hubble image, we see two galaxies.
They look like they're frozen in some embrace.
And each one probably harbors a super-massive black hole at its core.
But they're not frozen; they're actually merging.
These two black holes are colliding, and they will merge over a billion-year time scale.
It's beyond our human perception to pick up a song of that duration.
But LISA could see the final stages of two super-massive black holes earlier in the universe's history, the last 15 minutes before they fall together.
And it's not just black holes, but it's also any big disturbance in the universe -- and the biggest of them all is the Big Bang.
When that expression was coined, it was derisive -- like, "Oh, who would believe in a Big Bang?"
This animation from my friends at Proton Studios shows looking at the Big Bang from the outside.
We don't ever want to do that actually. We want to be inside the universe because there's no such thing as standing outside the universe.
So imagine you're inside the Big Bang.
It's everywhere, it's all around you, and the space is wobbling chaotically.
Fourteen billion years pass and this song is still ringing all around us.
Galaxies form, and generations of stars form in those galaxies, and around one star, at least one star, is a habitable planet.
And here we are frantically building these experiments, doing these calculations, writing these computer codes.
Imagine a billion years ago, two black holes collided.
That song has been ringing through space for all that time.
We weren't even here.
It gets closer and closer -- 40,000 years ago, we're still doing cave paintings.
If it was the Big Bang we were going to pick up, it would sound like this.
It's literally the definition of noise.
It's white noise; it's such a chaotic ringing.
But it's around us everywhere, presumably, if it hasn't been wiped out by some other process in the universe.
And if we pick it up, it will be music to our ears because it will be the quiet echo of that moment of our creation, of our observable universe.
So within the next few years, we'll be able to turn up the soundtrack a little bit, render the universe in audio.
But if we detect those earliest moments, it'll bring us that much closer to an understanding of the Big Bang, which brings us that much closer to asking some of the hardest, most elusive, questions.
If we run the movie of our universe backwards, we know that there was a Big Bang in our past, and we might even hear the cacophonous sound of it, but was our Big Bang the only Big Bang?
I mean we have to ask, has it happened before?
Will it happen again?
I mean, in the spirit of rising to TED's challenge to reignite wonder, we can ask questions, at least for this last minute, that honestly might evade us forever.
But we have to ask: Is it possible that our universe is just a plume off of some greater history?
Or, is it possible that we're just a branch off of a multiverse -- each branch with its own Big Bang in its past -- maybe some of them with black holes playing drums, maybe some without -- maybe some with sentient life, and maybe some without -- not in our past, not in our future, but somehow fundamentally connected to us?
So we have to wonder, if there is a multiverse, in some other patch of that multiverse, are there creatures?
Here's my multiverse creatures.
Are there other creatures in the multiverse, wondering about us and wondering about their own origins?
And if they are, I can imagine them as we are, calculating, writing computer code, building instruments, trying to detect that faintest sound of their origins and wondering who else is out there.
Thank you. Thank you.
(Applause)
One winter morning, a couple of years ago, I was driving to work in Johannesburg, South Africa, and noticed a haze hanging over the city.
I make that drive on most days, so it was unusual that I hadn't noticed this before.
Johannesburg is known for its distinctive skyline, which I could barely see that morning.
It didn't take long for me to realize that I was looking at an enormous cloud of air pollution.
The contrast between the scenic environment I knew and this smog-covered skyline stirred up something within me.
I was appalled by the possibility of this city of bright and vivid sunsets being overrun by a dull haze.
At that moment, I felt an urge to do something about it, but I didn't know what.
All I knew was I couldn't just stand idly by.
The main challenge was, I didn't know much about environmental science air-quality management or atmospheric chemistry.
I am a computer engineer, and I was pretty sure I couldn't code my way out of this air pollution problem.
(Laughter) Who was I to do anything about this issue?
I was but a citizen.
In the following years, I learned a very important lesson, a lesson we all need to take to heart if we are to work towards a better future.
Even if you're not an expert in a particular domain, your outside expertise may hold the key to solving big problems within that domain.
Sometimes the unique perspective you have can result in unconventional thinking that can move the needle, but you need to be bold enough to try.
That's the only way you'll ever know.
What I knew back then was that if I was even going to try to make a difference, I had to get smart about air pollution first, and so I became a student again.
I did a bit of basic research and soon learned that air pollution is the world's biggest environmental health risk.
Data from the World Health Organization shows that almost 14 percent of all deaths worldwide in 2012 were attributable to household and ambient air pollution, with most occurring in low- and middle-income countries.
Ambient air pollution alone causes more deaths each year than malaria and HIV/AIDS.
In Africa, premature deaths from unsafe sanitation or childhood malnutrition pale in comparison to deaths due to air pollution, and it comes at a huge economic cost: over 400 billion US dollars as of 2013, according to a study by the Organisation for Economic Cooperation and Development.
Now, in my work, I explore new frontiers for artificial intelligence, where the symbiotic relationship between man and machine can find a beneficial footing and help us to make better decisions.
As I thought about the air pollution problem, it became clear that we needed to find a way to make better decisions about how we manage air pollution, and given the scale of the problem, it was necessary to do it in a collaborative way.
So I decided I'd better get to know some people working within the field.
I started to speak to officials from the City of Johannesburg and other surrounding cities, and I engaged the local scientific community, and I also made a few cold calls.
The process of engagement I embarked upon helped me to develop a deeper understanding of the problem.
It also helped me to avoid the trap people in my profession sometimes fall into when trying to innovate, where we are quick to apply a technology before we've firmly grasped the problem at hand.
I began to develop an idea about what I could do to improve the situation.
I started by simply asking myself how I could bring together in some meaningful way my skills in software engineering and artificial intelligence and the expertise of the people I'd reached out to.
I wanted to create an online air-quality management platform that would uncover trends in pollution and project into the future to determine what outcomes can be expected.
I was determined to see my idea translate into a practical solution, but I faced uncertainty and had no guarantee of success.
What I had was a very particular set of engineering skills, skills I'd acquired over my career (Laughter) that were new to people who had been working on the air pollution problem for so many years.
What I have come to realize is that sometimes just one fresh perspective, one new skill set, can make the conditions right for something remarkable to happen.
Our willpower and imagination are a guiding light, enabling us to chart new paths and navigate through obstacles.
Armed with a firmer understanding of the air pollution problem, and having managed to source over a decade's worth of data on air pollutant levels and the meteorological conditions for in and around Johannesburg, my colleagues from South Africa and China and myself created an air-quality decision support system that lives in the cloud.
This software system analyzes historical and real-time data to uncover the spatial-temporal trends in pollution.
We then used new machine learning technology to predict future levels of pollution for several different pollutants days in advance.
This means that citizens can make better decisions about their daily movements and about where to settle their families.
We can predict adverse pollution events ahead of time, identify heavy polluters, and they can be ordered by the relevant authorities to scale back their operations.
Through assisted scenario planning, city planners can also make better decisions about how to extend infrastructure, such as human settlements or industrial zones.
We completed a pilot of our technology that was run over a period of 120 days, covering all of South Africa.
Our results were confirmed when we demonstrated a tight correlation between the forecasting data and the data we were getting on the ground.
Through our leadership, we have brought cutting-edge, world-leading assets that can perform air-quality forecasting at an unprecedented resolution and accuracy, benefiting the city that I drove into one winter morning not very long ago, and thought to myself, "Something is wrong here. I wonder what can be done?"
So here is the point: What if I'd not investigated the problem of air pollution further?
What if I'd not shown some concern for the state of the environment and just hoped that someone, somewhere, was taking care of the matter?
What I have learned is that, when embarking on a challenging endeavor that advances a cause that we firmly believe in, it is important to focus on the possibility of success and consider the consequence of not acting.
We should not get distracted by resistance and opposition, but this should motivate us further.
So wherever you are in the world, the next time you find that there's some natural curiosity you have that is being piqued, and it's about something you care about, and you have some crazy or bold ideas, and perhaps it's outside the realm of your expertise, ask yourself this: Why not?
Why not just go ahead and tackle the problem as best as you can, in your own way?
You may be pleasantly surprised.
Thank you.
(Applause)
Many believe driving is an activity solely reserved for those who can see.
A blind person driving a vehicle safely and independently was thought to be an impossible task, until now.
Hello, my name is Dennis Hong, and we're bringing freedom and independence to the blind by building a vehicle for the visually impaired.
So before I talk about this car for the blind, let me briefly tell you about another project that I worked on called the DARPA Urban Challenge.
Now this was about building a robotic car that can drive itself.
You press start, nobody touches anything, and it can reach its destination fully autonomously.
So in 2007, our team won half a million dollars by placing third place in this competition.
So about that time, the National Federation of the Blind, or NFB, challenged the research committee about who can develop a car that lets a blind person drive safely and independently.
We decided to give it a try, because we thought, "Hey, how hard could it be?"
We have already an autonomous vehicle.
We just put a blind person in it and we're done, right?
(Laughter) We couldn't have been more wrong.
What NFB wanted was not a vehicle that can drive a blind person around, but a vehicle where a blind person can make active decisions and drive.
So we had to throw everything out the window and start from scratch.
So to test this crazy idea, we developed a small dune buggy prototype vehicle to test the feasibility.
And in the summer of 2009, we invited dozens of blind youth from all over the country and gave them a chance to take it for a spin.
It was an absolutely amazing experience.
But the problem with this car was it was designed to only be driven in a very controlled environment, in a flat, closed-off parking lot -- even the lanes defined by red traffic cones.
So with this success, we decided to take the next big step, to develop a real car that can be driven on real roads.
So how does it work?
Well, it's a rather complex system, but let me try to explain it, maybe simplify it.
So we have three steps.
We have perception, computation and non-visual interfaces.
Now obviously the driver cannot see, so the system needs to perceive the environment and gather information for the driver.
For that, we use an initial measurement unit.
So it measures acceleration, angular acceleration -- like a human ear, inner ear.
We fuse that information with a GPS unit to get an estimate of the location of the car.
We also use two cameras to detect the lanes of the road.
And we also use three laser range finders.
The lasers scan the environment to detect obstacles -- a car approaching from the front, the back and also any obstacles that run into the roads, any obstacles around the vehicle.
So all this vast amount of information is then fed into the computer, and the computer can do two things.
One is, first of all, process this information to have an understanding of the environment -- these are the lanes of the road, there's the obstacles -- and convey this information to the driver.
The system is also smart enough to figure out the safest way to operate the car.
So we can also generate instructions on how to operate the controls of the vehicle.
But the problem is this: How do we convey this information and instructions to a person who cannot see fast enough and accurate enough so he can drive?
So for this, we developed many different types of non-visual user interface technology.
So starting from a three-dimensional ping sound system, a vibrating vest, a click wheel with voice commands, a leg strip, even a shoe that applies pressure to the foot.
But today we're going to talk about three of these non-visual user interfaces.
Now the first interface is called a DriveGrip.
So these are a pair of gloves, and it has vibrating elements on the knuckle part so you can convey instructions about how to steer -- the direction and the intensity.
Another device is called SpeedStrip.
So this is a chair -- as a matter of fact, it's actually a massage chair.
We gut it out, and we rearrange the vibrating elements in different patterns, and we actuate them to convey information about the speed, and also instructions how to use the gas and the brake pedal.
So over here, you can see how the computer understands the environment, and because you cannot see the vibration, we actually put red LED's on the driver so that you can see what's happening.
This is the sensory data, and that data is transferred to the devices through the computer.
So these two devices, DriveGrip and SpeedStrip, are very effective.
But the problem is these are instructional cue devices.
So this is not really freedom, right?
The computer tells you how to drive -- turn left, turn right, speed up, stop.
We call this the "backseat-driver problem."
So we're moving away from the instructional cue devices, and we're now focusing more on the informational devices.
A good example for this informational non-visual user interface is called AirPix.
So think of it as a monitor for the blind.
So it's a small tablet, has many holes in it, and compressed air comes out, so it can actually draw images.
So even though you are blind, you can put your hand over it, you can see the lanes of the road and obstacles.
Actually, you can also change the frequency of the air coming out and possibly the temperature.
So it's actually a multi-dimensional user interface.
So here you can see the left camera, the right camera from the vehicle and how the computer interprets that and sends that information to the AirPix.
For this, we're showing a simulator, a blind person driving using the AirPix.
This simulator was also very useful for training the blind drivers and also quickly testing different types of ideas for different types of non-visual user interfaces.
So basically that's how it works.
But this vehicle is a prototype vehicle, and it's not going to be on the road until it's proven as safe as, or safer than, today's vehicle.
And I truly believe that this can happen.
But still, will the society, would they accept such a radical idea?
How are we going to handle insurance?
How are we going to issue driver's licenses?
There's many of these different kinds of hurdles besides technology challenges that we need to address before this becomes a reality.
Of course, the main goal of this project is to develop a car for the blind.
But potentially more important than this is the tremendous value of the spin-off technology that can come from this project.
The sensors that are used can see through the dark, the fog and rain.
And together with this new type of interfaces, we can use these technologies and apply them to safer cars for sighted people.
Or for the blind, everyday home appliances -- in the educational setting, in the office setting.
Just imagine, in a classroom a teacher writes on the blackboard and a blind student can see what's written and read using these non-visual interfaces.
This is priceless.
So today, the things I've showed you today, is just the beginning.
Thank you very much.
(Applause)
As an artist, connection is very important to me.
Through my work I'm trying to articulate that humans are not separate from nature and that everything is interconnected.
I first went to Antarctica almost 10 years ago, where I saw my first icebergs.
I was in awe.
My heart beat fast, my head was dizzy, trying to comprehend what it was that stood in front of me.
The icebergs around me were almost 200 feet out of the water, and I could only help but wonder that this was one snowflake on top of another snowflake, year after year.
Icebergs are born when they calve off of glaciers or break off of ice shelves.
Each iceberg has its own individual personality.
They have a distinct way of interacting with their environment and their experiences.
Some refuse to give up and hold on to the bitter end, while others can't take it anymore and crumble in a fit of dramatic passion.
It's easy to think, when you look at an iceberg, that they're isolated, that they're separate and alone, much like we as humans sometimes view ourselves.
But the reality is far from it.
As an iceberg melts, I am breathing in its ancient atmosphere.
As the iceberg melts, it is releasing mineral-rich fresh water that nourishes many forms of life.
I approach photographing these icebergs as if I'm making portraits of my ancestors, knowing that in these individual moments they exist in that way and will never exist that way again.
It is not a death when they melt; it is not an end, but a continuation of their path through the cycle of life.
Some of the ice in the icebergs that I photograph is very young -- a couple thousand years old.
And some of the ice is over 100,000 years old.
The last pictures I'd like to show you are of an iceberg that I photographed in Qeqetarsuaq, Greenland.
It's a very rare occasion that you get to actually witness an iceberg rolling.
So here it is.
You can see on the left side a small boat.
That's about a 15-foot boat.
And I'd like you to pay attention to the shape of the iceberg and where it is at the waterline.
You can see here, it begins to roll, and the boat has moved to the other side, and the man is standing there.
This is an average-size Greenlandic iceberg.
It's about 120 feet above the water, or 40 meters.
And this video is real time.
(Music) And just like that, the iceberg shows you a different side of its personality.
Thank you.
(Applause)
Do you know how many species of flowering plants there are?
There are a quarter of a million -- at least those are the ones we know about -- a quarter of a million species of flowering plants.
And flowers are a real bugger.
They're really difficult for plants to produce.
They take an enormous amount of energy and a lot of resources.
Why would they go to that bother?
And the answer of course, like so many things in the world, is sex.
I know what's on your mind when you're looking at these pictures.
And the reason that sexual reproduction is so important -- there are lots of other things that plants can do to reproduce.
You can take cuttings; they can sort of have sex with themselves; they can pollinate themselves.
But they really need to spread their genes to mix with other genes so that they can adapt to environmental niches.
Evolution works that way.
Now the way that plants transmit that information is through pollen.
Some of you may have seen some of these pictures before.
As I say, every home should have a scanning electron microscope to be able to see these.
And there is as many different kinds of pollen as there are flowering plants.
And that's actually rather useful for forensics and so on.
Most pollen that causes hay fever for us is from plants that use the wind to disseminate the pollen, and that's a very inefficient process, which is why it gets up our noses so much.
Because you have to chuck out masses and masses of it, hoping that your sex cells, your male sex cells, which are held within the pollen, will somehow reach another flower just by chance.
So all the grasses, which means all of the cereal crops, and most of the trees have wind-borne pollen.
But most species actually use insects to do their bidding, and that's more intelligent in a way, because the pollen, they don't need so much of it.
The insects and other species can take the pollen, transfer it directly to where it's required.
So we're aware, obviously, of the relationship between insects and plants.
There's a symbiotic relationship there, whether it's flies or birds or bees, they're getting something in return, and that something in return is generally nectar.
Sometimes that symbiosis has led to wonderful adaptations -- the hummingbird hawk-moth is beautiful in its adaptation.
The plant gets something, and the hawk-moth spreads the pollen somewhere else.
Plants have evolved to create little landing strips here and there for bees that might have lost their way.
There are markings on many plants that look like other insects.
These are the anthers of a lily, cleverly done so that when the unsuspecting insect lands on it, the anther flips up and whops it on the back with a great load of pollen that it then goes to another plant with.
And there's an orchid that might look to you as if it's got jaws, and in a way, it has; it forces the insect to crawl out, getting covered in pollen that it takes somewhere else.
Orchids: there are 20,000, at least, species of orchids -- amazingly, amazingly diverse.
And they get up to all sorts of tricks.
They have to try and attract pollinators to do their bidding.
This orchid, known as Darwin's orchid, because it's one that he studied and made a wonderful prediction when he saw it -- you can see that there's a very long nectar tube that descends down from the orchid.
And basically what the insect has to do -- we're in the middle of the flower -- it has to stick its little proboscis right into the middle of that and all the way down that nectar tube to get to the nectar.
And Darwin said, looking at this flower, "I guess something has coevolved with this."
And sure enough, there's the insect.
And I mean, normally it kind of rolls it away, but in its erect form, that's what it looks like.
Now you can imagine that if nectar is such a valuable thing and expensive for the plant to produce and it attracts lots of pollinators, then, just as in human sex, people might start to deceive.
They might say, "I've got a bit of nectar. Do you want to come and get it?"
Now this is a plant.
This is a plant here that insects in South Africa just love, and they've evolved with a long proboscis to get the nectar at the bottom.
And this is the mimic.
So this is a plant that is mimicking the first plant.
And here is the long-probosced fly that has not gotten any nectar from the mimic, because the mimic doesn't give it any nectar. It thought it would get some.
So not only has the fly not got the nectar from the mimic plant, it's also -- if you look very closely just at the head end, you can see that it's got a bit of pollen that it would be transmitting to another plant, if only some botanist hadn't come along and stuck it to a blue piece of card.
(Laughter) Now deceit carries on through the plant kingdom.
This flower with its black dots: they might look like black dots to us, but if I tell you, to a male insect of the right species, that looks like two females who are really, really hot to trot.
(Laughter) And when the insect gets there and lands on it, dousing itself in pollen, of course, that it's going to take to another plant, if you look at the every-home-should-have-one scanning electron microscope picture, you can see that there are actually some patterning there, which is three-dimensional.
So it probably even feels good for the insect, as well as looking good.
And these electron microscope pictures -- here's one of an orchid mimicking an insect -- you can see that different parts of the structure have different colors and different textures to our eye, have very, very different textures to what an insect might perceive.
And this one is evolved to mimic a glossy metallic surface you see on some beetles.
And under the scanning electron microscope, you can see the surface there -- really quite different from the other surfaces we looked at.
Sometimes the whole plant mimics an insect, even to us.
I mean, I think that looks like some sort of flying animal or beast.
It's a wonderful, amazing thing.
This one's clever. It's called obsidian.
I think of it as insidium sometimes.
To the right species of bee, this looks like another very aggressive bee, and it goes and bonks it on the head lots and lots of times to try and drive it away, and, of course, covers itself with pollen.
The other thing it does is that this plant mimics another orchid that has a wonderful store of food for insects.
And this one doesn't have anything for them.
So it's deceiving on two levels -- fabulous.
(Laughter) Here we see ylang ylang, the component of many perfumes.
I actually smelt someone with some on earlier.
And the flowers don't really have to be that gaudy.
They're sending out a fantastic array of scent to any insect that'll have it.
This one doesn't smell so good.
This is a flower that really, really smells pretty nasty and is designed, again, evolved, to look like carrion.
So flies love this.
They fly in and they pollinate.
This, which is helicodiceros, is also known as dead horse arum.
I don't know what a dead horse actually smells like, but this one probably smells pretty much like it.
It's really horrible.
And blowflies just can't help themselves.
They fly into this thing, and they fly all the way down it.
They lay their eggs in it, thinking it's a nice bit of carrion, and not realizing that there's no food for the eggs, that the eggs are going to die, but the plant, meanwhile, has benefited, because the bristles release and the flies disappear to pollinate the next flower -- fantastic.
Here's arum, arum maculatum, "lords and ladies," or "cuckoo-pint" in this country.
I photographed this thing last week in Dorset.
This thing heats up by about 15 degrees above ambient temperature -- amazing.
And if you look down into it, there's this sort of dam past the spadix, flies get attracted by the heat -- which is boiling off volatile chemicals, little midges -- and they get trapped underneath in this container.
They drink this fabulous nectar and then they're all a bit sticky.
At night they get covered in pollen, which showers down over them, and then the bristles that we saw above, they sort of wilt and allow all these midges out, covered in pollen -- fabulous thing.
Now if you think that's fabulous, this is one of my great favorites.
This is the philodendron selloum.
For anyone here from Brazil, you'll know about this plant.
This is the most amazing thing.
That sort of phallic bit there is about a foot long.
And it does something that no other plant that I know of does, and that is that when it flowers -- that's the spadix in the middle there -- for a period of about two days, it metabolizes in a way which is rather similar to mammals.
So instead of having starch, which is the food of plants, it takes something rather similar to brown fat and burns it at such a rate that it's burning fat, metabolizing, about the rate of a small cat.
And that's twice the energy output, weight for weight, than a hummingbird -- absolutely astonishing.
This thing does something else which is unusual.
Not only will it raise itself to 115 Fahrenheit, 43 or 44 degrees Centigrade, for two days, but it keeps constant temperature.
There's a thermoregulation mechanism in there that keeps constant temperature.
Now why does it do this, I hear you ask.
Now wouldn't you know it, there's some beetles that just love to make love at that temperature.
And they get inside, and they get it all on.
(Laughter) And the plant showers them with pollen, and off they go and pollinate.
And what a wonderful thing it is.
Now most pollinators that we think about are insects, but actually in the tropics, many birds and butterflies pollinate.
And many of the tropical flowers are red, and that's because butterflies and birds see similarly to us, we think, and can see the color red very well.
But if you look at the spectrum, birds and us, we see red, green and blue and see that spectrum.
Insects see green, blue and ultraviolet, and they see various shades of ultraviolet.
So there's something that goes on off the end there.
And wouldn't it be great if we could somehow see what that is, I hear you ask.
Well yes we can.
So what is an insect seeing?
Last week I took these pictures of rock rose, helianthemum, in Dorset.
These are little yellow flowers like we all see, little yellow flowers all over the place.
And this is what it looks like with visible light.
This is what it looks like if you take out the red.
Most bees don't perceive red.
And then I put some ultraviolet filters on my camera and took a very, very long exposure with the particular frequencies of ultraviolet light and this is what I got.
And that's a real fantastic bull's eye.
Now we don't know exactly what a bee sees, any more than you know what I'm seeing when I call this red.
We can't know what's going on in -- let alone an insect's -- another human being's mind.
But the contrast will look something like that, so standing out a lot from the background.
Here's another little flower -- different range of ultraviolet frequencies, different filters to match the pollinators.
And that's the sort of thing that it would be seeing.
Just in case you think that all yellow flowers have this property -- no flower was damaged in the process of this shot; it was just attached to the tripod, not killed -- then under ultraviolet light, look at that.
And that could be the basis of a sunscreen because sunscreens work by absorbing ultraviolet light.
So maybe the chemical in that would be useful.
Finally, there's one of evening primrose that Bjorn Rorslett from Norway sent me -- fantastic hidden pattern.
And I love the idea of something hidden.
I think there's something poetic here, that these pictures taken with ultraviolet filter, the main use of that filter is for astronomers to take pictures of Venus -- actually the clouds of Venus.
That's the main use of that filter.
Venus, of course, is the god of love and fertility, which is the flower story.
And just as flowers spend a lot of effort trying to get pollinators to do their bidding, they've also somehow managed to persuade us to plant great fields full of them and give them to each other at times of birth and death, and particularly at marriage, which, when you think of it, is the moment that encapsulates the transfer of genetic material from one organism to another.
Thank you very much.
(Applause)

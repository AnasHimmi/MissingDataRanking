{
    "submission_name": "mT5_large",
    "param_count": "-",
    "cs_restaurants_val": {
        "predictions_file": "mT5_large/cs_restaurants_val",
        "N": 781,
        "msttr-100": 0.5691,
        "msttr-100_nopunct": 0.59727,
        "total_length": 7857,
        "mean_pred_length": 10.060179257362355,
        "std_pred_length": 3.8811029054897834,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.04594628993254423,
        "vocab_size-1": 361,
        "unique-1": 103,
        "entropy-1": 6.598890507576971,
        "distinct-2": 0.13482193329564726,
        "vocab_size-2": 954,
        "unique-2": 387,
        "entropy-2": 8.43591031956862,
        "cond_entropy-2": 1.5393646115123536,
        "distinct-3": 0.2374900714853058,
        "vocab_size-3": 1495,
        "unique-3": 729,
        "entropy-3": 9.260803794456205,
        "cond_entropy-3": 0.7460931771163349,
        "total_length-nopunct": 6698,
        "mean_pred_length-nopunct": 8.57618437900128,
        "std_pred_length-nopunct": 3.460906054247137,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.0532994923857868,
        "vocab_size-1-nopunct": 357,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.782538524119743,
        "distinct-2-nopunct": 0.14399188778097008,
        "vocab_size-2-nopunct": 852,
        "unique-2-nopunct": 350,
        "entropy-2-nopunct": 8.338818787182655,
        "cond_entropy-2-nopunct": 1.571847315231582,
        "distinct-3-nopunct": 0.2612928348909657,
        "vocab_size-3-nopunct": 1342,
        "unique-3-nopunct": 671,
        "entropy-3-nopunct": 9.194806528860981,
        "cond_entropy-3-nopunct": 0.773067919263402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_val.json",
        "rouge1": {
            "precision": 0.54774,
            "recall": 0.50755,
            "fmeasure": 0.51253
        },
        "rouge2": {
            "precision": 0.32164,
            "recall": 0.29723,
            "fmeasure": 0.29961
        },
        "rougeL": {
            "precision": 0.49515,
            "recall": 0.45953,
            "fmeasure": 0.46393
        },
        "rougeLsum": {
            "precision": 0.49515,
            "recall": 0.45953,
            "fmeasure": 0.46393
        },
        "bleu": 17.52933,
        "nist": 3.931462631911082,
        "local_recall": {
            "1": 0.44837278106508877
        },
        "nubia": {
            "semantic_relation": 3.27555,
            "contradiction": 25.75973,
            "irrelevancy": 27.15708,
            "logical_agreement": 47.0832,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.84459,
            "nubia_score": 0.44179
        },
        "meteor": 0.23299172330524734,
        "bleurt": -0.11425,
        "bertscore": {
            "precision": 0.90436,
            "recall": 0.90059,
            "f1": 0.90224
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.61637,
        "msttr-100_nopunct": 0.67739,
        "total_length": 11388,
        "mean_pred_length": 24.756521739130434,
        "std_pred_length": 9.319070026701747,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 60,
        "distinct-1": 0.152880224798033,
        "vocab_size-1": 1741,
        "unique-1": 582,
        "entropy-1": 8.592519656391238,
        "distinct-2": 0.3654831625183016,
        "vocab_size-2": 3994,
        "unique-2": 1982,
        "entropy-2": 11.211273888607876,
        "cond_entropy-2": 2.4155941591971457,
        "distinct-3": 0.5172907909820404,
        "vocab_size-3": 5415,
        "unique-3": 3301,
        "entropy-3": 11.987999985622581,
        "cond_entropy-3": 0.7940796519030964,
        "total_length-nopunct": 9282,
        "mean_pred_length-nopunct": 20.178260869565218,
        "std_pred_length-nopunct": 8.128236159363349,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.18681318681318682,
        "vocab_size-1-nopunct": 1734,
        "unique-1-nopunct": 581,
        "entropy-1-nopunct": 9.291503588602005,
        "distinct-2-nopunct": 0.41895261845386533,
        "vocab_size-2-nopunct": 3696,
        "unique-2-nopunct": 2006,
        "entropy-2-nopunct": 11.246290555491875,
        "cond_entropy-2-nopunct": 2.008179170507271,
        "distinct-3-nopunct": 0.5673283903372399,
        "vocab_size-3-nopunct": 4744,
        "unique-3-nopunct": 3116,
        "entropy-3-nopunct": 11.839906467823354,
        "cond_entropy-3-nopunct": 0.617426893904783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.35872,
            "recall": 0.36272,
            "fmeasure": 0.35715
        },
        "rouge2": {
            "precision": 0.16848,
            "recall": 0.1687,
            "fmeasure": 0.16569
        },
        "rougeL": {
            "precision": 0.35182,
            "recall": 0.35627,
            "fmeasure": 0.35033
        },
        "rougeLsum": {
            "precision": 0.35182,
            "recall": 0.35627,
            "fmeasure": 0.35033
        },
        "bleu": 48.2251,
        "nist": 8.762246773369233,
        "local_recall": {
            "1": 0.2776077885952712,
            "2": 0.6711148179038088,
            "3": 0.8892443022790884,
            "4": 1.0,
            "5": 0.5,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 3.98628,
            "contradiction": 19.27504,
            "irrelevancy": 21.34471,
            "logical_agreement": 59.38025,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.51376,
            "nubia_score": 0.82911
        },
        "meteor": 0.6395986406044729,
        "bleurt": 0.16134,
        "bertscore": {
            "precision": 0.95444,
            "recall": 0.95204,
            "f1": 0.95258
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "mT5_large/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.64712,
        "msttr-100_nopunct": 0.67992,
        "total_length": 13279,
        "mean_pred_length": 26.558,
        "std_pred_length": 13.943408335123806,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 97,
        "distinct-1": 0.12945251901498606,
        "vocab_size-1": 1719,
        "unique-1": 786,
        "entropy-1": 8.208413671349566,
        "distinct-2": 0.4140386571719227,
        "vocab_size-2": 5291,
        "unique-2": 3463,
        "entropy-2": 11.456810517616102,
        "cond_entropy-2": 3.0905994123053158,
        "distinct-3": 0.6476911800635231,
        "vocab_size-3": 7953,
        "unique-3": 6295,
        "entropy-3": 12.524845905170784,
        "cond_entropy-3": 1.109803093312506,
        "total_length-nopunct": 11852,
        "mean_pred_length-nopunct": 23.704,
        "std_pred_length-nopunct": 12.627445664108002,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.14402632467094162,
        "vocab_size-1-nopunct": 1707,
        "unique-1-nopunct": 785,
        "entropy-1-nopunct": 8.46707579028947,
        "distinct-2-nopunct": 0.4271494009866103,
        "vocab_size-2-nopunct": 4849,
        "unique-2-nopunct": 3305,
        "entropy-2-nopunct": 11.329558604459981,
        "cond_entropy-2-nopunct": 2.9796836280108643,
        "distinct-3-nopunct": 0.6537043862882418,
        "vocab_size-3-nopunct": 7094,
        "unique-3-nopunct": 5694,
        "entropy-3-nopunct": 12.355752060183352,
        "cond_entropy-3-nopunct": 1.0585260777997594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "rouge1": {
            "precision": 0.66762,
            "recall": 0.69624,
            "fmeasure": 0.67147
        },
        "rouge2": {
            "precision": 0.41246,
            "recall": 0.43266,
            "fmeasure": 0.41532
        },
        "rougeL": {
            "precision": 0.52531,
            "recall": 0.54934,
            "fmeasure": 0.52859
        },
        "rougeLsum": {
            "precision": 0.52531,
            "recall": 0.54934,
            "fmeasure": 0.52859
        },
        "bleu": 37.84107,
        "nist": 7.4836367257687595,
        "local_recall": {
            "1": 0.23269914279740747,
            "2": 0.5517715858273133,
            "3": 0.8121527155404195,
            "4": 0.7777777777777778,
            "5": 0.7272727272727273
        },
        "nubia": {
            "semantic_relation": 3.94948,
            "contradiction": 26.76498,
            "irrelevancy": 14.58926,
            "logical_agreement": 58.64576,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.68641,
            "nubia_score": 0.62414
        },
        "meteor": 0.3505051843077886,
        "bleurt": -0.01571,
        "bertscore": {
            "precision": 0.89851,
            "recall": 0.90354,
            "f1": 0.89935
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72892,
        "msttr-100_nopunct": 0.77415,
        "total_length": 7473,
        "mean_pred_length": 20.81615598885794,
        "std_pred_length": 9.260673476905579,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3579553057674294,
        "vocab_size-1": 2675,
        "unique-1": 1949,
        "entropy-1": 9.169092875128287,
        "distinct-2": 0.8344110205229126,
        "vocab_size-2": 5936,
        "unique-2": 5505,
        "entropy-2": 12.196322045700507,
        "cond_entropy-2": 2.775686154122889,
        "distinct-3": 0.9613619541080681,
        "vocab_size-3": 6494,
        "unique-3": 6386,
        "entropy-3": 12.578535338759838,
        "cond_entropy-3": 0.4024308993694754,
        "total_length-nopunct": 6591,
        "mean_pred_length-nopunct": 18.35933147632312,
        "std_pred_length-nopunct": 8.059086506490225,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40388408435745715,
        "vocab_size-1-nopunct": 2662,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.522437969113502,
        "distinct-2-nopunct": 0.8629653401797176,
        "vocab_size-2-nopunct": 5378,
        "unique-2-nopunct": 5029,
        "entropy-2-nopunct": 12.141330080564511,
        "cond_entropy-2-nopunct": 2.7548271047488933,
        "distinct-3-nopunct": 0.9816107611101652,
        "vocab_size-3-nopunct": 5765,
        "unique-3-nopunct": 5685,
        "entropy-3-nopunct": 12.477857403520586,
        "cond_entropy-3-nopunct": 0.3587983845878242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84966,
            "recall": 0.81593,
            "fmeasure": 0.82379
        },
        "rouge2": {
            "precision": 0.71247,
            "recall": 0.68636,
            "fmeasure": 0.69017
        },
        "rougeL": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "bleu": 68.84591,
        "nist": 11.338523983358163,
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.17752234993614305,
            "3": 0.437636761487965,
            "4": 0.5768621236133122,
            "5": 0.6728971962616822,
            "6": 0.7874396135265701,
            "7": 0.8953799159984727
        },
        "nubia": {
            "semantic_relation": 4.3706,
            "contradiction": 4.05805,
            "irrelevancy": 17.82847,
            "logical_agreement": 78.11348,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.92526,
            "nubia_score": 0.71246
        },
        "meteor": 0.47385603354829703,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95042,
            "f1": 0.94997
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.56307,
        "msttr-100_nopunct": 0.59929,
        "total_length": 10118,
        "mean_pred_length": 12.016627078384799,
        "std_pred_length": 4.0548155033142494,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.05593990907293932,
        "vocab_size-1": 566,
        "unique-1": 205,
        "entropy-1": 6.709318470928623,
        "distinct-2": 0.15222078482104356,
        "vocab_size-2": 1412,
        "unique-2": 680,
        "entropy-2": 8.451311270493665,
        "cond_entropy-2": 1.564228147542923,
        "distinct-3": 0.24922930993597345,
        "vocab_size-3": 2102,
        "unique-3": 1292,
        "entropy-3": 9.096845187923597,
        "cond_entropy-3": 0.7720706598747012,
        "total_length-nopunct": 8552,
        "mean_pred_length-nopunct": 10.156769596199524,
        "std_pred_length-nopunct": 3.454025572050281,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.0657156220767072,
        "vocab_size-1-nopunct": 562,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 6.921227399434076,
        "distinct-2-nopunct": 0.15395590142671856,
        "vocab_size-2-nopunct": 1187,
        "unique-2-nopunct": 588,
        "entropy-2-nopunct": 8.28524060439648,
        "cond_entropy-2-nopunct": 1.5940076043675577,
        "distinct-3-nopunct": 0.2628130460104834,
        "vocab_size-3-nopunct": 1805,
        "unique-3-nopunct": 1140,
        "entropy-3-nopunct": 8.95423036463305,
        "cond_entropy-3-nopunct": 0.8530390101552029,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.48336,
            "recall": 0.4955,
            "fmeasure": 0.47502
        },
        "rouge2": {
            "precision": 0.28275,
            "recall": 0.292,
            "fmeasure": 0.27903
        },
        "rougeL": {
            "precision": 0.42993,
            "recall": 0.44285,
            "fmeasure": 0.42375
        },
        "rougeLsum": {
            "precision": 0.42993,
            "recall": 0.44285,
            "fmeasure": 0.42375
        },
        "bleu": 16.81699,
        "nist": 3.6772465985749125,
        "local_recall": {
            "1": 0.4764477694652258
        },
        "nubia": {
            "semantic_relation": 3.16974,
            "contradiction": 21.93488,
            "irrelevancy": 32.45387,
            "logical_agreement": 45.61125,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.6694,
            "nubia_score": 0.46732
        },
        "meteor": 0.24005517809317412,
        "bleurt": -0.17988,
        "bertscore": {
            "precision": 0.89509,
            "recall": 0.90232,
            "f1": 0.89844
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.63432,
        "msttr-100_nopunct": 0.67727,
        "total_length": 3797,
        "mean_pred_length": 10.289972899728998,
        "std_pred_length": 3.2825286454513485,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.21306294442981302,
        "vocab_size-1": 809,
        "unique-1": 443,
        "entropy-1": 7.487500749163054,
        "distinct-2": 0.5233372228704785,
        "vocab_size-2": 1794,
        "unique-2": 1248,
        "entropy-2": 10.209543291688082,
        "cond_entropy-2": 2.282314633055989,
        "distinct-3": 0.7123242889833279,
        "vocab_size-3": 2179,
        "unique-3": 1766,
        "entropy-3": 10.795462432247644,
        "cond_entropy-3": 0.6911037692878637,
        "total_length-nopunct": 3336,
        "mean_pred_length-nopunct": 9.040650406504065,
        "std_pred_length-nopunct": 3.0347536404578532,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.23980815347721823,
        "vocab_size-1-nopunct": 800,
        "unique-1-nopunct": 440,
        "entropy-1-nopunct": 7.762499553349392,
        "distinct-2-nopunct": 0.49612403100775193,
        "vocab_size-2-nopunct": 1472,
        "unique-2-nopunct": 1009,
        "entropy-2-nopunct": 9.877712724248923,
        "cond_entropy-2-nopunct": 2.441612270371021,
        "distinct-3-nopunct": 0.693225558121632,
        "vocab_size-3-nopunct": 1801,
        "unique-3-nopunct": 1443,
        "entropy-3-nopunct": 10.495171101718347,
        "cond_entropy-3-nopunct": 0.7500981965329511,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.7713,
            "recall": 0.75918,
            "fmeasure": 0.7573
        },
        "rouge2": {
            "precision": 0.54388,
            "recall": 0.53526,
            "fmeasure": 0.53297
        },
        "rougeL": {
            "precision": 0.68107,
            "recall": 0.67031,
            "fmeasure": 0.66827
        },
        "rougeLsum": {
            "precision": 0.68107,
            "recall": 0.67031,
            "fmeasure": 0.66827
        },
        "bleu": 52.44262,
        "nist": 8.424356828894352,
        "local_recall": {
            "1": 0.2399364406779661,
            "2": 0.6435562805872757,
            "3": 0.849269588313413,
            "4": 0.9736842105263158
        },
        "nubia": {
            "semantic_relation": 4.518,
            "contradiction": 8.42077,
            "irrelevancy": 8.55409,
            "logical_agreement": 83.02514,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.37121,
            "nubia_score": 0.78814
        },
        "meteor": 0.43408299070549833,
        "bleurt": 0.29141,
        "bertscore": {
            "precision": 0.93529,
            "recall": 0.93563,
            "f1": 0.93437
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.76048,
        "msttr-100_nopunct": 0.88294,
        "total_length": 2173,
        "mean_pred_length": 8.588932806324111,
        "std_pred_length": 2.718149373240524,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.4247583985273815,
        "vocab_size-1": 923,
        "unique-1": 629,
        "entropy-1": 8.3890504456878,
        "distinct-2": 0.7604166666666666,
        "vocab_size-2": 1460,
        "unique-2": 1192,
        "entropy-2": 10.277242370544734,
        "cond_entropy-2": 1.1915759847611014,
        "distinct-3": 0.8722255548890222,
        "vocab_size-3": 1454,
        "unique-3": 1291,
        "entropy-3": 10.41444334943906,
        "cond_entropy-3": 0.14110865050628352,
        "total_length-nopunct": 1741,
        "mean_pred_length-nopunct": 6.881422924901186,
        "std_pred_length-nopunct": 2.3661334912901433,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.527283170591614,
        "vocab_size-1-nopunct": 918,
        "unique-1-nopunct": 629,
        "entropy-1-nopunct": 9.133854633751346,
        "distinct-2-nopunct": 0.7788978494623656,
        "vocab_size-2-nopunct": 1159,
        "unique-2-nopunct": 968,
        "entropy-2-nopunct": 9.95439490991514,
        "cond_entropy-2-nopunct": 0.9502108101501446,
        "distinct-3-nopunct": 0.8793522267206477,
        "vocab_size-3-nopunct": 1086,
        "unique-3-nopunct": 976,
        "entropy-3-nopunct": 9.993000799798208,
        "cond_entropy-3-nopunct": 0.11015137684701964,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.34794,
            "recall": 0.34525,
            "fmeasure": 0.34493
        },
        "rouge2": {
            "precision": 0.18989,
            "recall": 0.18731,
            "fmeasure": 0.18773
        },
        "rougeL": {
            "precision": 0.3453,
            "recall": 0.34278,
            "fmeasure": 0.34239
        },
        "rougeLsum": {
            "precision": 0.3453,
            "recall": 0.34278,
            "fmeasure": 0.34239
        },
        "bleu": 63.22436,
        "nist": 8.79832349764662,
        "local_recall": {
            "1": 0.4,
            "2": 0.7391910739191074,
            "3": 0.8156996587030717,
            "4": 0.9142857142857143,
            "5": 0.9090909090909091,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.25588,
            "contradiction": 20.52017,
            "irrelevancy": 19.36467,
            "logical_agreement": 60.11515,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.90687,
            "nubia_score": 0.85964
        },
        "meteor": 0.77441428932878,
        "bleurt": 0.42238,
        "bertscore": {
            "precision": 0.97173,
            "recall": 0.96985,
            "f1": 0.9703
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72892,
        "msttr-100_nopunct": 0.77415,
        "total_length": 7473,
        "mean_pred_length": 20.81615598885794,
        "std_pred_length": 9.260673476905579,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3579553057674294,
        "vocab_size-1": 2675,
        "unique-1": 1949,
        "entropy-1": 9.169092875128287,
        "distinct-2": 0.8344110205229126,
        "vocab_size-2": 5936,
        "unique-2": 5505,
        "entropy-2": 12.196322045700507,
        "cond_entropy-2": 2.775686154122889,
        "distinct-3": 0.9613619541080681,
        "vocab_size-3": 6494,
        "unique-3": 6386,
        "entropy-3": 12.578535338759838,
        "cond_entropy-3": 0.4024308993694754,
        "total_length-nopunct": 6591,
        "mean_pred_length-nopunct": 18.35933147632312,
        "std_pred_length-nopunct": 8.059086506490225,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40388408435745715,
        "vocab_size-1-nopunct": 2662,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.522437969113502,
        "distinct-2-nopunct": 0.8629653401797176,
        "vocab_size-2-nopunct": 5378,
        "unique-2-nopunct": 5029,
        "entropy-2-nopunct": 12.141330080564511,
        "cond_entropy-2-nopunct": 2.7548271047488933,
        "distinct-3-nopunct": 0.9816107611101652,
        "vocab_size-3-nopunct": 5765,
        "unique-3-nopunct": 5685,
        "entropy-3-nopunct": 12.477857403520586,
        "cond_entropy-3-nopunct": 0.3587983845878242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84966,
            "recall": 0.81593,
            "fmeasure": 0.82379
        },
        "rouge2": {
            "precision": 0.71247,
            "recall": 0.68636,
            "fmeasure": 0.69017
        },
        "rougeL": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "bleu": 68.84591,
        "nist": 11.338523983358163,
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.17752234993614305,
            "3": 0.437636761487965,
            "4": 0.5768621236133122,
            "5": 0.6728971962616822,
            "6": 0.7874396135265701,
            "7": 0.8953799159984727
        },
        "nubia": {
            "semantic_relation": 4.3706,
            "contradiction": 4.05805,
            "irrelevancy": 17.82847,
            "logical_agreement": 78.11348,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.92526,
            "nubia_score": 0.71246
        },
        "meteor": 0.47385603354829703,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95042,
            "f1": 0.94997
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.14,
        "msttr-100_nopunct": 0.12,
        "total_length": 2384,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.00587248322147651,
        "vocab_size-1": 14,
        "unique-1": 0,
        "entropy-1": 3.702819531114783,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 15,
        "unique-2": 0,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.22388309575274976,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 14,
        "unique-3": 0,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 1788,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.04623,
            "recall": 0.11791,
            "fmeasure": 0.06496
        },
        "rouge2": {
            "precision": 0.01382,
            "recall": 0.0449,
            "fmeasure": 0.02049
        },
        "rougeL": {
            "precision": 0.04586,
            "recall": 0.11743,
            "fmeasure": 0.06454
        },
        "rougeLsum": {
            "precision": 0.04586,
            "recall": 0.11743,
            "fmeasure": 0.06454
        },
        "bleu": 0.27255,
        "nist": 0.28922102101257324,
        "local_recall": {
            "1": 0.05630026809651475
        },
        "nubia": {
            "semantic_relation": 1.18112,
            "contradiction": 35.16811,
            "irrelevancy": 44.28885,
            "logical_agreement": 20.54303,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.01751,
            "nubia_score": 0.04099
        },
        "meteor": 0.03938687663703715,
        "bleurt": -0.83455,
        "bertscore": {
            "precision": 0.81966,
            "recall": 0.8621,
            "f1": 0.84031
        }
    },
    "schema_guided_dialog_val": {
        "predictions_file": "mT5_large/schema_guided_dialog_val",
        "N": 10000,
        "msttr-100": 0.69932,
        "msttr-100_nopunct": 0.72724,
        "total_length": 124419,
        "mean_pred_length": 12.4419,
        "std_pred_length": 7.424313058458674,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 53,
        "distinct-1": 0.03439185333429782,
        "vocab_size-1": 4279,
        "unique-1": 1809,
        "entropy-1": 8.144549280688373,
        "distinct-2": 0.14711717459512844,
        "vocab_size-2": 16833,
        "unique-2": 8919,
        "entropy-2": 11.697334123021015,
        "cond_entropy-2": 3.2941015658548527,
        "distinct-3": 0.30521930664623637,
        "vocab_size-3": 31871,
        "unique-3": 20456,
        "entropy-3": 13.31667719495127,
        "cond_entropy-3": 1.639578284621419,
        "total_length-nopunct": 109642,
        "mean_pred_length-nopunct": 10.9642,
        "std_pred_length-nopunct": 6.8282441637656754,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.03888108571532807,
        "vocab_size-1-nopunct": 4263,
        "unique-1-nopunct": 1806,
        "entropy-1-nopunct": 8.369202393538956,
        "distinct-2-nopunct": 0.16127737299532327,
        "vocab_size-2-nopunct": 16070,
        "unique-2-nopunct": 8888,
        "entropy-2-nopunct": 11.599103979920976,
        "cond_entropy-2-nopunct": 3.379694354639549,
        "distinct-3-nopunct": 0.3283736908439943,
        "vocab_size-3-nopunct": 29441,
        "unique-3-nopunct": 19568,
        "entropy-3-nopunct": 13.21063490335058,
        "cond_entropy-3-nopunct": 1.6503276849798723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_val.json",
        "rouge1": {
            "precision": 0.61803,
            "recall": 0.60937,
            "fmeasure": 0.59987
        },
        "rouge2": {
            "precision": 0.40077,
            "recall": 0.39583,
            "fmeasure": 0.3885
        },
        "rougeL": {
            "precision": 0.55819,
            "recall": 0.55019,
            "fmeasure": 0.54172
        },
        "rougeLsum": {
            "precision": 0.55819,
            "recall": 0.55019,
            "fmeasure": 0.54172
        },
        "bleu": 35.32144,
        "nist": 7.4383331869098654,
        "local_recall": {
            "1": 0.6139965771262743
        },
        "nubia": {
            "semantic_relation": 3.85569,
            "contradiction": 3.90848,
            "irrelevancy": 19.62142,
            "logical_agreement": 76.4701,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.6687,
            "nubia_score": 0.70576
        },
        "meteor": 0.34277069065742743,
        "bleurt": 0.02147,
        "bertscore": {
            "precision": 0.8823,
            "recall": 0.87847,
            "f1": 0.87979
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.57542,
        "msttr-100_nopunct": 0.60009,
        "total_length": 37878,
        "mean_pred_length": 7.502079619726678,
        "std_pred_length": 2.838082007253419,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.031205449073340726,
        "vocab_size-1": 1182,
        "unique-1": 485,
        "entropy-1": 6.887589749169946,
        "distinct-2": 0.12790520576319717,
        "vocab_size-2": 4199,
        "unique-2": 2089,
        "entropy-2": 9.570100611482944,
        "cond_entropy-2": 2.3020052081473095,
        "distinct-3": 0.2322174226061915,
        "vocab_size-3": 6451,
        "unique-3": 3882,
        "entropy-3": 10.557937023707458,
        "cond_entropy-3": 1.007495236154112,
        "total_length-nopunct": 32334,
        "mean_pred_length-nopunct": 6.404040404040404,
        "std_pred_length-nopunct": 2.6305395039703203,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.03627760252365931,
        "vocab_size-1-nopunct": 1173,
        "unique-1-nopunct": 485,
        "entropy-1-nopunct": 7.071282502286371,
        "distinct-2-nopunct": 0.1327469305479201,
        "vocab_size-2-nopunct": 3622,
        "unique-2-nopunct": 1853,
        "entropy-2-nopunct": 9.281216747134552,
        "cond_entropy-2-nopunct": 2.4190320746055907,
        "distinct-3-nopunct": 0.23718525179856115,
        "vocab_size-3-nopunct": 5275,
        "unique-3-nopunct": 3246,
        "entropy-3-nopunct": 10.184879337495042,
        "cond_entropy-3-nopunct": 1.0471351246914813,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.50774,
            "recall": 0.48264,
            "fmeasure": 0.48239
        },
        "rouge2": {
            "precision": 0.30248,
            "recall": 0.28802,
            "fmeasure": 0.28672
        },
        "rougeL": {
            "precision": 0.48397,
            "recall": 0.45937,
            "fmeasure": 0.45969
        },
        "rougeLsum": {
            "precision": 0.48397,
            "recall": 0.45937,
            "fmeasure": 0.45969
        },
        "bleu": 26.36487,
        "nist": 4.716891979438891,
        "local_recall": {
            "1": 0.4624641330444457
        },
        "nubia": {
            "semantic_relation": 3.12317,
            "contradiction": 8.44754,
            "irrelevancy": 25.31266,
            "logical_agreement": 66.2398,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.55506,
            "nubia_score": 0.56805
        },
        "meteor": 0.2612337182108992,
        "bleurt": -0.11114,
        "bertscore": {
            "precision": 0.85756,
            "recall": 0.85087,
            "f1": 0.85359
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.55552,
        "msttr-100_nopunct": 0.58475,
        "total_length": 6755,
        "mean_pred_length": 11.091954022988507,
        "std_pred_length": 3.90966353079066,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.07638786084381939,
        "vocab_size-1": 516,
        "unique-1": 191,
        "entropy-1": 6.658199403959845,
        "distinct-2": 0.20354702245362838,
        "vocab_size-2": 1251,
        "unique-2": 622,
        "entropy-2": 8.698259202803087,
        "cond_entropy-2": 1.7797761687963385,
        "distinct-3": 0.3317681054722774,
        "vocab_size-3": 1837,
        "unique-3": 1158,
        "entropy-3": 9.56137924267497,
        "cond_entropy-3": 1.0180856101314537,
        "total_length-nopunct": 5929,
        "mean_pred_length-nopunct": 9.735632183908047,
        "std_pred_length-nopunct": 3.627218030810451,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.08652386574464496,
        "vocab_size-1-nopunct": 513,
        "unique-1-nopunct": 191,
        "entropy-1-nopunct": 6.836978210517651,
        "distinct-2-nopunct": 0.1962406015037594,
        "vocab_size-2-nopunct": 1044,
        "unique-2-nopunct": 529,
        "entropy-2-nopunct": 8.436203909929855,
        "cond_entropy-2-nopunct": 1.9100461613152973,
        "distinct-3-nopunct": 0.3328380386329866,
        "vocab_size-3-nopunct": 1568,
        "unique-3-nopunct": 1006,
        "entropy-3-nopunct": 9.323236900984638,
        "cond_entropy-3-nopunct": 1.142502449705787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.58901,
            "recall": 0.59018,
            "fmeasure": 0.57499
        },
        "rouge2": {
            "precision": 0.34582,
            "recall": 0.35244,
            "fmeasure": 0.34046
        },
        "rougeL": {
            "precision": 0.52242,
            "recall": 0.52467,
            "fmeasure": 0.51126
        },
        "rougeLsum": {
            "precision": 0.52242,
            "recall": 0.52467,
            "fmeasure": 0.51126
        },
        "bleu": 22.53021,
        "nist": 4.627283690909559,
        "local_recall": {
            "1": 0.5453577134741701
        },
        "nubia": {
            "semantic_relation": 3.67062,
            "contradiction": 18.25047,
            "irrelevancy": 30.54332,
            "logical_agreement": 51.20621,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.87708,
            "nubia_score": 0.5774
        },
        "meteor": 0.2754726954961569,
        "bleurt": -0.02175,
        "bertscore": {
            "precision": 0.91173,
            "recall": 0.91155,
            "f1": 0.91144
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 26.08474,
        "nist": 3.0666876995344965,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.75
        },
        "nubia": {
            "semantic_relation": 4.38363,
            "contradiction": 24.3006,
            "irrelevancy": 12.47741,
            "logical_agreement": 63.22199,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.72799,
            "nubia_score": 0.85497
        },
        "meteor": 0.6889533524705477,
        "bleurt": 0.23972,
        "bertscore": {
            "precision": 0.95677,
            "recall": 0.9542,
            "f1": 0.95549
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.63655,
        "msttr-100_nopunct": 0.66613,
        "total_length": 8423,
        "mean_pred_length": 24.065714285714286,
        "std_pred_length": 6.232057346936902,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 49,
        "distinct-1": 0.11812893268431675,
        "vocab_size-1": 995,
        "unique-1": 294,
        "entropy-1": 7.830427082126838,
        "distinct-2": 0.3221850613154961,
        "vocab_size-2": 2601,
        "unique-2": 1242,
        "entropy-2": 10.558691880545261,
        "cond_entropy-2": 2.5690844707651155,
        "distinct-3": 0.4890586559627088,
        "vocab_size-3": 3777,
        "unique-3": 2294,
        "entropy-3": 11.410913754475533,
        "cond_entropy-3": 0.9032556238641399,
        "total_length-nopunct": 7579,
        "mean_pred_length-nopunct": 21.654285714285713,
        "std_pred_length-nopunct": 5.766199186745502,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.130228262303734,
        "vocab_size-1-nopunct": 987,
        "unique-1-nopunct": 294,
        "entropy-1-nopunct": 8.022961006626398,
        "distinct-2-nopunct": 0.32646285793332414,
        "vocab_size-2-nopunct": 2360,
        "unique-2-nopunct": 1171,
        "entropy-2-nopunct": 10.401368818413872,
        "cond_entropy-2-nopunct": 2.503019039371593,
        "distinct-3-nopunct": 0.4942578863206861,
        "vocab_size-3-nopunct": 3400,
        "unique-3-nopunct": 2116,
        "entropy-3-nopunct": 11.248491162600923,
        "cond_entropy-3-nopunct": 0.8824249562345508,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.71415,
            "recall": 0.75175,
            "fmeasure": 0.72335
        },
        "rouge2": {
            "precision": 0.4615,
            "recall": 0.48549,
            "fmeasure": 0.46651
        },
        "rougeL": {
            "precision": 0.57114,
            "recall": 0.59662,
            "fmeasure": 0.57562
        },
        "rougeLsum": {
            "precision": 0.57114,
            "recall": 0.59662,
            "fmeasure": 0.57562
        },
        "bleu": 44.19282,
        "nist": 8.131041339596578,
        "local_recall": {
            "1": 0.22978975421972164,
            "2": 0.584895554365292,
            "3": 0.8751298026998962,
            "4": 0.7,
            "5": 0.7931034482758621
        },
        "nubia": {
            "semantic_relation": 4.39918,
            "contradiction": 9.35282,
            "irrelevancy": 9.88822,
            "logical_agreement": 80.75896,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.4326,
            "nubia_score": 0.76495
        },
        "meteor": 0.38853310189575835,
        "bleurt": 0.12972,
        "bertscore": {
            "precision": 0.91283,
            "recall": 0.91353,
            "f1": 0.91178
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.71773,
        "msttr-100_nopunct": 0.7405,
        "total_length": 2208,
        "mean_pred_length": 20.830188679245282,
        "std_pred_length": 4.276905286807819,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 37,
        "distinct-1": 0.4071557971014493,
        "vocab_size-1": 899,
        "unique-1": 655,
        "entropy-1": 8.243053133095502,
        "distinct-2": 0.8330161750713606,
        "vocab_size-2": 1751,
        "unique-2": 1587,
        "entropy-2": 10.547823508761965,
        "cond_entropy-2": 2.1099941587900264,
        "distinct-3": 0.9594188376753507,
        "vocab_size-3": 1915,
        "unique-3": 1861,
        "entropy-3": 10.86289609483839,
        "cond_entropy-3": 0.32141004111784366,
        "total_length-nopunct": 2059,
        "mean_pred_length-nopunct": 19.42452830188679,
        "std_pred_length-nopunct": 4.1115302967720515,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.43370568237008256,
        "vocab_size-1-nopunct": 893,
        "unique-1-nopunct": 653,
        "entropy-1-nopunct": 8.37187685798805,
        "distinct-2-nopunct": 0.840757808499744,
        "vocab_size-2-nopunct": 1642,
        "unique-2-nopunct": 1490,
        "entropy-2-nopunct": 10.470447585181837,
        "cond_entropy-2-nopunct": 2.1938097291848684,
        "distinct-3-nopunct": 0.969139144558744,
        "vocab_size-3-nopunct": 1790,
        "unique-3-nopunct": 1742,
        "entropy-3-nopunct": 10.784309019699846,
        "cond_entropy-3-nopunct": 0.3135983303102816,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.4511,
            "recall": 0.40328,
            "fmeasure": 0.41669
        },
        "rouge2": {
            "precision": 0.18713,
            "recall": 0.16015,
            "fmeasure": 0.16901
        },
        "rougeL": {
            "precision": 0.35355,
            "recall": 0.31494,
            "fmeasure": 0.32606
        },
        "rougeLsum": {
            "precision": 0.35355,
            "recall": 0.31494,
            "fmeasure": 0.32606
        },
        "bleu": 10.6933,
        "nist": 3.5717411052314736,
        "local_recall": {
            "1": 0.3728110599078341
        },
        "nubia": {
            "semantic_relation": 2.98183,
            "contradiction": 30.20583,
            "irrelevancy": 51.51035,
            "logical_agreement": 18.28382,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.67392,
            "nubia_score": 0.4252
        },
        "meteor": 0.18300030976958545,
        "bleurt": -0.29048,
        "bertscore": {
            "precision": 0.84775,
            "recall": 0.82729,
            "f1": 0.83708
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.68839,
        "msttr-100_nopunct": 0.71535,
        "total_length": 129109,
        "mean_pred_length": 12.9109,
        "std_pred_length": 7.548043533923211,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 72,
        "distinct-1": 0.03350657196632303,
        "vocab_size-1": 4326,
        "unique-1": 1861,
        "entropy-1": 8.077327051558402,
        "distinct-2": 0.147705043279685,
        "vocab_size-2": 17593,
        "unique-2": 9461,
        "entropy-2": 11.69630367798001,
        "cond_entropy-2": 3.3641347848143672,
        "distinct-3": 0.3109001090652467,
        "vocab_size-3": 33922,
        "unique-3": 22135,
        "entropy-3": 13.372173873521634,
        "cond_entropy-3": 1.697455803213869,
        "total_length-nopunct": 113860,
        "mean_pred_length-nopunct": 11.386,
        "std_pred_length-nopunct": 6.950252081759337,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.037853504303530655,
        "vocab_size-1-nopunct": 4310,
        "unique-1-nopunct": 1859,
        "entropy-1-nopunct": 8.28860207170367,
        "distinct-2-nopunct": 0.16222799922973233,
        "vocab_size-2-nopunct": 16849,
        "unique-2-nopunct": 9445,
        "entropy-2-nopunct": 11.600516979171415,
        "cond_entropy-2-nopunct": 3.4613407569373567,
        "distinct-3-nopunct": 0.33464373987897383,
        "vocab_size-3-nopunct": 31411,
        "unique-3-nopunct": 21189,
        "entropy-3-nopunct": 13.270174565446336,
        "cond_entropy-3-nopunct": 1.7252415506168328,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.57414,
            "recall": 0.55333,
            "fmeasure": 0.55142
        },
        "rouge2": {
            "precision": 0.35695,
            "recall": 0.3443,
            "fmeasure": 0.34243
        },
        "rougeL": {
            "precision": 0.51707,
            "recall": 0.49754,
            "fmeasure": 0.49633
        },
        "rougeLsum": {
            "precision": 0.51707,
            "recall": 0.49754,
            "fmeasure": 0.49633
        },
        "bleu": 31.67006,
        "nist": 6.842160574504702,
        "local_recall": {
            "1": 0.5646467070125392
        },
        "nubia": {
            "semantic_relation": 3.60514,
            "contradiction": 7.33838,
            "irrelevancy": 22.69577,
            "logical_agreement": 69.96585,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.57224,
            "nubia_score": 0.64012
        },
        "meteor": 0.31343013986425006,
        "bleurt": -0.0788,
        "bertscore": {
            "precision": 0.87207,
            "recall": 0.8658,
            "f1": 0.86842
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.71857,
        "msttr-100_nopunct": 0.8244,
        "total_length": 11219,
        "mean_pred_length": 22.710526315789473,
        "std_pred_length": 10.017353895875818,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 69,
        "distinct-1": 0.16908815402442284,
        "vocab_size-1": 1897,
        "unique-1": 743,
        "entropy-1": 8.691360076531074,
        "distinct-2": 0.4041958041958042,
        "vocab_size-2": 4335,
        "unique-2": 2422,
        "entropy-2": 11.348399655178383,
        "cond_entropy-2": 2.4343005616261273,
        "distinct-3": 0.565438373570521,
        "vocab_size-3": 5785,
        "unique-3": 3873,
        "entropy-3": 12.089236998930932,
        "cond_entropy-3": 0.7527495185508836,
        "total_length-nopunct": 9101,
        "mean_pred_length-nopunct": 18.423076923076923,
        "std_pred_length-nopunct": 8.170820121855485,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.20766948686957476,
        "vocab_size-1-nopunct": 1890,
        "unique-1-nopunct": 743,
        "entropy-1-nopunct": 9.413534487146498,
        "distinct-2-nopunct": 0.45404902985941675,
        "vocab_size-2-nopunct": 3908,
        "unique-2-nopunct": 2338,
        "entropy-2-nopunct": 11.303364947827202,
        "cond_entropy-2-nopunct": 1.9493127951679041,
        "distinct-3-nopunct": 0.6077899667200789,
        "vocab_size-3-nopunct": 4931,
        "unique-3-nopunct": 3480,
        "entropy-3-nopunct": 11.896334804513334,
        "cond_entropy-3-nopunct": 0.6292835700331233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.39963,
            "recall": 0.40396,
            "fmeasure": 0.39842
        },
        "rouge2": {
            "precision": 0.22521,
            "recall": 0.23111,
            "fmeasure": 0.22502
        },
        "rougeL": {
            "precision": 0.37179,
            "recall": 0.3765,
            "fmeasure": 0.37043
        },
        "rougeLsum": {
            "precision": 0.37179,
            "recall": 0.3765,
            "fmeasure": 0.37043
        },
        "bleu": 50.33638,
        "nist": 9.080362520338307,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.6487119437939111,
            "3": 0.9006280014776505,
            "4": 1.0,
            "5": 0.5,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 3.96563,
            "contradiction": 18.95439,
            "irrelevancy": 21.97077,
            "logical_agreement": 59.07484,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.58548,
            "nubia_score": 0.82473
        },
        "meteor": 0.6507335509345361,
        "bleurt": 0.15035,
        "bertscore": {
            "precision": 0.95516,
            "recall": 0.9531,
            "f1": 0.95345
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.71299,
        "msttr-100_nopunct": 0.80137,
        "total_length": 9747,
        "mean_pred_length": 27.533898305084747,
        "std_pred_length": 10.247514955798755,
        "median_pred_length": 26.0,
        "min_pred_length": 5,
        "max_pred_length": 69,
        "distinct-1": 0.16425566841079306,
        "vocab_size-1": 1601,
        "unique-1": 629,
        "entropy-1": 8.500494845820665,
        "distinct-2": 0.3722985201745981,
        "vocab_size-2": 3497,
        "unique-2": 1885,
        "entropy-2": 10.966215227915514,
        "cond_entropy-2": 2.288088108245294,
        "distinct-3": 0.5107865914371059,
        "vocab_size-3": 4617,
        "unique-3": 2964,
        "entropy-3": 11.654008025104643,
        "cond_entropy-3": 0.7004385629394474,
        "total_length-nopunct": 8055,
        "mean_pred_length-nopunct": 22.75423728813559,
        "std_pred_length-nopunct": 8.84001218204605,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.1978895096213532,
        "vocab_size-1-nopunct": 1594,
        "unique-1-nopunct": 629,
        "entropy-1-nopunct": 9.116080490036692,
        "distinct-2-nopunct": 0.41630957018569015,
        "vocab_size-2-nopunct": 3206,
        "unique-2-nopunct": 1862,
        "entropy-2-nopunct": 10.949392934631208,
        "cond_entropy-2-nopunct": 1.8775698627772317,
        "distinct-3-nopunct": 0.5464815570981353,
        "vocab_size-3-nopunct": 4015,
        "unique-3-nopunct": 2716,
        "entropy-3-nopunct": 11.479422548859363,
        "cond_entropy-3-nopunct": 0.5482791795374016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.59316,
            "recall": 0.5969,
            "fmeasure": 0.58986
        },
        "rouge2": {
            "precision": 0.34512,
            "recall": 0.3456,
            "fmeasure": 0.34072
        },
        "rougeL": {
            "precision": 0.56911,
            "recall": 0.57313,
            "fmeasure": 0.56584
        },
        "rougeLsum": {
            "precision": 0.56911,
            "recall": 0.57313,
            "fmeasure": 0.56584
        },
        "bleu": 52.26635,
        "nist": 8.886852795473386,
        "local_recall": {
            "1": 0.2941950028179598,
            "2": 0.6849840255591054,
            "3": 0.8965663416701992,
            "4": 0.972972972972973,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 3.95146,
            "contradiction": 19.10654,
            "irrelevancy": 22.13365,
            "logical_agreement": 58.75981,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.52757,
            "nubia_score": 0.83673
        },
        "meteor": 0.6667538907989624,
        "bleurt": 0.16948,
        "bertscore": {
            "precision": 0.9548,
            "recall": 0.95329,
            "f1": 0.95343
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.70714,
        "msttr-100_nopunct": 0.727,
        "total_length": 2166,
        "mean_pred_length": 20.433962264150942,
        "std_pred_length": 3.7316061287953204,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.38873499538319484,
        "vocab_size-1": 842,
        "unique-1": 612,
        "entropy-1": 8.12672153169351,
        "distinct-2": 0.8019417475728156,
        "vocab_size-2": 1652,
        "unique-2": 1459,
        "entropy-2": 10.452648883709879,
        "cond_entropy-2": 2.131740268222007,
        "distinct-3": 0.9406345957011258,
        "vocab_size-3": 1838,
        "unique-3": 1764,
        "entropy-3": 10.78851903833548,
        "cond_entropy-3": 0.3421053625642978,
        "total_length-nopunct": 2022,
        "mean_pred_length-nopunct": 19.07547169811321,
        "std_pred_length-nopunct": 3.5969014789397553,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4124629080118694,
        "vocab_size-1-nopunct": 834,
        "unique-1-nopunct": 607,
        "entropy-1-nopunct": 8.246734307943962,
        "distinct-2-nopunct": 0.8089770354906054,
        "vocab_size-2-nopunct": 1550,
        "unique-2-nopunct": 1375,
        "entropy-2-nopunct": 10.366625469144585,
        "cond_entropy-2-nopunct": 2.211977586126527,
        "distinct-3-nopunct": 0.9486187845303867,
        "vocab_size-3-nopunct": 1717,
        "unique-3-nopunct": 1655,
        "entropy-3-nopunct": 10.701394108241937,
        "cond_entropy-3-nopunct": 0.3356430534866569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.4366,
            "recall": 0.38555,
            "fmeasure": 0.40331
        },
        "rouge2": {
            "precision": 0.18468,
            "recall": 0.16162,
            "fmeasure": 0.16963
        },
        "rougeL": {
            "precision": 0.33475,
            "recall": 0.29659,
            "fmeasure": 0.30929
        },
        "rougeLsum": {
            "precision": 0.33475,
            "recall": 0.29659,
            "fmeasure": 0.30929
        },
        "bleu": 10.20023,
        "nist": 3.3904979418471757,
        "local_recall": {
            "1": 0.35690866510538644
        },
        "nubia": {
            "semantic_relation": 2.89918,
            "contradiction": 16.57528,
            "irrelevancy": 69.18739,
            "logical_agreement": 14.23733,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.54386,
            "nubia_score": 0.42665
        },
        "meteor": 0.17867928286312398,
        "bleurt": -0.35166,
        "bertscore": {
            "precision": 0.83402,
            "recall": 0.81615,
            "f1": 0.82474
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.14,
        "msttr-100_nopunct": 0.12,
        "total_length": 225,
        "mean_pred_length": 10.227272727272727,
        "std_pred_length": 0.4190702026042222,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.06222222222222222,
        "vocab_size-1": 14,
        "unique-1": 0,
        "entropy-1": 3.668320296915245,
        "distinct-2": 0.07389162561576355,
        "vocab_size-2": 15,
        "unique-2": 0,
        "entropy-2": 3.743475008257348,
        "cond_entropy-2": 0.041128327423969116,
        "distinct-3": 0.07734806629834254,
        "vocab_size-3": 14,
        "unique-3": 0,
        "entropy-3": 3.643325064418406,
        "cond_entropy-3": -0.04685768611740978,
        "total_length-nopunct": 181,
        "mean_pred_length-nopunct": 8.227272727272727,
        "std_pred_length-nopunct": 0.4190702026042222,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.06629834254143646,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.4307093677580003,
        "distinct-2-nopunct": 0.07547169811320754,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.404736870042131,
        "cond_entropy-2-nopunct": 0.0550712889277757,
        "distinct-3-nopunct": 0.08029197080291971,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.278413601621161,
        "cond_entropy-3-nopunct": -0.05811762954130655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.45468,
            "recall": 0.4404,
            "fmeasure": 0.44294
        },
        "rouge2": {
            "precision": 0.28278,
            "recall": 0.25732,
            "fmeasure": 0.26838
        },
        "rougeL": {
            "precision": 0.43347,
            "recall": 0.41186,
            "fmeasure": 0.41892
        },
        "rougeLsum": {
            "precision": 0.43347,
            "recall": 0.41186,
            "fmeasure": 0.41892
        },
        "bleu": 24.24378,
        "nist": 2.2723330266433663,
        "local_recall": {
            "1": 0.37714285714285717
        },
        "nubia": {
            "semantic_relation": 2.69152,
            "contradiction": 24.36968,
            "irrelevancy": 25.30708,
            "logical_agreement": 50.32324,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.96875,
            "nubia_score": 0.35019
        },
        "meteor": 0.20767810227352088,
        "bleurt": -0.13418,
        "bertscore": {
            "precision": 0.9064,
            "recall": 0.90527,
            "f1": 0.90578
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "mT5_large/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.68246,
        "msttr-100_nopunct": 0.71298,
        "total_length": 6513,
        "mean_pred_length": 13.026,
        "std_pred_length": 7.902235379941552,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 62,
        "distinct-1": 0.16229080300936588,
        "vocab_size-1": 1057,
        "unique-1": 604,
        "entropy-1": 7.849141107021806,
        "distinct-2": 0.512722434724763,
        "vocab_size-2": 3083,
        "unique-2": 2208,
        "entropy-2": 10.851740104338372,
        "cond_entropy-2": 2.753566100609302,
        "distinct-3": 0.7406130963177943,
        "vocab_size-3": 4083,
        "unique-3": 3448,
        "entropy-3": 11.679711451731498,
        "cond_entropy-3": 0.8472343389769219,
        "total_length-nopunct": 5704,
        "mean_pred_length-nopunct": 11.408,
        "std_pred_length-nopunct": 7.2510368913694,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.18320476858345022,
        "vocab_size-1-nopunct": 1045,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 8.050129456424878,
        "distinct-2-nopunct": 0.5345887778631822,
        "vocab_size-2-nopunct": 2782,
        "unique-2-nopunct": 2054,
        "entropy-2-nopunct": 10.696244225768302,
        "cond_entropy-2-nopunct": 2.7697624662655356,
        "distinct-3-nopunct": 0.7553146258503401,
        "vocab_size-3-nopunct": 3553,
        "unique-3-nopunct": 3052,
        "entropy-3-nopunct": 11.479329340175056,
        "cond_entropy-3-nopunct": 0.8204115651968288,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "rouge1": {
            "precision": 0.519,
            "recall": 0.51202,
            "fmeasure": 0.50073
        },
        "rouge2": {
            "precision": 0.29358,
            "recall": 0.28853,
            "fmeasure": 0.28199
        },
        "rougeL": {
            "precision": 0.45668,
            "recall": 0.45054,
            "fmeasure": 0.44083
        },
        "rougeLsum": {
            "precision": 0.45668,
            "recall": 0.45054,
            "fmeasure": 0.44083
        },
        "bleu": 26.74679,
        "nist": 5.351420086751373,
        "local_recall": {
            "1": 0.5306008902077152
        },
        "nubia": {
            "semantic_relation": 3.47157,
            "contradiction": 7.17968,
            "irrelevancy": 25.51527,
            "logical_agreement": 67.30505,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.58975,
            "nubia_score": 0.61063
        },
        "meteor": 0.29434300559697113,
        "bleurt": -0.16743,
        "bertscore": {
            "precision": 0.85646,
            "recall": 0.85387,
            "f1": 0.85458
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.5795,
        "msttr-100_nopunct": 0.60549,
        "total_length": 6079,
        "mean_pred_length": 12.158,
        "std_pred_length": 4.082283184689666,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.07484783681526568,
        "vocab_size-1": 455,
        "unique-1": 184,
        "entropy-1": 6.690153784524312,
        "distinct-2": 0.19537551532532713,
        "vocab_size-2": 1090,
        "unique-2": 581,
        "entropy-2": 8.364297246624442,
        "cond_entropy-2": 1.4986232085990168,
        "distinct-3": 0.30222484741090766,
        "vocab_size-3": 1535,
        "unique-3": 1004,
        "entropy-3": 8.947428846898434,
        "cond_entropy-3": 0.6945515742438412,
        "total_length-nopunct": 5153,
        "mean_pred_length-nopunct": 10.306,
        "std_pred_length-nopunct": 3.5009090248105563,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.08752183194255773,
        "vocab_size-1-nopunct": 451,
        "unique-1-nopunct": 184,
        "entropy-1-nopunct": 6.890295596963916,
        "distinct-2-nopunct": 0.19729206963249515,
        "vocab_size-2-nopunct": 918,
        "unique-2-nopunct": 490,
        "entropy-2-nopunct": 8.197394031532305,
        "cond_entropy-2-nopunct": 1.5132839154412685,
        "distinct-3-nopunct": 0.31663857452444016,
        "vocab_size-3-nopunct": 1315,
        "unique-3-nopunct": 869,
        "entropy-3-nopunct": 8.800778850229825,
        "cond_entropy-3-nopunct": 0.7633081941367076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.48154,
            "recall": 0.5007,
            "fmeasure": 0.47685
        },
        "rouge2": {
            "precision": 0.28238,
            "recall": 0.29606,
            "fmeasure": 0.28091
        },
        "rougeL": {
            "precision": 0.42571,
            "recall": 0.44577,
            "fmeasure": 0.4232
        },
        "rougeLsum": {
            "precision": 0.42571,
            "recall": 0.44577,
            "fmeasure": 0.4232
        },
        "bleu": 16.598,
        "nist": 3.593178643607956,
        "local_recall": {
            "1": 0.48497554157931516
        },
        "nubia": {
            "semantic_relation": 3.1678,
            "contradiction": 22.91595,
            "irrelevancy": 31.54964,
            "logical_agreement": 45.53441,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.64906,
            "nubia_score": 0.46868
        },
        "meteor": 0.24430630271481768,
        "bleurt": -0.18967,
        "bertscore": {
            "precision": 0.89439,
            "recall": 0.9024,
            "f1": 0.89813
        }
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.63942,
        "msttr-100_nopunct": 0.70353,
        "total_length": 10451,
        "mean_pred_length": 20.902,
        "std_pred_length": 12.15254689355281,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.19213472394986125,
        "vocab_size-1": 2008,
        "unique-1": 882,
        "entropy-1": 8.798985442813478,
        "distinct-2": 0.44889960807959,
        "vocab_size-2": 4467,
        "unique-2": 2699,
        "entropy-2": 11.452290899239149,
        "cond_entropy-2": 2.400237283610156,
        "distinct-3": 0.6097767432017775,
        "vocab_size-3": 5763,
        "unique-3": 4073,
        "entropy-3": 12.135013154497459,
        "cond_entropy-3": 0.6954217709972746,
        "total_length-nopunct": 8514,
        "mean_pred_length-nopunct": 17.028,
        "std_pred_length-nopunct": 10.004559760429242,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.2349072116513977,
        "vocab_size-1-nopunct": 2000,
        "unique-1-nopunct": 882,
        "entropy-1-nopunct": 9.533557269420545,
        "distinct-2-nopunct": 0.4953830796106813,
        "vocab_size-2-nopunct": 3970,
        "unique-2-nopunct": 2519,
        "entropy-2-nopunct": 11.398956882580578,
        "cond_entropy-2-nopunct": 1.9316271244088354,
        "distinct-3-nopunct": 0.6443971253659835,
        "vocab_size-3-nopunct": 4842,
        "unique-3-nopunct": 3553,
        "entropy-3-nopunct": 11.921935759172648,
        "cond_entropy-3-nopunct": 0.5583300259050976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.44716,
            "recall": 0.45322,
            "fmeasure": 0.44716
        },
        "rouge2": {
            "precision": 0.25331,
            "recall": 0.25244,
            "fmeasure": 0.2499
        },
        "rougeL": {
            "precision": 0.42461,
            "recall": 0.43057,
            "fmeasure": 0.42437
        },
        "rougeLsum": {
            "precision": 0.42461,
            "recall": 0.43057,
            "fmeasure": 0.42437
        },
        "bleu": 51.69416,
        "nist": 9.196756966603816,
        "local_recall": {
            "1": 0.2990547588005215,
            "2": 0.6648484848484848,
            "3": 0.8956043956043956,
            "4": 0.9333333333333333,
            "5": 0.8,
            "6": 1.0
        },
        "nubia": {
            "semantic_relation": 4.02549,
            "contradiction": 19.38464,
            "irrelevancy": 20.96558,
            "logical_agreement": 59.64978,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.64961,
            "nubia_score": 0.8383
        },
        "meteor": 0.6699173146354812,
        "bleurt": 0.22695,
        "bertscore": {
            "precision": 0.95901,
            "recall": 0.95697,
            "f1": 0.95736
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.73154,
        "msttr-100_nopunct": 0.82595,
        "total_length": 22703,
        "mean_pred_length": 21.11906976744186,
        "std_pred_length": 11.430955892795645,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.11941153151565873,
        "vocab_size-1": 2711,
        "unique-1": 864,
        "entropy-1": 8.968601033722647,
        "distinct-2": 0.3170427223968929,
        "vocab_size-2": 6857,
        "unique-2": 3358,
        "entropy-2": 11.847496440452627,
        "cond_entropy-2": 2.6191374202186397,
        "distinct-3": 0.4695664866442855,
        "vocab_size-3": 9651,
        "unique-3": 5814,
        "entropy-3": 12.699660985886377,
        "cond_entropy-3": 0.8717553098287583,
        "total_length-nopunct": 18548,
        "mean_pred_length-nopunct": 17.253953488372094,
        "std_pred_length-nopunct": 9.554722231863636,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.14572999784343327,
        "vocab_size-1-nopunct": 2703,
        "unique-1-nopunct": 864,
        "entropy-1-nopunct": 9.72584512873528,
        "distinct-2-nopunct": 0.3604990556859154,
        "vocab_size-2-nopunct": 6299,
        "unique-2-nopunct": 3337,
        "entropy-2-nopunct": 11.84863748151453,
        "cond_entropy-2-nopunct": 2.1974786424439308,
        "distinct-3-nopunct": 0.5110989145017685,
        "vocab_size-3-nopunct": 8381,
        "unique-3-nopunct": 5364,
        "entropy-3-nopunct": 12.53550054270754,
        "cond_entropy-3-nopunct": 0.7271647965458661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.45274,
            "recall": 0.45432,
            "fmeasure": 0.45012
        },
        "rouge2": {
            "precision": 0.25752,
            "recall": 0.25924,
            "fmeasure": 0.25549
        },
        "rougeL": {
            "precision": 0.43231,
            "recall": 0.4341,
            "fmeasure": 0.42961
        },
        "rougeLsum": {
            "precision": 0.43231,
            "recall": 0.4341,
            "fmeasure": 0.42961
        },
        "bleu": 52.48176,
        "nist": 9.593975167865848,
        "local_recall": {
            "1": 0.2940792811073266,
            "2": 0.675297410776767,
            "3": 0.8970588235294118,
            "4": 0.948051948051948,
            "5": 0.8918918918918919,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.03329,
            "contradiction": 19.08049,
            "irrelevancy": 21.51739,
            "logical_agreement": 59.40211,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.63239,
            "nubia_score": 0.83881
        },
        "meteor": 0.6708005208922352,
        "bleurt": 0.22085,
        "bertscore": {
            "precision": 0.95915,
            "recall": 0.95733,
            "f1": 0.95762
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68062,
        "msttr-100_nopunct": 0.70946,
        "total_length": 6433,
        "mean_pred_length": 12.866,
        "std_pred_length": 7.535253413124207,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.1562257111767449,
        "vocab_size-1": 1005,
        "unique-1": 580,
        "entropy-1": 7.778244599423729,
        "distinct-2": 0.4709253328838699,
        "vocab_size-2": 2794,
        "unique-2": 1933,
        "entropy-2": 10.604724246853175,
        "cond_entropy-2": 2.578646169987633,
        "distinct-3": 0.6850727038468618,
        "vocab_size-3": 3722,
        "unique-3": 3048,
        "entropy-3": 11.413802669822445,
        "cond_entropy-3": 0.8358025654307678,
        "total_length-nopunct": 5645,
        "mean_pred_length-nopunct": 11.29,
        "std_pred_length-nopunct": 6.932380543507404,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.1757307351638618,
        "vocab_size-1-nopunct": 992,
        "unique-1-nopunct": 576,
        "entropy-1-nopunct": 7.959189566280111,
        "distinct-2-nopunct": 0.48649173955296404,
        "vocab_size-2-nopunct": 2503,
        "unique-2-nopunct": 1777,
        "entropy-2-nopunct": 10.430108950140982,
        "cond_entropy-2-nopunct": 2.6088283791592084,
        "distinct-3-nopunct": 0.6978045630650022,
        "vocab_size-3-nopunct": 3242,
        "unique-3-nopunct": 2706,
        "entropy-3-nopunct": 11.202441511517002,
        "cond_entropy-3-nopunct": 0.8149864025023105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.5658,
            "recall": 0.56008,
            "fmeasure": 0.5496
        },
        "rouge2": {
            "precision": 0.35159,
            "recall": 0.34941,
            "fmeasure": 0.34153
        },
        "rougeL": {
            "precision": 0.51379,
            "recall": 0.50838,
            "fmeasure": 0.4992
        },
        "rougeLsum": {
            "precision": 0.51379,
            "recall": 0.50838,
            "fmeasure": 0.4992
        },
        "bleu": 32.4447,
        "nist": 6.018802056831418,
        "local_recall": {
            "1": 0.5786350148367952
        },
        "nubia": {
            "semantic_relation": 3.65275,
            "contradiction": 5.57803,
            "irrelevancy": 23.83144,
            "logical_agreement": 70.59053,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.48418,
            "nubia_score": 0.6613
        },
        "meteor": 0.32304039280873753,
        "bleurt": -0.04493,
        "bertscore": {
            "precision": 0.87173,
            "recall": 0.86951,
            "f1": 0.87008
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68697,
        "msttr-100_nopunct": 0.71052,
        "total_length": 6662,
        "mean_pred_length": 13.324,
        "std_pred_length": 8.292588498171122,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 72,
        "distinct-1": 0.14920444311017714,
        "vocab_size-1": 994,
        "unique-1": 532,
        "entropy-1": 7.846038169207123,
        "distinct-2": 0.4681921454073353,
        "vocab_size-2": 2885,
        "unique-2": 1971,
        "entropy-2": 10.690640321198272,
        "cond_entropy-2": 2.62152037724226,
        "distinct-3": 0.6865065347933592,
        "vocab_size-3": 3887,
        "unique-3": 3140,
        "entropy-3": 11.544564160760688,
        "cond_entropy-3": 0.8750872841771449,
        "total_length-nopunct": 5890,
        "mean_pred_length-nopunct": 11.78,
        "std_pred_length-nopunct": 7.617322364190714,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.166383701188455,
        "vocab_size-1-nopunct": 980,
        "unique-1-nopunct": 527,
        "entropy-1-nopunct": 8.012736784306798,
        "distinct-2-nopunct": 0.48460111317254173,
        "vocab_size-2-nopunct": 2612,
        "unique-2-nopunct": 1831,
        "entropy-2-nopunct": 10.540873911665168,
        "cond_entropy-2-nopunct": 2.6539013418285973,
        "distinct-3-nopunct": 0.7010224948875255,
        "vocab_size-3-nopunct": 3428,
        "unique-3-nopunct": 2824,
        "entropy-3-nopunct": 11.35890847721791,
        "cond_entropy-3-nopunct": 0.8649233452258214,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.57819,
            "recall": 0.56049,
            "fmeasure": 0.55823
        },
        "rouge2": {
            "precision": 0.36974,
            "recall": 0.35609,
            "fmeasure": 0.35483
        },
        "rougeL": {
            "precision": 0.51995,
            "recall": 0.50138,
            "fmeasure": 0.50078
        },
        "rougeLsum": {
            "precision": 0.51995,
            "recall": 0.50138,
            "fmeasure": 0.50078
        },
        "bleu": 32.61103,
        "nist": 6.132810382458151,
        "local_recall": {
            "1": 0.572250305037476
        },
        "nubia": {
            "semantic_relation": 3.67836,
            "contradiction": 6.28471,
            "irrelevancy": 21.8655,
            "logical_agreement": 71.84979,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.60839,
            "nubia_score": 0.65508
        },
        "meteor": 0.31834709707872977,
        "bleurt": -0.05698,
        "bertscore": {
            "precision": 0.87455,
            "recall": 0.86692,
            "f1": 0.87023
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.71519,
        "total_length": 6175,
        "mean_pred_length": 12.35,
        "std_pred_length": 7.295992050434266,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 45,
        "distinct-1": 0.15935222672064778,
        "vocab_size-1": 984,
        "unique-1": 552,
        "entropy-1": 7.781976609464509,
        "distinct-2": 0.47894273127753306,
        "vocab_size-2": 2718,
        "unique-2": 1900,
        "entropy-2": 10.566890517627396,
        "cond_entropy-2": 2.5428648712002606,
        "distinct-3": 0.6927536231884058,
        "vocab_size-3": 3585,
        "unique-3": 2971,
        "entropy-3": 11.362201442352895,
        "cond_entropy-3": 0.809311511349457,
        "total_length-nopunct": 5470,
        "mean_pred_length-nopunct": 10.94,
        "std_pred_length-nopunct": 6.738872309222071,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.17787934186471663,
        "vocab_size-1-nopunct": 973,
        "unique-1-nopunct": 551,
        "entropy-1-nopunct": 7.9491437133047524,
        "distinct-2-nopunct": 0.4915492957746479,
        "vocab_size-2-nopunct": 2443,
        "unique-2-nopunct": 1750,
        "entropy-2-nopunct": 10.394221596640069,
        "cond_entropy-2-nopunct": 2.5689081403232743,
        "distinct-3-nopunct": 0.7024608501118568,
        "vocab_size-3-nopunct": 3140,
        "unique-3-nopunct": 2639,
        "entropy-3-nopunct": 11.162805473072012,
        "cond_entropy-3-nopunct": 0.8061621542955988,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.58601,
            "recall": 0.55976,
            "fmeasure": 0.56242
        },
        "rouge2": {
            "precision": 0.36602,
            "recall": 0.34718,
            "fmeasure": 0.34954
        },
        "rougeL": {
            "precision": 0.53346,
            "recall": 0.50839,
            "fmeasure": 0.51143
        },
        "rougeLsum": {
            "precision": 0.53346,
            "recall": 0.50839,
            "fmeasure": 0.51143
        },
        "bleu": 32.64955,
        "nist": 6.092394136449097,
        "local_recall": {
            "1": 0.5714547453279589
        },
        "nubia": {
            "semantic_relation": 3.63348,
            "contradiction": 6.59547,
            "irrelevancy": 21.34745,
            "logical_agreement": 72.05707,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.6298,
            "nubia_score": 0.64556
        },
        "meteor": 0.31634138391104394,
        "bleurt": -0.04759,
        "bertscore": {
            "precision": 0.87647,
            "recall": 0.86846,
            "f1": 0.87201
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.50667,
        "msttr-100_nopunct": 0.51396,
        "total_length": 40541,
        "mean_pred_length": 24.51088270858525,
        "std_pred_length": 13.069188594348873,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 80,
        "distinct-1": 0.04210552280407489,
        "vocab_size-1": 1707,
        "unique-1": 395,
        "entropy-1": 8.031062375713969,
        "distinct-2": 0.15043587831408956,
        "vocab_size-2": 5850,
        "unique-2": 2272,
        "entropy-2": 11.11245771964814,
        "cond_entropy-2": 2.909805329192924,
        "distinct-3": 0.2718018961673784,
        "vocab_size-3": 10120,
        "unique-3": 5213,
        "entropy-3": 12.254841355417572,
        "cond_entropy-3": 1.2075868121919655,
        "total_length-nopunct": 36170,
        "mean_pred_length-nopunct": 21.86819830713422,
        "std_pred_length-nopunct": 11.791396942546035,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.046944982029306054,
        "vocab_size-1-nopunct": 1698,
        "unique-1-nopunct": 395,
        "entropy-1-nopunct": 8.281795005690356,
        "distinct-2-nopunct": 0.15891180901610846,
        "vocab_size-2-nopunct": 5485,
        "unique-2-nopunct": 2284,
        "entropy-2-nopunct": 10.99967201172095,
        "cond_entropy-2-nopunct": 2.8575403486711473,
        "distinct-3-nopunct": 0.2848883208569168,
        "vocab_size-3-nopunct": 9362,
        "unique-3-nopunct": 5038,
        "entropy-3-nopunct": 12.128051186966303,
        "cond_entropy-3-nopunct": 1.1805914682310747,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73864,
            "recall": 0.7478,
            "fmeasure": 0.73555
        },
        "rouge2": {
            "precision": 0.48722,
            "recall": 0.49295,
            "fmeasure": 0.48439
        },
        "rougeL": {
            "precision": 0.59069,
            "recall": 0.59787,
            "fmeasure": 0.58766
        },
        "rougeLsum": {
            "precision": 0.59069,
            "recall": 0.59787,
            "fmeasure": 0.58766
        },
        "bleu": 47.4632,
        "nist": 8.931036413127655,
        "local_recall": {
            "1": 0.23359134101063495,
            "2": 0.6045703454085931,
            "3": 0.874635241301908,
            "4": 0.9272727272727272,
            "5": 0.7931034482758621
        },
        "nubia": {
            "semantic_relation": 4.43741,
            "contradiction": 9.00042,
            "irrelevancy": 8.43483,
            "logical_agreement": 82.56475,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.57895,
            "nubia_score": 0.78144
        },
        "meteor": 0.3876020310528479,
        "bleurt": 0.17453,
        "bertscore": {
            "precision": 0.91899,
            "recall": 0.91915,
            "f1": 0.91778
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69809,
        "msttr-100_nopunct": 0.7245,
        "total_length": 6815,
        "mean_pred_length": 13.63,
        "std_pred_length": 7.832821969124537,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 48,
        "distinct-1": 0.15832721936903887,
        "vocab_size-1": 1079,
        "unique-1": 613,
        "entropy-1": 7.905058884368145,
        "distinct-2": 0.49073634204275535,
        "vocab_size-2": 3099,
        "unique-2": 2213,
        "entropy-2": 10.787581601588288,
        "cond_entropy-2": 2.668954447622529,
        "distinct-3": 0.7116079105760963,
        "vocab_size-3": 4138,
        "unique-3": 3445,
        "entropy-3": 11.627336880612226,
        "cond_entropy-3": 0.861427766110305,
        "total_length-nopunct": 6029,
        "mean_pred_length-nopunct": 12.058,
        "std_pred_length-nopunct": 7.189341833575589,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.17714380494277657,
        "vocab_size-1-nopunct": 1068,
        "unique-1-nopunct": 612,
        "entropy-1-nopunct": 8.073860222357387,
        "distinct-2-nopunct": 0.5029842647856755,
        "vocab_size-2-nopunct": 2781,
        "unique-2-nopunct": 2019,
        "entropy-2-nopunct": 10.62122959190883,
        "cond_entropy-2-nopunct": 2.673820192365606,
        "distinct-3-nopunct": 0.7221228384019082,
        "vocab_size-3-nopunct": 3633,
        "unique-3-nopunct": 3064,
        "entropy-3-nopunct": 11.432959799741706,
        "cond_entropy-3-nopunct": 0.851775616732484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.55732,
            "fmeasure": 0.56092
        },
        "rouge2": {
            "precision": 0.37268,
            "recall": 0.34687,
            "fmeasure": 0.34984
        },
        "rougeL": {
            "precision": 0.5313,
            "recall": 0.49978,
            "fmeasure": 0.50376
        },
        "rougeLsum": {
            "precision": 0.5313,
            "recall": 0.49978,
            "fmeasure": 0.50376
        },
        "bleu": 32.6136,
        "nist": 6.245190362655404,
        "local_recall": {
            "1": 0.5716878402903811
        },
        "nubia": {
            "semantic_relation": 3.65473,
            "contradiction": 7.23579,
            "irrelevancy": 21.89876,
            "logical_agreement": 70.86545,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.59519,
            "nubia_score": 0.64646
        },
        "meteor": 0.3176300052023021,
        "bleurt": -0.04217,
        "bertscore": {
            "precision": 0.87824,
            "recall": 0.86759,
            "f1": 0.87239
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.8125,
            "fmeasure": 0.7027
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.51453,
            "fmeasure": 0.41616
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.75298,
            "fmeasure": 0.61725
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.75298,
            "fmeasure": 0.61725
        },
        "bleu": 27.63558,
        "nist": 3.6165202612904346,
        "local_recall": {
            "1": 0.4,
            "2": 0.5714285714285714,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.24886,
            "contradiction": 0.10795,
            "irrelevancy": 46.67225,
            "logical_agreement": 53.2198,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.46095,
            "nubia_score": 0.85667
        },
        "meteor": 0.37611784411206733,
        "bleurt": 0.23508,
        "bertscore": {
            "precision": 0.89647,
            "recall": 0.9156,
            "f1": 0.90593
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.69268,
        "msttr-100_nopunct": 0.71697,
        "total_length": 37313,
        "mean_pred_length": 14.824394119984108,
        "std_pred_length": 4.548960343529668,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 43,
        "distinct-1": 0.06780478653552381,
        "vocab_size-1": 2530,
        "unique-1": 1196,
        "entropy-1": 8.108984134436783,
        "distinct-2": 0.2532762386481205,
        "vocab_size-2": 8813,
        "unique-2": 5157,
        "entropy-2": 11.501253767098266,
        "cond_entropy-2": 3.170786452312753,
        "distinct-3": 0.44970414201183434,
        "vocab_size-3": 14516,
        "unique-3": 10183,
        "entropy-3": 12.843913106774757,
        "cond_entropy-3": 1.393211132322861,
        "total_length-nopunct": 33013,
        "mean_pred_length-nopunct": 13.11601112435439,
        "std_pred_length-nopunct": 4.1011314054542005,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.07621240117529458,
        "vocab_size-1-nopunct": 2516,
        "unique-1-nopunct": 1194,
        "entropy-1-nopunct": 8.307441823880596,
        "distinct-2-nopunct": 0.26882214060860443,
        "vocab_size-2-nopunct": 8198,
        "unique-2-nopunct": 5001,
        "entropy-2-nopunct": 11.370270668945865,
        "cond_entropy-2-nopunct": 3.231013520229997,
        "distinct-3-nopunct": 0.4677436648915258,
        "vocab_size-3-nopunct": 13087,
        "unique-3-nopunct": 9465,
        "entropy-3-nopunct": 12.683023320624494,
        "cond_entropy-3-nopunct": 1.3944901657026785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.62624,
            "recall": 0.60969,
            "fmeasure": 0.60605
        },
        "rouge2": {
            "precision": 0.39557,
            "recall": 0.38391,
            "fmeasure": 0.38186
        },
        "rougeL": {
            "precision": 0.54219,
            "recall": 0.52806,
            "fmeasure": 0.52498
        },
        "rougeLsum": {
            "precision": 0.54219,
            "recall": 0.52806,
            "fmeasure": 0.52498
        },
        "bleu": 32.65049,
        "nist": 6.775155212090041,
        "local_recall": {
            "1": 0.5854557954936092
        },
        "nubia": {
            "semantic_relation": 4.01131,
            "contradiction": 5.72217,
            "irrelevancy": 21.50079,
            "logical_agreement": 72.77704,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.63163,
            "nubia_score": 0.7031
        },
        "meteor": 0.3251811200201812,
        "bleurt": -0.05014,
        "bertscore": {
            "precision": 0.8829,
            "recall": 0.87727,
            "f1": 0.87966
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.69051,
        "msttr-100_nopunct": 0.71868,
        "total_length": 25726,
        "mean_pred_length": 19.371987951807228,
        "std_pred_length": 5.028401111167902,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 38,
        "distinct-1": 0.08026898857187281,
        "vocab_size-1": 2065,
        "unique-1": 1002,
        "entropy-1": 8.026848237454862,
        "distinct-2": 0.2756373473235511,
        "vocab_size-2": 6725,
        "unique-2": 4052,
        "entropy-2": 11.190583160886368,
        "cond_entropy-2": 2.996175420904713,
        "distinct-3": 0.4729952319029042,
        "vocab_size-3": 10912,
        "unique-3": 7761,
        "entropy-3": 12.525555461552347,
        "cond_entropy-3": 1.3910750245553531,
        "total_length-nopunct": 22846,
        "mean_pred_length-nopunct": 17.20331325301205,
        "std_pred_length-nopunct": 4.53227261387164,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.08981878665849602,
        "vocab_size-1-nopunct": 2052,
        "unique-1-nopunct": 1000,
        "entropy-1-nopunct": 8.221419346440657,
        "distinct-2-nopunct": 0.2931499209963751,
        "vocab_size-2-nopunct": 6308,
        "unique-2-nopunct": 3909,
        "entropy-2-nopunct": 11.11951607704929,
        "cond_entropy-2-nopunct": 3.0355024358734397,
        "distinct-3-nopunct": 0.49653293709757307,
        "vocab_size-3-nopunct": 10025,
        "unique-3-nopunct": 7306,
        "entropy-3-nopunct": 12.443608220769928,
        "cond_entropy-3-nopunct": 1.400851084751151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.63403,
            "recall": 0.62271,
            "fmeasure": 0.61582
        },
        "rouge2": {
            "precision": 0.40551,
            "recall": 0.40078,
            "fmeasure": 0.39493
        },
        "rougeL": {
            "precision": 0.53977,
            "recall": 0.52965,
            "fmeasure": 0.52434
        },
        "rougeLsum": {
            "precision": 0.53977,
            "recall": 0.52965,
            "fmeasure": 0.52434
        },
        "bleu": 32.02251,
        "nist": 6.705260589325986,
        "local_recall": {
            "1": 0.6029358132749818
        },
        "nubia": {
            "semantic_relation": 4.15726,
            "contradiction": 6.29886,
            "irrelevancy": 19.52821,
            "logical_agreement": 74.17293,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.63163,
            "nubia_score": 0.72095
        },
        "meteor": 0.3283222437234797,
        "bleurt": -0.06071,
        "bertscore": {
            "precision": 0.88614,
            "recall": 0.88058,
            "f1": 0.88293
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.7365,
        "total_length": 2167,
        "mean_pred_length": 20.443396226415093,
        "std_pred_length": 4.341724265510376,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.41808952468850946,
        "vocab_size-1": 906,
        "unique-1": 676,
        "entropy-1": 8.264156451608835,
        "distinct-2": 0.834061135371179,
        "vocab_size-2": 1719,
        "unique-2": 1567,
        "entropy-2": 10.525834498555588,
        "cond_entropy-2": 2.0645120504462273,
        "distinct-3": 0.9498721227621484,
        "vocab_size-3": 1857,
        "unique-3": 1794,
        "entropy-3": 10.810413307820115,
        "cond_entropy-3": 0.2889134933268315,
        "total_length-nopunct": 2008,
        "mean_pred_length-nopunct": 18.943396226415093,
        "std_pred_length-nopunct": 4.188551757366346,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.44671314741035856,
        "vocab_size-1-nopunct": 897,
        "unique-1-nopunct": 674,
        "entropy-1-nopunct": 8.390725520907614,
        "distinct-2-nopunct": 0.8412197686645636,
        "vocab_size-2-nopunct": 1600,
        "unique-2-nopunct": 1461,
        "entropy-2-nopunct": 10.435475389324363,
        "cond_entropy-2-nopunct": 2.1387201220471814,
        "distinct-3-nopunct": 0.9604677060133631,
        "vocab_size-3-nopunct": 1725,
        "unique-3-nopunct": 1673,
        "entropy-3-nopunct": 10.720067549304794,
        "cond_entropy-3-nopunct": 0.2839113707024369,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.43084,
            "recall": 0.36715,
            "fmeasure": 0.39063
        },
        "rouge2": {
            "precision": 0.16578,
            "recall": 0.13924,
            "fmeasure": 0.14887
        },
        "rougeL": {
            "precision": 0.33275,
            "recall": 0.28478,
            "fmeasure": 0.30228
        },
        "rougeLsum": {
            "precision": 0.33275,
            "recall": 0.28478,
            "fmeasure": 0.30228
        },
        "bleu": 8.8801,
        "nist": 3.2236461340053864,
        "local_recall": {
            "1": 0.3419736243747158
        },
        "nubia": {
            "semantic_relation": 2.91966,
            "contradiction": 18.96463,
            "irrelevancy": 68.29223,
            "logical_agreement": 12.74314,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.67779,
            "nubia_score": 0.42169
        },
        "meteor": 0.1687630505898326,
        "bleurt": -0.30377,
        "bertscore": {
            "precision": 0.83935,
            "recall": 0.81775,
            "f1": 0.82816
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 8.75,
        "std_pred_length": 3.6314597615834874,
        "median_pred_length": 7.0,
        "min_pred_length": 6,
        "max_pred_length": 15,
        "distinct-1": 0.8857142857142857,
        "vocab_size-1": 31,
        "unique-1": 29,
        "entropy-1": 4.843568731230678,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": -0.11057057752583338,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.19930880822340663,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 3.4641016151377544,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.807354922057606,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644807,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.1875,
            "recall": 0.25,
            "fmeasure": 0.21429
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.125,
            "fmeasure": 0.1
        },
        "rougeL": {
            "precision": 0.1875,
            "recall": 0.25,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.1875,
            "recall": 0.25,
            "fmeasure": 0.21429
        },
        "bleu": 48.73099,
        "nist": 3.378154854248857,
        "local_recall": {
            "1": 0.5333333333333333,
            "2": 0.3076923076923077,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.32562,
            "contradiction": 21.08364,
            "irrelevancy": 15.69323,
            "logical_agreement": 63.22313,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.04348,
            "nubia_score": 0.87085
        },
        "meteor": 0.7360575779234485,
        "bleurt": 0.29741,
        "bertscore": {
            "precision": 0.94615,
            "recall": 0.95809,
            "f1": 0.95205
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69146,
        "msttr-100_nopunct": 0.71183,
        "total_length": 10318,
        "mean_pred_length": 22.0,
        "std_pred_length": 5.821436747021612,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 43,
        "distinct-1": 0.11639852684628804,
        "vocab_size-1": 1201,
        "unique-1": 587,
        "entropy-1": 7.847216766154887,
        "distinct-2": 0.3385115240125901,
        "vocab_size-2": 3334,
        "unique-2": 2065,
        "entropy-2": 10.524466492899823,
        "cond_entropy-2": 2.5482822862945533,
        "distinct-3": 0.5412579957356076,
        "vocab_size-3": 5077,
        "unique-3": 3714,
        "entropy-3": 11.676004153717807,
        "cond_entropy-3": 1.176992229647137,
        "total_length-nopunct": 9302,
        "mean_pred_length-nopunct": 19.83368869936034,
        "std_pred_length-nopunct": 5.284855402755936,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.1280369812943453,
        "vocab_size-1-nopunct": 1191,
        "unique-1-nopunct": 585,
        "entropy-1-nopunct": 7.989044283486996,
        "distinct-2-nopunct": 0.3551454771878184,
        "vocab_size-2-nopunct": 3137,
        "unique-2-nopunct": 1989,
        "entropy-2-nopunct": 10.459152903811123,
        "cond_entropy-2-nopunct": 2.555631738055839,
        "distinct-3-nopunct": 0.5646819703491153,
        "vocab_size-3-nopunct": 4723,
        "unique-3-nopunct": 3505,
        "entropy-3-nopunct": 11.617451339056537,
        "cond_entropy-3-nopunct": 1.1805911229402122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.65204,
            "recall": 0.6605,
            "fmeasure": 0.64418
        },
        "rouge2": {
            "precision": 0.42534,
            "recall": 0.43007,
            "fmeasure": 0.41961
        },
        "rougeL": {
            "precision": 0.56081,
            "recall": 0.56764,
            "fmeasure": 0.55404
        },
        "rougeLsum": {
            "precision": 0.56081,
            "recall": 0.56764,
            "fmeasure": 0.55404
        },
        "bleu": 33.80148,
        "nist": 6.469169071967345,
        "local_recall": {
            "1": 0.6411117544875506
        },
        "nubia": {
            "semantic_relation": 4.23522,
            "contradiction": 8.12793,
            "irrelevancy": 18.97856,
            "logical_agreement": 72.89351,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.70796,
            "nubia_score": 0.72355
        },
        "meteor": 0.34401823877663806,
        "bleurt": -0.03196,
        "bertscore": {
            "precision": 0.88834,
            "recall": 0.88737,
            "f1": 0.88746
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.72143,
        "msttr-100_nopunct": 0.735,
        "total_length": 2179,
        "mean_pred_length": 20.556603773584907,
        "std_pred_length": 4.734617971238087,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 37,
        "distinct-1": 0.40431390546122076,
        "vocab_size-1": 881,
        "unique-1": 626,
        "entropy-1": 8.242730654536924,
        "distinct-2": 0.8215147129763628,
        "vocab_size-2": 1703,
        "unique-2": 1532,
        "entropy-2": 10.489189911858166,
        "cond_entropy-2": 2.047999408519607,
        "distinct-3": 0.9430604982206405,
        "vocab_size-3": 1855,
        "unique-3": 1784,
        "entropy-3": 10.802586202494476,
        "cond_entropy-3": 0.3158061589288463,
        "total_length-nopunct": 2033,
        "mean_pred_length-nopunct": 19.17924528301887,
        "std_pred_length-nopunct": 4.459031898084843,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.4308903098868667,
        "vocab_size-1-nopunct": 876,
        "unique-1-nopunct": 626,
        "entropy-1-nopunct": 8.370291589828506,
        "distinct-2-nopunct": 0.8271925272444214,
        "vocab_size-2-nopunct": 1594,
        "unique-2-nopunct": 1440,
        "entropy-2-nopunct": 10.396536142589815,
        "cond_entropy-2-nopunct": 2.1124568056594053,
        "distinct-3-nopunct": 0.9500274574409665,
        "vocab_size-3-nopunct": 1730,
        "unique-3-nopunct": 1666,
        "entropy-3-nopunct": 10.713372847077663,
        "cond_entropy-3-nopunct": 0.3178434645784971,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.42241,
            "recall": 0.36919,
            "fmeasure": 0.38515
        },
        "rouge2": {
            "precision": 0.14733,
            "recall": 0.13154,
            "fmeasure": 0.13593
        },
        "rougeL": {
            "precision": 0.31888,
            "recall": 0.27974,
            "fmeasure": 0.2912
        },
        "rougeLsum": {
            "precision": 0.31888,
            "recall": 0.27974,
            "fmeasure": 0.2912
        },
        "bleu": 8.12217,
        "nist": 3.1949071227478347,
        "local_recall": {
            "1": 0.34051329055912005
        },
        "nubia": {
            "semantic_relation": 2.93582,
            "contradiction": 24.18972,
            "irrelevancy": 60.91226,
            "logical_agreement": 14.89802,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.59816,
            "nubia_score": 0.42285
        },
        "meteor": 0.16603788037572573,
        "bleurt": -0.3066,
        "bertscore": {
            "precision": 0.83857,
            "recall": 0.82137,
            "f1": 0.82955
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.69,
        "total_length": 321,
        "mean_pred_length": 16.894736842105264,
        "std_pred_length": 11.331812401340263,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 47,
        "distinct-1": 0.4485981308411215,
        "vocab_size-1": 144,
        "unique-1": 97,
        "entropy-1": 6.460109131439194,
        "distinct-2": 0.7450331125827815,
        "vocab_size-2": 225,
        "unique-2": 180,
        "entropy-2": 7.6175530442134844,
        "cond_entropy-2": 0.97571286713475,
        "distinct-3": 0.8515901060070671,
        "vocab_size-3": 241,
        "unique-3": 208,
        "entropy-3": 7.8220991880080275,
        "cond_entropy-3": 0.1780743057294722,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 13.578947368421053,
        "std_pred_length-nopunct": 9.560421646029086,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.5387596899224806,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.631043145924299,
        "distinct-2-nopunct": 0.8075313807531381,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 166,
        "entropy-2-nopunct": 7.428615672245986,
        "cond_entropy-2-nopunct": 0.7879997019513157,
        "distinct-3-nopunct": 0.8818181818181818,
        "vocab_size-3-nopunct": 194,
        "unique-3-nopunct": 174,
        "entropy-3-nopunct": 7.522179940758038,
        "cond_entropy-3-nopunct": 0.10098663931245534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.3396,
            "recall": 0.34921,
            "fmeasure": 0.33679
        },
        "rouge2": {
            "precision": 0.20614,
            "recall": 0.22368,
            "fmeasure": 0.20003
        },
        "rougeL": {
            "precision": 0.28847,
            "recall": 0.30518,
            "fmeasure": 0.28921
        },
        "rougeLsum": {
            "precision": 0.28847,
            "recall": 0.30518,
            "fmeasure": 0.28921
        },
        "bleu": 46.25371,
        "nist": 6.08148115319592,
        "local_recall": {
            "1": 0.27607361963190186,
            "2": 0.5729166666666666,
            "3": 0.8043478260869565
        },
        "nubia": {
            "semantic_relation": 3.77689,
            "contradiction": 31.97768,
            "irrelevancy": 17.47081,
            "logical_agreement": 50.55151,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.98027,
            "nubia_score": 0.74692
        },
        "meteor": 0.6300231944298633,
        "bleurt": 0.14708,
        "bertscore": {
            "precision": 0.94986,
            "recall": 0.94091,
            "f1": 0.94478
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.65425,
        "msttr-100_nopunct": 0.65671,
        "total_length": 8740,
        "mean_pred_length": 26.08955223880597,
        "std_pred_length": 5.57534911103849,
        "median_pred_length": 25.0,
        "min_pred_length": 13,
        "max_pred_length": 51,
        "distinct-1": 0.1051487414187643,
        "vocab_size-1": 919,
        "unique-1": 445,
        "entropy-1": 7.493863989934229,
        "distinct-2": 0.301249256395003,
        "vocab_size-2": 2532,
        "unique-2": 1504,
        "entropy-2": 10.058425872468883,
        "cond_entropy-2": 2.482614234091952,
        "distinct-3": 0.4924411400247832,
        "vocab_size-3": 3974,
        "unique-3": 2812,
        "entropy-3": 11.229380168348492,
        "cond_entropy-3": 1.1468643478566625,
        "total_length-nopunct": 7971,
        "mean_pred_length-nopunct": 23.79402985074627,
        "std_pred_length-nopunct": 4.813782470235929,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.11366202484004516,
        "vocab_size-1-nopunct": 906,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 7.540203021328376,
        "distinct-2-nopunct": 0.31744368779465687,
        "vocab_size-2-nopunct": 2424,
        "unique-2-nopunct": 1478,
        "entropy-2-nopunct": 10.027983298015478,
        "cond_entropy-2-nopunct": 2.502029963831503,
        "distinct-3-nopunct": 0.5119846596356663,
        "vocab_size-3-nopunct": 3738,
        "unique-3-nopunct": 2720,
        "entropy-3-nopunct": 11.143522423402139,
        "cond_entropy-3-nopunct": 1.1256895684765469,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.74201,
            "recall": 0.68925,
            "fmeasure": 0.70645
        },
        "rouge2": {
            "precision": 0.52499,
            "recall": 0.48617,
            "fmeasure": 0.49887
        },
        "rougeL": {
            "precision": 0.63637,
            "recall": 0.59019,
            "fmeasure": 0.60553
        },
        "rougeLsum": {
            "precision": 0.63637,
            "recall": 0.59019,
            "fmeasure": 0.60553
        },
        "bleu": 40.14969,
        "nist": 7.0055422805631835,
        "local_recall": {
            "1": 0.6699363057324841
        },
        "nubia": {
            "semantic_relation": 4.46721,
            "contradiction": 1.87745,
            "irrelevancy": 9.21258,
            "logical_agreement": 88.90998,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.38062,
            "nubia_score": 0.80895
        },
        "meteor": 0.3766765564950249,
        "bleurt": 0.06464,
        "bertscore": {
            "precision": 0.90931,
            "recall": 0.89695,
            "f1": 0.9028
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.69682,
        "msttr-100_nopunct": 0.7065,
        "total_length": 2207,
        "mean_pred_length": 20.82075471698113,
        "std_pred_length": 3.9592194051765817,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.3860444041685546,
        "vocab_size-1": 852,
        "unique-1": 622,
        "entropy-1": 8.071350180805384,
        "distinct-2": 0.7967634459781057,
        "vocab_size-2": 1674,
        "unique-2": 1500,
        "entropy-2": 10.401024597187186,
        "cond_entropy-2": 2.1434353062271,
        "distinct-3": 0.9403508771929825,
        "vocab_size-3": 1876,
        "unique-3": 1813,
        "entropy-3": 10.791796061606851,
        "cond_entropy-3": 0.3988604243778954,
        "total_length-nopunct": 2067,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.732190413553262,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.409288824383164,
        "vocab_size-1-nopunct": 846,
        "unique-1-nopunct": 621,
        "entropy-1-nopunct": 8.172982207161867,
        "distinct-2-nopunct": 0.7980622131565528,
        "vocab_size-2-nopunct": 1565,
        "unique-2-nopunct": 1405,
        "entropy-2-nopunct": 10.300007625730757,
        "cond_entropy-2-nopunct": 2.2258303239913984,
        "distinct-3-nopunct": 0.9460916442048517,
        "vocab_size-3-nopunct": 1755,
        "unique-3-nopunct": 1698,
        "entropy-3-nopunct": 10.705046830158661,
        "cond_entropy-3-nopunct": 0.4133767133806976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.43201,
            "recall": 0.38229,
            "fmeasure": 0.39702
        },
        "rouge2": {
            "precision": 0.16091,
            "recall": 0.13946,
            "fmeasure": 0.14534
        },
        "rougeL": {
            "precision": 0.33929,
            "recall": 0.30235,
            "fmeasure": 0.31257
        },
        "rougeLsum": {
            "precision": 0.33929,
            "recall": 0.30235,
            "fmeasure": 0.31257
        },
        "bleu": 9.00208,
        "nist": 3.2803429405647537,
        "local_recall": {
            "1": 0.3531047265987025
        },
        "nubia": {
            "semantic_relation": 2.86031,
            "contradiction": 21.20298,
            "irrelevancy": 62.9519,
            "logical_agreement": 15.84512,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.51274,
            "nubia_score": 0.40899
        },
        "meteor": 0.16615985330878444,
        "bleurt": -0.3497,
        "bertscore": {
            "precision": 0.83678,
            "recall": 0.82091,
            "f1": 0.82838
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "mT5_large/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.66623,
        "msttr-100_nopunct": 0.705,
        "total_length": 5383,
        "mean_pred_length": 10.766,
        "std_pred_length": 4.088917216085451,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 29,
        "distinct-1": 0.12669515140256363,
        "vocab_size-1": 682,
        "unique-1": 310,
        "entropy-1": 7.445644409522051,
        "distinct-2": 0.3784558672946959,
        "vocab_size-2": 1848,
        "unique-2": 1157,
        "entropy-2": 9.858046588651343,
        "cond_entropy-2": 2.205361658743876,
        "distinct-3": 0.5838466803559206,
        "vocab_size-3": 2559,
        "unique-3": 1963,
        "entropy-3": 10.699785946797746,
        "cond_entropy-3": 0.9047810165644887,
        "total_length-nopunct": 4644,
        "mean_pred_length-nopunct": 9.288,
        "std_pred_length-nopunct": 3.6371769272335377,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.14577950043066323,
        "vocab_size-1-nopunct": 677,
        "unique-1-nopunct": 309,
        "entropy-1-nopunct": 7.707644474418036,
        "distinct-2-nopunct": 0.39623552123552125,
        "vocab_size-2-nopunct": 1642,
        "unique-2-nopunct": 1052,
        "entropy-2-nopunct": 9.714371171979778,
        "cond_entropy-2-nopunct": 2.199472034911305,
        "distinct-3-nopunct": 0.6135490948985189,
        "vocab_size-3-nopunct": 2237,
        "unique-3-nopunct": 1751,
        "entropy-3-nopunct": 10.55410755605365,
        "cond_entropy-3-nopunct": 0.948320126251495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.46,
            "recall": 0.47504,
            "fmeasure": 0.45266
        },
        "rouge2": {
            "precision": 0.26189,
            "recall": 0.26995,
            "fmeasure": 0.25723
        },
        "rougeL": {
            "precision": 0.4036,
            "recall": 0.41602,
            "fmeasure": 0.39673
        },
        "rougeLsum": {
            "precision": 0.4036,
            "recall": 0.41602,
            "fmeasure": 0.39673
        },
        "bleu": 16.15818,
        "nist": 3.7161132782570854,
        "local_recall": {
            "1": 0.4435126950850221
        },
        "nubia": {
            "semantic_relation": 3.06261,
            "contradiction": 23.52126,
            "irrelevancy": 32.75454,
            "logical_agreement": 43.7242,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.79469,
            "nubia_score": 0.44308
        },
        "meteor": 0.22199274373196443,
        "bleurt": -0.24235,
        "bertscore": {
            "precision": 0.88704,
            "recall": 0.89139,
            "f1": 0.88893
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68418,
        "msttr-100_nopunct": 0.71508,
        "total_length": 6712,
        "mean_pred_length": 13.424,
        "std_pred_length": 7.672041710001321,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 51,
        "distinct-1": 0.15196662693682955,
        "vocab_size-1": 1020,
        "unique-1": 554,
        "entropy-1": 7.818681754297728,
        "distinct-2": 0.4771410173857051,
        "vocab_size-2": 2964,
        "unique-2": 2072,
        "entropy-2": 10.732955221201603,
        "cond_entropy-2": 2.6920715893544926,
        "distinct-3": 0.6973039215686274,
        "vocab_size-3": 3983,
        "unique-3": 3268,
        "entropy-3": 11.571197413665892,
        "cond_entropy-3": 0.8726978448765365,
        "total_length-nopunct": 5931,
        "mean_pred_length-nopunct": 11.862,
        "std_pred_length-nopunct": 7.075518072904626,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.17012308211094251,
        "vocab_size-1-nopunct": 1009,
        "unique-1-nopunct": 551,
        "entropy-1-nopunct": 7.990860242524766,
        "distinct-2-nopunct": 0.4907015282636715,
        "vocab_size-2-nopunct": 2665,
        "unique-2-nopunct": 1905,
        "entropy-2-nopunct": 10.571156211539963,
        "cond_entropy-2-nopunct": 2.723674831144319,
        "distinct-3-nopunct": 0.7057392009734333,
        "vocab_size-3-nopunct": 3480,
        "unique-3-nopunct": 2905,
        "entropy-3-nopunct": 11.3636195849519,
        "cond_entropy-3-nopunct": 0.8467609317078868,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.56306,
            "recall": 0.53846,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.34827,
            "recall": 0.3289,
            "fmeasure": 0.32985
        },
        "rougeL": {
            "precision": 0.50317,
            "recall": 0.47985,
            "fmeasure": 0.48055
        },
        "rougeLsum": {
            "precision": 0.50317,
            "recall": 0.47985,
            "fmeasure": 0.48055
        },
        "bleu": 30.45988,
        "nist": 5.9076897012853316,
        "local_recall": {
            "1": 0.5541214937188091
        },
        "nubia": {
            "semantic_relation": 3.51439,
            "contradiction": 8.06304,
            "irrelevancy": 23.05802,
            "logical_agreement": 68.87895,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.58811,
            "nubia_score": 0.61617
        },
        "meteor": 0.30157011438556064,
        "bleurt": -0.13644,
        "bertscore": {
            "precision": 0.86628,
            "recall": 0.85957,
            "f1": 0.86243
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.63895,
        "msttr-100_nopunct": 0.63629,
        "total_length": 7632,
        "mean_pred_length": 29.8125,
        "std_pred_length": 6.846246690705791,
        "median_pred_length": 30.0,
        "min_pred_length": 15,
        "max_pred_length": 51,
        "distinct-1": 0.07979559748427673,
        "vocab_size-1": 609,
        "unique-1": 265,
        "entropy-1": 7.140266704657918,
        "distinct-2": 0.2527114967462039,
        "vocab_size-2": 1864,
        "unique-2": 970,
        "entropy-2": 9.637474541466618,
        "cond_entropy-2": 2.4371671985582424,
        "distinct-3": 0.45196629213483147,
        "vocab_size-3": 3218,
        "unique-3": 2149,
        "entropy-3": 10.89242331622905,
        "cond_entropy-3": 1.2891114491714,
        "total_length-nopunct": 7001,
        "mean_pred_length-nopunct": 27.34765625,
        "std_pred_length-nopunct": 6.024707783937403,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.08584487930295671,
        "vocab_size-1-nopunct": 601,
        "unique-1-nopunct": 264,
        "entropy-1-nopunct": 7.167171323778977,
        "distinct-2-nopunct": 0.2627131208302446,
        "vocab_size-2-nopunct": 1772,
        "unique-2-nopunct": 936,
        "entropy-2-nopunct": 9.552138533806165,
        "cond_entropy-2-nopunct": 2.4470001824947096,
        "distinct-3-nopunct": 0.4664817383263985,
        "vocab_size-3-nopunct": 3027,
        "unique-3-nopunct": 2064,
        "entropy-3-nopunct": 10.805063723307683,
        "cond_entropy-3-nopunct": 1.285311792734623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.69026,
            "recall": 0.64092,
            "fmeasure": 0.65619
        },
        "rouge2": {
            "precision": 0.44956,
            "recall": 0.41691,
            "fmeasure": 0.42697
        },
        "rougeL": {
            "precision": 0.5707,
            "recall": 0.528,
            "fmeasure": 0.54162
        },
        "rougeLsum": {
            "precision": 0.5707,
            "recall": 0.528,
            "fmeasure": 0.54162
        },
        "bleu": 34.31253,
        "nist": 6.264023421670679,
        "local_recall": {
            "1": 0.6269652921981608
        },
        "nubia": {
            "semantic_relation": 3.94267,
            "contradiction": 6.9666,
            "irrelevancy": 22.9242,
            "logical_agreement": 70.1092,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.05394,
            "nubia_score": 0.66715
        },
        "meteor": 0.33922122525214315,
        "bleurt": -0.0756,
        "bertscore": {
            "precision": 0.8984,
            "recall": 0.88613,
            "f1": 0.89195
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 500,
        "msttr-100": 0.71218,
        "msttr-100_nopunct": 0.73074,
        "total_length": 10164,
        "mean_pred_length": 20.328,
        "std_pred_length": 4.34009400819844,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 41,
        "distinct-1": 0.26013380558835103,
        "vocab_size-1": 2644,
        "unique-1": 1659,
        "entropy-1": 8.868636705834845,
        "distinct-2": 0.6882243377483444,
        "vocab_size-2": 6651,
        "unique-2": 5632,
        "entropy-2": 12.12797069861272,
        "cond_entropy-2": 3.026236478193287,
        "distinct-3": 0.889022261021388,
        "vocab_size-3": 8147,
        "unique-3": 7599,
        "entropy-3": 12.851928834684418,
        "cond_entropy-3": 0.7304242475624382,
        "total_length-nopunct": 9462,
        "mean_pred_length-nopunct": 18.924,
        "std_pred_length-nopunct": 4.172076701116604,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.2782709786514479,
        "vocab_size-1-nopunct": 2633,
        "unique-1-nopunct": 1657,
        "entropy-1-nopunct": 9.039025380488416,
        "distinct-2-nopunct": 0.6956036598973443,
        "vocab_size-2-nopunct": 6234,
        "unique-2-nopunct": 5300,
        "entropy-2-nopunct": 12.051022103893478,
        "cond_entropy-2-nopunct": 3.1334769441119956,
        "distinct-3-nopunct": 0.8995509335854408,
        "vocab_size-3-nopunct": 7612,
        "unique-3-nopunct": 7127,
        "entropy-3-nopunct": 12.781036475608012,
        "cond_entropy-3-nopunct": 0.7383143852352003,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.41849,
            "recall": 0.37424,
            "fmeasure": 0.38724
        },
        "rouge2": {
            "precision": 0.15979,
            "recall": 0.14193,
            "fmeasure": 0.14723
        },
        "rougeL": {
            "precision": 0.3237,
            "recall": 0.28965,
            "fmeasure": 0.29948
        },
        "rougeLsum": {
            "precision": 0.3237,
            "recall": 0.28965,
            "fmeasure": 0.29948
        },
        "bleu": 9.14109,
        "nist": 3.6619417474221163,
        "local_recall": {
            "1": 0.3469119579500657
        },
        "nubia": {
            "semantic_relation": 2.8986,
            "contradiction": 21.80981,
            "irrelevancy": 64.03772,
            "logical_agreement": 14.15247,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.61456,
            "nubia_score": 0.42238
        },
        "meteor": 0.16741609344509936,
        "bleurt": -0.31774,
        "bertscore": {
            "precision": 0.83603,
            "recall": 0.81982,
            "f1": 0.82751
        }
    },
    "web_nlg_ru_val": {
        "predictions_file": "mT5_large/web_nlg_ru_val",
        "N": 790,
        "msttr-100": 0.47791,
        "msttr-100_nopunct": 0.51452,
        "total_length": 15309,
        "mean_pred_length": 19.378481012658227,
        "std_pred_length": 9.687250800532848,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 51,
        "distinct-1": 0.09321314259585864,
        "vocab_size-1": 1427,
        "unique-1": 474,
        "entropy-1": 8.233407383024021,
        "distinct-2": 0.23741304497554927,
        "vocab_size-2": 3447,
        "unique-2": 1557,
        "entropy-2": 10.666900982346005,
        "cond_entropy-2": 2.185632166868035,
        "distinct-3": 0.3551606089300022,
        "vocab_size-3": 4876,
        "unique-3": 2691,
        "entropy-3": 11.46022452823043,
        "cond_entropy-3": 0.8191436566845509,
        "total_length-nopunct": 12423,
        "mean_pred_length-nopunct": 15.725316455696202,
        "std_pred_length-nopunct": 8.24109751131456,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.11446510504709008,
        "vocab_size-1-nopunct": 1422,
        "unique-1-nopunct": 474,
        "entropy-1-nopunct": 8.866106204414113,
        "distinct-2-nopunct": 0.2731023811570532,
        "vocab_size-2-nopunct": 3177,
        "unique-2-nopunct": 1560,
        "entropy-2-nopunct": 10.660011037378883,
        "cond_entropy-2-nopunct": 1.8586367741900451,
        "distinct-3-nopunct": 0.3936180023978604,
        "vocab_size-3-nopunct": 4268,
        "unique-3-nopunct": 2521,
        "entropy-3-nopunct": 11.30399775325042,
        "cond_entropy-3-nopunct": 0.6846323317852382,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_val.json",
        "rouge1": {
            "precision": 0.33444,
            "recall": 0.33931,
            "fmeasure": 0.33486
        },
        "rouge2": {
            "precision": 0.13292,
            "recall": 0.13605,
            "fmeasure": 0.13332
        },
        "rougeL": {
            "precision": 0.32013,
            "recall": 0.32534,
            "fmeasure": 0.32071
        },
        "rougeLsum": {
            "precision": 0.32013,
            "recall": 0.32534,
            "fmeasure": 0.32071
        },
        "bleu": 46.39115,
        "nist": 8.14871060752078,
        "local_recall": {
            "1": 0.24778200253485425,
            "2": 0.635343618513324,
            "3": 0.849307913293288,
            "4": 0.8484848484848485,
            "5": 0.8846153846153846,
            "6": 1.0,
            "7": 0.875,
            "8": 0,
            "9": 1.0
        },
        "nubia": {
            "semantic_relation": 3.96434,
            "contradiction": 21.23623,
            "irrelevancy": 21.46078,
            "logical_agreement": 57.30299,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.60335,
            "nubia_score": 0.81522
        },
        "meteor": 0.6139189847272893,
        "bleurt": 0.18556,
        "bertscore": {
            "precision": 0.95375,
            "recall": 0.95206,
            "f1": 0.95209
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.62546,
            "fmeasure": 0.60304
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.39583,
            "fmeasure": 0.39915
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.62546,
            "fmeasure": 0.60304
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.62546,
            "fmeasure": 0.60304
        },
        "bleu": 34.91449,
        "nist": 3.050816487445029,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "nubia": {
            "semantic_relation": 4.44571,
            "contradiction": 0.42029,
            "irrelevancy": 60.77227,
            "logical_agreement": 38.80744,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.65015,
            "nubia_score": 0.74795
        },
        "meteor": 0.37246231344436204,
        "bleurt": 0.4654,
        "bertscore": {
            "precision": 0.93114,
            "recall": 0.93781,
            "f1": 0.93127
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.395,
        "msttr-100_nopunct": 0.425,
        "total_length": 294,
        "mean_pred_length": 18.375,
        "std_pred_length": 3.6890886408434267,
        "median_pred_length": 19.5,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.23129251700680273,
        "vocab_size-1": 68,
        "unique-1": 23,
        "entropy-1": 5.300072510780556,
        "distinct-2": 0.3381294964028777,
        "vocab_size-2": 94,
        "unique-2": 37,
        "entropy-2": 6.039845039300054,
        "cond_entropy-2": 0.6764401448680342,
        "distinct-3": 0.4198473282442748,
        "vocab_size-3": 110,
        "unique-3": 50,
        "entropy-3": 6.368578936670966,
        "cond_entropy-3": 0.34728032705871503,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 16.125,
        "std_pred_length-nopunct": 3.75624480032918,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.25193798449612403,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 5.267925982334186,
        "distinct-2-nopunct": 0.3512396694214876,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.923082384377802,
        "cond_entropy-2-nopunct": 0.7150177591215361,
        "distinct-3-nopunct": 0.4424778761061947,
        "vocab_size-3-nopunct": 100,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 6.246156726868984,
        "cond_entropy-3-nopunct": 0.3342518720919777,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.51357,
            "recall": 0.53779,
            "fmeasure": 0.51337
        },
        "rouge2": {
            "precision": 0.29343,
            "recall": 0.32154,
            "fmeasure": 0.29848
        },
        "rougeL": {
            "precision": 0.428,
            "recall": 0.45586,
            "fmeasure": 0.43045
        },
        "rougeLsum": {
            "precision": 0.428,
            "recall": 0.45586,
            "fmeasure": 0.43045
        },
        "bleu": 17.93316,
        "nist": 2.976964840693439,
        "local_recall": {
            "1": 0.4534412955465587
        },
        "nubia": {
            "semantic_relation": 3.31567,
            "contradiction": 33.3006,
            "irrelevancy": 28.63279,
            "logical_agreement": 38.06661,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.11336,
            "nubia_score": 0.50455
        },
        "meteor": 0.2382197587778059,
        "bleurt": -0.02396,
        "bertscore": {
            "precision": 0.90828,
            "recall": 0.91347,
            "f1": 0.91065
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 500,
        "msttr-100": 0.70137,
        "msttr-100_nopunct": 0.72368,
        "total_length": 10268,
        "mean_pred_length": 20.536,
        "std_pred_length": 4.641627300850425,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 62,
        "distinct-1": 0.2584729255940787,
        "vocab_size-1": 2654,
        "unique-1": 1703,
        "entropy-1": 8.842811822970324,
        "distinct-2": 0.676085176085176,
        "vocab_size-2": 6604,
        "unique-2": 5614,
        "entropy-2": 12.053792381946698,
        "cond_entropy-2": 2.982586084379107,
        "distinct-3": 0.8692274492878722,
        "vocab_size-3": 8056,
        "unique-3": 7513,
        "entropy-3": 12.773731658734745,
        "cond_entropy-3": 0.7301329767584953,
        "total_length-nopunct": 9571,
        "mean_pred_length-nopunct": 19.142,
        "std_pred_length-nopunct": 4.4530704014196765,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.2762511754257653,
        "vocab_size-1-nopunct": 2644,
        "unique-1-nopunct": 1702,
        "entropy-1-nopunct": 9.009362934575087,
        "distinct-2-nopunct": 0.6828354095469077,
        "vocab_size-2-nopunct": 6194,
        "unique-2-nopunct": 5284,
        "entropy-2-nopunct": 11.971413335516878,
        "cond_entropy-2-nopunct": 3.0847882957442354,
        "distinct-3-nopunct": 0.8770271846925679,
        "vocab_size-3-nopunct": 7517,
        "unique-3-nopunct": 7027,
        "entropy-3-nopunct": 12.695351101272957,
        "cond_entropy-3-nopunct": 0.7397527762914764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.41334,
            "recall": 0.36958,
            "fmeasure": 0.38226
        },
        "rouge2": {
            "precision": 0.15719,
            "recall": 0.13873,
            "fmeasure": 0.14408
        },
        "rougeL": {
            "precision": 0.31916,
            "recall": 0.28485,
            "fmeasure": 0.29473
        },
        "rougeLsum": {
            "precision": 0.31916,
            "recall": 0.28485,
            "fmeasure": 0.29473
        },
        "bleu": 8.60908,
        "nist": 3.550116090226943,
        "local_recall": {
            "1": 0.3396394611727417
        },
        "nubia": {
            "semantic_relation": 2.85082,
            "contradiction": 23.66733,
            "irrelevancy": 64.10377,
            "logical_agreement": 12.2289,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.57818,
            "nubia_score": 0.41121
        },
        "meteor": 0.1652990693090066,
        "bleurt": -0.33991,
        "bertscore": {
            "precision": 0.83399,
            "recall": 0.81609,
            "f1": 0.82459
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.45,
        "msttr-100_nopunct": 0.46,
        "total_length": 362,
        "mean_pred_length": 10.647058823529411,
        "std_pred_length": 3.5635602896143435,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.2513812154696133,
        "vocab_size-1": 91,
        "unique-1": 37,
        "entropy-1": 5.59819893757423,
        "distinct-2": 0.45426829268292684,
        "vocab_size-2": 149,
        "unique-2": 83,
        "entropy-2": 6.693683786722569,
        "cond_entropy-2": 0.8689063725653837,
        "distinct-3": 0.5952380952380952,
        "vocab_size-3": 175,
        "unique-3": 118,
        "entropy-3": 7.083684008585192,
        "cond_entropy-3": 0.40563747001711453,
        "total_length-nopunct": 317,
        "mean_pred_length-nopunct": 9.323529411764707,
        "std_pred_length-nopunct": 3.159677833868641,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.2807570977917981,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.660488205802741,
        "distinct-2-nopunct": 0.4628975265017668,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.491653159553932,
        "cond_entropy-2-nopunct": 0.8802931757586102,
        "distinct-3-nopunct": 0.6024096385542169,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.825099137475673,
        "cond_entropy-3-nopunct": 0.3799303572350479,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.55798,
            "recall": 0.52315,
            "fmeasure": 0.53067
        },
        "rouge2": {
            "precision": 0.3619,
            "recall": 0.33826,
            "fmeasure": 0.34361
        },
        "rougeL": {
            "precision": 0.48729,
            "recall": 0.45649,
            "fmeasure": 0.46345
        },
        "rougeLsum": {
            "precision": 0.48729,
            "recall": 0.45649,
            "fmeasure": 0.46345
        },
        "bleu": 16.24473,
        "nist": 2.917992797661067,
        "local_recall": {
            "1": 0.3970149253731343
        },
        "nubia": {
            "semantic_relation": 3.40381,
            "contradiction": 21.53039,
            "irrelevancy": 20.39545,
            "logical_agreement": 58.07416,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.39037,
            "nubia_score": 0.49761
        },
        "meteor": 0.2190294053763578,
        "bleurt": -0.17807,
        "bertscore": {
            "precision": 0.91951,
            "recall": 0.91402,
            "f1": 0.9166
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "mT5_large/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.69538,
        "msttr-100_nopunct": 0.72263,
        "total_length": 6545,
        "mean_pred_length": 13.09,
        "std_pred_length": 7.96705089728941,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 49,
        "distinct-1": 0.15920550038197098,
        "vocab_size-1": 1042,
        "unique-1": 575,
        "entropy-1": 7.9054646753565425,
        "distinct-2": 0.5177832919768404,
        "vocab_size-2": 3130,
        "unique-2": 2220,
        "entropy-2": 10.919140885538987,
        "cond_entropy-2": 2.7828156572373395,
        "distinct-3": 0.757619477006312,
        "vocab_size-3": 4201,
        "unique-3": 3543,
        "entropy-3": 11.76387202394112,
        "cond_entropy-3": 0.8601615356257021,
        "total_length-nopunct": 5771,
        "mean_pred_length-nopunct": 11.542,
        "std_pred_length-nopunct": 7.284794849547927,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.17813203950788425,
        "vocab_size-1-nopunct": 1028,
        "unique-1-nopunct": 570,
        "entropy-1-nopunct": 8.090392558975504,
        "distinct-2-nopunct": 0.5350028457598178,
        "vocab_size-2-nopunct": 2820,
        "unique-2-nopunct": 2039,
        "entropy-2-nopunct": 10.770643874050306,
        "cond_entropy-2-nopunct": 2.8059041663763113,
        "distinct-3-nopunct": 0.77342276252358,
        "vocab_size-3-nopunct": 3690,
        "unique-3-nopunct": 3165,
        "entropy-3-nopunct": 11.582531739209967,
        "cond_entropy-3-nopunct": 0.8449564335915943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "rouge1": {
            "precision": 0.52687,
            "recall": 0.49892,
            "fmeasure": 0.50018
        },
        "rouge2": {
            "precision": 0.31151,
            "recall": 0.28997,
            "fmeasure": 0.2921
        },
        "rougeL": {
            "precision": 0.46196,
            "recall": 0.43718,
            "fmeasure": 0.4384
        },
        "rougeLsum": {
            "precision": 0.46196,
            "recall": 0.43718,
            "fmeasure": 0.4384
        },
        "bleu": 27.6745,
        "nist": 5.581204896296584,
        "local_recall": {
            "1": 0.5176921736099006
        },
        "nubia": {
            "semantic_relation": 3.45786,
            "contradiction": 7.16995,
            "irrelevancy": 26.8261,
            "logical_agreement": 66.00395,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.80128,
            "nubia_score": 0.58755
        },
        "meteor": 0.2908340723948039,
        "bleurt": -0.19562,
        "bertscore": {
            "precision": 0.8579,
            "recall": 0.84958,
            "f1": 0.85317
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.57667,
        "msttr-100_nopunct": 0.56846,
        "total_length": 1502,
        "mean_pred_length": 32.65217391304348,
        "std_pred_length": 10.155780943799934,
        "median_pred_length": 33.0,
        "min_pred_length": 18,
        "max_pred_length": 72,
        "distinct-1": 0.14447403462050598,
        "vocab_size-1": 217,
        "unique-1": 81,
        "entropy-1": 6.49882050564754,
        "distinct-2": 0.4141483516483517,
        "vocab_size-2": 603,
        "unique-2": 337,
        "entropy-2": 8.584486745041076,
        "cond_entropy-2": 2.0558840744667495,
        "distinct-3": 0.6354609929078014,
        "vocab_size-3": 896,
        "unique-3": 646,
        "entropy-3": 9.478884201780176,
        "cond_entropy-3": 0.9175763590137491,
        "total_length-nopunct": 1393,
        "mean_pred_length-nopunct": 30.282608695652176,
        "std_pred_length-nopunct": 9.173835771362183,
        "median_pred_length-nopunct": 29.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.15218951902368988,
        "vocab_size-1-nopunct": 212,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.466325941147587,
        "distinct-2-nopunct": 0.4172234595397179,
        "vocab_size-2-nopunct": 562,
        "unique-2-nopunct": 322,
        "entropy-2-nopunct": 8.470157336950665,
        "cond_entropy-2-nopunct": 2.0500394274135316,
        "distinct-3-nopunct": 0.6364335126825519,
        "vocab_size-3-nopunct": 828,
        "unique-3-nopunct": 608,
        "entropy-3-nopunct": 9.354414864937919,
        "cond_entropy-3-nopunct": 0.9174966738745238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.62034,
            "recall": 0.65492,
            "fmeasure": 0.62282
        },
        "rouge2": {
            "precision": 0.38388,
            "recall": 0.41136,
            "fmeasure": 0.38798
        },
        "rougeL": {
            "precision": 0.5057,
            "recall": 0.53086,
            "fmeasure": 0.50713
        },
        "rougeLsum": {
            "precision": 0.5057,
            "recall": 0.53086,
            "fmeasure": 0.50713
        },
        "bleu": 33.61181,
        "nist": 4.955250435167436,
        "local_recall": {
            "1": 0.6284062758051198
        },
        "nubia": {
            "semantic_relation": 3.76325,
            "contradiction": 37.83029,
            "irrelevancy": 27.11795,
            "logical_agreement": 35.05176,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.38996,
            "nubia_score": 0.54004
        },
        "meteor": 0.31812753787687303,
        "bleurt": -0.15958,
        "bertscore": {
            "precision": 0.88294,
            "recall": 0.88993,
            "f1": 0.8861
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "mT5_large/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.69623,
        "msttr-100_nopunct": 0.71944,
        "total_length": 6185,
        "mean_pred_length": 12.37,
        "std_pred_length": 7.343371160441232,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 47,
        "distinct-1": 0.1683104284559418,
        "vocab_size-1": 1041,
        "unique-1": 604,
        "entropy-1": 7.889114081098613,
        "distinct-2": 0.5215479331574319,
        "vocab_size-2": 2965,
        "unique-2": 2177,
        "entropy-2": 10.797249073789393,
        "cond_entropy-2": 2.666210971047829,
        "distinct-3": 0.7523625843780135,
        "vocab_size-3": 3901,
        "unique-3": 3342,
        "entropy-3": 11.613662416715647,
        "cond_entropy-3": 0.8357346858882694,
        "total_length-nopunct": 5461,
        "mean_pred_length-nopunct": 10.922,
        "std_pred_length-nopunct": 6.815857686307718,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.1886101446621498,
        "vocab_size-1-nopunct": 1030,
        "unique-1-nopunct": 601,
        "entropy-1-nopunct": 8.070675323231217,
        "distinct-2-nopunct": 0.5359806490626889,
        "vocab_size-2-nopunct": 2659,
        "unique-2-nopunct": 1999,
        "entropy-2-nopunct": 10.62624684551739,
        "cond_entropy-2-nopunct": 2.675018953478091,
        "distinct-3-nopunct": 0.7579560735096369,
        "vocab_size-3-nopunct": 3382,
        "unique-3-nopunct": 2921,
        "entropy-3-nopunct": 11.405645507831185,
        "cond_entropy-3-nopunct": 0.8141210524479038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "rouge1": {
            "precision": 0.54149,
            "recall": 0.51381,
            "fmeasure": 0.51385
        },
        "rouge2": {
            "precision": 0.32203,
            "recall": 0.30195,
            "fmeasure": 0.3026
        },
        "rougeL": {
            "precision": 0.48319,
            "recall": 0.45846,
            "fmeasure": 0.45858
        },
        "rougeLsum": {
            "precision": 0.48319,
            "recall": 0.45846,
            "fmeasure": 0.45858
        },
        "bleu": 28.45299,
        "nist": 5.642937857412642,
        "local_recall": {
            "1": 0.5335287651154269
        },
        "nubia": {
            "semantic_relation": 3.47163,
            "contradiction": 7.50308,
            "irrelevancy": 24.01569,
            "logical_agreement": 68.48123,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.76849,
            "nubia_score": 0.59087
        },
        "meteor": 0.2953334361026671,
        "bleurt": -0.18881,
        "bertscore": {
            "precision": 0.86023,
            "recall": 0.85264,
            "f1": 0.85584
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.61354,
        "msttr-100_nopunct": 0.64814,
        "total_length": 4857,
        "mean_pred_length": 42.60526315789474,
        "std_pred_length": 10.449224281670034,
        "median_pred_length": 41.5,
        "min_pred_length": 21,
        "max_pred_length": 78,
        "distinct-1": 0.14865143092443894,
        "vocab_size-1": 722,
        "unique-1": 217,
        "entropy-1": 7.632680683809366,
        "distinct-2": 0.34998945814885096,
        "vocab_size-2": 1660,
        "unique-2": 799,
        "entropy-2": 10.014066016204925,
        "cond_entropy-2": 2.294597452379443,
        "distinct-3": 0.49060272197018795,
        "vocab_size-3": 2271,
        "unique-3": 1377,
        "entropy-3": 10.702448492429818,
        "cond_entropy-3": 0.7108110712433583,
        "total_length-nopunct": 4339,
        "mean_pred_length-nopunct": 38.06140350877193,
        "std_pred_length-nopunct": 9.38109809878007,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.16455404471076285,
        "vocab_size-1-nopunct": 714,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.827984236736782,
        "distinct-2-nopunct": 0.3663905325443787,
        "vocab_size-2-nopunct": 1548,
        "unique-2-nopunct": 778,
        "entropy-2-nopunct": 9.951187515285806,
        "cond_entropy-2-nopunct": 2.1858319600017047,
        "distinct-3-nopunct": 0.505716370712722,
        "vocab_size-3-nopunct": 2079,
        "unique-3-nopunct": 1298,
        "entropy-3-nopunct": 10.582589912332075,
        "cond_entropy-3-nopunct": 0.648173878952359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73604,
            "recall": 0.69848,
            "fmeasure": 0.70936
        },
        "rouge2": {
            "precision": 0.45437,
            "recall": 0.43155,
            "fmeasure": 0.43808
        },
        "rougeL": {
            "precision": 0.51361,
            "recall": 0.49293,
            "fmeasure": 0.49772
        },
        "rougeLsum": {
            "precision": 0.51361,
            "recall": 0.49293,
            "fmeasure": 0.49772
        },
        "bleu": 45.91734,
        "nist": 8.137959339112307,
        "local_recall": {
            "1": 0.2129105322763307,
            "2": 0.6397849462365591,
            "3": 0.8606516290726817
        },
        "nubia": {
            "semantic_relation": 4.1767,
            "contradiction": 7.19021,
            "irrelevancy": 12.12015,
            "logical_agreement": 80.68964,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.07323,
            "nubia_score": 0.73024
        },
        "meteor": 0.3569551507660971,
        "bleurt": 0.05709,
        "bertscore": {
            "precision": 0.90849,
            "recall": 0.89797,
            "f1": 0.90159
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 500,
        "msttr-100": 0.70188,
        "msttr-100_nopunct": 0.71947,
        "total_length": 10113,
        "mean_pred_length": 20.226,
        "std_pred_length": 4.47112111220441,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 62,
        "distinct-1": 0.258281419954514,
        "vocab_size-1": 2612,
        "unique-1": 1657,
        "entropy-1": 8.816407336309176,
        "distinct-2": 0.6766878185790076,
        "vocab_size-2": 6505,
        "unique-2": 5531,
        "entropy-2": 12.041630553220035,
        "cond_entropy-2": 2.993378104200228,
        "distinct-3": 0.8713925161856688,
        "vocab_size-3": 7941,
        "unique-3": 7410,
        "entropy-3": 12.763196030224359,
        "cond_entropy-3": 0.7337828744467055,
        "total_length-nopunct": 9429,
        "mean_pred_length-nopunct": 18.858,
        "std_pred_length-nopunct": 4.341179102501991,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.27595715346272137,
        "vocab_size-1-nopunct": 2602,
        "unique-1-nopunct": 1656,
        "entropy-1-nopunct": 8.979795841106109,
        "distinct-2-nopunct": 0.682159256355695,
        "vocab_size-2-nopunct": 6091,
        "unique-2-nopunct": 5200,
        "entropy-2-nopunct": 11.951102729800956,
        "cond_entropy-2-nopunct": 3.0993235905577476,
        "distinct-3-nopunct": 0.8804128603630323,
        "vocab_size-3-nopunct": 7421,
        "unique-3-nopunct": 6948,
        "entropy-3-nopunct": 12.685803208676845,
        "cond_entropy-3-nopunct": 0.7501324926931765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.41607,
            "recall": 0.36616,
            "fmeasure": 0.38159
        },
        "rouge2": {
            "precision": 0.15753,
            "recall": 0.13656,
            "fmeasure": 0.14298
        },
        "rougeL": {
            "precision": 0.32187,
            "recall": 0.28241,
            "fmeasure": 0.29453
        },
        "rougeLsum": {
            "precision": 0.32187,
            "recall": 0.28241,
            "fmeasure": 0.29453
        },
        "bleu": 8.80584,
        "nist": 3.5601917482244283,
        "local_recall": {
            "1": 0.33731581043409
        },
        "nubia": {
            "semantic_relation": 2.84793,
            "contradiction": 22.97453,
            "irrelevancy": 62.31787,
            "logical_agreement": 14.7076,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.61528,
            "nubia_score": 0.40943
        },
        "meteor": 0.16536172265073573,
        "bleurt": -0.33799,
        "bertscore": {
            "precision": 0.83568,
            "recall": 0.81591,
            "f1": 0.82533
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 12,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 8.166666666666666,
        "std_pred_length": 1.7716909687891083,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 10,
        "distinct-1": 0.3979591836734694,
        "vocab_size-1": 39,
        "unique-1": 20,
        "entropy-1": 4.888909739401175,
        "distinct-2": 0.5697674418604651,
        "vocab_size-2": 49,
        "unique-2": 30,
        "entropy-2": 5.407799928667884,
        "cond_entropy-2": 0.31721406661040935,
        "distinct-3": 0.581081081081081,
        "vocab_size-3": 43,
        "unique-3": 27,
        "entropy-3": 5.218597790866085,
        "cond_entropy-3": -0.17958317958445275,
        "total_length-nopunct": 79,
        "mean_pred_length-nopunct": 6.583333333333333,
        "std_pred_length-nopunct": 1.3202482931462383,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.45569620253164556,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.89336077346113,
        "distinct-2-nopunct": 0.582089552238806,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 5.072530607916149,
        "cond_entropy-2-nopunct": 0.20029318807091456,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.830382213091966,
        "cond_entropy-3-nopunct": -0.25591197692000095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.34987,
            "recall": 0.34497,
            "fmeasure": 0.34301
        },
        "rouge2": {
            "precision": 0.18291,
            "recall": 0.18574,
            "fmeasure": 0.18188
        },
        "rougeL": {
            "precision": 0.33796,
            "recall": 0.33145,
            "fmeasure": 0.33039
        },
        "rougeLsum": {
            "precision": 0.33796,
            "recall": 0.33145,
            "fmeasure": 0.33039
        },
        "bleu": 5.03664,
        "nist": 1.2511265542836936,
        "local_recall": {
            "1": 0.17073170731707318
        },
        "nubia": {
            "semantic_relation": 2.4609,
            "contradiction": 26.134,
            "irrelevancy": 34.82625,
            "logical_agreement": 39.03975,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.04028,
            "nubia_score": 0.25364
        },
        "meteor": 0.10128975915970304,
        "bleurt": -0.37273,
        "bertscore": {
            "precision": 0.87958,
            "recall": 0.8796,
            "f1": 0.87954
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 500,
        "msttr-100": 0.70745,
        "msttr-100_nopunct": 0.72884,
        "total_length": 10203,
        "mean_pred_length": 20.406,
        "std_pred_length": 4.201090810729994,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.26305988434774086,
        "vocab_size-1": 2684,
        "unique-1": 1678,
        "entropy-1": 8.882378360391833,
        "distinct-2": 0.6873132021024425,
        "vocab_size-2": 6669,
        "unique-2": 5657,
        "entropy-2": 12.121130127354498,
        "cond_entropy-2": 3.0050951987783288,
        "distinct-3": 0.8875366728240791,
        "vocab_size-3": 8168,
        "unique-3": 7644,
        "entropy-3": 12.846654587533266,
        "cond_entropy-3": 0.735622799924939,
        "total_length-nopunct": 9515,
        "mean_pred_length-nopunct": 19.03,
        "std_pred_length-nopunct": 3.9916287402512776,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.2811350499211771,
        "vocab_size-1-nopunct": 2675,
        "unique-1-nopunct": 1678,
        "entropy-1-nopunct": 9.051650489609447,
        "distinct-2-nopunct": 0.6928452579034942,
        "vocab_size-2-nopunct": 6246,
        "unique-2-nopunct": 5312,
        "entropy-2-nopunct": 12.036417759651904,
        "cond_entropy-2-nopunct": 3.110598840354124,
        "distinct-3-nopunct": 0.8961832061068702,
        "vocab_size-3-nopunct": 7631,
        "unique-3-nopunct": 7164,
        "entropy-3-nopunct": 12.771262050621637,
        "cond_entropy-3-nopunct": 0.747895038307532,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.40582,
            "recall": 0.36437,
            "fmeasure": 0.37587
        },
        "rouge2": {
            "precision": 0.15145,
            "recall": 0.1354,
            "fmeasure": 0.13975
        },
        "rougeL": {
            "precision": 0.31438,
            "recall": 0.28218,
            "fmeasure": 0.29098
        },
        "rougeLsum": {
            "precision": 0.31438,
            "recall": 0.28218,
            "fmeasure": 0.29098
        },
        "bleu": 8.99294,
        "nist": 3.553056392691793,
        "local_recall": {
            "1": 0.33718360787464846
        },
        "nubia": {
            "semantic_relation": 2.84373,
            "contradiction": 23.57044,
            "irrelevancy": 63.11044,
            "logical_agreement": 13.31913,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.62788,
            "nubia_score": 0.40525
        },
        "meteor": 0.1647489449944021,
        "bleurt": -0.34235,
        "bertscore": {
            "precision": 0.83302,
            "recall": 0.81527,
            "f1": 0.82372
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.47058,
        "msttr-100_nopunct": 0.48126,
        "total_length": 12179,
        "mean_pred_length": 24.358,
        "std_pred_length": 7.678140139382713,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 44,
        "distinct-1": 0.0093603744149766,
        "vocab_size-1": 114,
        "unique-1": 7,
        "entropy-1": 5.726991223775263,
        "distinct-2": 0.031252675742786194,
        "vocab_size-2": 365,
        "unique-2": 59,
        "entropy-2": 7.259621101800216,
        "cond_entropy-2": 1.441593542822304,
        "distinct-3": 0.06547991770283568,
        "vocab_size-3": 732,
        "unique-3": 193,
        "entropy-3": 8.175743150950948,
        "cond_entropy-3": 0.9381032222340122,
        "total_length-nopunct": 11156,
        "mean_pred_length-nopunct": 22.312,
        "std_pred_length-nopunct": 7.041779320597884,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.010039440659734672,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 5.785659720084411,
        "distinct-2-nopunct": 0.033596096096096095,
        "vocab_size-2-nopunct": 358,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 7.255990427177555,
        "cond_entropy-2-nopunct": 1.5122276693849783,
        "distinct-3-nopunct": 0.07168176447420244,
        "vocab_size-3-nopunct": 728,
        "unique-3-nopunct": 192,
        "entropy-3-nopunct": 8.237802747908008,
        "cond_entropy-3-nopunct": 0.9723416413060282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.78277,
            "recall": 0.71774,
            "fmeasure": 0.73836
        },
        "rouge2": {
            "precision": 0.48068,
            "recall": 0.44018,
            "fmeasure": 0.45274
        },
        "rougeL": {
            "precision": 0.55139,
            "recall": 0.50294,
            "fmeasure": 0.51858
        },
        "rougeLsum": {
            "precision": 0.55139,
            "recall": 0.50294,
            "fmeasure": 0.51858
        },
        "bleu": 32.88795,
        "nist": 5.496807282635727,
        "local_recall": {
            "1": 0.7195201339161165
        },
        "nubia": {
            "semantic_relation": 4.44878,
            "contradiction": 1.90596,
            "irrelevancy": 11.46669,
            "logical_agreement": 86.62735,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.48069,
            "nubia_score": 0.82984
        },
        "meteor": 0.37216540422958044,
        "bleurt": 0.24855,
        "bertscore": {
            "precision": 0.92625,
            "recall": 0.9077,
            "f1": 0.91661
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.19222,
        "msttr-100_nopunct": 0.1865,
        "total_length": 2707,
        "mean_pred_length": 14.792349726775956,
        "std_pred_length": 2.6073763477248137,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 16,
        "distinct-1": 0.01884004432951607,
        "vocab_size-1": 51,
        "unique-1": 17,
        "entropy-1": 4.103948194392808,
        "distinct-2": 0.02733755942947702,
        "vocab_size-2": 69,
        "unique-2": 28,
        "entropy-2": 4.446032430623058,
        "cond_entropy-2": 0.32988635367291586,
        "distinct-3": 0.027765912003417343,
        "vocab_size-3": 65,
        "unique-3": 26,
        "entropy-3": 4.36965626192677,
        "cond_entropy-3": -0.04870209691181152,
        "total_length-nopunct": 2048,
        "mean_pred_length-nopunct": 11.191256830601093,
        "std_pred_length-nopunct": 1.7653402757625223,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.0234375,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.087513927190509,
        "distinct-2-nopunct": 0.029490616621983913,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.063806617413098,
        "cond_entropy-2-nopunct": 0.008842453658754273,
        "distinct-3-nopunct": 0.03032104637336504,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 3.928170474538298,
        "cond_entropy-3-nopunct": -0.11045758661599492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.11525,
            "recall": 0.17157,
            "fmeasure": 0.12863
        },
        "rouge2": {
            "precision": 0.05724,
            "recall": 0.07968,
            "fmeasure": 0.06087
        },
        "rougeL": {
            "precision": 0.11161,
            "recall": 0.16686,
            "fmeasure": 0.12457
        },
        "rougeLsum": {
            "precision": 0.11161,
            "recall": 0.16686,
            "fmeasure": 0.12457
        },
        "bleu": 2.7593,
        "nist": 0.5600222746200093,
        "local_recall": {
            "1": 0.12163509471585245
        },
        "nubia": {
            "semantic_relation": 1.44662,
            "contradiction": 33.27754,
            "irrelevancy": 41.38639,
            "logical_agreement": 25.33607,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.07871,
            "nubia_score": 0.09211
        },
        "meteor": 0.07017926144267791,
        "bleurt": -0.72007,
        "bertscore": {
            "precision": 0.83402,
            "recall": 0.86844,
            "f1": 0.85075
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.50952,
        "msttr-100_nopunct": 0.51964,
        "total_length": 12453,
        "mean_pred_length": 24.906,
        "std_pred_length": 13.515071734918761,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 80,
        "distinct-1": 0.09885168232554405,
        "vocab_size-1": 1231,
        "unique-1": 365,
        "entropy-1": 7.922329967476946,
        "distinct-2": 0.29206057056805823,
        "vocab_size-2": 3491,
        "unique-2": 1692,
        "entropy-2": 10.828785185015159,
        "cond_entropy-2": 2.742205795810248,
        "distinct-3": 0.4598795075526063,
        "vocab_size-3": 5267,
        "unique-3": 3244,
        "entropy-3": 11.789826635919843,
        "cond_entropy-3": 1.0145817402609223,
        "total_length-nopunct": 11152,
        "mean_pred_length-nopunct": 22.304,
        "std_pred_length-nopunct": 12.280211073104566,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.1096664275466284,
        "vocab_size-1-nopunct": 1223,
        "unique-1-nopunct": 365,
        "entropy-1-nopunct": 8.149850162761439,
        "distinct-2-nopunct": 0.30088246338715735,
        "vocab_size-2-nopunct": 3205,
        "unique-2-nopunct": 1615,
        "entropy-2-nopunct": 10.706458115419256,
        "cond_entropy-2-nopunct": 2.6868176075891004,
        "distinct-3-nopunct": 0.4710401891252955,
        "vocab_size-3-nopunct": 4782,
        "unique-3-nopunct": 3040,
        "entropy-3-nopunct": 11.648260762665775,
        "cond_entropy-3-nopunct": 0.9856116410986402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73559,
            "recall": 0.74535,
            "fmeasure": 0.7325
        },
        "rouge2": {
            "precision": 0.48287,
            "recall": 0.4876,
            "fmeasure": 0.47932
        },
        "rougeL": {
            "precision": 0.58712,
            "recall": 0.59383,
            "fmeasure": 0.58367
        },
        "rougeLsum": {
            "precision": 0.58712,
            "recall": 0.59383,
            "fmeasure": 0.58367
        },
        "bleu": 46.15462,
        "nist": 8.634296535274824,
        "local_recall": {
            "1": 0.22711998418659815,
            "2": 0.6012894468951476,
            "3": 0.8713537771129394,
            "4": 0.8,
            "5": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.41808,
            "contradiction": 10.40567,
            "irrelevancy": 8.78119,
            "logical_agreement": 80.81314,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.59322,
            "nubia_score": 0.76862
        },
        "meteor": 0.3799002649192897,
        "bleurt": 0.16265,
        "bertscore": {
            "precision": 0.91758,
            "recall": 0.91742,
            "f1": 0.91631
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.4532,
        "msttr-100_nopunct": 0.47,
        "total_length": 2510,
        "mean_pred_length": 9.400749063670412,
        "std_pred_length": 2.913304011405891,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.12749003984063745,
        "vocab_size-1": 320,
        "unique-1": 162,
        "entropy-1": 5.996433974403302,
        "distinct-2": 0.282657155595185,
        "vocab_size-2": 634,
        "unique-2": 370,
        "entropy-2": 7.793995080553397,
        "cond_entropy-2": 1.5911941127921148,
        "distinct-3": 0.4073886639676113,
        "vocab_size-3": 805,
        "unique-3": 559,
        "entropy-3": 8.521401840165234,
        "cond_entropy-3": 1.0744303038397662,
        "total_length-nopunct": 2220,
        "mean_pred_length-nopunct": 8.314606741573034,
        "std_pred_length-nopunct": 2.7948407750187414,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.1427927927927928,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.101286449074414,
        "distinct-2-nopunct": 0.24628776241679468,
        "vocab_size-2-nopunct": 481,
        "unique-2-nopunct": 280,
        "entropy-2-nopunct": 7.305811572860164,
        "cond_entropy-2-nopunct": 1.7517703635159687,
        "distinct-3-nopunct": 0.3748517200474496,
        "vocab_size-3-nopunct": 632,
        "unique-3-nopunct": 448,
        "entropy-3-nopunct": 8.069938358922817,
        "cond_entropy-3-nopunct": 1.2316631956804787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.59121,
            "recall": 0.63525,
            "fmeasure": 0.59974
        },
        "rouge2": {
            "precision": 0.35903,
            "recall": 0.3923,
            "fmeasure": 0.36655
        },
        "rougeL": {
            "precision": 0.53253,
            "recall": 0.57018,
            "fmeasure": 0.53974
        },
        "rougeLsum": {
            "precision": 0.53253,
            "recall": 0.57018,
            "fmeasure": 0.53974
        },
        "bleu": 22.30993,
        "nist": 4.264324684636876,
        "local_recall": {
            "1": 0.5956175298804781
        },
        "nubia": {
            "semantic_relation": 3.75307,
            "contradiction": 18.82598,
            "irrelevancy": 31.21548,
            "logical_agreement": 49.95853,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.16768,
            "nubia_score": 0.60898
        },
        "meteor": 0.29857696965699293,
        "bleurt": 0.0206,
        "bertscore": {
            "precision": 0.91197,
            "recall": 0.91815,
            "f1": 0.91485
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.63143,
        "msttr-100_nopunct": 0.66841,
        "total_length": 12692,
        "mean_pred_length": 25.384,
        "std_pred_length": 13.42373062900176,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 80,
        "distinct-1": 0.09667507091080996,
        "vocab_size-1": 1227,
        "unique-1": 347,
        "entropy-1": 7.93775485427144,
        "distinct-2": 0.28510498687664043,
        "vocab_size-2": 3476,
        "unique-2": 1632,
        "entropy-2": 10.825302083335067,
        "cond_entropy-2": 2.729054463312029,
        "distinct-3": 0.45005131713992474,
        "vocab_size-3": 5262,
        "unique-3": 3180,
        "entropy-3": 11.769598223018585,
        "cond_entropy-3": 1.0006159073896033,
        "total_length-nopunct": 11362,
        "mean_pred_length-nopunct": 22.724,
        "std_pred_length-nopunct": 12.083866268707213,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.10719943671888751,
        "vocab_size-1-nopunct": 1218,
        "unique-1-nopunct": 347,
        "entropy-1-nopunct": 8.165612542725883,
        "distinct-2-nopunct": 0.292671699502854,
        "vocab_size-2-nopunct": 3179,
        "unique-2-nopunct": 1552,
        "entropy-2-nopunct": 10.694848680416145,
        "cond_entropy-2-nopunct": 2.6545699058327896,
        "distinct-3-nopunct": 0.4610113877629801,
        "vocab_size-3-nopunct": 4777,
        "unique-3-nopunct": 2985,
        "entropy-3-nopunct": 11.622272263771485,
        "cond_entropy-3-nopunct": 0.9673069498303261,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73693,
            "recall": 0.74771,
            "fmeasure": 0.73386
        },
        "rouge2": {
            "precision": 0.48981,
            "recall": 0.49703,
            "fmeasure": 0.48719
        },
        "rougeL": {
            "precision": 0.59055,
            "recall": 0.59831,
            "fmeasure": 0.58716
        },
        "rougeLsum": {
            "precision": 0.59055,
            "recall": 0.59831,
            "fmeasure": 0.58716
        },
        "bleu": 47.5129,
        "nist": 8.698225731854514,
        "local_recall": {
            "1": 0.24064394731340163,
            "2": 0.6016511867905057,
            "3": 0.8707653701380176,
            "4": 0.7777777777777778,
            "5": 0.8181818181818182
        },
        "nubia": {
            "semantic_relation": 4.42622,
            "contradiction": 8.33466,
            "irrelevancy": 9.01698,
            "logical_agreement": 82.64836,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.50109,
            "nubia_score": 0.77611
        },
        "meteor": 0.38650004950968,
        "bleurt": 0.15863,
        "bertscore": {
            "precision": 0.91961,
            "recall": 0.91831,
            "f1": 0.91738
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72641,
        "msttr-100_nopunct": 0.77159,
        "total_length": 7872,
        "mean_pred_length": 21.92757660167131,
        "std_pred_length": 9.145697344708735,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.36826727642276424,
        "vocab_size-1": 2899,
        "unique-1": 2127,
        "entropy-1": 9.246974371814963,
        "distinct-2": 0.8348196459470252,
        "vocab_size-2": 6272,
        "unique-2": 5809,
        "entropy-2": 12.278967879716744,
        "cond_entropy-2": 2.794687580953878,
        "distinct-3": 0.9636566955549343,
        "vocab_size-3": 6894,
        "unique-3": 6774,
        "entropy-3": 12.676595660248898,
        "cond_entropy-3": 0.41401468373945943,
        "total_length-nopunct": 6910,
        "mean_pred_length-nopunct": 19.24791086350975,
        "std_pred_length-nopunct": 7.931274425961432,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41794500723589,
        "vocab_size-1-nopunct": 2888,
        "unique-1-nopunct": 2127,
        "entropy-1-nopunct": 9.62963196659567,
        "distinct-2-nopunct": 0.8630743397954511,
        "vocab_size-2-nopunct": 5654,
        "unique-2-nopunct": 5281,
        "entropy-2-nopunct": 12.213759639242365,
        "cond_entropy-2-nopunct": 2.7129905594099775,
        "distinct-3-nopunct": 0.9828811369509044,
        "vocab_size-3-nopunct": 6086,
        "unique-3-nopunct": 6005,
        "entropy-3-nopunct": 12.557750920798163,
        "cond_entropy-3-nopunct": 0.36560027478198537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90381,
            "recall": 0.92223,
            "fmeasure": 0.90968
        },
        "rouge2": {
            "precision": 0.81248,
            "recall": 0.83712,
            "fmeasure": 0.82047
        },
        "rougeL": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "rougeLsum": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "bleu": 87.35189,
        "nist": 13.426135311676614,
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.18665768194070081,
            "3": 0.4108433734939759,
            "4": 0.6284403669724771,
            "5": 0.7556904400606981,
            "6": 0.8633802816901408,
            "7": 0.9180327868852459,
            "8": 0.962605548854041,
            "9": 0.9587301587301588,
            "10": 0.9868217054263566
        },
        "nubia": {
            "semantic_relation": 4.42253,
            "contradiction": 2.08708,
            "irrelevancy": 34.08185,
            "logical_agreement": 63.83107,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70222,
            "nubia_score": 0.70222
        },
        "meteor": 0.5615520197272345,
        "bleurt": 0.32083,
        "bertscore": {
            "precision": 0.97293,
            "recall": 0.98169,
            "f1": 0.97511
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.55,
        "msttr-100_nopunct": 0.57103,
        "total_length": 3390,
        "mean_pred_length": 11.414141414141413,
        "std_pred_length": 3.5751012352036833,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.08702064896755163,
        "vocab_size-1": 295,
        "unique-1": 126,
        "entropy-1": 6.462251053977935,
        "distinct-2": 0.2101519560297446,
        "vocab_size-2": 650,
        "unique-2": 336,
        "entropy-2": 8.060069613067304,
        "cond_entropy-2": 1.3255572606969561,
        "distinct-3": 0.32045779685264664,
        "vocab_size-3": 896,
        "unique-3": 531,
        "entropy-3": 8.681159036053081,
        "cond_entropy-3": 0.653849241142728,
        "total_length-nopunct": 2945,
        "mean_pred_length-nopunct": 9.915824915824915,
        "std_pred_length-nopunct": 3.3468894161532026,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.09915110356536502,
        "vocab_size-1-nopunct": 292,
        "unique-1-nopunct": 126,
        "entropy-1-nopunct": 6.628398411721542,
        "distinct-2-nopunct": 0.21148036253776434,
        "vocab_size-2-nopunct": 560,
        "unique-2-nopunct": 274,
        "entropy-2-nopunct": 7.914965774373368,
        "cond_entropy-2-nopunct": 1.4094759176649259,
        "distinct-3-nopunct": 0.32794555508294343,
        "vocab_size-3-nopunct": 771,
        "unique-3-nopunct": 455,
        "entropy-3-nopunct": 8.473626468307495,
        "cond_entropy-3-nopunct": 0.7034037332327546,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.57309,
            "recall": 0.55554,
            "fmeasure": 0.54794
        },
        "rouge2": {
            "precision": 0.3362,
            "recall": 0.33054,
            "fmeasure": 0.3244
        },
        "rougeL": {
            "precision": 0.51207,
            "recall": 0.49918,
            "fmeasure": 0.49177
        },
        "rougeLsum": {
            "precision": 0.51207,
            "recall": 0.49918,
            "fmeasure": 0.49177
        },
        "bleu": 20.90883,
        "nist": 4.0282353519734775,
        "local_recall": {
            "1": 0.505259339862169
        },
        "nubia": {
            "semantic_relation": 3.59743,
            "contradiction": 19.65803,
            "irrelevancy": 31.47501,
            "logical_agreement": 48.86696,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.69407,
            "nubia_score": 0.54293
        },
        "meteor": 0.25865731733892044,
        "bleurt": -0.08325,
        "bertscore": {
            "precision": 0.90759,
            "recall": 0.90471,
            "f1": 0.90594
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.56231,
        "msttr-100_nopunct": 0.6,
        "total_length": 1355,
        "mean_pred_length": 15.755813953488373,
        "std_pred_length": 4.288806541076672,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.16900369003690036,
        "vocab_size-1": 229,
        "unique-1": 95,
        "entropy-1": 6.4502453104545046,
        "distinct-2": 0.3727344365642238,
        "vocab_size-2": 473,
        "unique-2": 283,
        "entropy-2": 8.07351953724167,
        "cond_entropy-2": 1.4427259358764144,
        "distinct-3": 0.5156382079459002,
        "vocab_size-3": 610,
        "unique-3": 429,
        "entropy-3": 8.638045693969016,
        "cond_entropy-3": 0.5273942930576666,
        "total_length-nopunct": 1201,
        "mean_pred_length-nopunct": 13.965116279069768,
        "std_pred_length-nopunct": 3.945700263308723,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.18817651956702747,
        "vocab_size-1-nopunct": 226,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.572739603965105,
        "distinct-2-nopunct": 0.38565022421524664,
        "vocab_size-2-nopunct": 430,
        "unique-2-nopunct": 254,
        "entropy-2-nopunct": 8.022126467161522,
        "cond_entropy-2-nopunct": 1.4908832469361666,
        "distinct-3-nopunct": 0.5461613216715258,
        "vocab_size-3-nopunct": 562,
        "unique-3-nopunct": 398,
        "entropy-3-nopunct": 8.624496222038594,
        "cond_entropy-3-nopunct": 0.5659231434388059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.61131,
            "recall": 0.53854,
            "fmeasure": 0.56457
        },
        "rouge2": {
            "precision": 0.33481,
            "recall": 0.29692,
            "fmeasure": 0.31009
        },
        "rougeL": {
            "precision": 0.50009,
            "recall": 0.44107,
            "fmeasure": 0.46272
        },
        "rougeLsum": {
            "precision": 0.50009,
            "recall": 0.44107,
            "fmeasure": 0.46272
        },
        "bleu": 20.92639,
        "nist": 4.267015976056323,
        "local_recall": {
            "1": 0.4988593155893536
        },
        "nubia": {
            "semantic_relation": 3.51395,
            "contradiction": 16.48015,
            "irrelevancy": 20.85841,
            "logical_agreement": 62.66143,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.34254,
            "nubia_score": 0.55529
        },
        "meteor": 0.2543728714738743,
        "bleurt": -0.0009,
        "bertscore": {
            "precision": 0.92608,
            "recall": 0.91538,
            "f1": 0.92058
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72641,
        "msttr-100_nopunct": 0.77159,
        "total_length": 7872,
        "mean_pred_length": 21.92757660167131,
        "std_pred_length": 9.145697344708735,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.36826727642276424,
        "vocab_size-1": 2899,
        "unique-1": 2127,
        "entropy-1": 9.246974371814963,
        "distinct-2": 0.8348196459470252,
        "vocab_size-2": 6272,
        "unique-2": 5809,
        "entropy-2": 12.278967879716744,
        "cond_entropy-2": 2.794687580953878,
        "distinct-3": 0.9636566955549343,
        "vocab_size-3": 6894,
        "unique-3": 6774,
        "entropy-3": 12.676595660248898,
        "cond_entropy-3": 0.41401468373945943,
        "total_length-nopunct": 6910,
        "mean_pred_length-nopunct": 19.24791086350975,
        "std_pred_length-nopunct": 7.931274425961432,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41794500723589,
        "vocab_size-1-nopunct": 2888,
        "unique-1-nopunct": 2127,
        "entropy-1-nopunct": 9.62963196659567,
        "distinct-2-nopunct": 0.8630743397954511,
        "vocab_size-2-nopunct": 5654,
        "unique-2-nopunct": 5281,
        "entropy-2-nopunct": 12.213759639242365,
        "cond_entropy-2-nopunct": 2.7129905594099775,
        "distinct-3-nopunct": 0.9828811369509044,
        "vocab_size-3-nopunct": 6086,
        "unique-3-nopunct": 6005,
        "entropy-3-nopunct": 12.557750920798163,
        "cond_entropy-3-nopunct": 0.36560027478198537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90381,
            "recall": 0.92223,
            "fmeasure": 0.90968
        },
        "rouge2": {
            "precision": 0.81248,
            "recall": 0.83712,
            "fmeasure": 0.82047
        },
        "rougeL": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "rougeLsum": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "bleu": 87.35189,
        "nist": 13.426135311676614,
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.18665768194070081,
            "3": 0.4108433734939759,
            "4": 0.6284403669724771,
            "5": 0.7556904400606981,
            "6": 0.8633802816901408,
            "7": 0.9180327868852459,
            "8": 0.962605548854041,
            "9": 0.9587301587301588,
            "10": 0.9868217054263566
        },
        "nubia": {
            "semantic_relation": 4.42253,
            "contradiction": 2.08708,
            "irrelevancy": 34.08185,
            "logical_agreement": 63.83107,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70222,
            "nubia_score": 0.70222
        },
        "meteor": 0.5615520197272345,
        "bleurt": 0.32083,
        "bertscore": {
            "precision": 0.97293,
            "recall": 0.98169,
            "f1": 0.97511
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72641,
        "msttr-100_nopunct": 0.77159,
        "total_length": 7872,
        "mean_pred_length": 21.92757660167131,
        "std_pred_length": 9.145697344708735,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.36826727642276424,
        "vocab_size-1": 2899,
        "unique-1": 2127,
        "entropy-1": 9.246974371814963,
        "distinct-2": 0.8348196459470252,
        "vocab_size-2": 6272,
        "unique-2": 5809,
        "entropy-2": 12.278967879716744,
        "cond_entropy-2": 2.794687580953878,
        "distinct-3": 0.9636566955549343,
        "vocab_size-3": 6894,
        "unique-3": 6774,
        "entropy-3": 12.676595660248898,
        "cond_entropy-3": 0.41401468373945943,
        "total_length-nopunct": 6910,
        "mean_pred_length-nopunct": 19.24791086350975,
        "std_pred_length-nopunct": 7.931274425961432,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41794500723589,
        "vocab_size-1-nopunct": 2888,
        "unique-1-nopunct": 2127,
        "entropy-1-nopunct": 9.62963196659567,
        "distinct-2-nopunct": 0.8630743397954511,
        "vocab_size-2-nopunct": 5654,
        "unique-2-nopunct": 5281,
        "entropy-2-nopunct": 12.213759639242365,
        "cond_entropy-2-nopunct": 2.7129905594099775,
        "distinct-3-nopunct": 0.9828811369509044,
        "vocab_size-3-nopunct": 6086,
        "unique-3-nopunct": 6005,
        "entropy-3-nopunct": 12.557750920798163,
        "cond_entropy-3-nopunct": 0.36560027478198537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90381,
            "recall": 0.92223,
            "fmeasure": 0.90968
        },
        "rouge2": {
            "precision": 0.81248,
            "recall": 0.83712,
            "fmeasure": 0.82047
        },
        "rougeL": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "rougeLsum": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "bleu": 87.35189,
        "nist": 13.426135311676614,
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.18665768194070081,
            "3": 0.4108433734939759,
            "4": 0.6284403669724771,
            "5": 0.7556904400606981,
            "6": 0.8633802816901408,
            "7": 0.9180327868852459,
            "8": 0.962605548854041,
            "9": 0.9587301587301588,
            "10": 0.9868217054263566
        },
        "nubia": {
            "semantic_relation": 4.42253,
            "contradiction": 2.08708,
            "irrelevancy": 34.08185,
            "logical_agreement": 63.83107,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70222,
            "nubia_score": 0.70222
        },
        "meteor": 0.5615520197272345,
        "bleurt": 0.32083,
        "bertscore": {
            "precision": 0.97293,
            "recall": 0.98169,
            "f1": 0.97511
        }
    },
    "common_gen_val": {
        "predictions_file": "mT5_large/common_gen_val",
        "N": 993,
        "msttr-100": 0.55466,
        "msttr-100_nopunct": 0.58232,
        "total_length": 10398,
        "mean_pred_length": 10.471299093655588,
        "std_pred_length": 2.5508784546508676,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.12310059626851318,
        "vocab_size-1": 1280,
        "unique-1": 612,
        "entropy-1": 6.986834911050454,
        "distinct-2": 0.4046783625730994,
        "vocab_size-2": 3806,
        "unique-2": 2661,
        "entropy-2": 10.494500087070577,
        "cond_entropy-2": 3.273510482163681,
        "distinct-3": 0.6562054208273894,
        "vocab_size-3": 5520,
        "unique-3": 4551,
        "entropy-3": 11.86668272007381,
        "cond_entropy-3": 1.4889431027362348,
        "total_length-nopunct": 9545,
        "mean_pred_length-nopunct": 9.612286002014098,
        "std_pred_length-nopunct": 2.440785147391205,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.13389209009952854,
        "vocab_size-1-nopunct": 1278,
        "unique-1-nopunct": 612,
        "entropy-1-nopunct": 7.1557991785754025,
        "distinct-2-nopunct": 0.4002572497661366,
        "vocab_size-2-nopunct": 3423,
        "unique-2-nopunct": 2430,
        "entropy-2-nopunct": 10.264158175229301,
        "cond_entropy-2-nopunct": 3.498271490367171,
        "distinct-3-nopunct": 0.6615954491334832,
        "vocab_size-3-nopunct": 5001,
        "unique-3-nopunct": 4158,
        "entropy-3-nopunct": 11.710967400022415,
        "cond_entropy-3-nopunct": 1.586788760039156,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_val.json",
        "rouge1": {
            "precision": 0.6443,
            "recall": 0.60255,
            "fmeasure": 0.61058
        },
        "rouge2": {
            "precision": 0.32218,
            "recall": 0.29481,
            "fmeasure": 0.30024
        },
        "rougeL": {
            "precision": 0.56043,
            "recall": 0.5245,
            "fmeasure": 0.5317
        },
        "rougeLsum": {
            "precision": 0.56043,
            "recall": 0.5245,
            "fmeasure": 0.5317
        },
        "bleu": 24.9565,
        "nist": 6.404936460095608,
        "local_recall": {
            "1": 0.10204974378202725,
            "2": 0.30611702127659574,
            "3": 0.49302744039586144,
            "4": 0.7535245503159942,
            "5": 0.7188841201716738,
            "6": 0.7619047619047619,
            "7": 0.6666666666666666,
            "8": 1.0
        },
        "nubia": {
            "semantic_relation": 3.01973,
            "contradiction": 33.04859,
            "irrelevancy": 25.45529,
            "logical_agreement": 41.49611,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.59515,
            "nubia_score": 0.42281
        },
        "meteor": 0.25178636616558747,
        "bleurt": -0.45811,
        "bertscore": {
            "precision": 0.88502,
            "recall": 0.88132,
            "f1": 0.88189
        }
    },
    "common_gen_test": {
        "predictions_file": "mT5_large/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "mT5_large/common_gen_challenge_test_scramble",
        "N": 500
    },
    "dart_val": {
        "predictions_file": "mT5_large/dart_val",
        "N": 2768
    },
    "dart_test": {
        "predictions_file": "mT5_large/dart_test",
        "N": 6959
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.47368,
        "msttr-100_nopunct": 0.47971,
        "total_length": 3830,
        "mean_pred_length": 30.64,
        "std_pred_length": 12.209111351773313,
        "median_pred_length": 28.0,
        "min_pred_length": 10,
        "max_pred_length": 78,
        "distinct-1": 0.12114882506527415,
        "vocab_size-1": 464,
        "unique-1": 121,
        "entropy-1": 7.054165952556545,
        "distinct-2": 0.3076923076923077,
        "vocab_size-2": 1140,
        "unique-2": 493,
        "entropy-2": 9.402481100296738,
        "cond_entropy-2": 2.24938137617246,
        "distinct-3": 0.4611731843575419,
        "vocab_size-3": 1651,
        "unique-3": 939,
        "entropy-3": 10.185376718125928,
        "cond_entropy-3": 0.8111140283786461,
        "total_length-nopunct": 3456,
        "mean_pred_length-nopunct": 27.648,
        "std_pred_length-nopunct": 11.122773754778976,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.13252314814814814,
        "vocab_size-1-nopunct": 458,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 7.166287926089534,
        "distinct-2-nopunct": 0.3188231762233564,
        "vocab_size-2-nopunct": 1062,
        "unique-2-nopunct": 489,
        "entropy-2-nopunct": 9.286010919988144,
        "cond_entropy-2-nopunct": 2.1973142111013217,
        "distinct-3-nopunct": 0.47629444791016845,
        "vocab_size-3-nopunct": 1527,
        "unique-3-nopunct": 907,
        "entropy-3-nopunct": 10.059670768845544,
        "cond_entropy-3-nopunct": 0.7877877876166571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.66977,
            "recall": 0.68386,
            "fmeasure": 0.66526
        },
        "rouge2": {
            "precision": 0.39552,
            "recall": 0.4033,
            "fmeasure": 0.39082
        },
        "rougeL": {
            "precision": 0.49817,
            "recall": 0.51672,
            "fmeasure": 0.49748
        },
        "rougeLsum": {
            "precision": 0.49817,
            "recall": 0.51672,
            "fmeasure": 0.49748
        },
        "bleu": 35.65199,
        "nist": 6.6535241822407265,
        "local_recall": {
            "1": 0.18270481144343304,
            "2": 0.49563046192259674,
            "3": 0.8261904761904761
        },
        "nubia": {
            "semantic_relation": 3.99861,
            "contradiction": 11.88214,
            "irrelevancy": 16.27147,
            "logical_agreement": 71.84639,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.32278,
            "nubia_score": 0.65111
        },
        "meteor": 0.3317326157487445,
        "bleurt": -0.03154,
        "bertscore": {
            "precision": 0.89228,
            "recall": 0.88556,
            "f1": 0.88694
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.49603,
        "msttr-100_nopunct": 0.50208,
        "total_length": 36012,
        "mean_pred_length": 23.849006622516555,
        "std_pred_length": 13.169239029993161,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 78,
        "distinct-1": 0.04492946795512607,
        "vocab_size-1": 1618,
        "unique-1": 403,
        "entropy-1": 7.990237828055654,
        "distinct-2": 0.15326647730566345,
        "vocab_size-2": 5288,
        "unique-2": 2081,
        "entropy-2": 10.989486808471437,
        "cond_entropy-2": 2.8238004421627503,
        "distinct-3": 0.27000484966052374,
        "vocab_size-3": 8908,
        "unique-3": 4599,
        "entropy-3": 12.0667763781931,
        "cond_entropy-3": 1.1461759756950352,
        "total_length-nopunct": 32201,
        "mean_pred_length-nopunct": 21.325165562913906,
        "std_pred_length-nopunct": 11.90306721305686,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.04996739231700879,
        "vocab_size-1-nopunct": 1609,
        "unique-1-nopunct": 403,
        "entropy-1-nopunct": 8.233194466430593,
        "distinct-2-nopunct": 0.1592975139291649,
        "vocab_size-2-nopunct": 4889,
        "unique-2-nopunct": 2023,
        "entropy-2-nopunct": 10.862723232653622,
        "cond_entropy-2-nopunct": 2.7742772949200316,
        "distinct-3-nopunct": 0.27970254617730717,
        "vocab_size-3-nopunct": 8162,
        "unique-3-nopunct": 4349,
        "entropy-3-nopunct": 11.929813319371293,
        "cond_entropy-3-nopunct": 1.122835940122919,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.74433,
            "recall": 0.75634,
            "fmeasure": 0.74292
        },
        "rouge2": {
            "precision": 0.49897,
            "recall": 0.50644,
            "fmeasure": 0.49703
        },
        "rougeL": {
            "precision": 0.60279,
            "recall": 0.61335,
            "fmeasure": 0.60155
        },
        "rougeLsum": {
            "precision": 0.60279,
            "recall": 0.61335,
            "fmeasure": 0.60155
        },
        "bleu": 49.29889,
        "nist": 9.003263816605783,
        "local_recall": {
            "1": 0.23840022772559066,
            "2": 0.619721632460486,
            "3": 0.8849945932192609,
            "4": 0.9411764705882353,
            "5": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 4.47595,
            "contradiction": 8.68967,
            "irrelevancy": 8.27221,
            "logical_agreement": 83.03812,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.6,
            "nubia_score": 0.79348
        },
        "meteor": 0.3960961151306755,
        "bleurt": 0.20363,
        "bertscore": {
            "precision": 0.92247,
            "recall": 0.92293,
            "f1": 0.9214
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.62322,
        "msttr-100_nopunct": 0.62696,
        "total_length": 28665,
        "mean_pred_length": 20.51896921975662,
        "std_pred_length": 7.195836469950784,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 72,
        "distinct-1": 0.06146869004011861,
        "vocab_size-1": 1762,
        "unique-1": 840,
        "entropy-1": 7.448865720606197,
        "distinct-2": 0.19942790083614492,
        "vocab_size-2": 5438,
        "unique-2": 3165,
        "entropy-2": 10.246675579809644,
        "cond_entropy-2": 2.693340712478131,
        "distinct-3": 0.3714197363843686,
        "vocab_size-3": 9609,
        "unique-3": 6652,
        "entropy-3": 11.764827954000701,
        "cond_entropy-3": 1.5384489932015113,
        "total_length-nopunct": 26008,
        "mean_pred_length-nopunct": 18.617036506800286,
        "std_pred_length-nopunct": 6.7309536440671875,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.06724853891110427,
        "vocab_size-1-nopunct": 1749,
        "unique-1-nopunct": 838,
        "entropy-1-nopunct": 7.508794624863889,
        "distinct-2-nopunct": 0.213278615253342,
        "vocab_size-2-nopunct": 5249,
        "unique-2-nopunct": 3130,
        "entropy-2-nopunct": 10.196665994945109,
        "cond_entropy-2-nopunct": 2.7662072144564114,
        "distinct-3-nopunct": 0.39127250796932883,
        "vocab_size-3-nopunct": 9083,
        "unique-3-nopunct": 6416,
        "entropy-3-nopunct": 11.710747124888186,
        "cond_entropy-3-nopunct": 1.5566276798712004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.65697,
            "recall": 0.65425,
            "fmeasure": 0.64306
        },
        "rouge2": {
            "precision": 0.4426,
            "recall": 0.43945,
            "fmeasure": 0.43239
        },
        "rougeL": {
            "precision": 0.5694,
            "recall": 0.56621,
            "fmeasure": 0.55718
        },
        "rougeLsum": {
            "precision": 0.5694,
            "recall": 0.56621,
            "fmeasure": 0.55718
        },
        "bleu": 36.21032,
        "nist": 6.682743901602905,
        "local_recall": {
            "1": 0.6413176087840585
        },
        "nubia": {
            "semantic_relation": 4.10807,
            "contradiction": 5.35191,
            "irrelevancy": 21.70292,
            "logical_agreement": 72.94517,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.8093,
            "nubia_score": 0.7014
        },
        "meteor": 0.34437216267348597,
        "bleurt": -0.04437,
        "bertscore": {
            "precision": 0.88391,
            "recall": 0.88095,
            "f1": 0.882
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "mT5_large/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.731,
        "msttr-100_nopunct": 0.74073,
        "total_length": 6084,
        "mean_pred_length": 12.168,
        "std_pred_length": 7.0176759685810515,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 40,
        "distinct-1": 0.17422748191978962,
        "vocab_size-1": 1060,
        "unique-1": 591,
        "entropy-1": 8.098090721889655,
        "distinct-2": 0.5331303724928367,
        "vocab_size-2": 2977,
        "unique-2": 2159,
        "entropy-2": 10.861073308054733,
        "cond_entropy-2": 2.753042636737522,
        "distinct-3": 0.7671583087512291,
        "vocab_size-3": 3901,
        "unique-3": 3312,
        "entropy-3": 11.670901481037594,
        "cond_entropy-3": 0.8558482013561408,
        "total_length-nopunct": 5561,
        "mean_pred_length-nopunct": 11.122,
        "std_pred_length-nopunct": 6.512688845630505,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.18863513756518613,
        "vocab_size-1-nopunct": 1049,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 8.169370646964278,
        "distinct-2-nopunct": 0.5483106105512745,
        "vocab_size-2-nopunct": 2775,
        "unique-2-nopunct": 2062,
        "entropy-2-nopunct": 10.752740394271338,
        "cond_entropy-2-nopunct": 2.7125695564118937,
        "distinct-3-nopunct": 0.7775586237124699,
        "vocab_size-3-nopunct": 3548,
        "unique-3-nopunct": 3049,
        "entropy-3-nopunct": 11.540014350205315,
        "cond_entropy-3-nopunct": 0.8264551843522641,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "rouge1": {
            "precision": 0.55826,
            "recall": 0.49599,
            "fmeasure": 0.51143
        },
        "rouge2": {
            "precision": 0.34246,
            "recall": 0.29918,
            "fmeasure": 0.30941
        },
        "rougeL": {
            "precision": 0.49476,
            "recall": 0.44014,
            "fmeasure": 0.45336
        },
        "rougeLsum": {
            "precision": 0.49476,
            "recall": 0.44014,
            "fmeasure": 0.45336
        },
        "bleu": 26.88332,
        "nist": 5.48214342109128,
        "local_recall": {
            "1": 0.5147665401748887
        },
        "nubia": {
            "semantic_relation": 3.48912,
            "contradiction": 6.90163,
            "irrelevancy": 23.21295,
            "logical_agreement": 69.88542,
            "grammar_ref": 4.79983,
            "grammar_hyp": 5.09246,
            "nubia_score": 0.57263
        },
        "meteor": 0.2881148441836217,
        "bleurt": -0.22464,
        "bertscore": {
            "precision": 0.85978,
            "recall": 0.84038,
            "f1": 0.84943
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.73048,
        "msttr-100_nopunct": 0.82545,
        "total_length": 23148,
        "mean_pred_length": 21.005444646098002,
        "std_pred_length": 11.442587981773187,
        "median_pred_length": 19.5,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.119189562813202,
        "vocab_size-1": 2759,
        "unique-1": 894,
        "entropy-1": 8.97650864554108,
        "distinct-2": 0.3166107230336569,
        "vocab_size-2": 6980,
        "unique-2": 3447,
        "entropy-2": 11.861552417412437,
        "cond_entropy-2": 2.623259601396024,
        "distinct-3": 0.4694900687547746,
        "vocab_size-3": 9833,
        "unique-3": 5957,
        "entropy-3": 12.721614512179197,
        "cond_entropy-3": 0.8786542716381455,
        "total_length-nopunct": 18904,
        "mean_pred_length-nopunct": 17.15426497277677,
        "std_pred_length-nopunct": 9.562089342314602,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.14552475666525602,
        "vocab_size-1-nopunct": 2751,
        "unique-1-nopunct": 894,
        "entropy-1-nopunct": 9.734903577905172,
        "distinct-2-nopunct": 0.360408942815414,
        "vocab_size-2-nopunct": 6416,
        "unique-2-nopunct": 3425,
        "entropy-2-nopunct": 11.86600226508474,
        "cond_entropy-2-nopunct": 2.205152312295598,
        "distinct-3-nopunct": 0.5111377245508982,
        "vocab_size-3-nopunct": 8536,
        "unique-3-nopunct": 5487,
        "entropy-3-nopunct": 12.55764612143538,
        "cond_entropy-3-nopunct": 0.7330571220617518,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.44957,
            "recall": 0.45209,
            "fmeasure": 0.44727
        },
        "rouge2": {
            "precision": 0.25542,
            "recall": 0.25762,
            "fmeasure": 0.25342
        },
        "rougeL": {
            "precision": 0.42876,
            "recall": 0.43158,
            "fmeasure": 0.42643
        },
        "rougeLsum": {
            "precision": 0.42876,
            "recall": 0.43158,
            "fmeasure": 0.42643
        },
        "bleu": 52.29289,
        "nist": 9.57840186955675,
        "local_recall": {
            "1": 0.2941974163157519,
            "2": 0.6733177377184533,
            "3": 0.8941966784847919,
            "4": 0.948051948051948,
            "5": 0.8918918918918919,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.02809,
            "contradiction": 19.36759,
            "irrelevancy": 21.41617,
            "logical_agreement": 59.21624,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.64079,
            "nubia_score": 0.83663
        },
        "meteor": 0.6698747228487918,
        "bleurt": 0.21903,
        "bertscore": {
            "precision": 0.95885,
            "recall": 0.95701,
            "f1": 0.95731
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "mT5_large/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.68758,
        "msttr-100_nopunct": 0.71621,
        "total_length": 6666,
        "mean_pred_length": 13.332,
        "std_pred_length": 7.770828527254992,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 50,
        "distinct-1": 0.156015601560156,
        "vocab_size-1": 1040,
        "unique-1": 567,
        "entropy-1": 7.8530440710841125,
        "distinct-2": 0.5027570548167369,
        "vocab_size-2": 3100,
        "unique-2": 2164,
        "entropy-2": 10.879493064155472,
        "cond_entropy-2": 2.798304202503633,
        "distinct-3": 0.7472643840451818,
        "vocab_size-3": 4234,
        "unique-3": 3534,
        "entropy-3": 11.758017706247143,
        "cond_entropy-3": 0.8948180932583796,
        "total_length-nopunct": 5867,
        "mean_pred_length-nopunct": 11.734,
        "std_pred_length-nopunct": 7.16374510992679,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.1752173171978865,
        "vocab_size-1-nopunct": 1028,
        "unique-1-nopunct": 564,
        "entropy-1-nopunct": 8.043863661243558,
        "distinct-2-nopunct": 0.5226383454443824,
        "vocab_size-2-nopunct": 2805,
        "unique-2-nopunct": 2005,
        "entropy-2-nopunct": 10.733711532347492,
        "cond_entropy-2-nopunct": 2.816073891986642,
        "distinct-3-nopunct": 0.7591945757139922,
        "vocab_size-3-nopunct": 3695,
        "unique-3-nopunct": 3129,
        "entropy-3-nopunct": 11.562036928265462,
        "cond_entropy-3-nopunct": 0.871348949515168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.52828,
            "recall": 0.50378,
            "fmeasure": 0.50293
        },
        "rouge2": {
            "precision": 0.29537,
            "recall": 0.28091,
            "fmeasure": 0.28011
        },
        "rougeL": {
            "precision": 0.45817,
            "recall": 0.43665,
            "fmeasure": 0.43594
        },
        "rougeLsum": {
            "precision": 0.45817,
            "recall": 0.43665,
            "fmeasure": 0.43594
        },
        "bleu": 26.90123,
        "nist": 5.590922398101958,
        "local_recall": {
            "1": 0.5262433316124592
        },
        "nubia": {
            "semantic_relation": 3.36829,
            "contradiction": 8.80135,
            "irrelevancy": 26.30445,
            "logical_agreement": 64.8942,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.70865,
            "nubia_score": 0.56966
        },
        "meteor": 0.28744352444052157,
        "bleurt": -0.22704,
        "bertscore": {
            "precision": 0.8541,
            "recall": 0.84777,
            "f1": 0.85042
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "mT5_large/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.65292,
        "msttr-100_nopunct": 0.71943,
        "total_length": 10648,
        "mean_pred_length": 21.296,
        "std_pred_length": 12.125691073089401,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 70,
        "distinct-1": 0.21036814425244177,
        "vocab_size-1": 2240,
        "unique-1": 1075,
        "entropy-1": 8.946018995572778,
        "distinct-2": 0.5267047694126922,
        "vocab_size-2": 5345,
        "unique-2": 3692,
        "entropy-2": 11.779662020470889,
        "cond_entropy-2": 2.5789324262590445,
        "distinct-3": 0.7274046434494196,
        "vocab_size-3": 7018,
        "unique-3": 5671,
        "entropy-3": 12.518838217493975,
        "cond_entropy-3": 0.7456242011451789,
        "total_length-nopunct": 8744,
        "mean_pred_length-nopunct": 17.488,
        "std_pred_length-nopunct": 10.127677719990896,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 59,
        "distinct-1-nopunct": 0.25514638609332113,
        "vocab_size-1-nopunct": 2231,
        "unique-1-nopunct": 1075,
        "entropy-1-nopunct": 9.662104593611925,
        "distinct-2-nopunct": 0.5811499272197962,
        "vocab_size-2-nopunct": 4791,
        "unique-2-nopunct": 3470,
        "entropy-2-nopunct": 11.736547992930355,
        "cond_entropy-2-nopunct": 2.1410128302518614,
        "distinct-3-nopunct": 0.7629132231404959,
        "vocab_size-3-nopunct": 5908,
        "unique-3-nopunct": 4956,
        "entropy-3-nopunct": 12.297928136585115,
        "cond_entropy-3-nopunct": 0.5816772944314433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.42593,
            "recall": 0.43889,
            "fmeasure": 0.42823
        },
        "rouge2": {
            "precision": 0.22151,
            "recall": 0.22882,
            "fmeasure": 0.22169
        },
        "rougeL": {
            "precision": 0.39748,
            "recall": 0.41165,
            "fmeasure": 0.40027
        },
        "rougeLsum": {
            "precision": 0.39748,
            "recall": 0.41165,
            "fmeasure": 0.40027
        },
        "bleu": 42.63721,
        "nist": 8.234789313119798,
        "local_recall": {
            "1": 0.28226857887874834,
            "2": 0.6245454545454545,
            "3": 0.8465765004226543,
            "4": 0.8888888888888888,
            "5": 1.0,
            "6": 1.0
        },
        "nubia": {
            "semantic_relation": 3.9335,
            "contradiction": 21.70602,
            "irrelevancy": 22.73129,
            "logical_agreement": 55.5627,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.63085,
            "nubia_score": 0.81095
        },
        "meteor": 0.6113572397417,
        "bleurt": 0.14367,
        "bertscore": {
            "precision": 0.94985,
            "recall": 0.94894,
            "f1": 0.94871
        }
    },
    "mlsum_de_val": {
        "predictions_file": "mT5_large/mlsum_de_val",
        "N": 11392,
        "msttr-100": 0.7752,
        "msttr-100_nopunct": 0.82636,
        "total_length": 309460,
        "mean_pred_length": 27.164676966292134,
        "std_pred_length": 9.769576042353865,
        "median_pred_length": 26.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.11623150003231435,
        "vocab_size-1": 35969,
        "unique-1": 21475,
        "entropy-1": 10.523413452392166,
        "distinct-2": 0.5329455023685871,
        "vocab_size-2": 158854,
        "unique-2": 128164,
        "entropy-2": 16.0270434397625,
        "cond_entropy-2": 5.261654912479015,
        "distinct-3": 0.857560451520183,
        "vocab_size-3": 245842,
        "unique-3": 227002,
        "entropy-3": 17.69004290587064,
        "cond_entropy-3": 1.6408939779988905,
        "total_length-nopunct": 274121,
        "mean_pred_length-nopunct": 24.062587780898877,
        "std_pred_length-nopunct": 8.596876346099878,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 77,
        "distinct-1-nopunct": 0.13116105661368518,
        "vocab_size-1-nopunct": 35954,
        "unique-1-nopunct": 21473,
        "entropy-1-nopunct": 11.0855903373512,
        "distinct-2-nopunct": 0.5948220409623605,
        "vocab_size-2-nopunct": 156277,
        "unique-2-nopunct": 129204,
        "entropy-2-nopunct": 16.29642392943937,
        "cond_entropy-2-nopunct": 5.3104601393101065,
        "distinct-3-nopunct": 0.8944405320346785,
        "vocab_size-3-nopunct": 224806,
        "unique-3-nopunct": 211182,
        "entropy-3-nopunct": 17.629571694868513,
        "cond_entropy-3-nopunct": 1.367160633163727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_val.json",
        "rouge1": {
            "precision": 0.44799,
            "recall": 0.45674,
            "fmeasure": 0.44463
        },
        "rouge2": {
            "precision": 0.33577,
            "recall": 0.34239,
            "fmeasure": 0.33595
        },
        "rougeL": {
            "precision": 0.40967,
            "recall": 0.41724,
            "fmeasure": 0.40735
        },
        "rougeLsum": {
            "precision": 0.40967,
            "recall": 0.41724,
            "fmeasure": 0.40735
        },
        "bleu": 37.11317,
        "nist": 7.298372599807077,
        "local_recall": {
            "1": 0.4696861454487077
        },
        "nubia": {
            "semantic_relation": 2.75061,
            "contradiction": 23.61537,
            "irrelevancy": 41.31806,
            "logical_agreement": 35.06657,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.96688,
            "nubia_score": 0.41191
        },
        "meteor": 0.4293037093679457,
        "bleurt": -0.23787,
        "bertscore": {
            "precision": 0.89209,
            "recall": 0.89454,
            "f1": 0.89317
        }
    },
    "mlsum_de_test": {
        "predictions_file": "mT5_large/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.77545,
        "msttr-100_nopunct": 0.82575,
        "total_length": 293050,
        "mean_pred_length": 27.40065451145395,
        "std_pred_length": 9.889469540868141,
        "median_pred_length": 26.0,
        "min_pred_length": 7,
        "max_pred_length": 93,
        "distinct-1": 0.12019791844395154,
        "vocab_size-1": 35224,
        "unique-1": 21109,
        "entropy-1": 10.52599848942237,
        "distinct-2": 0.5406775158931133,
        "vocab_size-2": 152663,
        "unique-2": 123686,
        "entropy-2": 15.99347703822895,
        "cond_entropy-2": 5.229529636540587,
        "distinct-3": 0.8615512037105205,
        "vocab_size-3": 234049,
        "unique-3": 216812,
        "entropy-3": 17.622224051083517,
        "cond_entropy-3": 1.6079889080898624,
        "total_length-nopunct": 259716,
        "mean_pred_length-nopunct": 24.283870967741937,
        "std_pred_length-nopunct": 8.735285056880452,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 86,
        "distinct-1-nopunct": 0.13556731198693958,
        "vocab_size-1-nopunct": 35209,
        "unique-1-nopunct": 21107,
        "entropy-1-nopunct": 11.085225356571724,
        "distinct-2-nopunct": 0.6025515920344068,
        "vocab_size-2-nopunct": 150048,
        "unique-2-nopunct": 124664,
        "entropy-2-nopunct": 16.256950871728673,
        "cond_entropy-2-nopunct": 5.2709503684535575,
        "distinct-3-nopunct": 0.8980178411083978,
        "vocab_size-3-nopunct": 214021,
        "unique-3-nopunct": 201678,
        "entropy-3-nopunct": 17.560368934246537,
        "cond_entropy-3-nopunct": 1.337571069118395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "rouge1": {
            "precision": 0.46382,
            "recall": 0.47273,
            "fmeasure": 0.46064
        },
        "rouge2": {
            "precision": 0.35381,
            "recall": 0.36075,
            "fmeasure": 0.35405
        },
        "rougeL": {
            "precision": 0.42542,
            "recall": 0.43312,
            "fmeasure": 0.42324
        },
        "rougeLsum": {
            "precision": 0.42542,
            "recall": 0.43312,
            "fmeasure": 0.42324
        },
        "bleu": 38.9409,
        "nist": 7.567538673713097,
        "local_recall": {
            "1": 0.4858509146819262
        },
        "nubia": {
            "semantic_relation": 2.80344,
            "contradiction": 23.58744,
            "irrelevancy": 40.10129,
            "logical_agreement": 36.31127,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.96127,
            "nubia_score": 0.42458
        },
        "meteor": 0.44605997685734006,
        "bleurt": -0.21472,
        "bertscore": {
            "precision": 0.89462,
            "recall": 0.89702,
            "f1": 0.89567
        }
    },
    "xsum_val": {
        "predictions_file": "mT5_large/xsum_val",
        "N": 1117,
        "msttr-100": 0.70513,
        "msttr-100_nopunct": 0.72435,
        "total_length": 23225,
        "mean_pred_length": 20.79230080572963,
        "std_pred_length": 4.3208198460804,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 40,
        "distinct-1": 0.18979547900968782,
        "vocab_size-1": 4408,
        "unique-1": 2491,
        "entropy-1": 9.071275053125103,
        "distinct-2": 0.6038990410711055,
        "vocab_size-2": 13351,
        "unique-2": 10937,
        "entropy-2": 12.830203321470217,
        "cond_entropy-2": 3.5222135973157616,
        "distinct-3": 0.8368348339764661,
        "vocab_size-3": 17566,
        "unique-3": 16148,
        "entropy-3": 13.836279253905237,
        "cond_entropy-3": 1.0099612878338438,
        "total_length-nopunct": 21612,
        "mean_pred_length-nopunct": 19.348254252461953,
        "std_pred_length-nopunct": 4.1255507861352845,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.20349805663520268,
        "vocab_size-1-nopunct": 4398,
        "unique-1-nopunct": 2490,
        "entropy-1-nopunct": 9.2539684293754,
        "distinct-2-nopunct": 0.6139546230787997,
        "vocab_size-2-nopunct": 12583,
        "unique-2-nopunct": 10374,
        "entropy-2-nopunct": 12.766531728863136,
        "cond_entropy-2-nopunct": 3.6368627540124217,
        "distinct-3-nopunct": 0.8498297037878006,
        "vocab_size-3-nopunct": 16468,
        "unique-3-nopunct": 15207,
        "entropy-3-nopunct": 13.7799759371236,
        "cond_entropy-3-nopunct": 1.0225690305195438,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_val.json",
        "rouge1": {
            "precision": 0.40861,
            "recall": 0.37361,
            "fmeasure": 0.38223
        },
        "rouge2": {
            "precision": 0.15449,
            "recall": 0.1411,
            "fmeasure": 0.14427
        },
        "rougeL": {
            "precision": 0.3159,
            "recall": 0.28903,
            "fmeasure": 0.29552
        },
        "rougeLsum": {
            "precision": 0.3159,
            "recall": 0.28903,
            "fmeasure": 0.29552
        },
        "bleu": 9.17424,
        "nist": 3.7936265789806076,
        "local_recall": {
            "1": 0.348256234188652
        },
        "nubia": {
            "semantic_relation": 2.87494,
            "contradiction": 21.54153,
            "irrelevancy": 65.72957,
            "logical_agreement": 12.7289,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.64199,
            "nubia_score": 0.41785
        },
        "meteor": 0.16801368331953886,
        "bleurt": -0.34059,
        "bertscore": {
            "precision": 0.83399,
            "recall": 0.81878,
            "f1": 0.82598
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.39545,
            "recall": 0.50556,
            "fmeasure": 0.43284
        },
        "rouge2": {
            "precision": 0.14983,
            "recall": 0.22193,
            "fmeasure": 0.17613
        },
        "rougeL": {
            "precision": 0.25751,
            "recall": 0.39921,
            "fmeasure": 0.30544
        },
        "rougeLsum": {
            "precision": 0.25751,
            "recall": 0.39921,
            "fmeasure": 0.30544
        },
        "bleu": 6.58208,
        "nist": 2.122458708375069,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2,
            "3": 0.5909090909090909
        },
        "nubia": {
            "semantic_relation": 3.1977,
            "contradiction": 0.73816,
            "irrelevancy": 98.97694,
            "logical_agreement": 0.2849,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.28601,
            "nubia_score": 0.50367
        },
        "meteor": 0.21973997199592243,
        "bleurt": 0.01677,
        "bertscore": {
            "precision": 0.79886,
            "recall": 0.85974,
            "f1": 0.81512
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.22792,
        "msttr-100_nopunct": 0.2193,
        "total_length": 5352,
        "mean_pred_length": 5.444557477110885,
        "std_pred_length": 1.615895224922491,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 12,
        "distinct-1": 0.015321375186846039,
        "vocab_size-1": 82,
        "unique-1": 13,
        "entropy-1": 3.9677749962991093,
        "distinct-2": 0.03959716182192721,
        "vocab_size-2": 173,
        "unique-2": 53,
        "entropy-2": 4.843192033429882,
        "cond_entropy-2": 0.7495316064335643,
        "distinct-3": 0.06556408741878322,
        "vocab_size-3": 222,
        "unique-3": 80,
        "entropy-3": 5.654922495292237,
        "cond_entropy-3": 0.6565366039438288,
        "total_length-nopunct": 4328,
        "mean_pred_length-nopunct": 4.402848423194303,
        "std_pred_length-nopunct": 1.2894722099680214,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.018253234750462106,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7613929916573294,
        "distinct-2-nopunct": 0.04245142002989537,
        "vocab_size-2-nopunct": 142,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 4.534895874337903,
        "cond_entropy-2-nopunct": 0.6313662185301339,
        "distinct-3-nopunct": 0.06265876375952582,
        "vocab_size-3-nopunct": 148,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 4.93638541457136,
        "cond_entropy-3-nopunct": 0.612326803250007,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.5418,
            "recall": 0.51332,
            "fmeasure": 0.51897
        },
        "rouge2": {
            "precision": 0.37151,
            "recall": 0.35012,
            "fmeasure": 0.3547
        },
        "rougeL": {
            "precision": 0.54117,
            "recall": 0.51274,
            "fmeasure": 0.51838
        },
        "rougeLsum": {
            "precision": 0.54117,
            "recall": 0.51274,
            "fmeasure": 0.51838
        },
        "bleu": 30.68944,
        "nist": 2.873174748273784,
        "local_recall": {
            "1": 0.4943266966388354
        },
        "nubia": {
            "semantic_relation": 3.13922,
            "contradiction": 2.43595,
            "irrelevancy": 23.56961,
            "logical_agreement": 73.99444,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.61651,
            "nubia_score": 0.59455
        },
        "meteor": 0.27660186231349404,
        "bleurt": 0.1434,
        "bertscore": {
            "precision": 0.86114,
            "recall": 0.85483,
            "f1": 0.85755
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.62516,
        "msttr-100_nopunct": 0.66262,
        "total_length": 9396,
        "mean_pred_length": 30.80655737704918,
        "std_pred_length": 8.05627479410821,
        "median_pred_length": 31.0,
        "min_pred_length": 10,
        "max_pred_length": 80,
        "distinct-1": 0.11717752234993614,
        "vocab_size-1": 1101,
        "unique-1": 346,
        "entropy-1": 7.866098509184641,
        "distinct-2": 0.3209767902320977,
        "vocab_size-2": 2918,
        "unique-2": 1417,
        "entropy-2": 10.66466680290659,
        "cond_entropy-2": 2.671508716327917,
        "distinct-3": 0.49556111996357843,
        "vocab_size-3": 4354,
        "unique-3": 2712,
        "entropy-3": 11.597993775782601,
        "cond_entropy-3": 0.9703311258204192,
        "total_length-nopunct": 8406,
        "mean_pred_length-nopunct": 27.560655737704916,
        "std_pred_length-nopunct": 7.4255049767791546,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.13014513442778966,
        "vocab_size-1-nopunct": 1094,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 8.09326945407215,
        "distinct-2-nopunct": 0.336254783360079,
        "vocab_size-2-nopunct": 2724,
        "unique-2-nopunct": 1407,
        "entropy-2-nopunct": 10.581766624590266,
        "cond_entropy-2-nopunct": 2.5858997210962418,
        "distinct-3-nopunct": 0.5135967162647511,
        "vocab_size-3-nopunct": 4004,
        "unique-3-nopunct": 2598,
        "entropy-3-nopunct": 11.484522534056826,
        "cond_entropy-3-nopunct": 0.9290008951491256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.71122,
            "recall": 0.72932,
            "fmeasure": 0.71232
        },
        "rouge2": {
            "precision": 0.44852,
            "recall": 0.45818,
            "fmeasure": 0.44793
        },
        "rougeL": {
            "precision": 0.54418,
            "recall": 0.55664,
            "fmeasure": 0.54417
        },
        "rougeLsum": {
            "precision": 0.54418,
            "recall": 0.55664,
            "fmeasure": 0.54417
        },
        "bleu": 44.52203,
        "nist": 8.262704891871556,
        "local_recall": {
            "1": 0.22160044767767206,
            "2": 0.6065943992773261,
            "3": 0.867349487884087
        },
        "nubia": {
            "semantic_relation": 4.32077,
            "contradiction": 11.06504,
            "irrelevancy": 9.72276,
            "logical_agreement": 79.21219,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.23806,
            "nubia_score": 0.74761
        },
        "meteor": 0.37560937535551636,
        "bleurt": 0.11936,
        "bertscore": {
            "precision": 0.90797,
            "recall": 0.90716,
            "f1": 0.90612
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.63895,
        "msttr-100_nopunct": 0.67294,
        "total_length": 3830,
        "mean_pred_length": 48.48101265822785,
        "std_pred_length": 12.605866385495036,
        "median_pred_length": 47.0,
        "min_pred_length": 25,
        "max_pred_length": 78,
        "distinct-1": 0.15848563968668408,
        "vocab_size-1": 607,
        "unique-1": 249,
        "entropy-1": 7.499851279653419,
        "distinct-2": 0.3532391362303386,
        "vocab_size-2": 1325,
        "unique-2": 719,
        "entropy-2": 9.693167771002232,
        "cond_entropy-2": 2.120166418194118,
        "distinct-3": 0.46949891067538124,
        "vocab_size-3": 1724,
        "unique-3": 1086,
        "entropy-3": 10.248456819992047,
        "cond_entropy-3": 0.5743415527924546,
        "total_length-nopunct": 3408,
        "mean_pred_length-nopunct": 43.139240506329116,
        "std_pred_length-nopunct": 11.37812043966951,
        "median_pred_length-nopunct": 42.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.17634976525821597,
        "vocab_size-1-nopunct": 601,
        "unique-1-nopunct": 248,
        "entropy-1-nopunct": 7.694470468651272,
        "distinct-2-nopunct": 0.37188344848302796,
        "vocab_size-2-nopunct": 1238,
        "unique-2-nopunct": 693,
        "entropy-2-nopunct": 9.630293610584888,
        "cond_entropy-2-nopunct": 1.9845637358090642,
        "distinct-3-nopunct": 0.48923076923076925,
        "vocab_size-3-nopunct": 1590,
        "unique-3-nopunct": 1032,
        "entropy-3-nopunct": 10.142696710174128,
        "cond_entropy-3-nopunct": 0.5232954360811294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.7646,
            "recall": 0.7066,
            "fmeasure": 0.7284
        },
        "rouge2": {
            "precision": 0.47856,
            "recall": 0.44699,
            "fmeasure": 0.45795
        },
        "rougeL": {
            "precision": 0.51239,
            "recall": 0.47593,
            "fmeasure": 0.48846
        },
        "rougeLsum": {
            "precision": 0.51239,
            "recall": 0.47593,
            "fmeasure": 0.48846
        },
        "bleu": 48.95579,
        "nist": 8.175072393328728,
        "local_recall": {
            "1": 0.25210084033613445,
            "2": 0.5336856010568032,
            "3": 0.8759291023441966
        },
        "nubia": {
            "semantic_relation": 4.13122,
            "contradiction": 6.6167,
            "irrelevancy": 6.20968,
            "logical_agreement": 87.17362,
            "grammar_ref": 3.96506,
            "grammar_hyp": 3.94156,
            "nubia_score": 0.74314
        },
        "meteor": 0.36669953746728035,
        "bleurt": -0.00139,
        "bertscore": {
            "precision": 0.91239,
            "recall": 0.89795,
            "f1": 0.90399
        }
    },
    "totto_val": {
        "predictions_file": "mT5_large/totto_val",
        "N": 7700,
        "msttr-100": 0.7239,
        "msttr-100_nopunct": 0.77837,
        "total_length": 128060,
        "mean_pred_length": 16.631168831168832,
        "std_pred_length": 6.843486992626587,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 95,
        "distinct-1": 0.17172419178510073,
        "vocab_size-1": 21991,
        "unique-1": 15103,
        "entropy-1": 10.090902466697576,
        "distinct-2": 0.5483715520106348,
        "vocab_size-2": 66002,
        "unique-2": 55193,
        "entropy-2": 14.650685161555884,
        "cond_entropy-2": 4.172292758108591,
        "distinct-3": 0.7830552103674774,
        "vocab_size-3": 88219,
        "unique-3": 80478,
        "entropy-3": 15.940642800100635,
        "cond_entropy-3": 1.2653725002336778,
        "total_length-nopunct": 111242,
        "mean_pred_length-nopunct": 14.447012987012988,
        "std_pred_length-nopunct": 5.816382832961702,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.19749734812391004,
        "vocab_size-1-nopunct": 21970,
        "unique-1-nopunct": 15100,
        "entropy-1-nopunct": 10.661979903833469,
        "distinct-2-nopunct": 0.5941453709605764,
        "vocab_size-2-nopunct": 61519,
        "unique-2-nopunct": 52575,
        "entropy-2-nopunct": 14.653343551193263,
        "cond_entropy-2-nopunct": 4.160950159264835,
        "distinct-3-nopunct": 0.8095198347279898,
        "vocab_size-3-nopunct": 77586,
        "unique-3-nopunct": 71679,
        "entropy-3-nopunct": 15.80820200748433,
        "cond_entropy-3-nopunct": 1.2284430287109198,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_val.json",
        "rouge1": {
            "precision": 0.74866,
            "recall": 0.73196,
            "fmeasure": 0.72882
        },
        "rouge2": {
            "precision": 0.52353,
            "recall": 0.51315,
            "fmeasure": 0.51005
        },
        "rougeL": {
            "precision": 0.64864,
            "recall": 0.63746,
            "fmeasure": 0.63282
        },
        "rougeLsum": {
            "precision": 0.64864,
            "recall": 0.63746,
            "fmeasure": 0.63282
        },
        "bleu": 46.45888,
        "nist": 10.718828841367866,
        "local_recall": {
            "1": 0.22805288658947195,
            "2": 0.46034073754582705,
            "3": 0.7728520054631799
        },
        "nubia": {
            "semantic_relation": 4.17242,
            "contradiction": 8.79673,
            "irrelevancy": 31.12722,
            "logical_agreement": 60.07605,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.62424,
            "nubia_score": 0.72509
        },
        "meteor": 0.3947815402022216,
        "bleurt": 0.27542,
        "bertscore": {
            "precision": 0.92693,
            "recall": 0.92484,
            "f1": 0.92427
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.63172,
        "msttr-100_nopunct": 0.6804,
        "total_length": 2955,
        "mean_pred_length": 9.94949494949495,
        "std_pred_length": 3.115207849717927,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.23316412859560068,
        "vocab_size-1": 689,
        "unique-1": 372,
        "entropy-1": 7.392025484733516,
        "distinct-2": 0.5485327313769752,
        "vocab_size-2": 1458,
        "unique-2": 1016,
        "entropy-2": 9.96867963074207,
        "cond_entropy-2": 2.120510909639382,
        "distinct-3": 0.7318932655654383,
        "vocab_size-3": 1728,
        "unique-3": 1407,
        "entropy-3": 10.485347356497124,
        "cond_entropy-3": 0.615470368810801,
        "total_length-nopunct": 2595,
        "mean_pred_length-nopunct": 8.737373737373737,
        "std_pred_length-nopunct": 2.917216485848032,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.26204238921001927,
        "vocab_size-1-nopunct": 680,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 7.674024941358655,
        "distinct-2-nopunct": 0.5226283724978242,
        "vocab_size-2-nopunct": 1201,
        "unique-2-nopunct": 822,
        "entropy-2-nopunct": 9.64742597508442,
        "cond_entropy-2-nopunct": 2.284991974289816,
        "distinct-3-nopunct": 0.7156421789105447,
        "vocab_size-3-nopunct": 1432,
        "unique-3-nopunct": 1149,
        "entropy-3-nopunct": 10.195754835929408,
        "cond_entropy-3-nopunct": 0.6742160182472723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.78933,
            "recall": 0.77462,
            "fmeasure": 0.77398
        },
        "rouge2": {
            "precision": 0.57122,
            "recall": 0.55872,
            "fmeasure": 0.55822
        },
        "rougeL": {
            "precision": 0.70409,
            "recall": 0.69116,
            "fmeasure": 0.69009
        },
        "rougeLsum": {
            "precision": 0.70409,
            "recall": 0.69116,
            "fmeasure": 0.69009
        },
        "bleu": 56.37817,
        "nist": 8.614912088862464,
        "local_recall": {
            "1": 0.23255813953488372,
            "2": 0.6601036269430052,
            "3": 0.8683092608326253,
            "4": 0.9736842105263158
        },
        "nubia": {
            "semantic_relation": 4.57941,
            "contradiction": 8.28681,
            "irrelevancy": 7.00501,
            "logical_agreement": 84.70818,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.31253,
            "nubia_score": 0.81423
        },
        "meteor": 0.4481243362706722,
        "bleurt": 0.35751,
        "bertscore": {
            "precision": 0.9427,
            "recall": 0.94268,
            "f1": 0.9416
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.63,
        "total_length": 156,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.136557881996952,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.46794871794871795,
        "vocab_size-1": 73,
        "unique-1": 45,
        "entropy-1": 5.690676893517897,
        "distinct-2": 0.7346938775510204,
        "vocab_size-2": 108,
        "unique-2": 83,
        "entropy-2": 6.583826596448732,
        "cond_entropy-2": 0.8182730220911271,
        "distinct-3": 0.8478260869565217,
        "vocab_size-3": 117,
        "unique-3": 100,
        "entropy-3": 6.778743478485943,
        "cond_entropy-3": 0.16261696707697773,
        "total_length-nopunct": 138,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.590109871423003,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5144927536231884,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.719259958750933,
        "distinct-2-nopunct": 0.7674418604651163,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.479992177803235,
        "cond_entropy-2-nopunct": 0.77015600279414,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 105,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.650599866423838,
        "cond_entropy-3-nopunct": 0.12711698610874222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "rouge1": {
            "precision": 0.58464,
            "recall": 0.54362,
            "fmeasure": 0.55581
        },
        "rouge2": {
            "precision": 0.34393,
            "recall": 0.31444,
            "fmeasure": 0.32402
        },
        "rougeL": {
            "precision": 0.47709,
            "recall": 0.43483,
            "fmeasure": 0.44885
        },
        "rougeLsum": {
            "precision": 0.47709,
            "recall": 0.43483,
            "fmeasure": 0.44885
        },
        "bleu": 26.40858,
        "nist": 3.405994152866275,
        "local_recall": {
            "1": 0.5333333333333333
        },
        "nubia": {
            "semantic_relation": 3.4979,
            "contradiction": 10.79035,
            "irrelevancy": 30.66859,
            "logical_agreement": 58.54106,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.20664,
            "nubia_score": 0.55848
        },
        "meteor": 0.2734360711793606,
        "bleurt": -0.04227,
        "bertscore": {
            "precision": 0.92731,
            "recall": 0.91776,
            "f1": 0.92239
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.70429,
        "msttr-100_nopunct": 0.7305,
        "total_length": 2175,
        "mean_pred_length": 20.5188679245283,
        "std_pred_length": 4.491566798268816,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 41,
        "distinct-1": 0.39586206896551723,
        "vocab_size-1": 861,
        "unique-1": 617,
        "entropy-1": 8.135227337636426,
        "distinct-2": 0.8173030449492509,
        "vocab_size-2": 1691,
        "unique-2": 1514,
        "entropy-2": 10.482725692159589,
        "cond_entropy-2": 2.154026677724244,
        "distinct-3": 0.9490575649516046,
        "vocab_size-3": 1863,
        "unique-3": 1798,
        "entropy-3": 10.815578405806091,
        "cond_entropy-3": 0.3350697677362835,
        "total_length-nopunct": 2028,
        "mean_pred_length-nopunct": 19.132075471698112,
        "std_pred_length-nopunct": 4.352564786504518,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.42061143984220906,
        "vocab_size-1-nopunct": 853,
        "unique-1-nopunct": 612,
        "entropy-1-nopunct": 8.256408803252347,
        "distinct-2-nopunct": 0.8220603537981269,
        "vocab_size-2-nopunct": 1580,
        "unique-2-nopunct": 1417,
        "entropy-2-nopunct": 10.39284714612567,
        "cond_entropy-2-nopunct": 2.228135262048551,
        "distinct-3-nopunct": 0.9531938325991189,
        "vocab_size-3-nopunct": 1731,
        "unique-3-nopunct": 1671,
        "entropy-3-nopunct": 10.717263528918282,
        "cond_entropy-3-nopunct": 0.3245334529844521,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.36367,
            "recall": 0.32708,
            "fmeasure": 0.33744
        },
        "rouge2": {
            "precision": 0.11032,
            "recall": 0.10118,
            "fmeasure": 0.10299
        },
        "rougeL": {
            "precision": 0.27516,
            "recall": 0.2502,
            "fmeasure": 0.25643
        },
        "rougeLsum": {
            "precision": 0.27516,
            "recall": 0.2502,
            "fmeasure": 0.25643
        },
        "bleu": 4.9749,
        "nist": 2.7953202287459167,
        "local_recall": {
            "1": 0.3028464769015399
        },
        "nubia": {
            "semantic_relation": 2.71349,
            "contradiction": 18.24156,
            "irrelevancy": 71.86682,
            "logical_agreement": 9.89163,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.58815,
            "nubia_score": 0.38071
        },
        "meteor": 0.144570962001495,
        "bleurt": -0.35439,
        "bertscore": {
            "precision": 0.82324,
            "recall": 0.80381,
            "f1": 0.81311
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.71133,
        "msttr-100_nopunct": 0.80571,
        "total_length": 6063,
        "mean_pred_length": 28.33177570093458,
        "std_pred_length": 9.475360059056086,
        "median_pred_length": 27.0,
        "min_pred_length": 14,
        "max_pred_length": 69,
        "distinct-1": 0.2525152564736929,
        "vocab_size-1": 1531,
        "unique-1": 769,
        "entropy-1": 8.635465857360087,
        "distinct-2": 0.5253889553769875,
        "vocab_size-2": 3073,
        "unique-2": 1941,
        "entropy-2": 11.086695737266142,
        "cond_entropy-2": 2.277846960901644,
        "distinct-3": 0.673469387755102,
        "vocab_size-3": 3795,
        "unique-3": 2742,
        "entropy-3": 11.635962585964398,
        "cond_entropy-3": 0.5609983320677562,
        "total_length-nopunct": 4905,
        "mean_pred_length-nopunct": 22.92056074766355,
        "std_pred_length-nopunct": 7.640781365310615,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.3107033639143731,
        "vocab_size-1-nopunct": 1524,
        "unique-1-nopunct": 768,
        "entropy-1-nopunct": 9.36885069885997,
        "distinct-2-nopunct": 0.5823918141121296,
        "vocab_size-2-nopunct": 2732,
        "unique-2-nopunct": 1820,
        "entropy-2-nopunct": 11.029002822368462,
        "cond_entropy-2-nopunct": 1.7045747714271693,
        "distinct-3-nopunct": 0.7100737100737101,
        "vocab_size-3-nopunct": 3179,
        "unique-3-nopunct": 2388,
        "entropy-3-nopunct": 11.422700045203511,
        "cond_entropy-3-nopunct": 0.4101330296716952,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.44877,
            "recall": 0.45885,
            "fmeasure": 0.44902
        },
        "rouge2": {
            "precision": 0.26831,
            "recall": 0.27233,
            "fmeasure": 0.26529
        },
        "rougeL": {
            "precision": 0.41706,
            "recall": 0.42736,
            "fmeasure": 0.41704
        },
        "rougeLsum": {
            "precision": 0.41706,
            "recall": 0.42736,
            "fmeasure": 0.41704
        },
        "bleu": 51.29781,
        "nist": 8.838295516615256,
        "local_recall": {
            "1": 0.28177727784026996,
            "2": 0.6996681415929203,
            "3": 0.9106227106227106
        },
        "nubia": {
            "semantic_relation": 3.94404,
            "contradiction": 18.59771,
            "irrelevancy": 21.4188,
            "logical_agreement": 59.98349,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.49929,
            "nubia_score": 0.82907
        },
        "meteor": 0.6614746094466272,
        "bleurt": 0.13008,
        "bertscore": {
            "precision": 0.95275,
            "recall": 0.95179,
            "f1": 0.95175
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.72023,
        "msttr-100_nopunct": 0.80111,
        "total_length": 4425,
        "mean_pred_length": 20.677570093457945,
        "std_pred_length": 5.578979379598396,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.28836158192090394,
        "vocab_size-1": 1276,
        "unique-1": 662,
        "entropy-1": 8.571665337658597,
        "distinct-2": 0.59225837093327,
        "vocab_size-2": 2494,
        "unique-2": 1686,
        "entropy-2": 10.859690886714292,
        "cond_entropy-2": 2.0463887857708203,
        "distinct-3": 0.7533149862396797,
        "vocab_size-3": 3011,
        "unique-3": 2346,
        "entropy-3": 11.382188877581072,
        "cond_entropy-3": 0.5175885351358339,
        "total_length-nopunct": 3668,
        "mean_pred_length-nopunct": 17.14018691588785,
        "std_pred_length-nopunct": 5.086997531972676,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.34596510359869137,
        "vocab_size-1-nopunct": 1269,
        "unique-1-nopunct": 661,
        "entropy-1-nopunct": 9.156618184421774,
        "distinct-2-nopunct": 0.6360741169658367,
        "vocab_size-2-nopunct": 2197,
        "unique-2-nopunct": 1543,
        "entropy-2-nopunct": 10.762571241761476,
        "cond_entropy-2-nopunct": 1.6550265962608097,
        "distinct-3-nopunct": 0.7765432098765432,
        "vocab_size-3-nopunct": 2516,
        "unique-3-nopunct": 2012,
        "entropy-3-nopunct": 11.138815106675962,
        "cond_entropy-3-nopunct": 0.40352047520025974,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.45853,
            "recall": 0.46989,
            "fmeasure": 0.4604
        },
        "rouge2": {
            "precision": 0.2355,
            "recall": 0.24543,
            "fmeasure": 0.23829
        },
        "rougeL": {
            "precision": 0.43678,
            "recall": 0.44904,
            "fmeasure": 0.43908
        },
        "rougeLsum": {
            "precision": 0.43678,
            "recall": 0.44904,
            "fmeasure": 0.43908
        },
        "bleu": 48.72684,
        "nist": 8.59161712250429,
        "local_recall": {
            "1": 0.287033616549686,
            "2": 0.6641394996209249,
            "3": 0.9081272084805654,
            "4": 1.0
        },
        "nubia": {
            "semantic_relation": 3.98761,
            "contradiction": 19.26087,
            "irrelevancy": 21.94847,
            "logical_agreement": 58.79065,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.59176,
            "nubia_score": 0.83051
        },
        "meteor": 0.6535270369322487,
        "bleurt": 0.143,
        "bertscore": {
            "precision": 0.95451,
            "recall": 0.95352,
            "f1": 0.95333
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.61625,
        "msttr-100_nopunct": 0.63143,
        "total_length": 842,
        "mean_pred_length": 11.694444444444445,
        "std_pred_length": 3.569309335964378,
        "median_pred_length": 10.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.336104513064133,
        "vocab_size-1": 283,
        "unique-1": 186,
        "entropy-1": 6.71303142572761,
        "distinct-2": 0.674025974025974,
        "vocab_size-2": 519,
        "unique-2": 407,
        "entropy-2": 8.684415055025603,
        "cond_entropy-2": 1.6925324976386034,
        "distinct-3": 0.8022922636103151,
        "vocab_size-3": 560,
        "unique-3": 477,
        "entropy-3": 8.977274241300453,
        "cond_entropy-3": 0.35926990589942737,
        "total_length-nopunct": 741,
        "mean_pred_length-nopunct": 10.291666666666666,
        "std_pred_length-nopunct": 3.186069940642651,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.3738191632928475,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 185,
        "entropy-1-nopunct": 6.825832648965123,
        "distinct-2-nopunct": 0.6427503736920778,
        "vocab_size-2-nopunct": 430,
        "unique-2-nopunct": 329,
        "entropy-2-nopunct": 8.382042087447932,
        "cond_entropy-2-nopunct": 1.7859348395835093,
        "distinct-3-nopunct": 0.7805695142378559,
        "vocab_size-3-nopunct": 466,
        "unique-3-nopunct": 392,
        "entropy-3-nopunct": 8.693217864194647,
        "cond_entropy-3-nopunct": 0.3862468406812429,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.69691,
            "recall": 0.6955,
            "fmeasure": 0.6885
        },
        "rouge2": {
            "precision": 0.4311,
            "recall": 0.4385,
            "fmeasure": 0.42881
        },
        "rougeL": {
            "precision": 0.5861,
            "recall": 0.58429,
            "fmeasure": 0.57827
        },
        "rougeLsum": {
            "precision": 0.5861,
            "recall": 0.58429,
            "fmeasure": 0.57827
        },
        "bleu": 38.51172,
        "nist": 6.223685393737058,
        "local_recall": {
            "1": 0.2652582159624413,
            "2": 0.5823754789272031,
            "3": 0.7811550151975684
        },
        "nubia": {
            "semantic_relation": 4.26468,
            "contradiction": 8.97333,
            "irrelevancy": 14.94407,
            "logical_agreement": 76.0826,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.61326,
            "nubia_score": 0.6805
        },
        "meteor": 0.3865127192126055,
        "bleurt": 0.01871,
        "bertscore": {
            "precision": 0.90469,
            "recall": 0.90653,
            "f1": 0.90452
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.53229,
        "msttr-100_nopunct": 0.5523,
        "total_length": 8359,
        "mean_pred_length": 31.074349442379184,
        "std_pred_length": 10.857391399265715,
        "median_pred_length": 31.0,
        "min_pred_length": 10,
        "max_pred_length": 80,
        "distinct-1": 0.09749970092116282,
        "vocab_size-1": 815,
        "unique-1": 255,
        "entropy-1": 7.478200588210168,
        "distinct-2": 0.2875154511742892,
        "vocab_size-2": 2326,
        "unique-2": 1152,
        "entropy-2": 10.238932470358934,
        "cond_entropy-2": 2.649142551021973,
        "distinct-3": 0.4559519243063547,
        "vocab_size-3": 3566,
        "unique-3": 2174,
        "entropy-3": 11.223180756782552,
        "cond_entropy-3": 1.020763306902236,
        "total_length-nopunct": 7425,
        "mean_pred_length-nopunct": 27.602230483271377,
        "std_pred_length-nopunct": 9.902205578674993,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.10882154882154882,
        "vocab_size-1-nopunct": 808,
        "unique-1-nopunct": 255,
        "entropy-1-nopunct": 7.661935506860406,
        "distinct-2-nopunct": 0.30310229178311904,
        "vocab_size-2-nopunct": 2169,
        "unique-2-nopunct": 1131,
        "entropy-2-nopunct": 10.145733372962257,
        "cond_entropy-2-nopunct": 2.5717462895918874,
        "distinct-3-nopunct": 0.4771308261942791,
        "vocab_size-3-nopunct": 3286,
        "unique-3-nopunct": 2096,
        "entropy-3-nopunct": 11.109321417726878,
        "cond_entropy-3-nopunct": 0.9841200261534382,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.67468,
            "recall": 0.67014,
            "fmeasure": 0.66149
        },
        "rouge2": {
            "precision": 0.3787,
            "recall": 0.37557,
            "fmeasure": 0.36997
        },
        "rougeL": {
            "precision": 0.47978,
            "recall": 0.47326,
            "fmeasure": 0.4678
        },
        "rougeLsum": {
            "precision": 0.47978,
            "recall": 0.47326,
            "fmeasure": 0.4678
        },
        "bleu": 33.6971,
        "nist": 7.104241016810866,
        "local_recall": {
            "1": 0.19040568551969203,
            "2": 0.48598130841121495,
            "3": 0.8100026462026991,
            "4": 0.75,
            "5": 0.75
        },
        "nubia": {
            "semantic_relation": 4.01719,
            "contradiction": 12.0839,
            "irrelevancy": 12.9892,
            "logical_agreement": 74.9269,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.34175,
            "nubia_score": 0.65333
        },
        "meteor": 0.3271095039848503,
        "bleurt": -0.0846,
        "bertscore": {
            "precision": 0.88702,
            "recall": 0.8823,
            "f1": 0.88313
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.50407,
        "msttr-100_nopunct": 0.51068,
        "total_length": 29793,
        "mean_pred_length": 22.536308623298034,
        "std_pred_length": 12.286443742523133,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 80,
        "distinct-1": 0.048400631020709566,
        "vocab_size-1": 1442,
        "unique-1": 415,
        "entropy-1": 7.85356823149589,
        "distinct-2": 0.16283235573039234,
        "vocab_size-2": 4636,
        "unique-2": 1897,
        "entropy-2": 10.862601343199763,
        "cond_entropy-2": 2.8286980143324643,
        "distinct-3": 0.28785590629489116,
        "vocab_size-3": 7815,
        "unique-3": 4041,
        "entropy-3": 11.972262216505403,
        "cond_entropy-3": 1.176407985845068,
        "total_length-nopunct": 26626,
        "mean_pred_length-nopunct": 20.140695915279878,
        "std_pred_length-nopunct": 11.202841335064818,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.05381957485164877,
        "vocab_size-1-nopunct": 1433,
        "unique-1-nopunct": 415,
        "entropy-1-nopunct": 8.077956371853373,
        "distinct-2-nopunct": 0.16890610180208662,
        "vocab_size-2-nopunct": 4274,
        "unique-2-nopunct": 1818,
        "entropy-2-nopunct": 10.72831855362714,
        "cond_entropy-2-nopunct": 2.799616276330375,
        "distinct-3-nopunct": 0.29855725127178717,
        "vocab_size-3-nopunct": 7160,
        "unique-3-nopunct": 3837,
        "entropy-3-nopunct": 11.830446811608558,
        "cond_entropy-3-nopunct": 1.1592414707705543,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73791,
            "recall": 0.74868,
            "fmeasure": 0.73521
        },
        "rouge2": {
            "precision": 0.48864,
            "recall": 0.49565,
            "fmeasure": 0.48603
        },
        "rougeL": {
            "precision": 0.59954,
            "recall": 0.60823,
            "fmeasure": 0.59685
        },
        "rougeLsum": {
            "precision": 0.59954,
            "recall": 0.60823,
            "fmeasure": 0.59685
        },
        "bleu": 45.59373,
        "nist": 8.576140333447139,
        "local_recall": {
            "1": 0.22339795140946414,
            "2": 0.5841180604356992,
            "3": 0.8607405186628692,
            "4": 0.9411764705882353,
            "5": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 4.41177,
            "contradiction": 8.9348,
            "irrelevancy": 9.45408,
            "logical_agreement": 81.61112,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.64945,
            "nubia_score": 0.77141
        },
        "meteor": 0.3817573228664707,
        "bleurt": 0.18915,
        "bertscore": {
            "precision": 0.91854,
            "recall": 0.9185,
            "f1": 0.91717
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.48345,
        "msttr-100_nopunct": 0.48377,
        "total_length": 14578,
        "mean_pred_length": 31.899343544857768,
        "std_pred_length": 12.910343062582585,
        "median_pred_length": 30.0,
        "min_pred_length": 11,
        "max_pred_length": 78,
        "distinct-1": 0.0823158183564275,
        "vocab_size-1": 1200,
        "unique-1": 422,
        "entropy-1": 7.796313461059505,
        "distinct-2": 0.23482756178740882,
        "vocab_size-2": 3316,
        "unique-2": 1626,
        "entropy-2": 10.473379750314734,
        "cond_entropy-2": 2.5568476283642543,
        "distinct-3": 0.36255854800936765,
        "vocab_size-3": 4954,
        "unique-3": 2999,
        "entropy-3": 11.354518705454524,
        "cond_entropy-3": 0.9255067810819351,
        "total_length-nopunct": 13000,
        "mean_pred_length-nopunct": 28.446389496717725,
        "std_pred_length-nopunct": 11.455454258110887,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.0916923076923077,
        "vocab_size-1-nopunct": 1192,
        "unique-1-nopunct": 420,
        "entropy-1-nopunct": 8.024571937904257,
        "distinct-2-nopunct": 0.24603364426373275,
        "vocab_size-2-nopunct": 3086,
        "unique-2-nopunct": 1581,
        "entropy-2-nopunct": 10.380149321821385,
        "cond_entropy-2-nopunct": 2.4481848729982922,
        "distinct-3-nopunct": 0.3771305642892603,
        "vocab_size-3-nopunct": 4558,
        "unique-3-nopunct": 2825,
        "entropy-3-nopunct": 11.24283532552658,
        "cond_entropy-3-nopunct": 0.8914556513127904,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.72193,
            "recall": 0.72776,
            "fmeasure": 0.7173
        },
        "rouge2": {
            "precision": 0.45803,
            "recall": 0.46061,
            "fmeasure": 0.45408
        },
        "rougeL": {
            "precision": 0.53976,
            "recall": 0.5457,
            "fmeasure": 0.53639
        },
        "rougeLsum": {
            "precision": 0.53976,
            "recall": 0.5457,
            "fmeasure": 0.53639
        },
        "bleu": 48.19038,
        "nist": 8.495671112619883,
        "local_recall": {
            "1": 0.2410968660968661,
            "2": 0.6228786926461345,
            "3": 0.891523221825268,
            "4": 0.75,
            "5": 0.75
        },
        "nubia": {
            "semantic_relation": 4.39158,
            "contradiction": 9.97846,
            "irrelevancy": 7.62986,
            "logical_agreement": 82.39168,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.30494,
            "nubia_score": 0.77481
        },
        "meteor": 0.3849923779722726,
        "bleurt": 0.07585,
        "bertscore": {
            "precision": 0.91297,
            "recall": 0.91184,
            "f1": 0.9111
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.69955,
        "msttr-100_nopunct": 0.7195,
        "total_length": 2244,
        "mean_pred_length": 21.169811320754718,
        "std_pred_length": 4.198992911858045,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 32,
        "distinct-1": 0.39928698752228164,
        "vocab_size-1": 896,
        "unique-1": 650,
        "entropy-1": 8.176619612722547,
        "distinct-2": 0.8115060804490177,
        "vocab_size-2": 1735,
        "unique-2": 1550,
        "entropy-2": 10.510464689574183,
        "cond_entropy-2": 2.150617471389003,
        "distinct-3": 0.9429133858267716,
        "vocab_size-3": 1916,
        "unique-3": 1840,
        "entropy-3": 10.852008042812685,
        "cond_entropy-3": 0.3550021219509707,
        "total_length-nopunct": 2089,
        "mean_pred_length-nopunct": 19.70754716981132,
        "std_pred_length-nopunct": 4.097783526820404,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.42556247008137865,
        "vocab_size-1-nopunct": 889,
        "unique-1-nopunct": 648,
        "entropy-1-nopunct": 8.289312999302437,
        "distinct-2-nopunct": 0.815935451336359,
        "vocab_size-2-nopunct": 1618,
        "unique-2-nopunct": 1450,
        "entropy-2-nopunct": 10.411627743778936,
        "cond_entropy-2-nopunct": 2.2198015152595088,
        "distinct-3-nopunct": 0.9499200852424081,
        "vocab_size-3-nopunct": 1783,
        "unique-3-nopunct": 1718,
        "entropy-3-nopunct": 10.758236461464532,
        "cond_entropy-3-nopunct": 0.3619381748285626,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.38323,
            "recall": 0.35046,
            "fmeasure": 0.35774
        },
        "rouge2": {
            "precision": 0.11181,
            "recall": 0.10198,
            "fmeasure": 0.10353
        },
        "rougeL": {
            "precision": 0.29438,
            "recall": 0.26741,
            "fmeasure": 0.27344
        },
        "rougeLsum": {
            "precision": 0.29438,
            "recall": 0.26741,
            "fmeasure": 0.27344
        },
        "bleu": 5.51033,
        "nist": 2.9380112013177606,
        "local_recall": {
            "1": 0.31105990783410137
        },
        "nubia": {
            "semantic_relation": 2.73054,
            "contradiction": 28.53456,
            "irrelevancy": 64.63428,
            "logical_agreement": 6.83116,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.6111,
            "nubia_score": 0.37491
        },
        "meteor": 0.14862005063262584,
        "bleurt": -0.38886,
        "bertscore": {
            "precision": 0.82401,
            "recall": 0.81109,
            "f1": 0.81719
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.74267,
        "msttr-100_nopunct": 0.84042,
        "total_length": 3039,
        "mean_pred_length": 15.195,
        "std_pred_length": 5.647740698721924,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.34814083580125044,
        "vocab_size-1": 1058,
        "unique-1": 656,
        "entropy-1": 8.426420030571375,
        "distinct-2": 0.6713631560408595,
        "vocab_size-2": 1906,
        "unique-2": 1439,
        "entropy-2": 10.552725721640407,
        "cond_entropy-2": 1.8023531685291232,
        "distinct-3": 0.8219022356953392,
        "vocab_size-3": 2169,
        "unique-3": 1842,
        "entropy-3": 10.95321015623877,
        "cond_entropy-3": 0.40699276914735344,
        "total_length-nopunct": 2475,
        "mean_pred_length-nopunct": 12.375,
        "std_pred_length-nopunct": 4.726983710570622,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.42505050505050507,
        "vocab_size-1-nopunct": 1052,
        "unique-1-nopunct": 655,
        "entropy-1-nopunct": 9.053400586773375,
        "distinct-2-nopunct": 0.7094505494505494,
        "vocab_size-2-nopunct": 1614,
        "unique-2-nopunct": 1254,
        "entropy-2-nopunct": 10.375851158867809,
        "cond_entropy-2-nopunct": 1.3960381834357238,
        "distinct-3-nopunct": 0.8404819277108434,
        "vocab_size-3-nopunct": 1744,
        "unique-3-nopunct": 1505,
        "entropy-3-nopunct": 10.653800438993473,
        "cond_entropy-3-nopunct": 0.3139320386437716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.38655,
            "recall": 0.39048,
            "fmeasure": 0.38627
        },
        "rouge2": {
            "precision": 0.1941,
            "recall": 0.19657,
            "fmeasure": 0.19371
        },
        "rougeL": {
            "precision": 0.37063,
            "recall": 0.37375,
            "fmeasure": 0.36966
        },
        "rougeLsum": {
            "precision": 0.37063,
            "recall": 0.37375,
            "fmeasure": 0.36966
        },
        "bleu": 55.66348,
        "nist": 8.835117766970985,
        "local_recall": {
            "1": 0.272238514173998,
            "2": 0.6300403225806451,
            "3": 0.9011703511053316,
            "4": 0.95,
            "5": 0.8846153846153846,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.03731,
            "contradiction": 17.98107,
            "irrelevancy": 22.60224,
            "logical_agreement": 59.41669,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.71769,
            "nubia_score": 0.83115
        },
        "meteor": 0.7074574069236457,
        "bleurt": 0.2232,
        "bertscore": {
            "precision": 0.96279,
            "recall": 0.96051,
            "f1": 0.96071
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.63255,
        "msttr-100_nopunct": 0.66512,
        "total_length": 38479,
        "mean_pred_length": 29.713513513513515,
        "std_pred_length": 11.87342230164885,
        "median_pred_length": 28.0,
        "min_pred_length": 8,
        "max_pred_length": 80,
        "distinct-1": 0.04093141713661998,
        "vocab_size-1": 1575,
        "unique-1": 392,
        "entropy-1": 7.976584263119245,
        "distinct-2": 0.1421041308089501,
        "vocab_size-2": 5284,
        "unique-2": 2017,
        "entropy-2": 10.988007781413799,
        "cond_entropy-2": 2.87549983287652,
        "distinct-3": 0.2576834127448522,
        "vocab_size-3": 9248,
        "unique-3": 4632,
        "entropy-3": 12.13426103497397,
        "cond_entropy-3": 1.197801748418427,
        "total_length-nopunct": 34435,
        "mean_pred_length-nopunct": 26.590733590733592,
        "std_pred_length-nopunct": 10.719847316490643,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.04550602584579643,
        "vocab_size-1-nopunct": 1567,
        "unique-1-nopunct": 392,
        "entropy-1-nopunct": 8.210141264106229,
        "distinct-2-nopunct": 0.1524441762220881,
        "vocab_size-2-nopunct": 5052,
        "unique-2-nopunct": 2075,
        "entropy-2-nopunct": 10.91053388919968,
        "cond_entropy-2-nopunct": 2.810854925155081,
        "distinct-3-nopunct": 0.2738263463652065,
        "vocab_size-3-nopunct": 8720,
        "unique-3-nopunct": 4592,
        "entropy-3-nopunct": 12.037604637947997,
        "cond_entropy-3-nopunct": 1.162718952095395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.7215,
            "recall": 0.73663,
            "fmeasure": 0.72117
        },
        "rouge2": {
            "precision": 0.46043,
            "recall": 0.46978,
            "fmeasure": 0.45944
        },
        "rougeL": {
            "precision": 0.55213,
            "recall": 0.56484,
            "fmeasure": 0.55183
        },
        "rougeLsum": {
            "precision": 0.55213,
            "recall": 0.56484,
            "fmeasure": 0.55183
        },
        "bleu": 45.65477,
        "nist": 8.676716807235104,
        "local_recall": {
            "1": 0.2272696361781707,
            "2": 0.5871752866838287,
            "3": 0.8719017972512628,
            "4": 0.8235294117647058,
            "5": 0.7931034482758621
        },
        "nubia": {
            "semantic_relation": 4.35749,
            "contradiction": 9.73288,
            "irrelevancy": 9.4533,
            "logical_agreement": 80.81382,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.32208,
            "nubia_score": 0.76297
        },
        "meteor": 0.3756370403055402,
        "bleurt": 0.11755,
        "bertscore": {
            "precision": 0.91121,
            "recall": 0.91022,
            "f1": 0.90931
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.644,
        "msttr-100_nopunct": 0.68889,
        "total_length": 2095,
        "mean_pred_length": 18.217391304347824,
        "std_pred_length": 6.635586024637099,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 52,
        "distinct-1": 0.2515513126491647,
        "vocab_size-1": 527,
        "unique-1": 241,
        "entropy-1": 7.42454755206842,
        "distinct-2": 0.5328282828282829,
        "vocab_size-2": 1055,
        "unique-2": 671,
        "entropy-2": 9.578650215473438,
        "cond_entropy-2": 1.959090698538319,
        "distinct-3": 0.67828418230563,
        "vocab_size-3": 1265,
        "unique-3": 931,
        "entropy-3": 10.054454976153858,
        "cond_entropy-3": 0.5198701402933825,
        "total_length-nopunct": 1855,
        "mean_pred_length-nopunct": 16.130434782608695,
        "std_pred_length-nopunct": 5.904341422805006,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.2803234501347709,
        "vocab_size-1-nopunct": 520,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.62656740412995,
        "distinct-2-nopunct": 0.5229885057471264,
        "vocab_size-2-nopunct": 910,
        "unique-2-nopunct": 575,
        "entropy-2-nopunct": 9.343273667126205,
        "cond_entropy-2-nopunct": 1.8430550219569068,
        "distinct-3-nopunct": 0.6676923076923077,
        "vocab_size-3-nopunct": 1085,
        "unique-3-nopunct": 790,
        "entropy-3-nopunct": 9.821649728514918,
        "cond_entropy-3-nopunct": 0.5246302431063334,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.75204,
            "recall": 0.76747,
            "fmeasure": 0.75133
        },
        "rouge2": {
            "precision": 0.50748,
            "recall": 0.52066,
            "fmeasure": 0.50786
        },
        "rougeL": {
            "precision": 0.63427,
            "recall": 0.64916,
            "fmeasure": 0.6344
        },
        "rougeLsum": {
            "precision": 0.63427,
            "recall": 0.64916,
            "fmeasure": 0.6344
        },
        "bleu": 51.90683,
        "nist": 8.047064188735886,
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.6304761904761905,
            "3": 0.878099173553719
        },
        "nubia": {
            "semantic_relation": 4.60187,
            "contradiction": 5.74452,
            "irrelevancy": 5.10139,
            "logical_agreement": 89.15409,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.65099,
            "nubia_score": 0.82632
        },
        "meteor": 0.4273675773190928,
        "bleurt": 0.21708,
        "bertscore": {
            "precision": 0.92525,
            "recall": 0.93028,
            "f1": 0.92633
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.64417,
        "msttr-100_nopunct": 0.68072,
        "total_length": 15616,
        "mean_pred_length": 30.146718146718147,
        "std_pred_length": 14.265061769895604,
        "median_pred_length": 28.0,
        "min_pred_length": 5,
        "max_pred_length": 78,
        "distinct-1": 0.052894467213114756,
        "vocab_size-1": 826,
        "unique-1": 221,
        "entropy-1": 7.635818160417761,
        "distinct-2": 0.14770168234203207,
        "vocab_size-2": 2230,
        "unique-2": 832,
        "entropy-2": 9.932636389176043,
        "cond_entropy-2": 2.1721778227051156,
        "distinct-3": 0.2308641975308642,
        "vocab_size-3": 3366,
        "unique-3": 1606,
        "entropy-3": 10.648890377828444,
        "cond_entropy-3": 0.7584537041983694,
        "total_length-nopunct": 13956,
        "mean_pred_length-nopunct": 26.942084942084943,
        "std_pred_length-nopunct": 12.75354917277686,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.05868443680137575,
        "vocab_size-1-nopunct": 819,
        "unique-1-nopunct": 221,
        "entropy-1-nopunct": 7.849646283535298,
        "distinct-2-nopunct": 0.15582675993451406,
        "vocab_size-2-nopunct": 2094,
        "unique-2-nopunct": 836,
        "entropy-2-nopunct": 9.827061846817589,
        "cond_entropy-2-nopunct": 2.0585399271967644,
        "distinct-3-nopunct": 0.24164086687306502,
        "vocab_size-3-nopunct": 3122,
        "unique-3-nopunct": 1548,
        "entropy-3-nopunct": 10.52404589940438,
        "cond_entropy-3-nopunct": 0.721358027373274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.80782,
            "recall": 0.80237,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.58481,
            "recall": 0.58169,
            "fmeasure": 0.57868
        },
        "rougeL": {
            "precision": 0.64776,
            "recall": 0.64633,
            "fmeasure": 0.64217
        },
        "rougeLsum": {
            "precision": 0.64776,
            "recall": 0.64633,
            "fmeasure": 0.64217
        },
        "bleu": 60.04886,
        "nist": 9.234194777944689,
        "local_recall": {
            "1": 0.2622089970243305,
            "2": 0.6790872328134027,
            "3": 0.9434124035438697,
            "4": 0.9736842105263158
        },
        "nubia": {
            "semantic_relation": 4.6994,
            "contradiction": 3.45079,
            "irrelevancy": 4.87949,
            "logical_agreement": 91.66972,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.14619,
            "nubia_score": 0.88677
        },
        "meteor": 0.4305221869168416,
        "bleurt": 0.33358,
        "bertscore": {
            "precision": 0.94519,
            "recall": 0.94054,
            "f1": 0.9418
        }
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "mT5_large/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.72373,
        "msttr-100_nopunct": 0.7658,
        "total_length": 150686,
        "mean_pred_length": 29.791617240015817,
        "std_pred_length": 9.333358377476321,
        "median_pred_length": 30.0,
        "min_pred_length": 6,
        "max_pred_length": 87,
        "distinct-1": 0.1043627145189334,
        "vocab_size-1": 15726,
        "unique-1": 9710,
        "entropy-1": 9.372002027767165,
        "distinct-2": 0.42415606888785123,
        "vocab_size-2": 61769,
        "unique-2": 50833,
        "entropy-2": 13.30220137335334,
        "cond_entropy-2": 3.8423970680941952,
        "distinct-3": 0.6374333072490574,
        "vocab_size-3": 89604,
        "unique-3": 83902,
        "entropy-3": 14.303454871009757,
        "cond_entropy-3": 0.9969087538352611,
        "total_length-nopunct": 132412,
        "mean_pred_length-nopunct": 26.1787267694741,
        "std_pred_length-nopunct": 8.08938829855261,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.118644835815485,
        "vocab_size-1-nopunct": 15710,
        "unique-1-nopunct": 9705,
        "entropy-1-nopunct": 9.837072208638832,
        "distinct-2-nopunct": 0.4774565384675786,
        "vocab_size-2-nopunct": 60806,
        "unique-2-nopunct": 51333,
        "entropy-2-nopunct": 13.493983069389834,
        "cond_entropy-2-nopunct": 3.7399204655584843,
        "distinct-3-nopunct": 0.670864132923399,
        "vocab_size-3-nopunct": 82044,
        "unique-3-nopunct": 78229,
        "entropy-3-nopunct": 14.256609627876129,
        "cond_entropy-3-nopunct": 0.774920829704648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.27591,
            "recall": 0.37728,
            "fmeasure": 0.30938
        },
        "rouge2": {
            "precision": 0.18604,
            "recall": 0.25612,
            "fmeasure": 0.20978
        },
        "rougeL": {
            "precision": 0.25051,
            "recall": 0.3429,
            "fmeasure": 0.28128
        },
        "rougeLsum": {
            "precision": 0.25051,
            "recall": 0.3429,
            "fmeasure": 0.28128
        },
        "bleu": 19.6508,
        "nist": 3.8917053977157594,
        "local_recall": {
            "1": 0.3845891691035817
        },
        "nubia": {
            "semantic_relation": 1.92689,
            "contradiction": 23.72101,
            "irrelevancy": 60.15165,
            "logical_agreement": 16.12734,
            "grammar_ref": 5.17449,
            "grammar_hyp": 4.96996,
            "nubia_score": 0.22809
        },
        "meteor": 0.32778404291826896,
        "bleurt": -0.54146,
        "bertscore": {
            "precision": 0.85824,
            "recall": 0.87632,
            "f1": 0.86693
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.61206,
        "msttr-100_nopunct": 0.6398,
        "total_length": 27759,
        "mean_pred_length": 23.584536958368734,
        "std_pred_length": 11.884456430550522,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 80,
        "distinct-1": 0.04150005403652869,
        "vocab_size-1": 1152,
        "unique-1": 260,
        "entropy-1": 7.5917817882186975,
        "distinct-2": 0.15435256940786998,
        "vocab_size-2": 4103,
        "unique-2": 1638,
        "entropy-2": 10.627964694890348,
        "cond_entropy-2": 2.878432429256419,
        "distinct-3": 0.28651840188939187,
        "vocab_size-3": 7279,
        "unique-3": 3794,
        "entropy-3": 11.836719849593653,
        "cond_entropy-3": 1.2758417339127954,
        "total_length-nopunct": 24780,
        "mean_pred_length-nopunct": 21.053525913338998,
        "std_pred_length-nopunct": 10.81887757749962,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.04612590799031477,
        "vocab_size-1-nopunct": 1143,
        "unique-1-nopunct": 260,
        "entropy-1-nopunct": 7.78252879097481,
        "distinct-2-nopunct": 0.16222514087192305,
        "vocab_size-2-nopunct": 3829,
        "unique-2-nopunct": 1616,
        "entropy-2-nopunct": 10.496029448162282,
        "cond_entropy-2-nopunct": 2.8582084152855765,
        "distinct-3-nopunct": 0.30098992241148664,
        "vocab_size-3-nopunct": 6750,
        "unique-3-nopunct": 3676,
        "entropy-3-nopunct": 11.706234071111538,
        "cond_entropy-3-nopunct": 1.2625917191854412,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.69857,
            "recall": 0.71611,
            "fmeasure": 0.69861
        },
        "rouge2": {
            "precision": 0.43001,
            "recall": 0.44082,
            "fmeasure": 0.42911
        },
        "rougeL": {
            "precision": 0.55177,
            "recall": 0.565,
            "fmeasure": 0.55084
        },
        "rougeLsum": {
            "precision": 0.55177,
            "recall": 0.565,
            "fmeasure": 0.55084
        },
        "bleu": 37.66684,
        "nist": 7.631673165620316,
        "local_recall": {
            "1": 0.21357925688318632,
            "2": 0.5510765002290426,
            "3": 0.8284674551319163,
            "4": 0.7,
            "5": 0.7931034482758621
        },
        "nubia": {
            "semantic_relation": 4.27426,
            "contradiction": 11.74877,
            "irrelevancy": 11.00044,
            "logical_agreement": 77.25079,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.69235,
            "nubia_score": 0.72241
        },
        "meteor": 0.35414549702576514,
        "bleurt": 0.07811,
        "bertscore": {
            "precision": 0.90379,
            "recall": 0.90533,
            "f1": 0.90312
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.69632,
        "total_length": 2133,
        "mean_pred_length": 20.12264150943396,
        "std_pred_length": 5.9616744991444035,
        "median_pred_length": 18.5,
        "min_pred_length": 11,
        "max_pred_length": 62,
        "distinct-1": 0.3863103609939053,
        "vocab_size-1": 824,
        "unique-1": 617,
        "entropy-1": 8.002948253459152,
        "distinct-2": 0.7829304390725209,
        "vocab_size-2": 1587,
        "unique-2": 1426,
        "entropy-2": 10.269416436282405,
        "cond_entropy-2": 2.074434019767499,
        "distinct-3": 0.9125455491931286,
        "vocab_size-3": 1753,
        "unique-3": 1681,
        "entropy-3": 10.614716887727475,
        "cond_entropy-3": 0.36903861637784513,
        "total_length-nopunct": 1995,
        "mean_pred_length-nopunct": 18.82075471698113,
        "std_pred_length-nopunct": 5.830623724380431,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.4100250626566416,
        "vocab_size-1-nopunct": 818,
        "unique-1-nopunct": 617,
        "entropy-1-nopunct": 8.103820522743844,
        "distinct-2-nopunct": 0.7792482795129698,
        "vocab_size-2-nopunct": 1472,
        "unique-2-nopunct": 1322,
        "entropy-2-nopunct": 10.147924599565794,
        "cond_entropy-2-nopunct": 2.163318763982167,
        "distinct-3-nopunct": 0.9147504206393718,
        "vocab_size-3-nopunct": 1631,
        "unique-3-nopunct": 1565,
        "entropy-3-nopunct": 10.510246558822097,
        "cond_entropy-3-nopunct": 0.3867339309306729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.37217,
            "recall": 0.31913,
            "fmeasure": 0.33637
        },
        "rouge2": {
            "precision": 0.12624,
            "recall": 0.10526,
            "fmeasure": 0.11239
        },
        "rougeL": {
            "precision": 0.28063,
            "recall": 0.24231,
            "fmeasure": 0.2544
        },
        "rougeLsum": {
            "precision": 0.28063,
            "recall": 0.24231,
            "fmeasure": 0.2544
        },
        "bleu": 6.27669,
        "nist": 2.6881665560962573,
        "local_recall": {
            "1": 0.2915492957746479
        },
        "nubia": {
            "semantic_relation": 2.61746,
            "contradiction": 24.50416,
            "irrelevancy": 64.01333,
            "logical_agreement": 11.48251,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.58804,
            "nubia_score": 0.34875
        },
        "meteor": 0.14017986082997438,
        "bleurt": -0.40379,
        "bertscore": {
            "precision": 0.82098,
            "recall": 0.80132,
            "f1": 0.81056
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.753,
        "total_length": 1245,
        "mean_pred_length": 38.90625,
        "std_pred_length": 7.493160944321161,
        "median_pred_length": 39.0,
        "min_pred_length": 25,
        "max_pred_length": 57,
        "distinct-1": 0.30522088353413657,
        "vocab_size-1": 380,
        "unique-1": 196,
        "entropy-1": 7.336453044728759,
        "distinct-2": 0.5490519373454246,
        "vocab_size-2": 666,
        "unique-2": 415,
        "entropy-2": 8.985724627892345,
        "cond_entropy-2": 1.5548785747855935,
        "distinct-3": 0.6562235393734124,
        "vocab_size-3": 775,
        "unique-3": 542,
        "entropy-3": 9.347951674829245,
        "cond_entropy-3": 0.36788705105522596,
        "total_length-nopunct": 1060,
        "mean_pred_length-nopunct": 33.125,
        "std_pred_length-nopunct": 7.0522602759682655,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 47,
        "distinct-1-nopunct": 0.35283018867924526,
        "vocab_size-1-nopunct": 374,
        "unique-1-nopunct": 193,
        "entropy-1-nopunct": 7.659593625077834,
        "distinct-2-nopunct": 0.5778210116731517,
        "vocab_size-2-nopunct": 594,
        "unique-2-nopunct": 379,
        "entropy-2-nopunct": 8.896295637100977,
        "cond_entropy-2-nopunct": 1.2540633655814928,
        "distinct-3-nopunct": 0.6767068273092369,
        "vocab_size-3-nopunct": 674,
        "unique-3-nopunct": 485,
        "entropy-3-nopunct": 9.161188717885368,
        "cond_entropy-3-nopunct": 0.27175022920034636,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.85089,
            "recall": 0.84773,
            "fmeasure": 0.84126
        },
        "rouge2": {
            "precision": 0.58767,
            "recall": 0.60347,
            "fmeasure": 0.58889
        },
        "rougeL": {
            "precision": 0.80491,
            "recall": 0.79999,
            "fmeasure": 0.7946
        },
        "rougeLsum": {
            "precision": 0.80491,
            "recall": 0.79999,
            "fmeasure": 0.7946
        },
        "bleu": 57.16218,
        "nist": 7.932736900099666,
        "local_recall": {
            "1": 0.33793103448275863,
            "2": 0.7136465324384788,
            "3": 0.9009584664536742
        },
        "nubia": {
            "semantic_relation": 3.7859,
            "contradiction": 19.19253,
            "irrelevancy": 25.82523,
            "logical_agreement": 54.98224,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.45155,
            "nubia_score": 0.86177
        },
        "meteor": 0.6918387511285242,
        "bleurt": 0.26679,
        "bertscore": {
            "precision": 0.95864,
            "recall": 0.95548,
            "f1": 0.95698
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.691,
        "msttr-100_nopunct": 0.70579,
        "total_length": 2066,
        "mean_pred_length": 19.49056603773585,
        "std_pred_length": 4.404640098416943,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 34,
        "distinct-1": 0.3910939012584705,
        "vocab_size-1": 808,
        "unique-1": 590,
        "entropy-1": 8.039885516047526,
        "distinct-2": 0.7948979591836735,
        "vocab_size-2": 1558,
        "unique-2": 1370,
        "entropy-2": 10.336483187258402,
        "cond_entropy-2": 2.093511328473697,
        "distinct-3": 0.9320388349514563,
        "vocab_size-3": 1728,
        "unique-3": 1643,
        "entropy-3": 10.693967267830857,
        "cond_entropy-3": 0.37331565618096757,
        "total_length-nopunct": 1926,
        "mean_pred_length-nopunct": 18.169811320754718,
        "std_pred_length-nopunct": 4.2236345300754214,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4174454828660436,
        "vocab_size-1-nopunct": 804,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 8.164796301286238,
        "distinct-2-nopunct": 0.7945054945054945,
        "vocab_size-2-nopunct": 1446,
        "unique-2-nopunct": 1272,
        "entropy-2-nopunct": 10.224083057393136,
        "cond_entropy-2-nopunct": 2.1690906598565345,
        "distinct-3-nopunct": 0.9364060676779463,
        "vocab_size-3-nopunct": 1605,
        "unique-3-nopunct": 1528,
        "entropy-3-nopunct": 10.594129703328962,
        "cond_entropy-3-nopunct": 0.38116640466023344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.33394,
            "recall": 0.29311,
            "fmeasure": 0.30399
        },
        "rouge2": {
            "precision": 0.09294,
            "recall": 0.08063,
            "fmeasure": 0.08427
        },
        "rougeL": {
            "precision": 0.26206,
            "recall": 0.23016,
            "fmeasure": 0.2385
        },
        "rougeLsum": {
            "precision": 0.26206,
            "recall": 0.23016,
            "fmeasure": 0.2385
        },
        "bleu": 5.29793,
        "nist": 2.3994291445889666,
        "local_recall": {
            "1": 0.26410505836575876
        },
        "nubia": {
            "semantic_relation": 2.45897,
            "contradiction": 28.96992,
            "irrelevancy": 62.71991,
            "logical_agreement": 8.31017,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.62865,
            "nubia_score": 0.3298
        },
        "meteor": 0.12296998225606365,
        "bleurt": -0.46481,
        "bertscore": {
            "precision": 0.814,
            "recall": 0.79189,
            "f1": 0.80242
        }
    },
    "mlsum_es_val": {
        "predictions_file": "mT5_large/mlsum_es_val",
        "N": 9977,
        "msttr-100": 0.71248,
        "msttr-100_nopunct": 0.72293,
        "total_length": 212485,
        "mean_pred_length": 21.29748421369149,
        "std_pred_length": 6.656652464719733,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 90,
        "distinct-1": 0.11492575946537403,
        "vocab_size-1": 24420,
        "unique-1": 13504,
        "entropy-1": 9.968602677962965,
        "distinct-2": 0.49080530151895235,
        "vocab_size-2": 99392,
        "unique-2": 77414,
        "entropy-2": 15.200002059949094,
        "cond_entropy-2": 5.414795664997542,
        "distinct-3": 0.8218936171317865,
        "vocab_size-3": 158240,
        "unique-3": 143685,
        "entropy-3": 17.002244301044342,
        "cond_entropy-3": 1.8490573890987732,
        "total_length-nopunct": 201462,
        "mean_pred_length-nopunct": 20.19264307908189,
        "std_pred_length-nopunct": 6.00140089223674,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 85,
        "distinct-1-nopunct": 0.12111961560989169,
        "vocab_size-1-nopunct": 24401,
        "unique-1-nopunct": 13502,
        "entropy-1-nopunct": 10.115227541451414,
        "distinct-2-nopunct": 0.5131994673212001,
        "vocab_size-2-nopunct": 98270,
        "unique-2-nopunct": 77707,
        "entropy-2-nopunct": 15.275385592664495,
        "cond_entropy-2-nopunct": 5.356064116166366,
        "distinct-3-nopunct": 0.8383046477290257,
        "vocab_size-3-nopunct": 152159,
        "unique-3-nopunct": 139431,
        "entropy-3-nopunct": 16.974847160954205,
        "cond_entropy-3-nopunct": 1.7408397763358656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_val.json",
        "rouge1": {
            "precision": 0.32676,
            "recall": 0.30329,
            "fmeasure": 0.30437
        },
        "rouge2": {
            "precision": 0.13056,
            "recall": 0.12203,
            "fmeasure": 0.12199
        },
        "rougeL": {
            "precision": 0.26208,
            "recall": 0.24417,
            "fmeasure": 0.24461
        },
        "rougeLsum": {
            "precision": 0.26208,
            "recall": 0.24417,
            "fmeasure": 0.24461
        },
        "bleu": 9.29728,
        "nist": 3.2043945943044263,
        "local_recall": {
            "1": 0.28296100949080816
        },
        "nubia": {
            "semantic_relation": 1.76289,
            "contradiction": 26.64609,
            "irrelevancy": 61.02023,
            "logical_agreement": 12.33368,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.2379,
            "nubia_score": 0.19858
        },
        "meteor": 0.22146683489665814,
        "bleurt": -0.40693,
        "bertscore": {
            "precision": 0.84549,
            "recall": 0.84206,
            "f1": 0.84358
        }
    },
    "mlsum_es_test": {
        "predictions_file": "mT5_large/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.71232,
        "msttr-100_nopunct": 0.72316,
        "total_length": 285186,
        "mean_pred_length": 21.336675145892563,
        "std_pred_length": 6.345040289422046,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 106,
        "distinct-1": 0.10157932016298135,
        "vocab_size-1": 28969,
        "unique-1": 15719,
        "entropy-1": 10.001038861643098,
        "distinct-2": 0.45716282834228533,
        "vocab_size-2": 124266,
        "unique-2": 95334,
        "entropy-2": 15.36007545698203,
        "cond_entropy-2": 5.547295550038519,
        "distinct-3": 0.7940871489704164,
        "vocab_size-3": 205235,
        "unique-3": 184294,
        "entropy-3": 17.30716185030687,
        "cond_entropy-3": 1.9967001014200019,
        "total_length-nopunct": 270151,
        "mean_pred_length-nopunct": 20.211806075115966,
        "std_pred_length-nopunct": 5.724335911014202,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 84,
        "distinct-1-nopunct": 0.10717339561948688,
        "vocab_size-1-nopunct": 28953,
        "unique-1-nopunct": 15716,
        "entropy-1-nopunct": 10.154217058533815,
        "distinct-2-nopunct": 0.48083026656541467,
        "vocab_size-2-nopunct": 123470,
        "unique-2-nopunct": 96494,
        "entropy-2-nopunct": 15.448733835988728,
        "cond_entropy-2-nopunct": 5.494801858816022,
        "distinct-3-nopunct": 0.8128330163216512,
        "vocab_size-3-nopunct": 197859,
        "unique-3-nopunct": 179526,
        "entropy-3-nopunct": 17.289246367790923,
        "cond_entropy-3-nopunct": 1.8841766783952834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "rouge1": {
            "precision": 0.32938,
            "recall": 0.30481,
            "fmeasure": 0.30659
        },
        "rouge2": {
            "precision": 0.13155,
            "recall": 0.12248,
            "fmeasure": 0.12293
        },
        "rougeL": {
            "precision": 0.26359,
            "recall": 0.2448,
            "fmeasure": 0.24586
        },
        "rougeLsum": {
            "precision": 0.26359,
            "recall": 0.2448,
            "fmeasure": 0.24586
        },
        "bleu": 9.22307,
        "nist": 3.2383986697347176,
        "local_recall": {
            "1": 0.282022989895631
        },
        "nubia": {
            "semantic_relation": 1.75158,
            "contradiction": 27.46306,
            "irrelevancy": 60.67155,
            "logical_agreement": 11.86539,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.23111,
            "nubia_score": 0.19657
        },
        "meteor": 0.22211401266394218,
        "bleurt": -0.41329,
        "bertscore": {
            "precision": 0.84579,
            "recall": 0.84186,
            "f1": 0.84364
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 8.8,
        "std_pred_length": 0.7483314773547883,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.4318181818181818,
        "vocab_size-1": 19,
        "unique-1": 5,
        "entropy-1": 4.073210744553411,
        "distinct-2": 0.5641025641025641,
        "vocab_size-2": 22,
        "unique-2": 9,
        "entropy-2": 4.3361829878711236,
        "cond_entropy-2": 0.14300977911213772,
        "distinct-3": 0.6470588235294118,
        "vocab_size-3": 22,
        "unique-3": 12,
        "entropy-3": 4.337175341123076,
        "cond_entropy-3": -0.05808974519533622,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 7.8,
        "std_pred_length-nopunct": 0.7483314773547882,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.46153846153846156,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 4.019143808983936,
        "distinct-2-nopunct": 0.5882352941176471,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 4.1973257087065035,
        "cond_entropy-2-nopunct": 0.16572320993515824,
        "distinct-3-nopunct": 0.6896551724137931,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 4.211260736432281,
        "cond_entropy-3-nopunct": -0.0655202081171303,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.65397,
            "recall": 0.48477,
            "fmeasure": 0.50424
        },
        "rouge2": {
            "precision": 0.37381,
            "recall": 0.21818,
            "fmeasure": 0.24768
        },
        "rougeL": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "rougeLsum": {
            "precision": 0.60675,
            "recall": 0.45271,
            "fmeasure": 0.46606
        },
        "bleu": 12.15204,
        "nist": 1.1584778190719272,
        "local_recall": {
            "1": 0.42857142857142855
        },
        "nubia": {
            "semantic_relation": 2.89259,
            "contradiction": 18.10595,
            "irrelevancy": 42.12701,
            "logical_agreement": 39.76705,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.71656,
            "nubia_score": 0.31537
        },
        "meteor": 0.22250577795179702,
        "bleurt": -0.39693,
        "bertscore": {
            "precision": 0.89285,
            "recall": 0.82928,
            "f1": 0.85844
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.275,
        "msttr-100_nopunct": 0.275,
        "total_length": 1438,
        "mean_pred_length": 11.983333333333333,
        "std_pred_length": 4.26220469814495,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.0584144645340751,
        "vocab_size-1": 84,
        "unique-1": 2,
        "entropy-1": 5.357569285976599,
        "distinct-2": 0.09484066767830046,
        "vocab_size-2": 125,
        "unique-2": 6,
        "entropy-2": 6.345965530847316,
        "cond_entropy-2": 0.7949113433626764,
        "distinct-3": 0.1310517529215359,
        "vocab_size-3": 157,
        "unique-3": 23,
        "entropy-3": 6.7259287945007955,
        "cond_entropy-3": 0.4489824093355615,
        "total_length-nopunct": 1285,
        "mean_pred_length-nopunct": 10.708333333333334,
        "std_pred_length-nopunct": 3.837090549998643,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.06459143968871596,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 5.448302532061487,
        "distinct-2-nopunct": 0.09957081545064378,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 6.16458434766767,
        "cond_entropy-2-nopunct": 0.869319651192703,
        "distinct-3-nopunct": 0.1416267942583732,
        "vocab_size-3-nopunct": 148,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 6.57120811962286,
        "cond_entropy-3-nopunct": 0.48480798443719664,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.75694,
            "recall": 0.61925,
            "fmeasure": 0.65532
        },
        "rouge2": {
            "precision": 0.49303,
            "recall": 0.39679,
            "fmeasure": 0.42027
        },
        "rougeL": {
            "precision": 0.62039,
            "recall": 0.50139,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.62039,
            "recall": 0.50139,
            "fmeasure": 0.53333
        },
        "bleu": 26.87352,
        "nist": 4.230905465962132,
        "local_recall": {
            "1": 0.5942704863424384
        },
        "nubia": {
            "semantic_relation": 4.06242,
            "contradiction": 2.36387,
            "irrelevancy": 25.62963,
            "logical_agreement": 72.0065,
            "grammar_ref": 5.42765,
            "grammar_hyp": 5.20346,
            "nubia_score": 0.70113
        },
        "meteor": 0.30940985545013927,
        "bleurt": 0.00324,
        "bertscore": {
            "precision": 0.91464,
            "recall": 0.88145,
            "f1": 0.89684
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.76381,
        "msttr-100_nopunct": 0.88353,
        "total_length": 2182,
        "mean_pred_length": 8.590551181102363,
        "std_pred_length": 2.7129155386449906,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.425756186984418,
        "vocab_size-1": 929,
        "unique-1": 634,
        "entropy-1": 8.397422643123834,
        "distinct-2": 0.7614107883817427,
        "vocab_size-2": 1468,
        "unique-2": 1200,
        "entropy-2": 10.285853759403212,
        "cond_entropy-2": 1.1908965345016638,
        "distinct-3": 0.8727598566308243,
        "vocab_size-3": 1461,
        "unique-3": 1298,
        "entropy-3": 10.421695562296613,
        "cond_entropy-3": 0.13971284479888654,
        "total_length-nopunct": 1748,
        "mean_pred_length-nopunct": 6.881889763779528,
        "std_pred_length-nopunct": 2.3614828293261647,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.528604118993135,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 634,
        "entropy-1-nopunct": 9.145034302658944,
        "distinct-2-nopunct": 0.7797858099062919,
        "vocab_size-2-nopunct": 1165,
        "unique-2-nopunct": 974,
        "entropy-2-nopunct": 9.962548980998585,
        "cond_entropy-2-nopunct": 0.9468402244663688,
        "distinct-3-nopunct": 0.8798387096774194,
        "vocab_size-3-nopunct": 1091,
        "unique-3-nopunct": 981,
        "entropy-3-nopunct": 9.99994800169176,
        "cond_entropy-3-nopunct": 0.10864654823622787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.34657,
            "recall": 0.34389,
            "fmeasure": 0.34357
        },
        "rouge2": {
            "precision": 0.18914,
            "recall": 0.18657,
            "fmeasure": 0.18699
        },
        "rougeL": {
            "precision": 0.34394,
            "recall": 0.34143,
            "fmeasure": 0.34104
        },
        "rougeLsum": {
            "precision": 0.34394,
            "recall": 0.34143,
            "fmeasure": 0.34104
        },
        "bleu": 63.08982,
        "nist": 8.801555250611552,
        "local_recall": {
            "1": 0.39945652173913043,
            "2": 0.739251040221914,
            "3": 0.8156996587030717,
            "4": 0.9142857142857143,
            "5": 0.9090909090909091,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.25638,
            "contradiction": 20.53506,
            "irrelevancy": 19.33756,
            "logical_agreement": 60.12738,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.90617,
            "nubia_score": 0.85962
        },
        "meteor": 0.7741277490333419,
        "bleurt": 0.42166,
        "bertscore": {
            "precision": 0.97167,
            "recall": 0.96979,
            "f1": 0.97024
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.62481,
        "msttr-100_nopunct": 0.66207,
        "total_length": 10690,
        "mean_pred_length": 10.408958130477117,
        "std_pred_length": 4.520238766431456,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.11000935453695042,
        "vocab_size-1": 1176,
        "unique-1": 632,
        "entropy-1": 7.374065025132185,
        "distinct-2": 0.3123253647935424,
        "vocab_size-2": 3018,
        "unique-2": 1870,
        "entropy-2": 10.223871761285563,
        "cond_entropy-2": 2.494185831982899,
        "distinct-3": 0.5054423344140806,
        "vocab_size-3": 4365,
        "unique-3": 3153,
        "entropy-3": 11.326396124156824,
        "cond_entropy-3": 1.1599421255036606,
        "total_length-nopunct": 9226,
        "mean_pred_length-nopunct": 8.983446932814022,
        "std_pred_length-nopunct": 4.202136818818255,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.12649035334923042,
        "vocab_size-1-nopunct": 1167,
        "unique-1-nopunct": 632,
        "entropy-1-nopunct": 7.658648769681338,
        "distinct-2-nopunct": 0.3252835711672155,
        "vocab_size-2-nopunct": 2667,
        "unique-2-nopunct": 1669,
        "entropy-2-nopunct": 10.070393624134143,
        "cond_entropy-2-nopunct": 2.666038381759124,
        "distinct-3-nopunct": 0.5229268292682927,
        "vocab_size-3-nopunct": 3752,
        "unique-3-nopunct": 2761,
        "entropy-3-nopunct": 11.122615675625086,
        "cond_entropy-3-nopunct": 1.20271524883788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.66534,
            "recall": 0.64839,
            "fmeasure": 0.64459
        },
        "rouge2": {
            "precision": 0.45954,
            "recall": 0.44739,
            "fmeasure": 0.44244
        },
        "rougeL": {
            "precision": 0.6061,
            "recall": 0.59031,
            "fmeasure": 0.58666
        },
        "rougeLsum": {
            "precision": 0.6061,
            "recall": 0.59031,
            "fmeasure": 0.58666
        },
        "bleu": 43.28,
        "nist": 7.137310597086053,
        "local_recall": {
            "1": 0.6175237254469212
        },
        "nubia": {
            "semantic_relation": 4.04054,
            "contradiction": 7.26819,
            "irrelevancy": 16.44104,
            "logical_agreement": 76.29077,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.76214,
            "nubia_score": 0.74033
        },
        "meteor": 0.3676514617442622,
        "bleurt": 0.2071,
        "bertscore": {
            "precision": 0.90331,
            "recall": 0.89797,
            "f1": 0.90021
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.56,
        "msttr-100_nopunct": 0.61,
        "total_length": 702,
        "mean_pred_length": 12.535714285714286,
        "std_pred_length": 7.048212249809688,
        "median_pred_length": 9.5,
        "min_pred_length": 6,
        "max_pred_length": 40,
        "distinct-1": 0.29914529914529914,
        "vocab_size-1": 210,
        "unique-1": 126,
        "entropy-1": 6.280436384402566,
        "distinct-2": 0.5959752321981424,
        "vocab_size-2": 385,
        "unique-2": 287,
        "entropy-2": 8.127615060679583,
        "cond_entropy-2": 1.612450930218671,
        "distinct-3": 0.7389830508474576,
        "vocab_size-3": 436,
        "unique-3": 356,
        "entropy-3": 8.529462462977571,
        "cond_entropy-3": 0.456585650538381,
        "total_length-nopunct": 630,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 6.52809860744853,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.3253968253968254,
        "vocab_size-1-nopunct": 205,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.365115723241225,
        "distinct-2-nopunct": 0.578397212543554,
        "vocab_size-2-nopunct": 332,
        "unique-2-nopunct": 248,
        "entropy-2-nopunct": 7.877776385910805,
        "cond_entropy-2-nopunct": 1.6688857880692118,
        "distinct-3-nopunct": 0.7258687258687259,
        "vocab_size-3-nopunct": 376,
        "unique-3-nopunct": 306,
        "entropy-3-nopunct": 8.293808571681609,
        "cond_entropy-3-nopunct": 0.4537159296531865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73636,
            "recall": 0.74407,
            "fmeasure": 0.72959
        },
        "rouge2": {
            "precision": 0.50914,
            "recall": 0.51782,
            "fmeasure": 0.50559
        },
        "rougeL": {
            "precision": 0.61562,
            "recall": 0.62508,
            "fmeasure": 0.6105
        },
        "rougeLsum": {
            "precision": 0.61562,
            "recall": 0.62508,
            "fmeasure": 0.6105
        },
        "bleu": 41.90509,
        "nist": 6.201110874332136,
        "local_recall": {
            "1": 0.22832369942196531,
            "2": 0.625,
            "3": 0.8478260869565217
        },
        "nubia": {
            "semantic_relation": 4.52691,
            "contradiction": 4.55372,
            "irrelevancy": 6.61739,
            "logical_agreement": 88.8289,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.31865,
            "nubia_score": 0.79482
        },
        "meteor": 0.4094553603023637,
        "bleurt": 0.20121,
        "bertscore": {
            "precision": 0.92545,
            "recall": 0.93186,
            "f1": 0.92717
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.2415,
        "msttr-100_nopunct": 0.24352,
        "total_length": 6040,
        "mean_pred_length": 15.526992287917738,
        "std_pred_length": 3.520402006204344,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.0173841059602649,
        "vocab_size-1": 105,
        "unique-1": 6,
        "entropy-1": 5.5710900265362975,
        "distinct-2": 0.03963900194655813,
        "vocab_size-2": 224,
        "unique-2": 27,
        "entropy-2": 6.746986081971174,
        "cond_entropy-2": 1.0320092869474253,
        "distinct-3": 0.0653743823641201,
        "vocab_size-3": 344,
        "unique-3": 66,
        "entropy-3": 7.399379965464091,
        "cond_entropy-3": 0.6781637293788211,
        "total_length-nopunct": 5497,
        "mean_pred_length-nopunct": 14.131105398457583,
        "std_pred_length-nopunct": 3.22279542419584,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.018737493178097146,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 5.638722871675819,
        "distinct-2-nopunct": 0.04130775254502741,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 6.6453345728952335,
        "cond_entropy-2-nopunct": 1.0649913176334473,
        "distinct-3-nopunct": 0.0712015257469803,
        "vocab_size-3-nopunct": 336,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 7.359716908999802,
        "cond_entropy-3-nopunct": 0.6904752148326498,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.78805,
            "recall": 0.67486,
            "fmeasure": 0.71439
        },
        "rouge2": {
            "precision": 0.51835,
            "recall": 0.44216,
            "fmeasure": 0.46832
        },
        "rougeL": {
            "precision": 0.63007,
            "recall": 0.53525,
            "fmeasure": 0.56873
        },
        "rougeLsum": {
            "precision": 0.63007,
            "recall": 0.53525,
            "fmeasure": 0.56873
        },
        "bleu": 32.62599,
        "nist": 4.907009506740099,
        "local_recall": {
            "1": 0.6552284924377948
        },
        "nubia": {
            "semantic_relation": 4.33705,
            "contradiction": 2.41889,
            "irrelevancy": 10.0864,
            "logical_agreement": 87.49471,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.96812,
            "nubia_score": 0.79371
        },
        "meteor": 0.352763434474799,
        "bleurt": 0.21873,
        "bertscore": {
            "precision": 0.93192,
            "recall": 0.90656,
            "f1": 0.91871
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.24943,
        "msttr-100_nopunct": 0.24884,
        "total_length": 14086,
        "mean_pred_length": 19.112618724559024,
        "std_pred_length": 3.690475593054772,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.007596194803350845,
        "vocab_size-1": 107,
        "unique-1": 3,
        "entropy-1": 5.620797137421063,
        "distinct-2": 0.021949209678627613,
        "vocab_size-2": 293,
        "unique-2": 32,
        "entropy-2": 6.983181463691671,
        "cond_entropy-2": 1.2525250431275332,
        "distinct-3": 0.04297494449730416,
        "vocab_size-3": 542,
        "unique-3": 99,
        "entropy-3": 7.757602748414774,
        "cond_entropy-3": 0.8005635413971083,
        "total_length-nopunct": 12926,
        "mean_pred_length-nopunct": 17.53867028493894,
        "std_pred_length-nopunct": 3.3532721411709754,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.008123162617979266,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 5.665369157322079,
        "distinct-2-nopunct": 0.023217655262942,
        "vocab_size-2-nopunct": 283,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 6.902228232765923,
        "cond_entropy-2-nopunct": 1.283358171144962,
        "distinct-3-nopunct": 0.046891372685993714,
        "vocab_size-3-nopunct": 537,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 7.736209696047602,
        "cond_entropy-3-nopunct": 0.8104246403919622,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.78058,
            "recall": 0.70446,
            "fmeasure": 0.72872
        },
        "rouge2": {
            "precision": 0.50405,
            "recall": 0.45517,
            "fmeasure": 0.47052
        },
        "rougeL": {
            "precision": 0.60864,
            "recall": 0.55219,
            "fmeasure": 0.57001
        },
        "rougeLsum": {
            "precision": 0.60864,
            "recall": 0.55219,
            "fmeasure": 0.57001
        },
        "bleu": 33.48532,
        "nist": 5.217599088978934,
        "local_recall": {
            "1": 0.6938992042440318
        },
        "nubia": {
            "semantic_relation": 4.37673,
            "contradiction": 1.7595,
            "irrelevancy": 11.46896,
            "logical_agreement": 86.77153,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.66598,
            "nubia_score": 0.79924
        },
        "meteor": 0.36647352571679,
        "bleurt": 0.26435,
        "bertscore": {
            "precision": 0.92989,
            "recall": 0.9085,
            "f1": 0.91867
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.25915,
        "msttr-100_nopunct": 0.25234,
        "total_length": 25844,
        "mean_pred_length": 21.772535804549285,
        "std_pred_length": 4.450664184431906,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 37,
        "distinct-1": 0.003946757467884228,
        "vocab_size-1": 102,
        "unique-1": 1,
        "entropy-1": 5.494905762180664,
        "distinct-2": 0.013626961917508213,
        "vocab_size-2": 336,
        "unique-2": 40,
        "entropy-2": 6.824077927824424,
        "cond_entropy-2": 1.233298015733453,
        "distinct-3": 0.02778014486578611,
        "vocab_size-3": 652,
        "unique-3": 111,
        "entropy-3": 7.6241867589848304,
        "cond_entropy-3": 0.815806340424074,
        "total_length-nopunct": 23554,
        "mean_pred_length-nopunct": 19.84330244313395,
        "std_pred_length-nopunct": 3.9502865064556847,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.004245563386261357,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 1,
        "entropy-1-nopunct": 5.551080111458786,
        "distinct-2-nopunct": 0.014485626145661018,
        "vocab_size-2-nopunct": 324,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 6.808533640823023,
        "cond_entropy-2-nopunct": 1.2918816051296949,
        "distinct-3-nopunct": 0.030406043437204912,
        "vocab_size-3-nopunct": 644,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 7.676216505524767,
        "cond_entropy-3-nopunct": 0.8479982884143517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.78814,
            "recall": 0.71196,
            "fmeasure": 0.73766
        },
        "rouge2": {
            "precision": 0.46882,
            "recall": 0.42547,
            "fmeasure": 0.43965
        },
        "rougeL": {
            "precision": 0.5629,
            "recall": 0.50881,
            "fmeasure": 0.52702
        },
        "rougeLsum": {
            "precision": 0.5629,
            "recall": 0.50881,
            "fmeasure": 0.52702
        },
        "bleu": 31.59985,
        "nist": 5.125638476528553,
        "local_recall": {
            "1": 0.7069945677348718
        },
        "nubia": {
            "semantic_relation": 4.44987,
            "contradiction": 1.38111,
            "irrelevancy": 7.58552,
            "logical_agreement": 91.03337,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.54174,
            "nubia_score": 0.83469
        },
        "meteor": 0.3650073370485626,
        "bleurt": 0.25788,
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.90619,
            "f1": 0.91691
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.535,
        "msttr-100_nopunct": 0.53,
        "total_length": 294,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.8591264740685998,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.3707482993197279,
        "vocab_size-1": 109,
        "unique-1": 68,
        "entropy-1": 5.616087335326799,
        "distinct-2": 0.6804511278195489,
        "vocab_size-2": 181,
        "unique-2": 140,
        "entropy-2": 7.193201633191101,
        "cond_entropy-2": 1.337704194114989,
        "distinct-3": 0.8235294117647058,
        "vocab_size-3": 196,
        "unique-3": 170,
        "entropy-3": 7.463711213164585,
        "cond_entropy-3": 0.34672076679988273,
        "total_length-nopunct": 260,
        "mean_pred_length-nopunct": 9.285714285714286,
        "std_pred_length-nopunct": 3.4729273660409197,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.40384615384615385,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.661069134432512,
        "distinct-2-nopunct": 0.6508620689655172,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.904043523513365,
        "cond_entropy-2-nopunct": 1.4496400701120946,
        "distinct-3-nopunct": 0.803921568627451,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.189075543274792,
        "cond_entropy-3-nopunct": 0.35917558203825517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.84028,
            "recall": 0.79213,
            "fmeasure": 0.8049
        },
        "rouge2": {
            "precision": 0.6337,
            "recall": 0.5925,
            "fmeasure": 0.60372
        },
        "rougeL": {
            "precision": 0.70777,
            "recall": 0.66624,
            "fmeasure": 0.67852
        },
        "rougeLsum": {
            "precision": 0.70777,
            "recall": 0.66624,
            "fmeasure": 0.67852
        },
        "bleu": 61.00874,
        "nist": 6.875613304294782,
        "local_recall": {
            "1": 0.1292517006802721,
            "2": 0.6170212765957447,
            "3": 0.8962962962962963,
            "4": 1.0
        },
        "nubia": {
            "semantic_relation": 4.31106,
            "contradiction": 17.89818,
            "irrelevancy": 4.98106,
            "logical_agreement": 77.12075,
            "grammar_ref": 4.67502,
            "grammar_hyp": 5.19514,
            "nubia_score": 0.70597
        },
        "meteor": 0.4229273207353739,
        "bleurt": 0.31152,
        "bertscore": {
            "precision": 0.94089,
            "recall": 0.92883,
            "f1": 0.93321
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 89,
        "mean_pred_length": 22.25,
        "std_pred_length": 9.832980219648569,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 38,
        "distinct-1": 0.6404494382022472,
        "vocab_size-1": 57,
        "unique-1": 38,
        "entropy-1": 5.575295616501036,
        "distinct-2": 0.8470588235294118,
        "vocab_size-2": 72,
        "unique-2": 59,
        "entropy-2": 6.103508583196531,
        "cond_entropy-2": 0.44894121675404525,
        "distinct-3": 0.9012345679012346,
        "vocab_size-3": 73,
        "unique-3": 65,
        "entropy-3": 6.142319138687086,
        "cond_entropy-3": 0.029224498845688406,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7428571428571429,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.593429088311723,
        "distinct-2-nopunct": 0.8787878787878788,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.801969876934219,
        "cond_entropy-2-nopunct": 0.18669917064993796,
        "distinct-3-nopunct": 0.9354838709677419,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.825164052322359,
        "cond_entropy-3-nopunct": 0.006576384576808924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.38214,
            "recall": 0.54545,
            "fmeasure": 0.43929
        },
        "rouge2": {
            "precision": 0.09722,
            "recall": 0.1162,
            "fmeasure": 0.10458
        },
        "rougeL": {
            "precision": 0.38214,
            "recall": 0.53636,
            "fmeasure": 0.43452
        },
        "rougeLsum": {
            "precision": 0.38214,
            "recall": 0.53636,
            "fmeasure": 0.43452
        },
        "bleu": 24.05951,
        "nist": 3.4123866788341024,
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.6923076923076923,
            "3": 0.6153846153846154
        },
        "nubia": {
            "semantic_relation": 3.52623,
            "contradiction": 34.91089,
            "irrelevancy": 18.67532,
            "logical_agreement": 46.41379,
            "grammar_ref": 2.93748,
            "grammar_hyp": 2.88328,
            "nubia_score": 0.64297
        },
        "meteor": 0.5096727212676396,
        "bleurt": -0.00756,
        "bertscore": {
            "precision": 0.93378,
            "recall": 0.94653,
            "f1": 0.93983
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.28889,
        "msttr-100_nopunct": 0.28506,
        "total_length": 38985,
        "mean_pred_length": 27.7275960170697,
        "std_pred_length": 4.714665632921852,
        "median_pred_length": 28.0,
        "min_pred_length": 15,
        "max_pred_length": 41,
        "distinct-1": 0.0025394382454790305,
        "vocab_size-1": 99,
        "unique-1": 6,
        "entropy-1": 5.541923514633078,
        "distinct-2": 0.00912743819686527,
        "vocab_size-2": 343,
        "unique-2": 41,
        "entropy-2": 6.979630511980056,
        "cond_entropy-2": 1.363463758460785,
        "distinct-3": 0.01940673983357753,
        "vocab_size-3": 702,
        "unique-3": 112,
        "entropy-3": 7.805741684677304,
        "cond_entropy-3": 0.8528573650541683,
        "total_length-nopunct": 35646,
        "mean_pred_length-nopunct": 25.352773826458037,
        "std_pred_length-nopunct": 4.278284192813578,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.0027212029400213206,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 5.5932114646348605,
        "distinct-2-nopunct": 0.009813084112149532,
        "vocab_size-2-nopunct": 336,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 6.983050422913421,
        "cond_entropy-2-nopunct": 1.431391166857928,
        "distinct-3-nopunct": 0.02131936407382591,
        "vocab_size-3-nopunct": 700,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 7.871760308113043,
        "cond_entropy-3-nopunct": 0.8907138883098732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.77392,
            "recall": 0.73642,
            "fmeasure": 0.74567
        },
        "rouge2": {
            "precision": 0.47295,
            "recall": 0.45047,
            "fmeasure": 0.45572
        },
        "rougeL": {
            "precision": 0.52279,
            "recall": 0.49786,
            "fmeasure": 0.50389
        },
        "rougeLsum": {
            "precision": 0.52279,
            "recall": 0.49786,
            "fmeasure": 0.50389
        },
        "bleu": 32.64063,
        "nist": 5.256835883535778,
        "local_recall": {
            "1": 0.7293660196239254
        },
        "nubia": {
            "semantic_relation": 4.51535,
            "contradiction": 1.79643,
            "irrelevancy": 10.98845,
            "logical_agreement": 87.21512,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.28178,
            "nubia_score": 0.85525
        },
        "meteor": 0.3751153996650117,
        "bleurt": 0.29042,
        "bertscore": {
            "precision": 0.92435,
            "recall": 0.91104,
            "f1": 0.91742
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.66354,
        "msttr-100_nopunct": 0.68929,
        "total_length": 20602,
        "mean_pred_length": 21.505219206680586,
        "std_pred_length": 6.370393575342642,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 49,
        "distinct-1": 0.08251626055722745,
        "vocab_size-1": 1700,
        "unique-1": 795,
        "entropy-1": 7.72290278502678,
        "distinct-2": 0.2610466300142537,
        "vocab_size-2": 5128,
        "unique-2": 3080,
        "entropy-2": 10.627558950644673,
        "cond_entropy-2": 2.764878569258642,
        "distinct-3": 0.44407577865781866,
        "vocab_size-3": 8298,
        "unique-3": 5779,
        "entropy-3": 12.011480964254355,
        "cond_entropy-3": 1.4541978212258844,
        "total_length-nopunct": 18217,
        "mean_pred_length-nopunct": 19.015657620041754,
        "std_pred_length-nopunct": 5.817399315603234,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.09260580776198057,
        "vocab_size-1-nopunct": 1687,
        "unique-1-nopunct": 794,
        "entropy-1-nopunct": 7.9291311218084894,
        "distinct-2-nopunct": 0.27805782490294917,
        "vocab_size-2-nopunct": 4799,
        "unique-2-nopunct": 2940,
        "entropy-2-nopunct": 10.610178260581248,
        "cond_entropy-2-nopunct": 2.824108846078804,
        "distinct-3-nopunct": 0.47432672842156925,
        "vocab_size-3-nopunct": 7732,
        "unique-3-nopunct": 5501,
        "entropy-3-nopunct": 12.030241615489036,
        "cond_entropy-3-nopunct": 1.503171680363687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.64101,
            "recall": 0.61961,
            "fmeasure": 0.61977
        },
        "rouge2": {
            "precision": 0.40328,
            "recall": 0.38864,
            "fmeasure": 0.38894
        },
        "rougeL": {
            "precision": 0.55839,
            "recall": 0.53903,
            "fmeasure": 0.53956
        },
        "rougeLsum": {
            "precision": 0.55839,
            "recall": 0.53903,
            "fmeasure": 0.53956
        },
        "bleu": 31.84738,
        "nist": 6.546198211471992,
        "local_recall": {
            "1": 0.6066307735902522
        },
        "nubia": {
            "semantic_relation": 4.30421,
            "contradiction": 5.72126,
            "irrelevancy": 18.05859,
            "logical_agreement": 76.22015,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.77528,
            "nubia_score": 0.74358
        },
        "meteor": 0.3357635391270268,
        "bleurt": -0.0682,
        "bertscore": {
            "precision": 0.88455,
            "recall": 0.87911,
            "f1": 0.88145
        }
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "mT5_large/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.70973,
        "msttr-100_nopunct": 0.7178,
        "total_length": 44258,
        "mean_pred_length": 22.836945304437563,
        "std_pred_length": 6.728958516925082,
        "median_pred_length": 22.0,
        "min_pred_length": 3,
        "max_pred_length": 75,
        "distinct-1": 0.17477066293099552,
        "vocab_size-1": 7735,
        "unique-1": 4674,
        "entropy-1": 9.325534164279025,
        "distinct-2": 0.5938563327032136,
        "vocab_size-2": 25132,
        "unique-2": 20593,
        "entropy-2": 13.693947342455674,
        "cond_entropy-2": 4.505773478091989,
        "distinct-3": 0.8858649893516913,
        "vocab_size-3": 35773,
        "unique-3": 33371,
        "entropy-3": 14.988095267240693,
        "cond_entropy-3": 1.3133117460668462,
        "total_length-nopunct": 41944,
        "mean_pred_length-nopunct": 21.642930856553146,
        "std_pred_length-nopunct": 6.079322079110105,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 71,
        "distinct-1-nopunct": 0.18410261300781994,
        "vocab_size-1-nopunct": 7722,
        "unique-1-nopunct": 4671,
        "entropy-1-nopunct": 9.431652568627714,
        "distinct-2-nopunct": 0.6179823026546019,
        "vocab_size-2-nopunct": 24723,
        "unique-2-nopunct": 20480,
        "entropy-2-nopunct": 13.742598907866947,
        "cond_entropy-2-nopunct": 4.457117727472479,
        "distinct-3-nopunct": 0.898655038352422,
        "vocab_size-3-nopunct": 34210,
        "unique-3-nopunct": 32173,
        "entropy-3-nopunct": 14.939987050159333,
        "cond_entropy-3-nopunct": 1.2106582228373046,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.28649,
            "recall": 0.25634,
            "fmeasure": 0.26018
        },
        "rouge2": {
            "precision": 0.07949,
            "recall": 0.07093,
            "fmeasure": 0.07205
        },
        "rougeL": {
            "precision": 0.21392,
            "recall": 0.19179,
            "fmeasure": 0.19424
        },
        "rougeLsum": {
            "precision": 0.21392,
            "recall": 0.19179,
            "fmeasure": 0.19424
        },
        "bleu": 4.60445,
        "nist": 2.162759788049372,
        "local_recall": {
            "1": 0.23564685483094114
        },
        "nubia": {
            "semantic_relation": 1.45484,
            "contradiction": 26.53964,
            "irrelevancy": 64.09175,
            "logical_agreement": 9.36861,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.19187,
            "nubia_score": 0.15543
        },
        "meteor": 0.17437666626589185,
        "bleurt": -0.48186,
        "bertscore": {
            "precision": 0.83808,
            "recall": 0.83208,
            "f1": 0.8349
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.66091,
        "msttr-100_nopunct": 0.74704,
        "total_length": 3377,
        "mean_pred_length": 9.96165191740413,
        "std_pred_length": 3.857529691948752,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.35149541012733193,
        "vocab_size-1": 1187,
        "unique-1": 744,
        "entropy-1": 8.530944366828347,
        "distinct-2": 0.6803818301514154,
        "vocab_size-2": 2067,
        "unique-2": 1596,
        "entropy-2": 10.655097312124488,
        "cond_entropy-2": 1.540859768336521,
        "distinct-3": 0.8221563542052612,
        "vocab_size-3": 2219,
        "unique-3": 1889,
        "entropy-3": 10.979970939541394,
        "cond_entropy-3": 0.3396796543620298,
        "total_length-nopunct": 2708,
        "mean_pred_length-nopunct": 7.988200589970502,
        "std_pred_length-nopunct": 3.302789025383599,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.4364844903988183,
        "vocab_size-1-nopunct": 1182,
        "unique-1-nopunct": 744,
        "entropy-1-nopunct": 9.277321230635732,
        "distinct-2-nopunct": 0.709582102152807,
        "vocab_size-2-nopunct": 1681,
        "unique-2-nopunct": 1330,
        "entropy-2-nopunct": 10.392863074067536,
        "cond_entropy-2-nopunct": 1.2499958916442442,
        "distinct-3-nopunct": 0.8394088669950739,
        "vocab_size-3-nopunct": 1704,
        "unique-3-nopunct": 1481,
        "entropy-3-nopunct": 10.60556119658865,
        "cond_entropy-3-nopunct": 0.29227225572960164,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.29654,
            "recall": 0.29601,
            "fmeasure": 0.29479
        },
        "rouge2": {
            "precision": 0.14172,
            "recall": 0.13979,
            "fmeasure": 0.1401
        },
        "rougeL": {
            "precision": 0.29458,
            "recall": 0.29417,
            "fmeasure": 0.29289
        },
        "rougeLsum": {
            "precision": 0.29458,
            "recall": 0.29417,
            "fmeasure": 0.29289
        },
        "bleu": 60.00782,
        "nist": 9.0189398317148,
        "local_recall": {
            "1": 0.35177182368193605,
            "2": 0.6944696282864914,
            "3": 0.8612521150592216,
            "4": 0.9166666666666666,
            "5": 0.8,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.20885,
            "contradiction": 20.25269,
            "irrelevancy": 20.04299,
            "logical_agreement": 59.70432,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.8414,
            "nubia_score": 0.85404
        },
        "meteor": 0.7518392717576633,
        "bleurt": 0.37912,
        "bertscore": {
            "precision": 0.96992,
            "recall": 0.9679,
            "f1": 0.96831
        }
    },
    "wiki_lingua_spanish_es_val": {
        "predictions_file": "mT5_large/wiki_lingua_spanish_es_val",
        "N": 11316,
        "msttr-100": 0.47689,
        "msttr-100_nopunct": 0.55186,
        "total_length": 313977,
        "mean_pred_length": 27.746288441145282,
        "std_pred_length": 17.762226617885172,
        "median_pred_length": 24.0,
        "min_pred_length": 2,
        "max_pred_length": 156,
        "distinct-1": 0.03373177016150865,
        "vocab_size-1": 10591,
        "unique-1": 3540,
        "entropy-1": 8.575458765692112,
        "distinct-2": 0.1903647975788093,
        "vocab_size-2": 57616,
        "unique-2": 33344,
        "entropy-2": 13.477832916190328,
        "cond_entropy-2": 4.68698899668447,
        "distinct-3": 0.45399097290154283,
        "vocab_size-3": 132268,
        "unique-3": 98043,
        "entropy-3": 15.767804580405112,
        "cond_entropy-3": 2.3062121165965928,
        "total_length-nopunct": 257580,
        "mean_pred_length-nopunct": 22.762460233297986,
        "std_pred_length-nopunct": 15.051917613773071,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 125,
        "distinct-1-nopunct": 0.04103579470455781,
        "vocab_size-1-nopunct": 10570,
        "unique-1-nopunct": 3537,
        "entropy-1-nopunct": 9.570970390214717,
        "distinct-2-nopunct": 0.30869997766633506,
        "vocab_size-2-nopunct": 76022,
        "unique-2-nopunct": 51747,
        "entropy-2-nopunct": 14.268727199188865,
        "cond_entropy-2-nopunct": 4.840358483337092,
        "distinct-3-nopunct": 0.5904890807019336,
        "vocab_size-3-nopunct": 138736,
        "unique-3-nopunct": 112068,
        "entropy-3-nopunct": 16.30319755623344,
        "cond_entropy-3-nopunct": 2.0924723223809703,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_val.json",
        "rouge1": {
            "precision": 0.45467,
            "recall": 0.30902,
            "fmeasure": 0.34402
        },
        "rouge2": {
            "precision": 0.168,
            "recall": 0.11443,
            "fmeasure": 0.12707
        },
        "rougeL": {
            "precision": 0.38655,
            "recall": 0.26508,
            "fmeasure": 0.29372
        },
        "rougeLsum": {
            "precision": 0.38655,
            "recall": 0.26508,
            "fmeasure": 0.29372
        },
        "bleu": 8.77099,
        "nist": 2.8127399311420533,
        "local_recall": {
            "1": 0.2545937784828181
        },
        "sari": 67.88539,
        "nubia": {
            "semantic_relation": 2.95509,
            "contradiction": 14.82686,
            "irrelevancy": 34.68002,
            "logical_agreement": 50.49312,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.63641,
            "nubia_score": 0.41597
        },
        "meteor": 0.15022602505915908,
        "bleurt": -0.37642,
        "bertscore": {
            "precision": 0.86939,
            "recall": 0.82578,
            "f1": 0.84638
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.64591,
        "msttr-100_nopunct": 0.6535,
        "total_length": 2265,
        "mean_pred_length": 31.458333333333332,
        "std_pred_length": 7.673796503542284,
        "median_pred_length": 31.0,
        "min_pred_length": 16,
        "max_pred_length": 49,
        "distinct-1": 0.1814569536423841,
        "vocab_size-1": 411,
        "unique-1": 211,
        "entropy-1": 7.092104147930894,
        "distinct-2": 0.44049247606019154,
        "vocab_size-2": 966,
        "unique-2": 616,
        "entropy-2": 9.134578028089193,
        "cond_entropy-2": 1.982309521678472,
        "distinct-3": 0.6308345120226309,
        "vocab_size-3": 1338,
        "unique-3": 1026,
        "entropy-3": 9.927778723392711,
        "cond_entropy-3": 0.7878663700674485,
        "total_length-nopunct": 2028,
        "mean_pred_length-nopunct": 28.166666666666668,
        "std_pred_length-nopunct": 7.243771270700243,
        "median_pred_length-nopunct": 28.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.1987179487179487,
        "vocab_size-1-nopunct": 403,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.144008876349297,
        "distinct-2-nopunct": 0.4662576687116564,
        "vocab_size-2-nopunct": 912,
        "unique-2-nopunct": 596,
        "entropy-2-nopunct": 9.095506423876548,
        "cond_entropy-2-nopunct": 1.9764009441336996,
        "distinct-3-nopunct": 0.6549893842887473,
        "vocab_size-3-nopunct": 1234,
        "unique-3-nopunct": 971,
        "entropy-3-nopunct": 9.850845845929715,
        "cond_entropy-3-nopunct": 0.7852710137686866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.66509,
            "recall": 0.60462,
            "fmeasure": 0.62754
        },
        "rouge2": {
            "precision": 0.42715,
            "recall": 0.3896,
            "fmeasure": 0.40358
        },
        "rougeL": {
            "precision": 0.52906,
            "recall": 0.48001,
            "fmeasure": 0.49847
        },
        "rougeLsum": {
            "precision": 0.52906,
            "recall": 0.48001,
            "fmeasure": 0.49847
        },
        "bleu": 34.43509,
        "nist": 5.792272014589783,
        "local_recall": {
            "1": 0.6197112991538078
        },
        "nubia": {
            "semantic_relation": 4.10069,
            "contradiction": 2.59674,
            "irrelevancy": 15.10006,
            "logical_agreement": 82.3032,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.20485,
            "nubia_score": 0.69305
        },
        "meteor": 0.3370065189433103,
        "bleurt": -0.07479,
        "bertscore": {
            "precision": 0.89493,
            "recall": 0.8814,
            "f1": 0.88789
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.41169,
            "fmeasure": 0.52019
        },
        "rouge2": {
            "precision": 0.47826,
            "recall": 0.27498,
            "fmeasure": 0.34854
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.38718,
            "fmeasure": 0.48936
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.38718,
            "fmeasure": 0.48936
        },
        "bleu": 33.03154,
        "nist": 1.932921756148143,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nubia": {
            "semantic_relation": 2.44186,
            "contradiction": 39.30571,
            "irrelevancy": 48.44123,
            "logical_agreement": 12.25306,
            "grammar_ref": 4.14314,
            "grammar_hyp": 3.3337,
            "nubia_score": 0.21316
        },
        "meteor": 0.2466456478628103,
        "bleurt": -0.61388,
        "bertscore": {
            "precision": 0.95089,
            "recall": 0.87138,
            "f1": 0.9094
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.7102,
        "msttr-100_nopunct": 0.807,
        "total_length": 4931,
        "mean_pred_length": 31.0125786163522,
        "std_pred_length": 7.510150298208493,
        "median_pred_length": 30.0,
        "min_pred_length": 17,
        "max_pred_length": 69,
        "distinct-1": 0.2646522003650375,
        "vocab_size-1": 1305,
        "unique-1": 659,
        "entropy-1": 8.471511895707476,
        "distinct-2": 0.5513411567476949,
        "vocab_size-2": 2631,
        "unique-2": 1712,
        "entropy-2": 10.87360580904547,
        "cond_entropy-2": 2.246716428568515,
        "distinct-3": 0.7073487968783871,
        "vocab_size-3": 3263,
        "unique-3": 2449,
        "entropy-3": 11.448578180703027,
        "cond_entropy-3": 0.5881295423377825,
        "total_length-nopunct": 4001,
        "mean_pred_length-nopunct": 25.163522012578618,
        "std_pred_length-nopunct": 6.619842683567022,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.32441889527618095,
        "vocab_size-1-nopunct": 1298,
        "unique-1-nopunct": 658,
        "entropy-1-nopunct": 9.18140411406237,
        "distinct-2-nopunct": 0.6111400312337324,
        "vocab_size-2-nopunct": 2348,
        "unique-2-nopunct": 1622,
        "entropy-2-nopunct": 10.842111064565742,
        "cond_entropy-2-nopunct": 1.7016781982816034,
        "distinct-3-nopunct": 0.7502036383383112,
        "vocab_size-3-nopunct": 2763,
        "unique-3-nopunct": 2181,
        "entropy-3-nopunct": 11.240086668055874,
        "cond_entropy-3-nopunct": 0.4093767257669331,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.52044,
            "recall": 0.51134,
            "fmeasure": 0.5111
        },
        "rouge2": {
            "precision": 0.29911,
            "recall": 0.29468,
            "fmeasure": 0.29187
        },
        "rougeL": {
            "precision": 0.49003,
            "recall": 0.48235,
            "fmeasure": 0.48114
        },
        "rougeLsum": {
            "precision": 0.49003,
            "recall": 0.48235,
            "fmeasure": 0.48114
        },
        "bleu": 47.58957,
        "nist": 8.485803601419752,
        "local_recall": {
            "1": 0.2621832358674464,
            "2": 0.6482315112540193,
            "3": 0.8743455497382199
        },
        "nubia": {
            "semantic_relation": 3.92579,
            "contradiction": 20.23091,
            "irrelevancy": 21.63864,
            "logical_agreement": 58.13045,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.44149,
            "nubia_score": 0.81296
        },
        "meteor": 0.6124043017549522,
        "bleurt": 0.11178,
        "bertscore": {
            "precision": 0.9484,
            "recall": 0.94519,
            "f1": 0.94621
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.31862,
        "msttr-100_nopunct": 0.31202,
        "total_length": 26991,
        "mean_pred_length": 34.872093023255815,
        "std_pred_length": 4.834514318335302,
        "median_pred_length": 35.0,
        "min_pred_length": 19,
        "max_pred_length": 47,
        "distinct-1": 0.0033714942017709607,
        "vocab_size-1": 91,
        "unique-1": 0,
        "entropy-1": 5.630152080748628,
        "distinct-2": 0.010794522637982988,
        "vocab_size-2": 283,
        "unique-2": 17,
        "entropy-2": 7.042195740768664,
        "cond_entropy-2": 1.353526642035818,
        "distinct-3": 0.020988091027001533,
        "vocab_size-3": 534,
        "unique-3": 61,
        "entropy-3": 7.876713460702354,
        "cond_entropy-3": 0.8582391318641225,
        "total_length-nopunct": 24780,
        "mean_pred_length-nopunct": 32.01550387596899,
        "std_pred_length-nopunct": 4.2416986799919485,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.003591606133979015,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 5.6714982966023,
        "distinct-2-nopunct": 0.011830375739398484,
        "vocab_size-2-nopunct": 284,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 7.061247326921517,
        "cond_entropy-2-nopunct": 1.4316483885850473,
        "distinct-3-nopunct": 0.02363119834710744,
        "vocab_size-3-nopunct": 549,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 7.945320167932742,
        "cond_entropy-3-nopunct": 0.895036546388346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.77809,
            "recall": 0.78064,
            "fmeasure": 0.7736
        },
        "rouge2": {
            "precision": 0.48038,
            "recall": 0.48288,
            "fmeasure": 0.478
        },
        "rougeL": {
            "precision": 0.50495,
            "recall": 0.50596,
            "fmeasure": 0.50171
        },
        "rougeLsum": {
            "precision": 0.50495,
            "recall": 0.50596,
            "fmeasure": 0.50171
        },
        "bleu": 36.62535,
        "nist": 5.534377370316629,
        "local_recall": {
            "1": 0.7647305417113047
        },
        "nubia": {
            "semantic_relation": 4.54371,
            "contradiction": 2.87632,
            "irrelevancy": 13.76032,
            "logical_agreement": 83.36336,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.00123,
            "nubia_score": 0.86972
        },
        "meteor": 0.39167707086790016,
        "bleurt": 0.32265,
        "bertscore": {
            "precision": 0.92309,
            "recall": 0.91619,
            "f1": 0.91948
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.64138,
        "msttr-100_nopunct": 0.7066,
        "total_length": 6548,
        "mean_pred_length": 20.72151898734177,
        "std_pred_length": 7.385731555104739,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 56,
        "distinct-1": 0.24480757483200977,
        "vocab_size-1": 1603,
        "unique-1": 800,
        "entropy-1": 8.659069550563263,
        "distinct-2": 0.5351412066752247,
        "vocab_size-2": 3335,
        "unique-2": 2181,
        "entropy-2": 11.15957166084171,
        "cond_entropy-2": 2.2539787975040895,
        "distinct-3": 0.7003042596348884,
        "vocab_size-3": 4143,
        "unique-3": 3117,
        "entropy-3": 11.779971818554179,
        "cond_entropy-3": 0.6283182669708302,
        "total_length-nopunct": 5338,
        "mean_pred_length-nopunct": 16.89240506329114,
        "std_pred_length-nopunct": 6.290524764326683,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.29917572124391156,
        "vocab_size-1-nopunct": 1597,
        "unique-1-nopunct": 799,
        "entropy-1-nopunct": 9.351571873671215,
        "distinct-2-nopunct": 0.5917960971724413,
        "vocab_size-2-nopunct": 2972,
        "unique-2-nopunct": 2039,
        "entropy-2-nopunct": 11.116139421212983,
        "cond_entropy-2-nopunct": 1.821658232499043,
        "distinct-3-nopunct": 0.7424564385890353,
        "vocab_size-3-nopunct": 3494,
        "unique-3-nopunct": 2743,
        "entropy-3-nopunct": 11.569258678257635,
        "cond_entropy-3-nopunct": 0.4755531353365967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.39286,
            "recall": 0.40313,
            "fmeasure": 0.3945
        },
        "rouge2": {
            "precision": 0.20094,
            "recall": 0.20338,
            "fmeasure": 0.20002
        },
        "rougeL": {
            "precision": 0.37962,
            "recall": 0.39003,
            "fmeasure": 0.38107
        },
        "rougeLsum": {
            "precision": 0.37962,
            "recall": 0.39003,
            "fmeasure": 0.38107
        },
        "bleu": 49.54054,
        "nist": 8.86388133610723,
        "local_recall": {
            "1": 0.2849109653233365,
            "2": 0.6796912686927159,
            "3": 0.8901408450704226,
            "4": 0.9473684210526315,
            "5": 0.9545454545454546,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.00804,
            "contradiction": 18.70911,
            "irrelevancy": 21.61883,
            "logical_agreement": 59.67206,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.59839,
            "nubia_score": 0.82936
        },
        "meteor": 0.6545824882614539,
        "bleurt": 0.162,
        "bertscore": {
            "precision": 0.95651,
            "recall": 0.95468,
            "f1": 0.95482
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.67917,
        "msttr-100_nopunct": 0.751,
        "total_length": 1263,
        "mean_pred_length": 43.55172413793103,
        "std_pred_length": 6.077580092929182,
        "median_pred_length": 43.0,
        "min_pred_length": 33,
        "max_pred_length": 55,
        "distinct-1": 0.27157561361836896,
        "vocab_size-1": 343,
        "unique-1": 162,
        "entropy-1": 7.126276153191314,
        "distinct-2": 0.4959481361426256,
        "vocab_size-2": 612,
        "unique-2": 350,
        "entropy-2": 8.835937365794274,
        "cond_entropy-2": 1.6285130589278574,
        "distinct-3": 0.6066390041493775,
        "vocab_size-3": 731,
        "unique-3": 469,
        "entropy-3": 9.247613885819161,
        "cond_entropy-3": 0.4134798502621996,
        "total_length-nopunct": 1047,
        "mean_pred_length-nopunct": 36.10344827586207,
        "std_pred_length-nopunct": 5.9384476526434655,
        "median_pred_length-nopunct": 36.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3218720152817574,
        "vocab_size-1-nopunct": 337,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 7.48124118341158,
        "distinct-2-nopunct": 0.5333988212180747,
        "vocab_size-2-nopunct": 543,
        "unique-2-nopunct": 326,
        "entropy-2-nopunct": 8.735924484850976,
        "cond_entropy-2-nopunct": 1.2699427572385302,
        "distinct-3-nopunct": 0.6349848331648129,
        "vocab_size-3-nopunct": 628,
        "unique-3-nopunct": 422,
        "entropy-3-nopunct": 9.05034372890742,
        "cond_entropy-3-nopunct": 0.3191268354343606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.89472,
            "recall": 0.88218,
            "fmeasure": 0.8818
        },
        "rouge2": {
            "precision": 0.70441,
            "recall": 0.69755,
            "fmeasure": 0.69001
        },
        "rougeL": {
            "precision": 0.8486,
            "recall": 0.83742,
            "fmeasure": 0.83551
        },
        "rougeLsum": {
            "precision": 0.8486,
            "recall": 0.83742,
            "fmeasure": 0.83551
        },
        "bleu": 55.8539,
        "nist": 7.728963258656083,
        "local_recall": {
            "1": 0.3409090909090909,
            "2": 0.6282352941176471,
            "3": 0.8944281524926686
        },
        "nubia": {
            "semantic_relation": 3.71209,
            "contradiction": 20.63297,
            "irrelevancy": 21.40965,
            "logical_agreement": 57.95738,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.49381,
            "nubia_score": 0.87585
        },
        "meteor": 0.6826574183949957,
        "bleurt": 0.16814,
        "bertscore": {
            "precision": 0.954,
            "recall": 0.95165,
            "f1": 0.95236
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.502,
        "msttr-100_nopunct": 0.528,
        "total_length": 10087,
        "mean_pred_length": 9.8505859375,
        "std_pred_length": 5.822080448639236,
        "median_pred_length": 7.0,
        "min_pred_length": 3,
        "max_pred_length": 31,
        "distinct-1": 0.07534450282541885,
        "vocab_size-1": 760,
        "unique-1": 420,
        "entropy-1": 6.397792030281481,
        "distinct-2": 0.222553238442017,
        "vocab_size-2": 2017,
        "unique-2": 1223,
        "entropy-2": 8.97071349409332,
        "cond_entropy-2": 2.28239624588601,
        "distinct-3": 0.3794004229381764,
        "vocab_size-3": 3050,
        "unique-3": 2127,
        "entropy-3": 10.052025663263718,
        "cond_entropy-3": 1.0567664851171474,
        "total_length-nopunct": 8553,
        "mean_pred_length-nopunct": 8.3525390625,
        "std_pred_length-nopunct": 5.158591646167743,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.08780544838068514,
        "vocab_size-1-nopunct": 751,
        "unique-1-nopunct": 418,
        "entropy-1-nopunct": 6.621614338824942,
        "distinct-2-nopunct": 0.24850577765971577,
        "vocab_size-2-nopunct": 1871,
        "unique-2-nopunct": 1186,
        "entropy-2-nopunct": 8.88564845690992,
        "cond_entropy-2-nopunct": 2.4423382829880134,
        "distinct-3-nopunct": 0.4239815526518063,
        "vocab_size-3-nopunct": 2758,
        "unique-3-nopunct": 2013,
        "entropy-3-nopunct": 9.976324532697685,
        "cond_entropy-3-nopunct": 1.0937301121938672,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.41213,
            "recall": 0.38398,
            "fmeasure": 0.38739
        },
        "rouge2": {
            "precision": 0.19839,
            "recall": 0.18655,
            "fmeasure": 0.18779
        },
        "rougeL": {
            "precision": 0.36966,
            "recall": 0.34361,
            "fmeasure": 0.34695
        },
        "rougeLsum": {
            "precision": 0.36966,
            "recall": 0.34361,
            "fmeasure": 0.34695
        },
        "bleu": 22.9527,
        "nist": 4.277891693962304,
        "local_recall": {
            "1": 0.4109198552790264
        },
        "nubia": {
            "semantic_relation": 2.44287,
            "contradiction": 11.25667,
            "irrelevancy": 32.27647,
            "logical_agreement": 56.46685,
            "grammar_ref": 5.2128,
            "grammar_hyp": 4.98629,
            "nubia_score": 0.4062
        },
        "meteor": 0.2349799973654472,
        "bleurt": -0.57137,
        "bertscore": {
            "precision": 0.84124,
            "recall": 0.83399,
            "f1": 0.83713
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.38,
        "msttr-100_nopunct": 0.37045,
        "total_length": 2510,
        "mean_pred_length": 34.38356164383562,
        "std_pred_length": 4.773299415990284,
        "median_pred_length": 34.0,
        "min_pred_length": 25,
        "max_pred_length": 45,
        "distinct-1": 0.034262948207171316,
        "vocab_size-1": 86,
        "unique-1": 3,
        "entropy-1": 5.567001493353717,
        "distinct-2": 0.09355765285186705,
        "vocab_size-2": 228,
        "unique-2": 34,
        "entropy-2": 6.983133233779386,
        "cond_entropy-2": 1.3582666945124253,
        "distinct-3": 0.16412859560067683,
        "vocab_size-3": 388,
        "unique-3": 99,
        "entropy-3": 7.802640082028409,
        "cond_entropy-3": 0.8446869916890706,
        "total_length-nopunct": 2297,
        "mean_pred_length-nopunct": 31.465753424657535,
        "std_pred_length-nopunct": 4.229971960724524,
        "median_pred_length-nopunct": 31.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.03656943839791032,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 5.59808732990861,
        "distinct-2-nopunct": 0.10206834532374101,
        "vocab_size-2-nopunct": 227,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 6.986817607479137,
        "cond_entropy-2-nopunct": 1.431288684823167,
        "distinct-3-nopunct": 0.18131101813110181,
        "vocab_size-3-nopunct": 390,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 7.853668655871899,
        "cond_entropy-3-nopunct": 0.8774332514326354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.76942,
            "recall": 0.78504,
            "fmeasure": 0.77315
        },
        "rouge2": {
            "precision": 0.50012,
            "recall": 0.51047,
            "fmeasure": 0.50253
        },
        "rougeL": {
            "precision": 0.512,
            "recall": 0.52223,
            "fmeasure": 0.51445
        },
        "rougeLsum": {
            "precision": 0.512,
            "recall": 0.52223,
            "fmeasure": 0.51445
        },
        "bleu": 37.40583,
        "nist": 5.263125357091278,
        "local_recall": {
            "1": 0.7754065040650406
        },
        "nubia": {
            "semantic_relation": 4.41268,
            "contradiction": 3.0156,
            "irrelevancy": 20.74651,
            "logical_agreement": 76.23788,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.07129,
            "nubia_score": 0.8504
        },
        "meteor": 0.39655105515600253,
        "bleurt": 0.28858,
        "bertscore": {
            "precision": 0.92039,
            "recall": 0.91767,
            "f1": 0.9189
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.67463,
        "msttr-100_nopunct": 0.69435,
        "total_length": 19049,
        "mean_pred_length": 15.28812199036918,
        "std_pred_length": 5.324129949151827,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.10084518872381752,
        "vocab_size-1": 1921,
        "unique-1": 913,
        "entropy-1": 7.983654962351476,
        "distinct-2": 0.2982081671628377,
        "vocab_size-2": 5309,
        "unique-2": 3246,
        "entropy-2": 10.790767365287293,
        "cond_entropy-2": 2.6080945834066935,
        "distinct-3": 0.4842664733949387,
        "vocab_size-3": 8018,
        "unique-3": 5770,
        "entropy-3": 12.032423685267046,
        "cond_entropy-3": 1.2856927748801976,
        "total_length-nopunct": 17099,
        "mean_pred_length-nopunct": 13.723113964686998,
        "std_pred_length-nopunct": 4.886634104518388,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.11146850693022983,
        "vocab_size-1-nopunct": 1906,
        "unique-1-nopunct": 911,
        "entropy-1-nopunct": 8.135358595570306,
        "distinct-2-nopunct": 0.3059988645682205,
        "vocab_size-2-nopunct": 4851,
        "unique-2-nopunct": 3050,
        "entropy-2-nopunct": 10.641920363540546,
        "cond_entropy-2-nopunct": 2.64990518743875,
        "distinct-3-nopunct": 0.4942151023481892,
        "vocab_size-3-nopunct": 7219,
        "unique-3-nopunct": 5261,
        "entropy-3-nopunct": 11.883215267992297,
        "cond_entropy-3-nopunct": 1.3137350286113318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.68272,
            "recall": 0.66173,
            "fmeasure": 0.65992
        },
        "rouge2": {
            "precision": 0.47792,
            "recall": 0.46131,
            "fmeasure": 0.46017
        },
        "rougeL": {
            "precision": 0.5996,
            "recall": 0.58032,
            "fmeasure": 0.57945
        },
        "rougeLsum": {
            "precision": 0.5996,
            "recall": 0.58032,
            "fmeasure": 0.57945
        },
        "bleu": 38.54242,
        "nist": 7.212391654185767,
        "local_recall": {
            "1": 0.6360219544207135
        },
        "nubia": {
            "semantic_relation": 4.27533,
            "contradiction": 7.03559,
            "irrelevancy": 19.13867,
            "logical_agreement": 73.82574,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.76845,
            "nubia_score": 0.76096
        },
        "meteor": 0.3649816083178667,
        "bleurt": -0.02691,
        "bertscore": {
            "precision": 0.89781,
            "recall": 0.89054,
            "f1": 0.89372
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 45.0,
        "std_pred_length": 0.0,
        "median_pred_length": 45.0,
        "min_pred_length": 45,
        "max_pred_length": 45,
        "distinct-1": 0.37777777777777777,
        "vocab_size-1": 34,
        "unique-1": 0,
        "entropy-1": 4.908193929518776,
        "distinct-2": 0.4659090909090909,
        "vocab_size-2": 41,
        "unique-2": 0,
        "entropy-2": 5.30591144813358,
        "cond_entropy-2": 0.365527954224144,
        "distinct-3": 0.4883720930232558,
        "vocab_size-3": 42,
        "unique-3": 0,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": 0.07741191518488139,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 41.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 41.0,
        "min_pred_length-nopunct": 41,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4024390243902439,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.912072431289048,
        "distinct-2-nopunct": 0.4875,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.37099265293153866,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": 0.014756175256937383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.80488,
            "recall": 0.82456,
            "fmeasure": 0.81409
        },
        "rouge2": {
            "precision": 0.5625,
            "recall": 0.57383,
            "fmeasure": 0.56774
        },
        "rougeL": {
            "precision": 0.43902,
            "recall": 0.44862,
            "fmeasure": 0.4435
        },
        "rougeLsum": {
            "precision": 0.43902,
            "recall": 0.44862,
            "fmeasure": 0.4435
        },
        "bleu": 47.53505,
        "nist": 4.259175463121251,
        "local_recall": {
            "1": 0.8142857142857143
        },
        "nubia": {
            "semantic_relation": 4.83407,
            "contradiction": 0.11302,
            "irrelevancy": 0.62378,
            "logical_agreement": 99.26319,
            "grammar_ref": 4.16331,
            "grammar_hyp": 3.59114,
            "nubia_score": 0.97707
        },
        "meteor": 0.45711364268294047,
        "bleurt": 0.29421,
        "bertscore": {
            "precision": 0.93717,
            "recall": 0.92813,
            "f1": 0.93263
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.62679,
        "msttr-100_nopunct": 0.659,
        "total_length": 7839,
        "mean_pred_length": 36.80281690140845,
        "std_pred_length": 8.880986259852875,
        "median_pred_length": 35.0,
        "min_pred_length": 20,
        "max_pred_length": 75,
        "distinct-1": 0.12450567674448272,
        "vocab_size-1": 976,
        "unique-1": 275,
        "entropy-1": 7.825289847487551,
        "distinct-2": 0.33175976921059536,
        "vocab_size-2": 2530,
        "unique-2": 1235,
        "entropy-2": 10.499478310756045,
        "cond_entropy-2": 2.567504866681486,
        "distinct-3": 0.4910292728989613,
        "vocab_size-3": 3640,
        "unique-3": 2226,
        "entropy-3": 11.346290669686605,
        "cond_entropy-3": 0.8751006244052428,
        "total_length-nopunct": 7042,
        "mean_pred_length-nopunct": 33.06103286384977,
        "std_pred_length-nopunct": 8.166175104331323,
        "median_pred_length-nopunct": 32.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.1374609485941494,
        "vocab_size-1-nopunct": 968,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 8.038634196909776,
        "distinct-2-nopunct": 0.34836725728510765,
        "vocab_size-2-nopunct": 2379,
        "unique-2-nopunct": 1202,
        "entropy-2-nopunct": 10.454157233051738,
        "cond_entropy-2-nopunct": 2.495334189505699,
        "distinct-3-nopunct": 0.5087666263603385,
        "vocab_size-3-nopunct": 3366,
        "unique-3-nopunct": 2132,
        "entropy-3-nopunct": 11.248588539092733,
        "cond_entropy-3-nopunct": 0.8159175736361479,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.72016,
            "recall": 0.71771,
            "fmeasure": 0.71298
        },
        "rouge2": {
            "precision": 0.43964,
            "recall": 0.43205,
            "fmeasure": 0.43175
        },
        "rougeL": {
            "precision": 0.51508,
            "recall": 0.5134,
            "fmeasure": 0.50923
        },
        "rougeLsum": {
            "precision": 0.51508,
            "recall": 0.5134,
            "fmeasure": 0.50923
        },
        "bleu": 45.24356,
        "nist": 8.3866003427762,
        "local_recall": {
            "1": 0.22807625649913346,
            "2": 0.5646050214329456,
            "3": 0.876621504756414
        },
        "nubia": {
            "semantic_relation": 4.32529,
            "contradiction": 10.66089,
            "irrelevancy": 9.83403,
            "logical_agreement": 79.50508,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.0633,
            "nubia_score": 0.76349
        },
        "meteor": 0.3663396738167658,
        "bleurt": 0.07599,
        "bertscore": {
            "precision": 0.90698,
            "recall": 0.90454,
            "f1": 0.90458
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.64048,
        "msttr-100_nopunct": 0.68145,
        "total_length": 6229,
        "mean_pred_length": 17.84813753581662,
        "std_pred_length": 5.217051415412277,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.15781024241451277,
        "vocab_size-1": 983,
        "unique-1": 384,
        "entropy-1": 7.759068336552366,
        "distinct-2": 0.4010204081632653,
        "vocab_size-2": 2358,
        "unique-2": 1345,
        "entropy-2": 10.454042666433129,
        "cond_entropy-2": 2.4780880800638956,
        "distinct-3": 0.5700596637136142,
        "vocab_size-3": 3153,
        "unique-3": 2160,
        "entropy-3": 11.206363937624575,
        "cond_entropy-3": 0.8261970858608065,
        "total_length-nopunct": 5516,
        "mean_pred_length-nopunct": 15.805157593123209,
        "std_pred_length-nopunct": 4.642753455187074,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.17675852066715012,
        "vocab_size-1-nopunct": 975,
        "unique-1-nopunct": 384,
        "entropy-1-nopunct": 7.999583955056591,
        "distinct-2-nopunct": 0.39616798916198953,
        "vocab_size-2-nopunct": 2047,
        "unique-2-nopunct": 1184,
        "entropy-2-nopunct": 10.229392583988126,
        "cond_entropy-2-nopunct": 2.4028080413405886,
        "distinct-3-nopunct": 0.5695309256953093,
        "vocab_size-3-nopunct": 2744,
        "unique-3-nopunct": 1901,
        "entropy-3-nopunct": 10.99385770873112,
        "cond_entropy-3-nopunct": 0.8245203555315986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73422,
            "recall": 0.76883,
            "fmeasure": 0.74386
        },
        "rouge2": {
            "precision": 0.49584,
            "recall": 0.52159,
            "fmeasure": 0.50256
        },
        "rougeL": {
            "precision": 0.61128,
            "recall": 0.64292,
            "fmeasure": 0.61991
        },
        "rougeLsum": {
            "precision": 0.61128,
            "recall": 0.64292,
            "fmeasure": 0.61991
        },
        "bleu": 46.98844,
        "nist": 8.274094100363246,
        "local_recall": {
            "1": 0.23018717642373557,
            "2": 0.5889487870619946,
            "3": 0.8755980861244019,
            "4": 1.0
        },
        "nubia": {
            "semantic_relation": 4.55824,
            "contradiction": 8.60517,
            "irrelevancy": 6.97836,
            "logical_agreement": 84.41647,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.7184,
            "nubia_score": 0.81015
        },
        "meteor": 0.4106955909694432,
        "bleurt": 0.20861,
        "bertscore": {
            "precision": 0.92024,
            "recall": 0.92643,
            "f1": 0.92186
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.63654,
        "msttr-100_nopunct": 0.70256,
        "total_length": 5258,
        "mean_pred_length": 24.23041474654378,
        "std_pred_length": 7.13803315623471,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 43,
        "distinct-1": 0.2708254089007227,
        "vocab_size-1": 1424,
        "unique-1": 737,
        "entropy-1": 8.605062611315466,
        "distinct-2": 0.5596111882562984,
        "vocab_size-2": 2821,
        "unique-2": 1859,
        "entropy-2": 10.99796979010649,
        "cond_entropy-2": 2.184358296657906,
        "distinct-3": 0.7133084577114428,
        "vocab_size-3": 3441,
        "unique-3": 2598,
        "entropy-3": 11.533900602082428,
        "cond_entropy-3": 0.5378244066655036,
        "total_length-nopunct": 4329,
        "mean_pred_length-nopunct": 19.94930875576037,
        "std_pred_length-nopunct": 6.178766373643009,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.3270963270963271,
        "vocab_size-1-nopunct": 1416,
        "unique-1-nopunct": 735,
        "entropy-1-nopunct": 9.251766149786254,
        "distinct-2-nopunct": 0.6106517509727627,
        "vocab_size-2-nopunct": 2511,
        "unique-2-nopunct": 1723,
        "entropy-2-nopunct": 10.939275709657423,
        "cond_entropy-2-nopunct": 1.7371765219927808,
        "distinct-3-nopunct": 0.74403080872914,
        "vocab_size-3-nopunct": 2898,
        "unique-3-nopunct": 2251,
        "entropy-3-nopunct": 11.313865597612143,
        "cond_entropy-3-nopunct": 0.3950531236726055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.53693,
            "recall": 0.53637,
            "fmeasure": 0.53154
        },
        "rouge2": {
            "precision": 0.28972,
            "recall": 0.29203,
            "fmeasure": 0.28642
        },
        "rougeL": {
            "precision": 0.50895,
            "recall": 0.50928,
            "fmeasure": 0.50379
        },
        "rougeLsum": {
            "precision": 0.50895,
            "recall": 0.50928,
            "fmeasure": 0.50379
        },
        "bleu": 48.46962,
        "nist": 8.531846332123198,
        "local_recall": {
            "1": 0.25950920245398773,
            "2": 0.6463022508038585,
            "3": 0.8980190755685987,
            "4": 1.0
        },
        "nubia": {
            "semantic_relation": 3.95503,
            "contradiction": 18.49881,
            "irrelevancy": 21.88771,
            "logical_agreement": 59.61348,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.5383,
            "nubia_score": 0.81934
        },
        "meteor": 0.6332813874553158,
        "bleurt": 0.12479,
        "bertscore": {
            "precision": 0.95094,
            "recall": 0.94868,
            "f1": 0.94921
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.635,
        "msttr-100_nopunct": 0.70711,
        "total_length": 4689,
        "mean_pred_length": 32.79020979020979,
        "std_pred_length": 10.798117646665682,
        "median_pred_length": 29.0,
        "min_pred_length": 14,
        "max_pred_length": 69,
        "distinct-1": 0.254851780763489,
        "vocab_size-1": 1195,
        "unique-1": 561,
        "entropy-1": 8.457552444871169,
        "distinct-2": 0.5208974923009239,
        "vocab_size-2": 2368,
        "unique-2": 1441,
        "entropy-2": 10.74336078371348,
        "cond_entropy-2": 2.1457363240855813,
        "distinct-3": 0.660458778105837,
        "vocab_size-3": 2908,
        "unique-3": 2068,
        "entropy-3": 11.235465189162735,
        "cond_entropy-3": 0.4977391861025917,
        "total_length-nopunct": 3800,
        "mean_pred_length-nopunct": 26.573426573426573,
        "std_pred_length-nopunct": 8.645698643939156,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.3128947368421053,
        "vocab_size-1-nopunct": 1189,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 9.139404811853987,
        "distinct-2-nopunct": 0.573147388569866,
        "vocab_size-2-nopunct": 2096,
        "unique-2-nopunct": 1358,
        "entropy-2-nopunct": 10.669498944110483,
        "cond_entropy-2-nopunct": 1.5578663302245486,
        "distinct-3-nopunct": 0.6949345475241889,
        "vocab_size-3-nopunct": 2442,
        "unique-3-nopunct": 1810,
        "entropy-3-nopunct": 11.028308296457942,
        "cond_entropy-3-nopunct": 0.3680241145817554,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.5477,
            "recall": 0.55963,
            "fmeasure": 0.54896
        },
        "rouge2": {
            "precision": 0.3601,
            "recall": 0.38008,
            "fmeasure": 0.36349
        },
        "rougeL": {
            "precision": 0.50714,
            "recall": 0.51796,
            "fmeasure": 0.50746
        },
        "rougeLsum": {
            "precision": 0.50714,
            "recall": 0.51796,
            "fmeasure": 0.50746
        },
        "bleu": 51.81035,
        "nist": 8.659045855270405,
        "local_recall": {
            "1": 0.2925222781867493,
            "2": 0.6850715746421268,
            "3": 0.8969754253308129
        },
        "nubia": {
            "semantic_relation": 3.92437,
            "contradiction": 19.34632,
            "irrelevancy": 21.40189,
            "logical_agreement": 59.25179,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.5017,
            "nubia_score": 0.82988
        },
        "meteor": 0.6614637269756926,
        "bleurt": 0.13397,
        "bertscore": {
            "precision": 0.95212,
            "recall": 0.95146,
            "f1": 0.95137
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.65158,
        "msttr-100_nopunct": 0.67187,
        "total_length": 1967,
        "mean_pred_length": 35.125,
        "std_pred_length": 8.252840420122032,
        "median_pred_length": 34.5,
        "min_pred_length": 21,
        "max_pred_length": 69,
        "distinct-1": 0.33248601931875954,
        "vocab_size-1": 654,
        "unique-1": 355,
        "entropy-1": 7.961583510200803,
        "distinct-2": 0.6216640502354788,
        "vocab_size-2": 1188,
        "unique-2": 804,
        "entropy-2": 9.879491330520521,
        "cond_entropy-2": 1.7960219999439226,
        "distinct-3": 0.7466307277628033,
        "vocab_size-3": 1385,
        "unique-3": 1054,
        "entropy-3": 10.265534819456493,
        "cond_entropy-3": 0.39221896656593175,
        "total_length-nopunct": 1619,
        "mean_pred_length-nopunct": 28.910714285714285,
        "std_pred_length-nopunct": 6.796208989771656,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.3990117356392835,
        "vocab_size-1-nopunct": 646,
        "unique-1-nopunct": 354,
        "entropy-1-nopunct": 8.481043717192223,
        "distinct-2-nopunct": 0.6679462571976967,
        "vocab_size-2-nopunct": 1044,
        "unique-2-nopunct": 737,
        "entropy-2-nopunct": 9.771453835314208,
        "cond_entropy-2-nopunct": 1.3150748329201254,
        "distinct-3-nopunct": 0.7796947577969475,
        "vocab_size-3-nopunct": 1175,
        "unique-3-nopunct": 931,
        "entropy-3-nopunct": 10.046117233063924,
        "cond_entropy-3-nopunct": 0.28038524423071004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.83085,
            "recall": 0.79745,
            "fmeasure": 0.80767
        },
        "rouge2": {
            "precision": 0.62946,
            "recall": 0.6127,
            "fmeasure": 0.61398
        },
        "rougeL": {
            "precision": 0.76469,
            "recall": 0.73531,
            "fmeasure": 0.74354
        },
        "rougeLsum": {
            "precision": 0.76469,
            "recall": 0.73531,
            "fmeasure": 0.74354
        },
        "bleu": 53.90953,
        "nist": 8.380432822927252,
        "local_recall": {
            "1": 0.26078971533516987,
            "2": 0.6597774244833068,
            "3": 0.9012345679012346
        },
        "nubia": {
            "semantic_relation": 3.774,
            "contradiction": 19.79224,
            "irrelevancy": 24.71077,
            "logical_agreement": 55.49699,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.49195,
            "nubia_score": 0.84004
        },
        "meteor": 0.6437013294503835,
        "bleurt": 0.17355,
        "bertscore": {
            "precision": 0.95287,
            "recall": 0.95021,
            "f1": 0.95108
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.60857,
        "msttr-100_nopunct": 0.615,
        "total_length": 764,
        "mean_pred_length": 40.21052631578947,
        "std_pred_length": 8.06277311161039,
        "median_pred_length": 39.0,
        "min_pred_length": 25,
        "max_pred_length": 54,
        "distinct-1": 0.2879581151832461,
        "vocab_size-1": 220,
        "unique-1": 91,
        "entropy-1": 6.759939142661274,
        "distinct-2": 0.4778523489932886,
        "vocab_size-2": 356,
        "unique-2": 188,
        "entropy-2": 8.092770007046942,
        "cond_entropy-2": 1.2559280372084596,
        "distinct-3": 0.5523415977961432,
        "vocab_size-3": 401,
        "unique-3": 240,
        "entropy-3": 8.365243144300651,
        "cond_entropy-3": 0.2775262785079453,
        "total_length-nopunct": 650,
        "mean_pred_length-nopunct": 34.21052631578947,
        "std_pred_length-nopunct": 7.5573522749176,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.33384615384615385,
        "vocab_size-1-nopunct": 217,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 7.00853730041494,
        "distinct-2-nopunct": 0.5023771790808241,
        "vocab_size-2-nopunct": 317,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.989532644483054,
        "cond_entropy-2-nopunct": 0.999536886915623,
        "distinct-3-nopunct": 0.5784313725490197,
        "vocab_size-3-nopunct": 354,
        "unique-3-nopunct": 223,
        "entropy-3-nopunct": 8.195089818131503,
        "cond_entropy-3-nopunct": 0.21240147718542235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.93571,
            "recall": 0.93304,
            "fmeasure": 0.928
        },
        "rouge2": {
            "precision": 0.67836,
            "recall": 0.67082,
            "fmeasure": 0.66788
        },
        "rougeL": {
            "precision": 0.85944,
            "recall": 0.8538,
            "fmeasure": 0.85059
        },
        "rougeLsum": {
            "precision": 0.85944,
            "recall": 0.8538,
            "fmeasure": 0.85059
        },
        "bleu": 61.54116,
        "nist": 7.562745587385343,
        "local_recall": {
            "1": 0.4067796610169492,
            "2": 0.6992481203007519,
            "3": 0.9455445544554455
        },
        "nubia": {
            "semantic_relation": 3.76174,
            "contradiction": 19.61478,
            "irrelevancy": 25.60023,
            "logical_agreement": 54.78499,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.50114,
            "nubia_score": 0.86536
        },
        "meteor": 0.7488413919725202,
        "bleurt": 0.19314,
        "bertscore": {
            "precision": 0.96226,
            "recall": 0.96008,
            "f1": 0.96114
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72641,
        "msttr-100_nopunct": 0.77159,
        "total_length": 7872,
        "mean_pred_length": 21.92757660167131,
        "std_pred_length": 9.145697344708735,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.36826727642276424,
        "vocab_size-1": 2899,
        "unique-1": 2127,
        "entropy-1": 9.246974371814963,
        "distinct-2": 0.8348196459470252,
        "vocab_size-2": 6272,
        "unique-2": 5809,
        "entropy-2": 12.278967879716744,
        "cond_entropy-2": 2.794687580953878,
        "distinct-3": 0.9636566955549343,
        "vocab_size-3": 6894,
        "unique-3": 6774,
        "entropy-3": 12.676595660248898,
        "cond_entropy-3": 0.41401468373945943,
        "total_length-nopunct": 6910,
        "mean_pred_length-nopunct": 19.24791086350975,
        "std_pred_length-nopunct": 7.931274425961432,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41794500723589,
        "vocab_size-1-nopunct": 2888,
        "unique-1-nopunct": 2127,
        "entropy-1-nopunct": 9.62963196659567,
        "distinct-2-nopunct": 0.8630743397954511,
        "vocab_size-2-nopunct": 5654,
        "unique-2-nopunct": 5281,
        "entropy-2-nopunct": 12.213759639242365,
        "cond_entropy-2-nopunct": 2.7129905594099775,
        "distinct-3-nopunct": 0.9828811369509044,
        "vocab_size-3-nopunct": 6086,
        "unique-3-nopunct": 6005,
        "entropy-3-nopunct": 12.557750920798163,
        "cond_entropy-3-nopunct": 0.36560027478198537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90381,
            "recall": 0.92223,
            "fmeasure": 0.90968
        },
        "rouge2": {
            "precision": 0.81248,
            "recall": 0.83712,
            "fmeasure": 0.82047
        },
        "rougeL": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "rougeLsum": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "bleu": 87.35189,
        "nist": 13.426135311676614,
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.18665768194070081,
            "3": 0.4108433734939759,
            "4": 0.6284403669724771,
            "5": 0.7556904400606981,
            "6": 0.8633802816901408,
            "7": 0.9180327868852459,
            "8": 0.962605548854041,
            "9": 0.9587301587301588,
            "10": 0.9868217054263566
        },
        "nubia": {
            "semantic_relation": 4.42253,
            "contradiction": 2.08708,
            "irrelevancy": 34.08185,
            "logical_agreement": 63.83107,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70222,
            "nubia_score": 0.70222
        },
        "meteor": 0.5615520197272345,
        "bleurt": 0.32083,
        "bertscore": {
            "precision": 0.97293,
            "recall": 0.98169,
            "f1": 0.97511
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72892,
        "msttr-100_nopunct": 0.77415,
        "total_length": 7473,
        "mean_pred_length": 20.81615598885794,
        "std_pred_length": 9.260673476905579,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3579553057674294,
        "vocab_size-1": 2675,
        "unique-1": 1949,
        "entropy-1": 9.169092875128287,
        "distinct-2": 0.8344110205229126,
        "vocab_size-2": 5936,
        "unique-2": 5505,
        "entropy-2": 12.196322045700507,
        "cond_entropy-2": 2.775686154122889,
        "distinct-3": 0.9613619541080681,
        "vocab_size-3": 6494,
        "unique-3": 6386,
        "entropy-3": 12.578535338759838,
        "cond_entropy-3": 0.4024308993694754,
        "total_length-nopunct": 6591,
        "mean_pred_length-nopunct": 18.35933147632312,
        "std_pred_length-nopunct": 8.059086506490225,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40388408435745715,
        "vocab_size-1-nopunct": 2662,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.522437969113502,
        "distinct-2-nopunct": 0.8629653401797176,
        "vocab_size-2-nopunct": 5378,
        "unique-2-nopunct": 5029,
        "entropy-2-nopunct": 12.141330080564511,
        "cond_entropy-2-nopunct": 2.7548271047488933,
        "distinct-3-nopunct": 0.9816107611101652,
        "vocab_size-3-nopunct": 5765,
        "unique-3-nopunct": 5685,
        "entropy-3-nopunct": 12.477857403520586,
        "cond_entropy-3-nopunct": 0.3587983845878242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84966,
            "recall": 0.81593,
            "fmeasure": 0.82379
        },
        "rouge2": {
            "precision": 0.71247,
            "recall": 0.68636,
            "fmeasure": 0.69017
        },
        "rougeL": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "bleu": 68.84591,
        "nist": 11.338523983358163,
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.17752234993614305,
            "3": 0.437636761487965,
            "4": 0.5768621236133122,
            "5": 0.6728971962616822,
            "6": 0.7874396135265701,
            "7": 0.8953799159984727
        },
        "nubia": {
            "semantic_relation": 4.3706,
            "contradiction": 4.05805,
            "irrelevancy": 17.82847,
            "logical_agreement": 78.11348,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.92526,
            "nubia_score": 0.71246
        },
        "meteor": 0.47385603354829703,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95042,
            "f1": 0.94997
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.602,
        "msttr-100_nopunct": 0.635,
        "total_length": 545,
        "mean_pred_length": 45.416666666666664,
        "std_pred_length": 5.880169120772709,
        "median_pred_length": 46.5,
        "min_pred_length": 34,
        "max_pred_length": 55,
        "distinct-1": 0.3211009174311927,
        "vocab_size-1": 175,
        "unique-1": 70,
        "entropy-1": 6.543599037404651,
        "distinct-2": 0.5384615384615384,
        "vocab_size-2": 287,
        "unique-2": 141,
        "entropy-2": 7.892668284282828,
        "cond_entropy-2": 1.2857813229226456,
        "distinct-3": 0.6468330134357005,
        "vocab_size-3": 337,
        "unique-3": 203,
        "entropy-3": 8.23045491151042,
        "cond_entropy-3": 0.3294602417512842,
        "total_length-nopunct": 460,
        "mean_pred_length-nopunct": 38.333333333333336,
        "std_pred_length-nopunct": 5.60257877132387,
        "median_pred_length-nopunct": 39.0,
        "min_pred_length-nopunct": 28,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3739130434782609,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.758238028039808,
        "distinct-2-nopunct": 0.5803571428571429,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.8131770348943865,
        "cond_entropy-2-nopunct": 1.0635932463042057,
        "distinct-3-nopunct": 0.6857798165137615,
        "vocab_size-3-nopunct": 299,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 8.078110500111562,
        "cond_entropy-3-nopunct": 0.26572514444937007,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.96779,
            "recall": 0.97222,
            "fmeasure": 0.96606
        },
        "rouge2": {
            "precision": 0.61898,
            "recall": 0.62176,
            "fmeasure": 0.6133
        },
        "rougeL": {
            "precision": 0.8795,
            "recall": 0.8872,
            "fmeasure": 0.87736
        },
        "rougeLsum": {
            "precision": 0.8795,
            "recall": 0.8872,
            "fmeasure": 0.87736
        },
        "bleu": 60.89069,
        "nist": 7.245144085417471,
        "local_recall": {
            "1": 0.4264705882352941,
            "2": 0.6149425287356322,
            "3": 0.9113924050632911
        },
        "nubia": {
            "semantic_relation": 3.61458,
            "contradiction": 25.29454,
            "irrelevancy": 24.51495,
            "logical_agreement": 50.19051,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.51704,
            "nubia_score": 0.86778
        },
        "meteor": 0.7202341769883704,
        "bleurt": 0.16902,
        "bertscore": {
            "precision": 0.95317,
            "recall": 0.95415,
            "f1": 0.95275
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.6413,
        "msttr-100_nopunct": 0.70862,
        "total_length": 23083,
        "mean_pred_length": 21.003639672429482,
        "std_pred_length": 11.445562313442357,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.1190486505220292,
        "vocab_size-1": 2748,
        "unique-1": 885,
        "entropy-1": 8.975408670713852,
        "distinct-2": 0.31632096069869,
        "vocab_size-2": 6954,
        "unique-2": 3426,
        "entropy-2": 11.85789465243351,
        "cond_entropy-2": 2.620696978439784,
        "distinct-3": 0.46923629399090255,
        "vocab_size-3": 9800,
        "unique-3": 5927,
        "entropy-3": 12.717807826500124,
        "cond_entropy-3": 0.8784535249652481,
        "total_length-nopunct": 18858,
        "mean_pred_length-nopunct": 17.159235668789808,
        "std_pred_length-nopunct": 9.568446674057778,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.14529642592003394,
        "vocab_size-1-nopunct": 2740,
        "unique-1-nopunct": 885,
        "entropy-1-nopunct": 9.731340996600217,
        "distinct-2-nopunct": 0.36009910467931755,
        "vocab_size-2-nopunct": 6395,
        "unique-2-nopunct": 3407,
        "entropy-2-nopunct": 11.862286355902492,
        "cond_entropy-2-nopunct": 2.204872730955892,
        "distinct-3-nopunct": 0.5108043217286915,
        "vocab_size-3-nopunct": 8510,
        "unique-3-nopunct": 5464,
        "entropy-3-nopunct": 12.553399755278905,
        "cond_entropy-3-nopunct": 0.7324875781432586,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.4508,
            "recall": 0.45333,
            "fmeasure": 0.44849
        },
        "rouge2": {
            "precision": 0.25611,
            "recall": 0.25832,
            "fmeasure": 0.25411
        },
        "rougeL": {
            "precision": 0.42993,
            "recall": 0.43276,
            "fmeasure": 0.42759
        },
        "rougeLsum": {
            "precision": 0.42993,
            "recall": 0.43276,
            "fmeasure": 0.42759
        },
        "bleu": 52.21459,
        "nist": 9.568450848873356,
        "local_recall": {
            "1": 0.2946185773579505,
            "2": 0.673053066850448,
            "3": 0.894391296192084,
            "4": 0.948051948051948,
            "5": 0.8918918918918919,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.02863,
            "contradiction": 19.35804,
            "irrelevancy": 21.42593,
            "logical_agreement": 59.21603,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.64067,
            "nubia_score": 0.83683
        },
        "meteor": 0.6694873453192137,
        "bleurt": 0.21923,
        "bertscore": {
            "precision": 0.95883,
            "recall": 0.95701,
            "f1": 0.9573
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.33429,
        "msttr-100_nopunct": 0.34514,
        "total_length": 4252,
        "mean_pred_length": 8.504,
        "std_pred_length": 1.7291570200534132,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.027281279397930385,
        "vocab_size-1": 116,
        "unique-1": 36,
        "entropy-1": 4.896612037248356,
        "distinct-2": 0.09088486140724947,
        "vocab_size-2": 341,
        "unique-2": 145,
        "entropy-2": 6.4782003135317305,
        "cond_entropy-2": 1.3617076344594263,
        "distinct-3": 0.1663591635916359,
        "vocab_size-3": 541,
        "unique-3": 268,
        "entropy-3": 7.236032912712716,
        "cond_entropy-3": 0.8542406340059718,
        "total_length-nopunct": 3759,
        "mean_pred_length-nopunct": 7.518,
        "std_pred_length-nopunct": 1.7290679570219327,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.030061186485767492,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 4.9435530329463315,
        "distinct-2-nopunct": 0.09297330469469162,
        "vocab_size-2-nopunct": 303,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 6.183895046577444,
        "cond_entropy-2-nopunct": 1.4483588616342624,
        "distinct-3-nopunct": 0.1660021747009786,
        "vocab_size-3-nopunct": 458,
        "unique-3-nopunct": 234,
        "entropy-3-nopunct": 6.861204408402104,
        "cond_entropy-3-nopunct": 0.9337825483289943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.5681,
            "recall": 0.55086,
            "fmeasure": 0.54974
        },
        "rouge2": {
            "precision": 0.34432,
            "recall": 0.33168,
            "fmeasure": 0.3308
        },
        "rougeL": {
            "precision": 0.5481,
            "recall": 0.53322,
            "fmeasure": 0.5313
        },
        "rougeLsum": {
            "precision": 0.5481,
            "recall": 0.53322,
            "fmeasure": 0.5313
        },
        "bleu": 29.21848,
        "nist": 3.756027683468856,
        "local_recall": {
            "1": 0.5362357313512078
        },
        "nubia": {
            "semantic_relation": 3.64127,
            "contradiction": 7.4361,
            "irrelevancy": 22.09287,
            "logical_agreement": 70.47103,
            "grammar_ref": 4.43492,
            "grammar_hyp": 3.98374,
            "nubia_score": 0.70441
        },
        "meteor": 0.293404934346175,
        "bleurt": 0.08078,
        "bertscore": {
            "precision": 0.88912,
            "recall": 0.88703,
            "f1": 0.88772
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 21.666666666666668,
        "std_pred_length": 10.274023338281626,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 35,
        "distinct-1": 0.5846153846153846,
        "vocab_size-1": 38,
        "unique-1": 29,
        "entropy-1": 4.805543444877674,
        "distinct-2": 0.8709677419354839,
        "vocab_size-2": 54,
        "unique-2": 49,
        "entropy-2": 5.659604979637028,
        "cond_entropy-2": 0.816165939669879,
        "distinct-3": 0.9152542372881356,
        "vocab_size-3": 54,
        "unique-3": 50,
        "entropy-3": 5.700356820511608,
        "cond_entropy-3": 0.05573106108220214,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 6.599663291074444,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7608695652173914,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.952591032002871,
        "distinct-2-nopunct": 0.8837209302325582,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.15859556855496,
        "cond_entropy-2-nopunct": 0.24583971730004933,
        "distinct-3-nopunct": 0.925,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.153055907333276,
        "cond_entropy-3-nopunct": 0.014535527739350932,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 75.70762,
        "nist": 5.954961377499613,
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.8333333333333334,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.82928,
            "contradiction": 22.86639,
            "irrelevancy": 17.8377,
            "logical_agreement": 59.2959,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.68735,
            "nubia_score": 0.76077
        },
        "meteor": 0.8019823989472722,
        "bleurt": 0.14365,
        "bertscore": {
            "precision": 0.96656,
            "recall": 0.95789,
            "f1": 0.96161
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.51245,
        "msttr-100_nopunct": 0.53333,
        "total_length": 21657,
        "mean_pred_length": 10.42204042348412,
        "std_pred_length": 5.5104621182608176,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 38,
        "distinct-1": 0.023687491342291176,
        "vocab_size-1": 513,
        "unique-1": 156,
        "entropy-1": 6.282592154124254,
        "distinct-2": 0.11885183104346493,
        "vocab_size-2": 2327,
        "unique-2": 1050,
        "entropy-2": 9.12481586595649,
        "cond_entropy-2": 2.5424891010748394,
        "distinct-3": 0.25432832409576595,
        "vocab_size-3": 4451,
        "unique-3": 2601,
        "entropy-3": 10.49150441311666,
        "cond_entropy-3": 1.4271990648201953,
        "total_length-nopunct": 18951,
        "mean_pred_length-nopunct": 9.119826756496632,
        "std_pred_length-nopunct": 5.018213369071945,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.026753205635586513,
        "vocab_size-1-nopunct": 507,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 6.45196492796847,
        "distinct-2-nopunct": 0.12961536182066022,
        "vocab_size-2-nopunct": 2187,
        "unique-2-nopunct": 1083,
        "entropy-2-nopunct": 8.875997281800192,
        "cond_entropy-2-nopunct": 2.612988801013438,
        "distinct-3-nopunct": 0.2656799134901325,
        "vocab_size-3-nopunct": 3931,
        "unique-3-nopunct": 2423,
        "entropy-3-nopunct": 10.215124665852327,
        "cond_entropy-3-nopunct": 1.4551187228388602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.47732,
            "recall": 0.44137,
            "fmeasure": 0.44312
        },
        "rouge2": {
            "precision": 0.23937,
            "recall": 0.22473,
            "fmeasure": 0.22263
        },
        "rougeL": {
            "precision": 0.43556,
            "recall": 0.40401,
            "fmeasure": 0.40538
        },
        "rougeLsum": {
            "precision": 0.43556,
            "recall": 0.40401,
            "fmeasure": 0.40538
        },
        "bleu": 17.64877,
        "nist": 3.6792407339377204,
        "local_recall": {
            "1": 0.43524602887152686
        },
        "nubia": {
            "semantic_relation": 3.09252,
            "contradiction": 12.3332,
            "irrelevancy": 25.63662,
            "logical_agreement": 62.03019,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.35837,
            "nubia_score": 0.52231
        },
        "meteor": 0.2337794061672785,
        "bleurt": -0.26389,
        "bertscore": {
            "precision": 0.84761,
            "recall": 0.83711,
            "f1": 0.84157
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.63936,
        "msttr-100_nopunct": 0.70976,
        "total_length": 20419,
        "mean_pred_length": 20.70892494929006,
        "std_pred_length": 11.785501004859482,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.12649982859101816,
        "vocab_size-1": 2583,
        "unique-1": 882,
        "entropy-1": 8.93122525067943,
        "distinct-2": 0.32702104667318477,
        "vocab_size-2": 6355,
        "unique-2": 3226,
        "entropy-2": 11.751693259946991,
        "cond_entropy-2": 2.5569047067010016,
        "distinct-3": 0.477747059142408,
        "vocab_size-3": 8813,
        "unique-3": 5450,
        "entropy-3": 12.568164728855821,
        "cond_entropy-3": 0.8360181726188163,
        "total_length-nopunct": 16646,
        "mean_pred_length-nopunct": 16.88235294117647,
        "std_pred_length-nopunct": 9.811837912763608,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.15469181785413913,
        "vocab_size-1-nopunct": 2575,
        "unique-1-nopunct": 882,
        "entropy-1-nopunct": 9.68675405216472,
        "distinct-2-nopunct": 0.3697956577266922,
        "vocab_size-2-nopunct": 5791,
        "unique-2-nopunct": 3157,
        "entropy-2-nopunct": 11.73979928206619,
        "cond_entropy-2-nopunct": 2.12773216396262,
        "distinct-3-nopunct": 0.5168324928444868,
        "vocab_size-3-nopunct": 7584,
        "unique-3-nopunct": 4942,
        "entropy-3-nopunct": 12.388537239524602,
        "cond_entropy-3-nopunct": 0.6902517028631091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.4845,
            "recall": 0.48601,
            "fmeasure": 0.48142
        },
        "rouge2": {
            "precision": 0.27698,
            "recall": 0.27846,
            "fmeasure": 0.27435
        },
        "rougeL": {
            "precision": 0.46166,
            "recall": 0.46351,
            "fmeasure": 0.45855
        },
        "rougeLsum": {
            "precision": 0.46166,
            "recall": 0.46351,
            "fmeasure": 0.45855
        },
        "bleu": 53.13604,
        "nist": 9.562966291062892,
        "local_recall": {
            "1": 0.30093992644053946,
            "2": 0.6725346627200498,
            "3": 0.8946813001266357,
            "4": 0.948051948051948,
            "5": 0.8918918918918919,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.03284,
            "contradiction": 19.44028,
            "irrelevancy": 21.49401,
            "logical_agreement": 59.06571,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.65343,
            "nubia_score": 0.83858
        },
        "meteor": 0.6776026611739889,
        "bleurt": 0.22743,
        "bertscore": {
            "precision": 0.95939,
            "recall": 0.95793,
            "f1": 0.95805
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.60444,
        "msttr-100_nopunct": 0.67182,
        "total_length": 2729,
        "mean_pred_length": 23.525862068965516,
        "std_pred_length": 7.491905064682575,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 60,
        "distinct-1": 0.25833638695492855,
        "vocab_size-1": 705,
        "unique-1": 329,
        "entropy-1": 7.905576262299575,
        "distinct-2": 0.5231534634519709,
        "vocab_size-2": 1367,
        "unique-2": 854,
        "entropy-2": 9.936759182924312,
        "cond_entropy-2": 1.846966616135641,
        "distinct-3": 0.657989587505006,
        "vocab_size-3": 1643,
        "unique-3": 1164,
        "entropy-3": 10.422094252824973,
        "cond_entropy-3": 0.4918567000717473,
        "total_length-nopunct": 2258,
        "mean_pred_length-nopunct": 19.46551724137931,
        "std_pred_length-nopunct": 6.658454613189884,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 51,
        "distinct-1-nopunct": 0.3095659875996457,
        "vocab_size-1-nopunct": 699,
        "unique-1-nopunct": 328,
        "entropy-1-nopunct": 8.393067534621402,
        "distinct-2-nopunct": 0.5588235294117647,
        "vocab_size-2-nopunct": 1197,
        "unique-2-nopunct": 779,
        "entropy-2-nopunct": 9.79322461060566,
        "cond_entropy-2-nopunct": 1.438054741569276,
        "distinct-3-nopunct": 0.6836130306021717,
        "vocab_size-3-nopunct": 1385,
        "unique-3-nopunct": 1012,
        "entropy-3-nopunct": 10.194084825055413,
        "cond_entropy-3-nopunct": 0.42659225782176957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.15268,
            "recall": 0.16379,
            "fmeasure": 0.15699
        },
        "rouge2": {
            "precision": 0.07213,
            "recall": 0.08046,
            "fmeasure": 0.07549
        },
        "rougeL": {
            "precision": 0.14909,
            "recall": 0.1602,
            "fmeasure": 0.1534
        },
        "rougeLsum": {
            "precision": 0.14909,
            "recall": 0.1602,
            "fmeasure": 0.1534
        },
        "bleu": 45.23861,
        "nist": 7.714176777674318,
        "local_recall": {
            "1": 0.24774774774774774,
            "2": 0.6792452830188679,
            "3": 0.8904991948470209
        },
        "nubia": {
            "semantic_relation": 3.9877,
            "contradiction": 18.74974,
            "irrelevancy": 20.75453,
            "logical_agreement": 60.49573,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.53337,
            "nubia_score": 0.82001
        },
        "meteor": 0.6121826271642355,
        "bleurt": 0.14756,
        "bertscore": {
            "precision": 0.95425,
            "recall": 0.94915,
            "f1": 0.95108
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.53685,
        "msttr-100_nopunct": 0.56532,
        "total_length": 5406,
        "mean_pred_length": 11.933774834437086,
        "std_pred_length": 5.07254507768975,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 40,
        "distinct-1": 0.16944136145024047,
        "vocab_size-1": 916,
        "unique-1": 458,
        "entropy-1": 7.506276260030123,
        "distinct-2": 0.4387240056531395,
        "vocab_size-2": 2173,
        "unique-2": 1398,
        "entropy-2": 10.312302230545761,
        "cond_entropy-2": 2.44854163852475,
        "distinct-3": 0.6257777777777778,
        "vocab_size-3": 2816,
        "unique-3": 2130,
        "entropy-3": 11.043496670193706,
        "cond_entropy-3": 0.8387038807229008,
        "total_length-nopunct": 4772,
        "mean_pred_length-nopunct": 10.534216335540838,
        "std_pred_length-nopunct": 4.633289575316847,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 36,
        "distinct-1-nopunct": 0.19006705783738476,
        "vocab_size-1-nopunct": 907,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 7.746430267536862,
        "distinct-2-nopunct": 0.4181523500810373,
        "vocab_size-2-nopunct": 1806,
        "unique-2-nopunct": 1150,
        "entropy-2-nopunct": 9.995979873662904,
        "cond_entropy-2-nopunct": 2.5374480319842836,
        "distinct-3-nopunct": 0.61148473874806,
        "vocab_size-3-nopunct": 2364,
        "unique-3-nopunct": 1771,
        "entropy-3-nopunct": 10.767069858030156,
        "cond_entropy-3-nopunct": 0.8853361848281895,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.75278,
            "recall": 0.75147,
            "fmeasure": 0.74414
        },
        "rouge2": {
            "precision": 0.52014,
            "recall": 0.5187,
            "fmeasure": 0.51289
        },
        "rougeL": {
            "precision": 0.6535,
            "recall": 0.65144,
            "fmeasure": 0.64498
        },
        "rougeLsum": {
            "precision": 0.6535,
            "recall": 0.65144,
            "fmeasure": 0.64498
        },
        "bleu": 48.40935,
        "nist": 8.264136134423357,
        "local_recall": {
            "1": 0.23692307692307693,
            "2": 0.6183879093198993,
            "3": 0.8415572657311,
            "4": 0.9736842105263158
        },
        "nubia": {
            "semantic_relation": 4.49564,
            "contradiction": 8.97275,
            "irrelevancy": 8.3493,
            "logical_agreement": 82.67795,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.27033,
            "nubia_score": 0.7815
        },
        "meteor": 0.4174671308277163,
        "bleurt": 0.24151,
        "bertscore": {
            "precision": 0.92921,
            "recall": 0.93034,
            "f1": 0.92856
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72892,
        "msttr-100_nopunct": 0.77415,
        "total_length": 7473,
        "mean_pred_length": 20.81615598885794,
        "std_pred_length": 9.260673476905579,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3579553057674294,
        "vocab_size-1": 2675,
        "unique-1": 1949,
        "entropy-1": 9.169092875128287,
        "distinct-2": 0.8344110205229126,
        "vocab_size-2": 5936,
        "unique-2": 5505,
        "entropy-2": 12.196322045700507,
        "cond_entropy-2": 2.775686154122889,
        "distinct-3": 0.9613619541080681,
        "vocab_size-3": 6494,
        "unique-3": 6386,
        "entropy-3": 12.578535338759838,
        "cond_entropy-3": 0.4024308993694754,
        "total_length-nopunct": 6591,
        "mean_pred_length-nopunct": 18.35933147632312,
        "std_pred_length-nopunct": 8.059086506490225,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40388408435745715,
        "vocab_size-1-nopunct": 2662,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.522437969113502,
        "distinct-2-nopunct": 0.8629653401797176,
        "vocab_size-2-nopunct": 5378,
        "unique-2-nopunct": 5029,
        "entropy-2-nopunct": 12.141330080564511,
        "cond_entropy-2-nopunct": 2.7548271047488933,
        "distinct-3-nopunct": 0.9816107611101652,
        "vocab_size-3-nopunct": 5765,
        "unique-3-nopunct": 5685,
        "entropy-3-nopunct": 12.477857403520586,
        "cond_entropy-3-nopunct": 0.3587983845878242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84966,
            "recall": 0.81593,
            "fmeasure": 0.82379
        },
        "rouge2": {
            "precision": 0.71247,
            "recall": 0.68636,
            "fmeasure": 0.69017
        },
        "rougeL": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "bleu": 68.84591,
        "nist": 11.338523983358163,
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.17752234993614305,
            "3": 0.437636761487965,
            "4": 0.5768621236133122,
            "5": 0.6728971962616822,
            "6": 0.7874396135265701,
            "7": 0.8953799159984727
        },
        "nubia": {
            "semantic_relation": 4.3706,
            "contradiction": 4.05805,
            "irrelevancy": 17.82847,
            "logical_agreement": 78.11348,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.92526,
            "nubia_score": 0.71246
        },
        "meteor": 0.47385603354829703,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95042,
            "f1": 0.94997
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "mT5_large/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.26094,
        "msttr-100_nopunct": 0.25411,
        "total_length": 6490,
        "mean_pred_length": 9.076923076923077,
        "std_pred_length": 3.5000038423094257,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 25,
        "distinct-1": 0.01802773497688752,
        "vocab_size-1": 117,
        "unique-1": 28,
        "entropy-1": 4.530023864853555,
        "distinct-2": 0.05887445887445888,
        "vocab_size-2": 340,
        "unique-2": 131,
        "entropy-2": 5.7741938009941505,
        "cond_entropy-2": 1.079923691349693,
        "distinct-3": 0.09525691699604744,
        "vocab_size-3": 482,
        "unique-3": 222,
        "entropy-3": 6.2411094626767865,
        "cond_entropy-3": 0.43072783206158055,
        "total_length-nopunct": 5691,
        "mean_pred_length-nopunct": 7.9594405594405595,
        "std_pred_length-nopunct": 3.1833974410126427,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.019855912844842734,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.46272616398245,
        "distinct-2-nopunct": 0.06270096463022508,
        "vocab_size-2-nopunct": 312,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 5.541049426190374,
        "cond_entropy-2-nopunct": 1.0296644759077753,
        "distinct-3-nopunct": 0.10021121802393804,
        "vocab_size-3-nopunct": 427,
        "unique-3-nopunct": 205,
        "entropy-3-nopunct": 5.99394379207699,
        "cond_entropy-3-nopunct": 0.3838070073016079,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "rouge1": {
            "precision": 0.55549,
            "recall": 0.56134,
            "fmeasure": 0.54574
        },
        "rouge2": {
            "precision": 0.3199,
            "recall": 0.31665,
            "fmeasure": 0.31035
        },
        "rougeL": {
            "precision": 0.47966,
            "recall": 0.47847,
            "fmeasure": 0.46826
        },
        "rougeLsum": {
            "precision": 0.47966,
            "recall": 0.47847,
            "fmeasure": 0.46826
        },
        "bleu": 27.88252,
        "nist": 3.0903799639474476,
        "local_recall": {
            "1": 0.5514085770680065
        },
        "nubia": {
            "semantic_relation": 3.61238,
            "contradiction": 1.03587,
            "irrelevancy": 23.74875,
            "logical_agreement": 75.21538,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.63856,
            "nubia_score": 0.71702
        },
        "meteor": 0.28638053855290224,
        "bleurt": 0.16453,
        "bertscore": {
            "precision": 0.8586,
            "recall": 0.85661,
            "f1": 0.85699
        }
    },
    "xsum_test": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 1166,
        "msttr-100": 0.7066,
        "msttr-100_nopunct": 0.72396,
        "total_length": 23876,
        "mean_pred_length": 20.476843910806174,
        "std_pred_length": 4.485432374888886,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 62,
        "distinct-1": 0.18977215614005696,
        "vocab_size-1": 4531,
        "unique-1": 2601,
        "entropy-1": 9.100817378524775,
        "distinct-2": 0.5970937912813739,
        "vocab_size-2": 13560,
        "unique-2": 11067,
        "entropy-2": 12.836462383177599,
        "cond_entropy-2": 3.492900262587741,
        "distinct-3": 0.8270051986632009,
        "vocab_size-3": 17817,
        "unique-3": 16312,
        "entropy-3": 13.835394618531504,
        "cond_entropy-3": 1.00681264221243,
        "total_length-nopunct": 22241,
        "mean_pred_length-nopunct": 19.074614065180103,
        "std_pred_length-nopunct": 4.310873063118442,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.203228272110067,
        "vocab_size-1-nopunct": 4520,
        "unique-1-nopunct": 2600,
        "entropy-1-nopunct": 9.286312454164708,
        "distinct-2-nopunct": 0.6046026097271648,
        "vocab_size-2-nopunct": 12742,
        "unique-2-nopunct": 10446,
        "entropy-2-nopunct": 12.766667847274544,
        "cond_entropy-2-nopunct": 3.6128039871609774,
        "distinct-3-nopunct": 0.838314330202421,
        "vocab_size-3-nopunct": 16690,
        "unique-3-nopunct": 15330,
        "entropy-3-nopunct": 13.777688803593877,
        "cond_entropy-3-nopunct": 1.0255588476062052,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.41419,
            "recall": 0.36864,
            "fmeasure": 0.38207
        },
        "rouge2": {
            "precision": 0.15693,
            "recall": 0.13855,
            "fmeasure": 0.14392
        },
        "rougeL": {
            "precision": 0.31998,
            "recall": 0.28537,
            "fmeasure": 0.2953
        },
        "rougeLsum": {
            "precision": 0.31998,
            "recall": 0.28537,
            "fmeasure": 0.2953
        },
        "bleu": 8.92168,
        "nist": 3.7287544049253065,
        "local_recall": {
            "1": 0.3399069449780168
        },
        "nubia": {
            "semantic_relation": 2.86188,
            "contradiction": 23.0281,
            "irrelevancy": 63.70664,
            "logical_agreement": 13.26526,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.60567,
            "nubia_score": 0.41171
        },
        "meteor": 0.16543657305060006,
        "bleurt": -0.3344,
        "bertscore": {
            "precision": 0.83454,
            "recall": 0.81682,
            "f1": 0.82525
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "mT5_large/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.75269,
        "msttr-100_nopunct": 0.77189,
        "total_length": 11997,
        "mean_pred_length": 23.994,
        "std_pred_length": 5.941545590164229,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.287488538801367,
        "vocab_size-1": 3449,
        "unique-1": 2253,
        "entropy-1": 9.378547088989013,
        "distinct-2": 0.780203531356006,
        "vocab_size-2": 8970,
        "unique-2": 8003,
        "entropy-2": 12.739398457718115,
        "cond_entropy-2": 3.154905450149176,
        "distinct-3": 0.9552605255978903,
        "vocab_size-3": 10505,
        "unique-3": 10228,
        "entropy-3": 13.305395617498426,
        "cond_entropy-3": 0.5716650412808119,
        "total_length-nopunct": 11184,
        "mean_pred_length-nopunct": 22.368,
        "std_pred_length-nopunct": 5.749136978712544,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.3074928469241774,
        "vocab_size-1-nopunct": 3439,
        "unique-1-nopunct": 2253,
        "entropy-1-nopunct": 9.556604217828003,
        "distinct-2-nopunct": 0.7879071508798203,
        "vocab_size-2-nopunct": 8418,
        "unique-2-nopunct": 7551,
        "entropy-2-nopunct": 12.65904278959114,
        "cond_entropy-2-nopunct": 3.203824767955092,
        "distinct-3-nopunct": 0.9596425765907306,
        "vocab_size-3-nopunct": 9773,
        "unique-3-nopunct": 9529,
        "entropy-3-nopunct": 13.212452198357672,
        "cond_entropy-3-nopunct": 0.5678389671166408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "rouge1": {
            "precision": 0.27534,
            "recall": 0.2903,
            "fmeasure": 0.27503
        },
        "rouge2": {
            "precision": 0.06176,
            "recall": 0.06589,
            "fmeasure": 0.06194
        },
        "rougeL": {
            "precision": 0.19948,
            "recall": 0.21039,
            "fmeasure": 0.19909
        },
        "rougeLsum": {
            "precision": 0.19948,
            "recall": 0.21039,
            "fmeasure": 0.19909
        },
        "bleu": 3.52659,
        "nist": 2.29199131663254,
        "local_recall": {
            "1": 0.26523804710401294
        },
        "nubia": {
            "semantic_relation": 2.02307,
            "contradiction": 30.88242,
            "irrelevancy": 64.76228,
            "logical_agreement": 4.3553,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.53846,
            "nubia_score": 0.20762
        },
        "meteor": 0.12016303802972883,
        "bleurt": -0.67811,
        "bertscore": {
            "precision": 0.79003,
            "recall": 0.79201,
            "f1": 0.79073
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.45238,
            "recall": 0.24488,
            "fmeasure": 0.31373
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.12302,
            "fmeasure": 0.15846
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.23587,
            "fmeasure": 0.30065
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.23587,
            "fmeasure": 0.30065
        },
        "bleu": 5.69617,
        "nist": 0.3606968816041921,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.23529411764705882
        },
        "nubia": {
            "semantic_relation": 3.09197,
            "contradiction": 95.89533,
            "irrelevancy": 2.1113,
            "logical_agreement": 1.99338,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.01325,
            "nubia_score": 0.30553
        },
        "meteor": 0.1756737359804898,
        "bleurt": -0.12172,
        "bertscore": {
            "precision": 0.89857,
            "recall": 0.81633,
            "f1": 0.85548
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "mT5_large/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.62222,
        "msttr-100_nopunct": 0.68417,
        "total_length": 11760,
        "mean_pred_length": 18.317757009345794,
        "std_pred_length": 12.050592827423777,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 69,
        "distinct-1": 0.16522108843537414,
        "vocab_size-1": 1943,
        "unique-1": 789,
        "entropy-1": 8.77830237859021,
        "distinct-2": 0.3888289260658392,
        "vocab_size-2": 4323,
        "unique-2": 2395,
        "entropy-2": 11.35242852640065,
        "cond_entropy-2": 2.2813721200376422,
        "distinct-3": 0.5349369988545246,
        "vocab_size-3": 5604,
        "unique-3": 3687,
        "entropy-3": 11.999432156420937,
        "cond_entropy-3": 0.6584735666219257,
        "total_length-nopunct": 9622,
        "mean_pred_length-nopunct": 14.98753894080997,
        "std_pred_length-nopunct": 9.917722290854627,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.2012055705674496,
        "vocab_size-1-nopunct": 1936,
        "unique-1-nopunct": 789,
        "entropy-1-nopunct": 9.47038711409237,
        "distinct-2-nopunct": 0.4234966592427617,
        "vocab_size-2-nopunct": 3803,
        "unique-2-nopunct": 2212,
        "entropy-2-nopunct": 11.254045719981121,
        "cond_entropy-2-nopunct": 1.8596913220903004,
        "distinct-3-nopunct": 0.5633245382585752,
        "vocab_size-3-nopunct": 4697,
        "unique-3-nopunct": 3178,
        "entropy-3-nopunct": 11.782213456590975,
        "cond_entropy-3-nopunct": 0.5778819575314806,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "rouge1": {
            "precision": 0.51467,
            "recall": 0.51613,
            "fmeasure": 0.51185
        },
        "rouge2": {
            "precision": 0.3177,
            "recall": 0.32134,
            "fmeasure": 0.31628
        },
        "rougeL": {
            "precision": 0.48388,
            "recall": 0.48554,
            "fmeasure": 0.48095
        },
        "rougeLsum": {
            "precision": 0.48388,
            "recall": 0.48554,
            "fmeasure": 0.48095
        },
        "bleu": 56.2301,
        "nist": 9.510700545021555,
        "local_recall": {
            "1": 0.3116845037384548,
            "2": 0.6754768392370573,
            "3": 0.8985304408677397,
            "4": 0.9473684210526315,
            "5": 0.9393939393939394,
            "6": 1.0,
            "7": 1.0
        },
        "nubia": {
            "semantic_relation": 4.05805,
            "contradiction": 19.43391,
            "irrelevancy": 21.46736,
            "logical_agreement": 59.09873,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.73181,
            "nubia_score": 0.84202
        },
        "meteor": 0.698627591430742,
        "bleurt": 0.26036,
        "bertscore": {
            "precision": 0.96201,
            "recall": 0.96057,
            "f1": 0.9607
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71131,
            "recall": 0.67199,
            "fmeasure": 0.66518
        },
        "rouge2": {
            "precision": 0.4895,
            "recall": 0.44961,
            "fmeasure": 0.45374
        },
        "rougeL": {
            "precision": 0.6353,
            "recall": 0.60329,
            "fmeasure": 0.59596
        },
        "rougeLsum": {
            "precision": 0.6353,
            "recall": 0.60329,
            "fmeasure": 0.59596
        },
        "bleu": 51.0892,
        "nist": 5.6910583939217885,
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.53125,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.0757,
            "contradiction": 6.97432,
            "irrelevancy": 23.87541,
            "logical_agreement": 69.15027,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.26446,
            "nubia_score": 0.65573
        },
        "meteor": 0.398940700301294,
        "bleurt": 0.24999,
        "bertscore": {
            "precision": 0.92125,
            "recall": 0.91113,
            "f1": 0.91483
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.70455,
        "msttr-100_nopunct": 0.7315,
        "total_length": 2203,
        "mean_pred_length": 20.78301886792453,
        "std_pred_length": 4.34156027292235,
        "median_pred_length": 20.5,
        "min_pred_length": 12,
        "max_pred_length": 36,
        "distinct-1": 0.3990013617793917,
        "vocab_size-1": 879,
        "unique-1": 652,
        "entropy-1": 8.17929955867725,
        "distinct-2": 0.8192656175488794,
        "vocab_size-2": 1718,
        "unique-2": 1529,
        "entropy-2": 10.530858484997177,
        "cond_entropy-2": 2.158690851388533,
        "distinct-3": 0.9563033651431442,
        "vocab_size-3": 1904,
        "unique-3": 1839,
        "entropy-3": 10.85755509235339,
        "cond_entropy-3": 0.32784730262148193,
        "total_length-nopunct": 2037,
        "mean_pred_length-nopunct": 19.21698113207547,
        "std_pred_length-nopunct": 4.03289473493175,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.42808051055473734,
        "vocab_size-1-nopunct": 872,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.312028840003828,
        "distinct-2-nopunct": 0.8280683583635422,
        "vocab_size-2-nopunct": 1599,
        "unique-2-nopunct": 1423,
        "entropy-2-nopunct": 10.448468483630613,
        "cond_entropy-2-nopunct": 2.2248921673995135,
        "distinct-3-nopunct": 0.9643835616438357,
        "vocab_size-3-nopunct": 1760,
        "unique-3-nopunct": 1704,
        "entropy-3-nopunct": 10.758187906183267,
        "cond_entropy-3-nopunct": 0.30822964302984995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.45829,
            "recall": 0.44426,
            "fmeasure": 0.44128
        },
        "rouge2": {
            "precision": 0.22042,
            "recall": 0.21292,
            "fmeasure": 0.21157
        },
        "rougeL": {
            "precision": 0.36096,
            "recall": 0.34939,
            "fmeasure": 0.34727
        },
        "rougeLsum": {
            "precision": 0.36096,
            "recall": 0.34939,
            "fmeasure": 0.34727
        },
        "bleu": 15.78637,
        "nist": 4.064641170560553,
        "local_recall": {
            "1": 0.4216928535225545
        },
        "nubia": {
            "semantic_relation": 3.11585,
            "contradiction": 18.74211,
            "irrelevancy": 66.56067,
            "logical_agreement": 14.69723,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.58653,
            "nubia_score": 0.48315
        },
        "meteor": 0.21076212198646452,
        "bleurt": -0.24094,
        "bertscore": {
            "precision": 0.85039,
            "recall": 0.8415,
            "f1": 0.84555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72489,
            "recall": 0.69345,
            "fmeasure": 0.70286
        },
        "rouge2": {
            "precision": 0.4824,
            "recall": 0.44819,
            "fmeasure": 0.46074
        },
        "rougeL": {
            "precision": 0.62135,
            "recall": 0.58003,
            "fmeasure": 0.59516
        },
        "rougeLsum": {
            "precision": 0.62135,
            "recall": 0.58003,
            "fmeasure": 0.59516
        },
        "bleu": 34.84152,
        "nist": 4.391157166151353,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3076923076923077,
            "3": 0.6533333333333333
        },
        "nubia": {
            "semantic_relation": 4.05006,
            "contradiction": 1.20643,
            "irrelevancy": 36.38623,
            "logical_agreement": 62.40733,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.5114,
            "nubia_score": 0.69059
        },
        "meteor": 0.3307856385082757,
        "bleurt": 0.22091,
        "bertscore": {
            "precision": 0.91723,
            "recall": 0.89933,
            "f1": 0.90461
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "mT5_large/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.48048,
        "msttr-100_nopunct": 0.5556,
        "total_length": 621591,
        "mean_pred_length": 27.465137857900316,
        "std_pred_length": 17.233798819373423,
        "median_pred_length": 24.0,
        "min_pred_length": 2,
        "max_pred_length": 148,
        "distinct-1": 0.02250354332672127,
        "vocab_size-1": 13988,
        "unique-1": 4307,
        "entropy-1": 8.625261450323771,
        "distinct-2": 0.1524394825021412,
        "vocab_size-2": 91305,
        "unique-2": 51791,
        "entropy-2": 13.72222112171596,
        "cond_entropy-2": 4.87704180833396,
        "distinct-3": 0.40099457426079294,
        "vocab_size-3": 231104,
        "unique-3": 165964,
        "entropy-3": 16.30717744657482,
        "cond_entropy-3": 2.5966035004516,
        "total_length-nopunct": 510878,
        "mean_pred_length-nopunct": 22.57325910215624,
        "std_pred_length-nopunct": 14.744481111311076,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 115,
        "distinct-1-nopunct": 0.02733333594321932,
        "vocab_size-1-nopunct": 13964,
        "unique-1-nopunct": 4305,
        "entropy-1-nopunct": 9.620989995300565,
        "distinct-2-nopunct": 0.2606605659418984,
        "vocab_size-2-nopunct": 127267,
        "unique-2-nopunct": 84077,
        "entropy-2-nopunct": 14.62968475489821,
        "cond_entropy-2-nopunct": 5.154523283565413,
        "distinct-3-nopunct": 0.5416752572891431,
        "vocab_size-3-nopunct": 252217,
        "unique-3-nopunct": 198620,
        "entropy-3-nopunct": 16.99174965535697,
        "cond_entropy-3-nopunct": 2.4234962277353373,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "rouge1": {
            "precision": 0.45374,
            "recall": 0.30557,
            "fmeasure": 0.34165
        },
        "rouge2": {
            "precision": 0.16739,
            "recall": 0.1127,
            "fmeasure": 0.12582
        },
        "rougeL": {
            "precision": 0.38505,
            "recall": 0.26147,
            "fmeasure": 0.291
        },
        "rougeLsum": {
            "precision": 0.38505,
            "recall": 0.26147,
            "fmeasure": 0.291
        },
        "bleu": 8.47008,
        "nist": 2.6910904674881766,
        "local_recall": {
            "1": 0.25105657286810723
        },
        "sari": 67.84965,
        "nubia": {
            "semantic_relation": 2.93914,
            "contradiction": 15.11116,
            "irrelevancy": 34.45264,
            "logical_agreement": 50.43619,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.64392,
            "nubia_score": 0.41459
        },
        "meteor": 0.14797582423675912,
        "bleurt": -0.38465,
        "bertscore": {
            "precision": 0.86879,
            "recall": 0.82436,
            "f1": 0.84535
        }
    },
    "wiki_lingua_russian_ru_val": {
        "predictions_file": "mT5_large/wiki_lingua_russian_ru_val",
        "N": 5288,
        "msttr-100": 0.49897,
        "msttr-100_nopunct": 0.56971,
        "total_length": 165811,
        "mean_pred_length": 31.35608925869894,
        "std_pred_length": 18.33882485221621,
        "median_pred_length": 27.0,
        "min_pred_length": 2,
        "max_pred_length": 128,
        "distinct-1": 0.04751795719222488,
        "vocab_size-1": 7879,
        "unique-1": 2628,
        "entropy-1": 8.607391119263442,
        "distinct-2": 0.24223942986363325,
        "vocab_size-2": 38885,
        "unique-2": 22603,
        "entropy-2": 13.342991613648959,
        "cond_entropy-2": 4.547192897403259,
        "distinct-3": 0.5207459657937965,
        "vocab_size-3": 80838,
        "unique-3": 60604,
        "entropy-3": 15.388605606613002,
        "cond_entropy-3": 2.05740221338073,
        "total_length-nopunct": 138147,
        "mean_pred_length-nopunct": 26.12462178517398,
        "std_pred_length-nopunct": 16.053833852455572,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 115,
        "distinct-1-nopunct": 0.056888676554684506,
        "vocab_size-1-nopunct": 7859,
        "unique-1-nopunct": 2626,
        "entropy-1-nopunct": 9.497486762622366,
        "distinct-2-nopunct": 0.3601132010145942,
        "vocab_size-2-nopunct": 47845,
        "unique-2-nopunct": 32636,
        "entropy-2-nopunct": 13.99609894660782,
        "cond_entropy-2-nopunct": 4.614836768951204,
        "distinct-3-nopunct": 0.6466811939549758,
        "vocab_size-3-nopunct": 82501,
        "unique-3-nopunct": 66968,
        "entropy-3-nopunct": 15.781007795749575,
        "cond_entropy-3-nopunct": 1.8271636319680278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_val.json",
        "rouge1": {
            "precision": 0.3966,
            "recall": 0.30854,
            "fmeasure": 0.32268
        },
        "rouge2": {
            "precision": 0.13727,
            "recall": 0.10823,
            "fmeasure": 0.11264
        },
        "rougeL": {
            "precision": 0.33084,
            "recall": 0.26007,
            "fmeasure": 0.27039
        },
        "rougeLsum": {
            "precision": 0.33084,
            "recall": 0.26007,
            "fmeasure": 0.27039
        },
        "bleu": 8.76535,
        "nist": 3.1429901836099323,
        "local_recall": {
            "1": 0.25237533655236866
        },
        "sari": 68.83987,
        "nubia": {
            "semantic_relation": 2.82111,
            "contradiction": 15.55332,
            "irrelevancy": 39.41742,
            "logical_agreement": 45.02925,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.55047,
            "nubia_score": 0.39403
        },
        "meteor": 0.14691082141978443,
        "bleurt": -0.38316,
        "bertscore": {
            "precision": 0.85475,
            "recall": 0.82381,
            "f1": 0.83836
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "mT5_large/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.49869,
        "msttr-100_nopunct": 0.56881,
        "total_length": 330483,
        "mean_pred_length": 31.236578449905483,
        "std_pred_length": 18.356424021272787,
        "median_pred_length": 27.0,
        "min_pred_length": 2,
        "max_pred_length": 131,
        "distinct-1": 0.03149935094997322,
        "vocab_size-1": 10410,
        "unique-1": 3229,
        "entropy-1": 8.653955974156665,
        "distinct-2": 0.1926177622591848,
        "vocab_size-2": 61619,
        "unique-2": 34790,
        "entropy-2": 13.593266496184734,
        "cond_entropy-2": 4.749516577658383,
        "distinct-3": 0.45831380143086675,
        "vocab_size-3": 141767,
        "unique-3": 102800,
        "entropy-3": 15.936692938445963,
        "cond_entropy-3": 2.352215165481762,
        "total_length-nopunct": 275063,
        "mean_pred_length-nopunct": 25.998393194706996,
        "std_pred_length-nopunct": 15.980455255066971,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 118,
        "distinct-1-nopunct": 0.03774771597779418,
        "vocab_size-1-nopunct": 10383,
        "unique-1-nopunct": 3227,
        "entropy-1-nopunct": 9.553857243784822,
        "distinct-2-nopunct": 0.30262436527111386,
        "vocab_size-2-nopunct": 80039,
        "unique-2-nopunct": 52783,
        "entropy-2-nopunct": 14.369081396461734,
        "cond_entropy-2-nopunct": 4.9340290575420465,
        "distinct-3-nopunct": 0.5918181674963766,
        "vocab_size-3-nopunct": 150265,
        "unique-3-nopunct": 118734,
        "entropy-3-nopunct": 16.47957903891417,
        "cond_entropy-3-nopunct": 2.1572413893436004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "rouge1": {
            "precision": 0.39515,
            "recall": 0.30973,
            "fmeasure": 0.3226
        },
        "rouge2": {
            "precision": 0.13681,
            "recall": 0.10803,
            "fmeasure": 0.11204
        },
        "rougeL": {
            "precision": 0.32876,
            "recall": 0.26006,
            "fmeasure": 0.26934
        },
        "rougeLsum": {
            "precision": 0.32876,
            "recall": 0.26006,
            "fmeasure": 0.26934
        },
        "bleu": 8.84398,
        "nist": 3.252500961059189,
        "local_recall": {
            "1": 0.2541002679717466
        },
        "sari": 68.71892,
        "nubia": {
            "semantic_relation": 2.82214,
            "contradiction": 15.68781,
            "irrelevancy": 39.52138,
            "logical_agreement": 44.79081,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.53637,
            "nubia_score": 0.39124
        },
        "meteor": 0.148017719090244,
        "bleurt": -0.38351,
        "bertscore": {
            "precision": 0.85485,
            "recall": 0.82385,
            "f1": 0.83844
        }
    },
    "wiki_lingua_turkish_tr_val": {
        "predictions_file": "mT5_large/wiki_lingua_turkish_tr_val",
        "N": 449,
        "msttr-100": 0.57784,
        "msttr-100_nopunct": 0.65103,
        "total_length": 16297,
        "mean_pred_length": 36.29621380846325,
        "std_pred_length": 19.0213573296578,
        "median_pred_length": 32.0,
        "min_pred_length": 4,
        "max_pred_length": 112,
        "distinct-1": 0.15100938823096274,
        "vocab_size-1": 2461,
        "unique-1": 1155,
        "entropy-1": 8.230037090919605,
        "distinct-2": 0.48914689550731955,
        "vocab_size-2": 7752,
        "unique-2": 5408,
        "entropy-2": 11.977712634692155,
        "cond_entropy-2": 3.6038905354305846,
        "distinct-3": 0.74673680109098,
        "vocab_size-3": 11499,
        "unique-3": 9587,
        "entropy-3": 13.15707958271936,
        "cond_entropy-3": 1.1867398261156765,
        "total_length-nopunct": 13675,
        "mean_pred_length-nopunct": 30.456570155902003,
        "std_pred_length-nopunct": 16.47387099781501,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 103,
        "distinct-1-nopunct": 0.17893967093235832,
        "vocab_size-1-nopunct": 2447,
        "unique-1-nopunct": 1153,
        "entropy-1-nopunct": 8.96057567890582,
        "distinct-2-nopunct": 0.5970815061243007,
        "vocab_size-2-nopunct": 7897,
        "unique-2-nopunct": 5988,
        "entropy-2-nopunct": 12.314460224901962,
        "cond_entropy-2-nopunct": 3.429706703641711,
        "distinct-3-nopunct": 0.8356421695233623,
        "vocab_size-3-nopunct": 10677,
        "unique-3-nopunct": 9372,
        "entropy-3-nopunct": 13.210941810356735,
        "cond_entropy-3-nopunct": 0.9117694158940569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_val.json",
        "rouge1": {
            "precision": 0.37666,
            "recall": 0.34667,
            "fmeasure": 0.33684
        },
        "rouge2": {
            "precision": 0.15159,
            "recall": 0.1431,
            "fmeasure": 0.13824
        },
        "rougeL": {
            "precision": 0.30582,
            "recall": 0.28218,
            "fmeasure": 0.27321
        },
        "rougeLsum": {
            "precision": 0.30582,
            "recall": 0.28218,
            "fmeasure": 0.27321
        },
        "bleu": 15.45152,
        "nist": 3.7116206267090837,
        "local_recall": {
            "1": 0.31592712842712845
        },
        "sari": 68.15904,
        "nubia": {
            "semantic_relation": 2.52937,
            "contradiction": 24.48839,
            "irrelevancy": 47.34329,
            "logical_agreement": 28.16832,
            "grammar_ref": 3.85457,
            "grammar_hyp": 3.79829,
            "nubia_score": 0.30766
        },
        "meteor": 0.17018914367788424,
        "bleurt": -0.47566,
        "bertscore": {
            "precision": 0.8434,
            "recall": 0.83311,
            "f1": 0.83764
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "mT5_large/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.5772,
        "msttr-100_nopunct": 0.64787,
        "total_length": 33937,
        "mean_pred_length": 37.70777777777778,
        "std_pred_length": 19.173713068665293,
        "median_pred_length": 35.0,
        "min_pred_length": 3,
        "max_pred_length": 115,
        "distinct-1": 0.10475292453664142,
        "vocab_size-1": 3555,
        "unique-1": 1526,
        "entropy-1": 8.346449268901079,
        "distinct-2": 0.39540515179949753,
        "vocab_size-2": 13063,
        "unique-2": 8349,
        "entropy-2": 12.405366433708936,
        "cond_entropy-2": 3.9144867958175493,
        "distinct-3": 0.6528300712574291,
        "vocab_size-3": 20980,
        "unique-3": 16306,
        "entropy-3": 13.836929178098362,
        "cond_entropy-3": 1.44188187410889,
        "total_length-nopunct": 28622,
        "mean_pred_length-nopunct": 31.802222222222223,
        "std_pred_length-nopunct": 16.723330195852323,
        "median_pred_length-nopunct": 29.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 100,
        "distinct-1-nopunct": 0.12364614632101181,
        "vocab_size-1-nopunct": 3539,
        "unique-1-nopunct": 1522,
        "entropy-1-nopunct": 9.062735205993938,
        "distinct-2-nopunct": 0.4935430344131015,
        "vocab_size-2-nopunct": 13682,
        "unique-2-nopunct": 9522,
        "entropy-2-nopunct": 12.832981352714794,
        "cond_entropy-2-nopunct": 3.851539036296251,
        "distinct-3-nopunct": 0.7494966818283498,
        "vocab_size-3-nopunct": 20103,
        "unique-3-nopunct": 16467,
        "entropy-3-nopunct": 14.012740112005597,
        "cond_entropy-3-nopunct": 1.2001582563993702,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "rouge1": {
            "precision": 0.37065,
            "recall": 0.35521,
            "fmeasure": 0.34036
        },
        "rouge2": {
            "precision": 0.15551,
            "recall": 0.15056,
            "fmeasure": 0.1446
        },
        "rougeL": {
            "precision": 0.29835,
            "recall": 0.28726,
            "fmeasure": 0.27453
        },
        "rougeLsum": {
            "precision": 0.29835,
            "recall": 0.28726,
            "fmeasure": 0.27453
        },
        "bleu": 16.27719,
        "nist": 3.893666781504311,
        "local_recall": {
            "1": 0.3264311814859927
        },
        "sari": 67.9507,
        "nubia": {
            "semantic_relation": 2.53579,
            "contradiction": 23.08326,
            "irrelevancy": 49.49376,
            "logical_agreement": 27.42298,
            "grammar_ref": 3.87672,
            "grammar_hyp": 3.77318,
            "nubia_score": 0.30857
        },
        "meteor": 0.1740851910170331,
        "bleurt": -0.44753,
        "bertscore": {
            "precision": 0.84241,
            "recall": 0.83608,
            "f1": 0.83872
        }
    },
    "wiki_lingua_vietnamese_vi_val": {
        "predictions_file": "mT5_large/wiki_lingua_vietnamese_vi_val",
        "N": 1957,
        "msttr-100": 0.55589,
        "msttr-100_nopunct": 0.63448,
        "total_length": 62320,
        "mean_pred_length": 31.844660194174757,
        "std_pred_length": 15.892696791051511,
        "median_pred_length": 29.0,
        "min_pred_length": 1,
        "max_pred_length": 116,
        "distinct-1": 0.07870667522464699,
        "vocab_size-1": 4905,
        "unique-1": 1944,
        "entropy-1": 8.446976730193754,
        "distinct-2": 0.33341616553186554,
        "vocab_size-2": 20126,
        "unique-2": 12566,
        "entropy-2": 12.854720510244187,
        "cond_entropy-2": 4.223411840681355,
        "distinct-3": 0.6340335918639889,
        "vocab_size-3": 37032,
        "unique-3": 29390,
        "entropy-3": 14.577160498447626,
        "cond_entropy-3": 1.7345444650171833,
        "total_length-nopunct": 51978,
        "mean_pred_length-nopunct": 26.56004087889627,
        "std_pred_length-nopunct": 13.997557915278788,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 108,
        "distinct-1-nopunct": 0.09405902497210358,
        "vocab_size-1-nopunct": 4889,
        "unique-1-nopunct": 1941,
        "entropy-1-nopunct": 9.296941589162172,
        "distinct-2-nopunct": 0.4596577505897405,
        "vocab_size-2-nopunct": 22993,
        "unique-2-nopunct": 16497,
        "entropy-2-nopunct": 13.385577638730386,
        "cond_entropy-2-nopunct": 4.196681731305945,
        "distinct-3-nopunct": 0.7586859734531686,
        "vocab_size-3-nopunct": 36467,
        "unique-3-nopunct": 31096,
        "entropy-3-nopunct": 14.8359071964046,
        "cond_entropy-3-nopunct": 1.4844130831189488,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_val.json",
        "rouge1": {
            "precision": 0.37281,
            "recall": 0.31204,
            "fmeasure": 0.31855
        },
        "rouge2": {
            "precision": 0.12284,
            "recall": 0.10502,
            "fmeasure": 0.10629
        },
        "rougeL": {
            "precision": 0.30074,
            "recall": 0.25363,
            "fmeasure": 0.25782
        },
        "rougeLsum": {
            "precision": 0.30074,
            "recall": 0.25363,
            "fmeasure": 0.25782
        },
        "bleu": 9.60867,
        "nist": 3.2939871479024094,
        "local_recall": {
            "1": 0.2678989045254995
        },
        "sari": 67.08024,
        "nubia": {
            "semantic_relation": 2.64879,
            "contradiction": 17.17233,
            "irrelevancy": 43.66306,
            "logical_agreement": 39.1646,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.63563,
            "nubia_score": 0.33849
        },
        "meteor": 0.1527604279676194,
        "bleurt": -0.36594,
        "bertscore": {
            "precision": 0.84994,
            "recall": 0.82826,
            "f1": 0.83842
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "mT5_large/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.5567,
        "msttr-100_nopunct": 0.63492,
        "total_length": 125443,
        "mean_pred_length": 32.02527444472811,
        "std_pred_length": 15.573001665072317,
        "median_pred_length": 29.0,
        "min_pred_length": 3,
        "max_pred_length": 116,
        "distinct-1": 0.05417600025509594,
        "vocab_size-1": 6796,
        "unique-1": 2459,
        "entropy-1": 8.561329020998555,
        "distinct-2": 0.27061698731135725,
        "vocab_size-2": 32887,
        "unique-2": 19676,
        "entropy-2": 13.2133657747873,
        "cond_entropy-2": 4.465434238328135,
        "distinct-3": 0.567762671224141,
        "vocab_size-3": 66774,
        "unique-3": 51180,
        "entropy-3": 15.23123321472919,
        "cond_entropy-3": 2.0251242253753294,
        "total_length-nopunct": 104748,
        "mean_pred_length-nopunct": 26.7418943068675,
        "std_pred_length-nopunct": 13.670621643903921,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 107,
        "distinct-1-nopunct": 0.06465994577462099,
        "vocab_size-1-nopunct": 6773,
        "unique-1-nopunct": 2457,
        "entropy-1-nopunct": 9.41941851797684,
        "distinct-2-nopunct": 0.3928256191052355,
        "vocab_size-2-nopunct": 39609,
        "unique-2-nopunct": 27371,
        "entropy-2-nopunct": 13.871634644617302,
        "cond_entropy-2-nopunct": 4.55980681015082,
        "distinct-3-nopunct": 0.7028086757331242,
        "vocab_size-3-nopunct": 68112,
        "unique-3-nopunct": 56558,
        "entropy-3-nopunct": 15.610167932452226,
        "cond_entropy-3-nopunct": 1.7731704570343008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "rouge1": {
            "precision": 0.37121,
            "recall": 0.31765,
            "fmeasure": 0.32143
        },
        "rouge2": {
            "precision": 0.12552,
            "recall": 0.1075,
            "fmeasure": 0.10862
        },
        "rougeL": {
            "precision": 0.29955,
            "recall": 0.25826,
            "fmeasure": 0.25993
        },
        "rougeLsum": {
            "precision": 0.29955,
            "recall": 0.25826,
            "fmeasure": 0.25993
        },
        "bleu": 10.04047,
        "nist": 3.4589151458679317,
        "local_recall": {
            "1": 0.2763189517350916
        },
        "sari": 66.89421,
        "nubia": {
            "semantic_relation": 2.67162,
            "contradiction": 16.62217,
            "irrelevancy": 43.46143,
            "logical_agreement": 39.9164,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.63622,
            "nubia_score": 0.34505
        },
        "meteor": 0.15696896054432555,
        "bleurt": -0.3703,
        "bertscore": {
            "precision": 0.8497,
            "recall": 0.83027,
            "f1": 0.83931
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "mT5_large/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.75798,
        "msttr-100_nopunct": 0.77775,
        "total_length": 11949,
        "mean_pred_length": 23.898,
        "std_pred_length": 6.513953945185674,
        "median_pred_length": 24.0,
        "min_pred_length": 0,
        "max_pred_length": 59,
        "distinct-1": 0.2906519374006193,
        "vocab_size-1": 3473,
        "unique-1": 2332,
        "entropy-1": 9.380485109335448,
        "distinct-2": 0.7837554585152838,
        "vocab_size-2": 8974,
        "unique-2": 8053,
        "entropy-2": 12.744564680352806,
        "cond_entropy-2": 3.1563335321930204,
        "distinct-3": 0.954342069217423,
        "vocab_size-3": 10451,
        "unique-3": 10151,
        "entropy-3": 13.298459083938287,
        "cond_entropy-3": 0.550074769070111,
        "total_length-nopunct": 11145,
        "mean_pred_length-nopunct": 22.29,
        "std_pred_length-nopunct": 6.2230137393388425,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.31063257065948857,
        "vocab_size-1-nopunct": 3462,
        "unique-1-nopunct": 2330,
        "entropy-1-nopunct": 9.560396582167517,
        "distinct-2-nopunct": 0.7913770430208529,
        "vocab_size-2-nopunct": 8425,
        "unique-2-nopunct": 7595,
        "entropy-2-nopunct": 12.662797264602498,
        "cond_entropy-2-nopunct": 3.1943347929961177,
        "distinct-3-nopunct": 0.9598896225485365,
        "vocab_size-3-nopunct": 9740,
        "unique-3-nopunct": 9491,
        "entropy-3-nopunct": 13.206296239985669,
        "cond_entropy-3-nopunct": 0.5502959539782906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "rouge1": {
            "precision": 0.29838,
            "recall": 0.31122,
            "fmeasure": 0.29682
        },
        "rouge2": {
            "precision": 0.07932,
            "recall": 0.08251,
            "fmeasure": 0.07866
        },
        "rougeL": {
            "precision": 0.22076,
            "recall": 0.23062,
            "fmeasure": 0.21979
        },
        "rougeLsum": {
            "precision": 0.22076,
            "recall": 0.23062,
            "fmeasure": 0.21979
        },
        "bleu": 4.45197,
        "nist": 2.559900336360364,
        "local_recall": {
            "1": 0.2840729001584786
        },
        "nubia": {
            "semantic_relation": 2.27844,
            "contradiction": 28.85792,
            "irrelevancy": 65.87622,
            "logical_agreement": 5.06586,
            "grammar_ref": 3.73468,
            "grammar_hyp": 4.64589,
            "nubia_score": 0.23554
        },
        "meteor": 0.13102693187545045,
        "bleurt": -0.67025,
        "bertscore": {
            "precision": 0.7975,
            "recall": 0.79926,
            "f1": 0.79759
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "mT5_large/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.76457,
        "msttr-100_nopunct": 0.78676,
        "total_length": 11616,
        "mean_pred_length": 23.232,
        "std_pred_length": 6.004179877385421,
        "median_pred_length": 23.0,
        "min_pred_length": 0,
        "max_pred_length": 50,
        "distinct-1": 0.31043388429752067,
        "vocab_size-1": 3606,
        "unique-1": 2507,
        "entropy-1": 9.469230115029156,
        "distinct-2": 0.7981469820994873,
        "vocab_size-2": 8873,
        "unique-2": 8029,
        "entropy-2": 12.757107509602333,
        "cond_entropy-2": 3.0686555943252247,
        "distinct-3": 0.9588434733471464,
        "vocab_size-3": 10181,
        "unique-3": 9920,
        "entropy-3": 13.267816621580508,
        "cond_entropy-3": 0.5117376646989898,
        "total_length-nopunct": 10829,
        "mean_pred_length-nopunct": 21.658,
        "std_pred_length-nopunct": 5.7265204094633235,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 48,
        "distinct-1-nopunct": 0.33160956690368454,
        "vocab_size-1-nopunct": 3591,
        "unique-1-nopunct": 2502,
        "entropy-1-nopunct": 9.655304800085869,
        "distinct-2-nopunct": 0.8058083252662149,
        "vocab_size-2-nopunct": 8324,
        "unique-2-nopunct": 7563,
        "entropy-2-nopunct": 12.675211543422423,
        "cond_entropy-2-nopunct": 3.1174116939932657,
        "distinct-3-nopunct": 0.9638897365476554,
        "vocab_size-3-nopunct": 9476,
        "unique-3-nopunct": 9253,
        "entropy-3-nopunct": 13.173346993228792,
        "cond_entropy-3-nopunct": 0.5098068869951052,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "rouge1": {
            "precision": 0.28652,
            "recall": 0.29246,
            "fmeasure": 0.28227
        },
        "rouge2": {
            "precision": 0.07407,
            "recall": 0.07477,
            "fmeasure": 0.07233
        },
        "rougeL": {
            "precision": 0.21632,
            "recall": 0.21888,
            "fmeasure": 0.21206
        },
        "rougeLsum": {
            "precision": 0.21632,
            "recall": 0.21888,
            "fmeasure": 0.21206
        },
        "bleu": 4.23172,
        "nist": 2.4858976567731275,
        "local_recall": {
            "1": 0.272700119474313
        },
        "nubia": {
            "semantic_relation": 2.05509,
            "contradiction": 32.47669,
            "irrelevancy": 61.82516,
            "logical_agreement": 5.49816,
            "grammar_ref": 3.78678,
            "grammar_hyp": 4.9979,
            "nubia_score": 0.19215
        },
        "meteor": 0.12463347955639775,
        "bleurt": -0.78611,
        "bertscore": {
            "precision": 0.79143,
            "recall": 0.79391,
            "f1": 0.79188
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "mT5_large/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.75393,
        "msttr-100_nopunct": 0.77358,
        "total_length": 11750,
        "mean_pred_length": 23.5,
        "std_pred_length": 5.798103138096113,
        "median_pred_length": 23.0,
        "min_pred_length": 5,
        "max_pred_length": 45,
        "distinct-1": 0.2865531914893617,
        "vocab_size-1": 3367,
        "unique-1": 2219,
        "entropy-1": 9.332948013782811,
        "distinct-2": 0.7735111111111111,
        "vocab_size-2": 8702,
        "unique-2": 7764,
        "entropy-2": 12.67777290957439,
        "cond_entropy-2": 3.1337621523465478,
        "distinct-3": 0.9506046511627907,
        "vocab_size-3": 10219,
        "unique-3": 9908,
        "entropy-3": 13.262430769302133,
        "cond_entropy-3": 0.5830955644647012,
        "total_length-nopunct": 10986,
        "mean_pred_length-nopunct": 21.972,
        "std_pred_length-nopunct": 5.657492023856507,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.3053886764973603,
        "vocab_size-1-nopunct": 3355,
        "unique-1-nopunct": 2216,
        "entropy-1-nopunct": 9.505583051596263,
        "distinct-2-nopunct": 0.7810413885180241,
        "vocab_size-2-nopunct": 8190,
        "unique-2-nopunct": 7347,
        "entropy-2-nopunct": 12.599936792950336,
        "cond_entropy-2-nopunct": 3.1872740670387523,
        "distinct-3-nopunct": 0.95583817344282,
        "vocab_size-3-nopunct": 9545,
        "unique-3-nopunct": 9273,
        "entropy-3-nopunct": 13.175384205455739,
        "cond_entropy-3-nopunct": 0.5854594032572943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "rouge1": {
            "precision": 0.32023,
            "recall": 0.33141,
            "fmeasure": 0.31769
        },
        "rouge2": {
            "precision": 0.09686,
            "recall": 0.10106,
            "fmeasure": 0.0963
        },
        "rougeL": {
            "precision": 0.24058,
            "recall": 0.24856,
            "fmeasure": 0.23837
        },
        "rougeLsum": {
            "precision": 0.24058,
            "recall": 0.24856,
            "fmeasure": 0.23837
        },
        "bleu": 6.09039,
        "nist": 2.8425219966416497,
        "local_recall": {
            "1": 0.3071514664523905
        },
        "nubia": {
            "semantic_relation": 2.36126,
            "contradiction": 28.19238,
            "irrelevancy": 66.7643,
            "logical_agreement": 5.04332,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.37993,
            "nubia_score": 0.26282
        },
        "meteor": 0.14203327305319832,
        "bleurt": -0.56895,
        "bertscore": {
            "precision": 0.80752,
            "recall": 0.806,
            "f1": 0.80643
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "mT5_large/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.7334,
        "msttr-100_nopunct": 0.75505,
        "total_length": 10304,
        "mean_pred_length": 25.69576059850374,
        "std_pred_length": 6.517745351834884,
        "median_pred_length": 25.0,
        "min_pred_length": 9,
        "max_pred_length": 50,
        "distinct-1": 0.22777562111801242,
        "vocab_size-1": 2347,
        "unique-1": 1501,
        "entropy-1": 8.729102641230071,
        "distinct-2": 0.6791881248106635,
        "vocab_size-2": 6726,
        "unique-2": 5788,
        "entropy-2": 12.081448044565429,
        "cond_entropy-2": 3.1902156334943044,
        "distinct-3": 0.888865501999579,
        "vocab_size-3": 8446,
        "unique-3": 8003,
        "entropy-3": 12.870704640552812,
        "cond_entropy-3": 0.7646513397914025,
        "total_length-nopunct": 9592,
        "mean_pred_length-nopunct": 23.920199501246884,
        "std_pred_length-nopunct": 6.136324613373872,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 46,
        "distinct-1-nopunct": 0.2433277731442869,
        "vocab_size-1-nopunct": 2334,
        "unique-1-nopunct": 1496,
        "entropy-1-nopunct": 8.874017543538358,
        "distinct-2-nopunct": 0.6974213904906974,
        "vocab_size-2-nopunct": 6410,
        "unique-2-nopunct": 5574,
        "entropy-2-nopunct": 12.038146229667287,
        "cond_entropy-2-nopunct": 3.213192090677318,
        "distinct-3-nopunct": 0.90193401592719,
        "vocab_size-3-nopunct": 7928,
        "unique-3-nopunct": 7563,
        "entropy-3-nopunct": 12.797217779600023,
        "cond_entropy-3-nopunct": 0.7431493862031918,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "rouge1": {
            "precision": 0.26547,
            "recall": 0.28373,
            "fmeasure": 0.26496
        },
        "rouge2": {
            "precision": 0.06529,
            "recall": 0.07145,
            "fmeasure": 0.06584
        },
        "rougeL": {
            "precision": 0.19418,
            "recall": 0.20839,
            "fmeasure": 0.194
        },
        "rougeLsum": {
            "precision": 0.19418,
            "recall": 0.20839,
            "fmeasure": 0.194
        },
        "bleu": 3.98288,
        "nist": 2.1014667912078004,
        "local_recall": {
            "1": 0.26201345506967805
        },
        "nubia": {
            "semantic_relation": 1.93161,
            "contradiction": 24.01609,
            "irrelevancy": 70.18109,
            "logical_agreement": 5.80282,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.49425,
            "nubia_score": 0.20775
        },
        "meteor": 0.11664777294030423,
        "bleurt": -0.71158,
        "bertscore": {
            "precision": 0.77977,
            "recall": 0.78011,
            "f1": 0.77962
        }
    },
    "e2e_nlg_val": {
        "predictions_file": "mT5_large/e2e_nlg_val",
        "N": 4299,
        "msttr-100": 0.27264,
        "msttr-100_nopunct": 0.26392,
        "total_length": 108063,
        "mean_pred_length": 25.136775994417306,
        "std_pred_length": 7.978710561113457,
        "median_pred_length": 26.0,
        "min_pred_length": 5,
        "max_pred_length": 45,
        "distinct-1": 0.0012955405643004544,
        "vocab_size-1": 140,
        "unique-1": 8,
        "entropy-1": 5.621697220836388,
        "distinct-2": 0.004307852434370302,
        "vocab_size-2": 447,
        "unique-2": 56,
        "entropy-2": 7.0458351223035125,
        "cond_entropy-2": 1.338488990024921,
        "distinct-3": 0.008827225657266374,
        "vocab_size-3": 878,
        "unique-3": 142,
        "entropy-3": 7.9101301363167495,
        "cond_entropy-3": 0.903891374098659,
        "total_length-nopunct": 98360,
        "mean_pred_length-nopunct": 22.879739474296347,
        "std_pred_length-nopunct": 7.249913978012522,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.0014030093533956892,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 5.668405024398106,
        "distinct-2-nopunct": 0.0046778154601800955,
        "vocab_size-2-nopunct": 440,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 7.003694625789897,
        "cond_entropy-2-nopunct": 1.386121324780749,
        "distinct-3-nopunct": 0.009770281410842005,
        "vocab_size-3-nopunct": 877,
        "unique-3-nopunct": 139,
        "entropy-3-nopunct": 7.93428493139041,
        "cond_entropy-3-nopunct": 0.9323032192428088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_val.json",
        "rouge1": {
            "precision": 0.74163,
            "recall": 0.75195,
            "fmeasure": 0.73737
        },
        "rouge2": {
            "precision": 0.46862,
            "recall": 0.4759,
            "fmeasure": 0.4664
        },
        "rougeL": {
            "precision": 0.54778,
            "recall": 0.55371,
            "fmeasure": 0.54375
        },
        "rougeLsum": {
            "precision": 0.54778,
            "recall": 0.55371,
            "fmeasure": 0.54375
        },
        "bleu": 36.11182,
        "nist": 5.382967732528899,
        "local_recall": {
            "1": 0.7443788208475806
        },
        "nubia": {
            "semantic_relation": 4.48331,
            "contradiction": 1.93122,
            "irrelevancy": 9.77127,
            "logical_agreement": 88.29751,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.2684,
            "nubia_score": 0.86004
        },
        "meteor": 0.38967346227780925,
        "bleurt": 0.31493,
        "bertscore": {
            "precision": 0.92041,
            "recall": 0.91333,
            "f1": 0.9166
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "mT5_large/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.28082,
        "msttr-100_nopunct": 0.27348,
        "total_length": 116028,
        "mean_pred_length": 24.723630939697422,
        "std_pred_length": 7.70742084633036,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 47,
        "distinct-1": 0.0011290378184576136,
        "vocab_size-1": 131,
        "unique-1": 0,
        "entropy-1": 5.711740195410757,
        "distinct-2": 0.004374186015179414,
        "vocab_size-2": 487,
        "unique-2": 38,
        "entropy-2": 7.2375412291906125,
        "cond_entropy-2": 1.4354028776471337,
        "distinct-3": 0.010202359295587105,
        "vocab_size-3": 1088,
        "unique-3": 141,
        "entropy-3": 8.172134618922811,
        "cond_entropy-3": 0.9588281446580537,
        "total_length-nopunct": 106106,
        "mean_pred_length-nopunct": 22.609418282548475,
        "std_pred_length-nopunct": 7.048235135087239,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.001215765366708763,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 5.7755394141664,
        "distinct-2-nopunct": 0.004723260331515684,
        "vocab_size-2-nopunct": 479,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 7.2428782228193205,
        "cond_entropy-2-nopunct": 1.5123075399517178,
        "distinct-3-nopunct": 0.011217948717948718,
        "vocab_size-3-nopunct": 1085,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 8.251689532414176,
        "cond_entropy-3-nopunct": 1.0023130904381121,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "rouge1": {
            "precision": 0.7798,
            "recall": 0.72493,
            "fmeasure": 0.74088
        },
        "rouge2": {
            "precision": 0.48264,
            "recall": 0.44891,
            "fmeasure": 0.45835
        },
        "rougeL": {
            "precision": 0.55475,
            "recall": 0.514,
            "fmeasure": 0.52599
        },
        "rougeLsum": {
            "precision": 0.55475,
            "recall": 0.514,
            "fmeasure": 0.52599
        },
        "bleu": 33.49628,
        "nist": 5.525374461271878,
        "local_recall": {
            "1": 0.7212636286285296
        },
        "nubia": {
            "semantic_relation": 4.45215,
            "contradiction": 1.96542,
            "irrelevancy": 11.14051,
            "logical_agreement": 86.89407,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.44002,
            "nubia_score": 0.834
        },
        "meteor": 0.37336547908939977,
        "bleurt": 0.26937,
        "bertscore": {
            "precision": 0.92634,
            "recall": 0.90916,
            "f1": 0.91738
        }
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "mT5_large/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.54573,
        "msttr-100_nopunct": 0.55196,
        "total_length": 12424,
        "mean_pred_length": 24.848,
        "std_pred_length": 7.1758550710002496,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 45,
        "distinct-1": 0.02784932388924662,
        "vocab_size-1": 346,
        "unique-1": 125,
        "entropy-1": 6.335863146368701,
        "distinct-2": 0.15087219054008721,
        "vocab_size-2": 1799,
        "unique-2": 1005,
        "entropy-2": 8.913436839871808,
        "cond_entropy-2": 2.486769925165795,
        "distinct-3": 0.33648459383753504,
        "vocab_size-3": 3844,
        "unique-3": 2595,
        "entropy-3": 10.54321568036801,
        "cond_entropy-3": 1.6308194544572285,
        "total_length-nopunct": 11277,
        "mean_pred_length-nopunct": 22.554,
        "std_pred_length-nopunct": 6.543934901876699,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.03041589075108628,
        "vocab_size-1-nopunct": 343,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.402135978479684,
        "distinct-2-nopunct": 0.16581608982091492,
        "vocab_size-2-nopunct": 1787,
        "unique-2-nopunct": 1039,
        "entropy-2-nopunct": 8.858065684645164,
        "cond_entropy-2-nopunct": 2.4868516451424063,
        "distinct-3-nopunct": 0.35662158217378614,
        "vocab_size-3-nopunct": 3665,
        "unique-3-nopunct": 2518,
        "entropy-3-nopunct": 10.516322459072345,
        "cond_entropy-3-nopunct": 1.6367879403815455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.71024,
            "recall": 0.66554,
            "fmeasure": 0.67594
        },
        "rouge2": {
            "precision": 0.39336,
            "recall": 0.36902,
            "fmeasure": 0.37419
        },
        "rougeL": {
            "precision": 0.46936,
            "recall": 0.43889,
            "fmeasure": 0.44583
        },
        "rougeLsum": {
            "precision": 0.46936,
            "recall": 0.43889,
            "fmeasure": 0.44583
        },
        "bleu": 25.03289,
        "nist": 4.792665916444385,
        "local_recall": {
            "1": 0.6628847763414861
        },
        "nubia": {
            "semantic_relation": 4.23675,
            "contradiction": 5.66727,
            "irrelevancy": 24.22626,
            "logical_agreement": 70.10646,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.87862,
            "nubia_score": 0.71679
        },
        "meteor": 0.3398501457829273,
        "bleurt": 0.0167,
        "bertscore": {
            "precision": 0.90038,
            "recall": 0.89412,
            "f1": 0.89691
        }
    },
    "web_nlg_en_val": {
        "predictions_file": "mT5_large/web_nlg_en_val",
        "N": 1667,
        "msttr-100": 0.53631,
        "msttr-100_nopunct": 0.56056,
        "total_length": 36356,
        "mean_pred_length": 21.809238152369527,
        "std_pred_length": 11.323125010679279,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 82,
        "distinct-1": 0.09310705248102101,
        "vocab_size-1": 3385,
        "unique-1": 1021,
        "entropy-1": 8.722784508041395,
        "distinct-2": 0.2837787194787973,
        "vocab_size-2": 9844,
        "unique-2": 4711,
        "entropy-2": 12.014891876249889,
        "cond_entropy-2": 3.0585731635508564,
        "distinct-3": 0.4501847253346254,
        "vocab_size-3": 14866,
        "unique-3": 8904,
        "entropy-3": 13.124259349270597,
        "cond_entropy-3": 1.1596612509873112,
        "total_length-nopunct": 32325,
        "mean_pred_length-nopunct": 19.39112177564487,
        "std_pred_length-nopunct": 10.226205459785492,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 66,
        "distinct-1-nopunct": 0.10440835266821345,
        "vocab_size-1-nopunct": 3375,
        "unique-1-nopunct": 1019,
        "entropy-1-nopunct": 9.081447143343592,
        "distinct-2-nopunct": 0.2949964120294866,
        "vocab_size-2-nopunct": 9044,
        "unique-2-nopunct": 4458,
        "entropy-2-nopunct": 11.909993408573705,
        "cond_entropy-2-nopunct": 2.968908923609675,
        "distinct-3-nopunct": 0.4627643061639819,
        "vocab_size-3-nopunct": 13416,
        "unique-3-nopunct": 8256,
        "entropy-3-nopunct": 12.985024450269336,
        "cond_entropy-3-nopunct": 1.1254952254067287,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_val.json",
        "rouge1": {
            "precision": 0.83978,
            "recall": 0.82716,
            "fmeasure": 0.82794
        },
        "rouge2": {
            "precision": 0.63724,
            "recall": 0.62881,
            "fmeasure": 0.62864
        },
        "rougeL": {
            "precision": 0.71373,
            "recall": 0.70529,
            "fmeasure": 0.70466
        },
        "rougeLsum": {
            "precision": 0.71373,
            "recall": 0.70529,
            "fmeasure": 0.70466
        },
        "bleu": 65.88675,
        "nist": 11.712496698831641,
        "local_recall": {
            "1": 0.31642439682301815,
            "2": 0.746455938697318,
            "3": 0.9516539440203562,
            "4": 0.9574468085106383,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "nubia": {
            "semantic_relation": 4.78411,
            "contradiction": 2.46716,
            "irrelevancy": 3.6657,
            "logical_agreement": 93.86714,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.49955,
            "nubia_score": 0.90852
        },
        "meteor": 0.46666175443527247,
        "bleurt": 0.46109,
        "bertscore": {
            "precision": 0.95904,
            "recall": 0.95505,
            "f1": 0.95628
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.63463,
        "msttr-100_nopunct": 0.67005,
        "total_length": 44371,
        "mean_pred_length": 24.941540191118605,
        "std_pred_length": 13.104584717933554,
        "median_pred_length": 23.0,
        "min_pred_length": 4,
        "max_pred_length": 80,
        "distinct-1": 0.03889928106195488,
        "vocab_size-1": 1726,
        "unique-1": 385,
        "entropy-1": 8.015010326370303,
        "distinct-2": 0.14138805409466568,
        "vocab_size-2": 6022,
        "unique-2": 2290,
        "entropy-2": 11.11965021721466,
        "cond_entropy-2": 2.9372489774600026,
        "distinct-3": 0.26018670521647513,
        "vocab_size-3": 10619,
        "unique-3": 5366,
        "entropy-3": 12.299055714416863,
        "cond_entropy-3": 1.2434536035419934,
        "total_length-nopunct": 39626,
        "mean_pred_length-nopunct": 22.274311410905003,
        "std_pred_length-nopunct": 11.838194681033873,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.043330136778882554,
        "vocab_size-1-nopunct": 1717,
        "unique-1-nopunct": 385,
        "entropy-1-nopunct": 8.260689374069024,
        "distinct-2-nopunct": 0.14981372367690965,
        "vocab_size-2-nopunct": 5670,
        "unique-2-nopunct": 2309,
        "entropy-2-nopunct": 11.010863809728804,
        "cond_entropy-2-nopunct": 2.887449600953671,
        "distinct-3-nopunct": 0.2736774980592215,
        "vocab_size-3-nopunct": 9871,
        "unique-3-nopunct": 5204,
        "entropy-3-nopunct": 12.178494511301757,
        "cond_entropy-3-nopunct": 1.2180729373811605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.7338,
            "recall": 0.7433,
            "fmeasure": 0.73061
        },
        "rouge2": {
            "precision": 0.48078,
            "recall": 0.48665,
            "fmeasure": 0.47782
        },
        "rougeL": {
            "precision": 0.58419,
            "recall": 0.59217,
            "fmeasure": 0.58132
        },
        "rougeLsum": {
            "precision": 0.58419,
            "recall": 0.59217,
            "fmeasure": 0.58132
        },
        "bleu": 46.46204,
        "nist": 8.837551504025436,
        "local_recall": {
            "1": 0.22910092374777669,
            "2": 0.5960959502767796,
            "3": 0.8704615384615385,
            "4": 0.9272727272727272,
            "5": 0.7931034482758621
        },
        "nubia": {
            "semantic_relation": 4.40658,
            "contradiction": 9.2029,
            "irrelevancy": 8.98546,
            "logical_agreement": 81.81163,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.56095,
            "nubia_score": 0.77229
        },
        "meteor": 0.3828413780278582,
        "bleurt": 0.16005,
        "bertscore": {
            "precision": 0.91711,
            "recall": 0.91679,
            "f1": 0.91561
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.5064,
        "msttr-100_nopunct": 0.5225,
        "total_length": 8636,
        "mean_pred_length": 20.85990338164251,
        "std_pred_length": 7.72783950223524,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 52,
        "distinct-1": 0.1325845298749421,
        "vocab_size-1": 1145,
        "unique-1": 406,
        "entropy-1": 7.886148560239915,
        "distinct-2": 0.36280710289467283,
        "vocab_size-2": 2983,
        "unique-2": 1612,
        "entropy-2": 10.705268742692745,
        "cond_entropy-2": 2.6288540088062913,
        "distinct-3": 0.5385502049180327,
        "vocab_size-3": 4205,
        "unique-3": 2791,
        "entropy-3": 11.583100963072294,
        "cond_entropy-3": 0.9415059682162349,
        "total_length-nopunct": 7665,
        "mean_pred_length-nopunct": 18.514492753623188,
        "std_pred_length-nopunct": 6.891746278824158,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.14833659491193738,
        "vocab_size-1-nopunct": 1137,
        "unique-1-nopunct": 406,
        "entropy-1-nopunct": 8.13092096340455,
        "distinct-2-nopunct": 0.3651910081368087,
        "vocab_size-2-nopunct": 2648,
        "unique-2-nopunct": 1454,
        "entropy-2-nopunct": 10.526705608282604,
        "cond_entropy-2-nopunct": 2.5472614583105133,
        "distinct-3-nopunct": 0.5429281848764078,
        "vocab_size-3-nopunct": 3712,
        "unique-3-nopunct": 2490,
        "entropy-3-nopunct": 11.398826967081487,
        "cond_entropy-3-nopunct": 0.9227448883409187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73329,
            "recall": 0.76026,
            "fmeasure": 0.73847
        },
        "rouge2": {
            "precision": 0.48928,
            "recall": 0.50844,
            "fmeasure": 0.49252
        },
        "rougeL": {
            "precision": 0.59806,
            "recall": 0.62107,
            "fmeasure": 0.60217
        },
        "rougeLsum": {
            "precision": 0.59806,
            "recall": 0.62107,
            "fmeasure": 0.60217
        },
        "bleu": 45.46538,
        "nist": 8.362576900177432,
        "local_recall": {
            "1": 0.2202330207445297,
            "2": 0.6017076845806127,
            "3": 0.8802547770700637,
            "4": 0.9090909090909091,
            "5": 0.75
        },
        "nubia": {
            "semantic_relation": 4.48737,
            "contradiction": 9.43075,
            "irrelevancy": 7.43975,
            "logical_agreement": 83.1295,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.57984,
            "nubia_score": 0.79154
        },
        "meteor": 0.3963559829688975,
        "bleurt": 0.1871,
        "bertscore": {
            "precision": 0.91875,
            "recall": 0.92284,
            "f1": 0.91941
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "mT5_large/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.55331,
        "msttr-100_nopunct": 0.56914,
        "total_length": 13079,
        "mean_pred_length": 26.158,
        "std_pred_length": 14.243491004665955,
        "median_pred_length": 24.0,
        "min_pred_length": 5,
        "max_pred_length": 88,
        "distinct-1": 0.12325101307439407,
        "vocab_size-1": 1612,
        "unique-1": 644,
        "entropy-1": 8.210275871189229,
        "distinct-2": 0.419508704984498,
        "vocab_size-2": 5277,
        "unique-2": 3416,
        "entropy-2": 11.48379013897907,
        "cond_entropy-2": 3.1101358691288024,
        "distinct-3": 0.658249855120457,
        "vocab_size-3": 7951,
        "unique-3": 6272,
        "entropy-3": 12.547880851855474,
        "cond_entropy-3": 1.1020457803055503,
        "total_length-nopunct": 11619,
        "mean_pred_length-nopunct": 23.238,
        "std_pred_length-nopunct": 13.001282859779646,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 79,
        "distinct-1-nopunct": 0.13779154832601773,
        "vocab_size-1-nopunct": 1601,
        "unique-1-nopunct": 643,
        "entropy-1-nopunct": 8.475922251998524,
        "distinct-2-nopunct": 0.4363701771742063,
        "vocab_size-2-nopunct": 4852,
        "unique-2-nopunct": 3255,
        "entropy-2-nopunct": 11.380175287540993,
        "cond_entropy-2-nopunct": 3.0151619987699294,
        "distinct-3-nopunct": 0.6700254261229871,
        "vocab_size-3-nopunct": 7115,
        "unique-3-nopunct": 5721,
        "entropy-3-nopunct": 12.390949448520468,
        "cond_entropy-3-nopunct": 1.0359885982354948,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "rouge1": {
            "precision": 0.67362,
            "recall": 0.7073,
            "fmeasure": 0.68062
        },
        "rouge2": {
            "precision": 0.40896,
            "recall": 0.43162,
            "fmeasure": 0.41388
        },
        "rougeL": {
            "precision": 0.52399,
            "recall": 0.55249,
            "fmeasure": 0.53036
        },
        "rougeLsum": {
            "precision": 0.52399,
            "recall": 0.55249,
            "fmeasure": 0.53036
        },
        "bleu": 36.91191,
        "nist": 7.520236999233539,
        "local_recall": {
            "1": 0.22968966198853527,
            "2": 0.5503902273498473,
            "3": 0.8234854151084517,
            "4": 0.6,
            "5": 0.7222222222222222
        },
        "nubia": {
            "semantic_relation": 4.14117,
            "contradiction": 16.81548,
            "irrelevancy": 15.63288,
            "logical_agreement": 67.55164,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.72978,
            "nubia_score": 0.67502
        },
        "meteor": 0.3504938654718246,
        "bleurt": 0.01927,
        "bertscore": {
            "precision": 0.89859,
            "recall": 0.90452,
            "f1": 0.89997
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.48592,
        "msttr-100_nopunct": 0.49774,
        "total_length": 10389,
        "mean_pred_length": 27.19633507853403,
        "std_pred_length": 8.189553246659367,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 63,
        "distinct-1": 0.10462989700644913,
        "vocab_size-1": 1087,
        "unique-1": 297,
        "entropy-1": 7.865786613040944,
        "distinct-2": 0.2969921055261317,
        "vocab_size-2": 2972,
        "unique-2": 1391,
        "entropy-2": 10.647076817271367,
        "cond_entropy-2": 2.636650344259402,
        "distinct-3": 0.45246753246753246,
        "vocab_size-3": 4355,
        "unique-3": 2580,
        "entropy-3": 11.52695281938193,
        "cond_entropy-3": 0.9244472587959415,
        "total_length-nopunct": 9335,
        "mean_pred_length-nopunct": 24.43717277486911,
        "std_pred_length-nopunct": 7.488209256602837,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 56,
        "distinct-1-nopunct": 0.11558650241028388,
        "vocab_size-1-nopunct": 1079,
        "unique-1-nopunct": 297,
        "entropy-1-nopunct": 8.079048446944292,
        "distinct-2-nopunct": 0.305372500837708,
        "vocab_size-2-nopunct": 2734,
        "unique-2-nopunct": 1329,
        "entropy-2-nopunct": 10.526992444548164,
        "cond_entropy-2-nopunct": 2.5584357512471616,
        "distinct-3-nopunct": 0.4627231361568078,
        "vocab_size-3-nopunct": 3966,
        "unique-3-nopunct": 2415,
        "entropy-3-nopunct": 11.389091677050736,
        "cond_entropy-3-nopunct": 0.8928005805876221,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.71602,
            "recall": 0.74902,
            "fmeasure": 0.7238
        },
        "rouge2": {
            "precision": 0.45549,
            "recall": 0.47753,
            "fmeasure": 0.46033
        },
        "rougeL": {
            "precision": 0.56184,
            "recall": 0.58611,
            "fmeasure": 0.56668
        },
        "rougeLsum": {
            "precision": 0.56184,
            "recall": 0.58611,
            "fmeasure": 0.56668
        },
        "bleu": 44.7561,
        "nist": 8.293246942387675,
        "local_recall": {
            "1": 0.2280527232031833,
            "2": 0.5933159722222222,
            "3": 0.8798274002157497,
            "4": 0.6666666666666666,
            "5": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 4.42486,
            "contradiction": 9.40878,
            "irrelevancy": 10.24632,
            "logical_agreement": 80.3449,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.30146,
            "nubia_score": 0.77908
        },
        "meteor": 0.38653021122284764,
        "bleurt": 0.14937,
        "bertscore": {
            "precision": 0.9133,
            "recall": 0.91405,
            "f1": 0.91229
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.48631,
        "msttr-100_nopunct": 0.48787,
        "total_length": 8452,
        "mean_pred_length": 33.67330677290837,
        "std_pred_length": 10.281149569751989,
        "median_pred_length": 33.0,
        "min_pred_length": 10,
        "max_pred_length": 80,
        "distinct-1": 0.10754850922858496,
        "vocab_size-1": 909,
        "unique-1": 230,
        "entropy-1": 7.812810128059178,
        "distinct-2": 0.2811852213144738,
        "vocab_size-2": 2306,
        "unique-2": 989,
        "entropy-2": 10.346912474013374,
        "cond_entropy-2": 2.419133335042332,
        "distinct-3": 0.4171069182389937,
        "vocab_size-3": 3316,
        "unique-3": 1833,
        "entropy-3": 11.106125808502721,
        "cond_entropy-3": 0.7926940469530315,
        "total_length-nopunct": 7550,
        "mean_pred_length-nopunct": 30.0796812749004,
        "std_pred_length-nopunct": 9.239704375693366,
        "median_pred_length-nopunct": 30.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 74,
        "distinct-1-nopunct": 0.11933774834437086,
        "vocab_size-1-nopunct": 901,
        "unique-1-nopunct": 229,
        "entropy-1-nopunct": 8.036635375475468,
        "distinct-2-nopunct": 0.2942868886148787,
        "vocab_size-2-nopunct": 2148,
        "unique-2-nopunct": 976,
        "entropy-2-nopunct": 10.262851134531282,
        "cond_entropy-2-nopunct": 2.3099330255122466,
        "distinct-3-nopunct": 0.4333144154370034,
        "vocab_size-3-nopunct": 3054,
        "unique-3-nopunct": 1759,
        "entropy-3-nopunct": 10.997721178329193,
        "cond_entropy-3-nopunct": 0.7571808237114096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73815,
            "recall": 0.73488,
            "fmeasure": 0.72968
        },
        "rouge2": {
            "precision": 0.47703,
            "recall": 0.47139,
            "fmeasure": 0.46936
        },
        "rougeL": {
            "precision": 0.55876,
            "recall": 0.55767,
            "fmeasure": 0.55277
        },
        "rougeLsum": {
            "precision": 0.55876,
            "recall": 0.55767,
            "fmeasure": 0.55277
        },
        "bleu": 48.82177,
        "nist": 8.481972193617603,
        "local_recall": {
            "1": 0.23516055789815116,
            "2": 0.6341232227488152,
            "3": 0.8861581920903955
        },
        "nubia": {
            "semantic_relation": 4.35463,
            "contradiction": 9.33825,
            "irrelevancy": 8.80734,
            "logical_agreement": 81.85441,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.2148,
            "nubia_score": 0.76493
        },
        "meteor": 0.38416735814395325,
        "bleurt": 0.1279,
        "bertscore": {
            "precision": 0.91367,
            "recall": 0.91058,
            "f1": 0.91081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68046,
            "recall": 0.61878,
            "fmeasure": 0.63883
        },
        "rouge2": {
            "precision": 0.4828,
            "recall": 0.43034,
            "fmeasure": 0.44414
        },
        "rougeL": {
            "precision": 0.57701,
            "recall": 0.5164,
            "fmeasure": 0.53595
        },
        "rougeLsum": {
            "precision": 0.57701,
            "recall": 0.5164,
            "fmeasure": 0.53595
        },
        "bleu": 17.54382,
        "nist": 2.9695269184710735,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.2727272727272727,
            "3": 0.65625
        },
        "nubia": {
            "semantic_relation": 3.92286,
            "contradiction": 14.84263,
            "irrelevancy": 14.47253,
            "logical_agreement": 70.68484,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.49399,
            "nubia_score": 0.57169
        },
        "meteor": 0.29025753848252517,
        "bleurt": -0.00145,
        "bertscore": {
            "precision": 0.90371,
            "recall": 0.8999,
            "f1": 0.90155
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.51484,
        "msttr-100_nopunct": 0.51673,
        "total_length": 6204,
        "mean_pred_length": 39.265822784810126,
        "std_pred_length": 11.56840837904208,
        "median_pred_length": 37.0,
        "min_pred_length": 20,
        "max_pred_length": 78,
        "distinct-1": 0.12508059316569956,
        "vocab_size-1": 776,
        "unique-1": 173,
        "entropy-1": 7.665401095888953,
        "distinct-2": 0.31524975190208404,
        "vocab_size-2": 1906,
        "unique-2": 831,
        "entropy-2": 10.12811685025499,
        "cond_entropy-2": 2.368289127110107,
        "distinct-3": 0.45805027173913043,
        "vocab_size-3": 2697,
        "unique-3": 1564,
        "entropy-3": 10.859741142636455,
        "cond_entropy-3": 0.7588542005088674,
        "total_length-nopunct": 5566,
        "mean_pred_length-nopunct": 35.22784810126582,
        "std_pred_length-nopunct": 10.358692756448393,
        "median_pred_length-nopunct": 33.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 68,
        "distinct-1-nopunct": 0.13798059647862018,
        "vocab_size-1-nopunct": 768,
        "unique-1-nopunct": 172,
        "entropy-1-nopunct": 7.85216697271838,
        "distinct-2-nopunct": 0.3300665680473373,
        "vocab_size-2-nopunct": 1785,
        "unique-2-nopunct": 813,
        "entropy-2-nopunct": 10.067177352312164,
        "cond_entropy-2-nopunct": 2.285747438523701,
        "distinct-3-nopunct": 0.4739047619047619,
        "vocab_size-3-nopunct": 2488,
        "unique-3-nopunct": 1493,
        "entropy-3-nopunct": 10.758132811532873,
        "cond_entropy-3-nopunct": 0.7121317853730563,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.72842,
            "recall": 0.72187,
            "fmeasure": 0.7188
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.44483,
            "fmeasure": 0.44425
        },
        "rougeL": {
            "precision": 0.51329,
            "recall": 0.50857,
            "fmeasure": 0.5058
        },
        "rougeLsum": {
            "precision": 0.51329,
            "recall": 0.50857,
            "fmeasure": 0.5058
        },
        "bleu": 47.64439,
        "nist": 8.2674200286635,
        "local_recall": {
            "1": 0.24842767295597484,
            "2": 0.5471698113207547,
            "3": 0.8792184724689165
        },
        "nubia": {
            "semantic_relation": 4.2785,
            "contradiction": 8.85849,
            "irrelevancy": 8.98763,
            "logical_agreement": 82.15387,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.06358,
            "nubia_score": 0.75383
        },
        "meteor": 0.36818586408191684,
        "bleurt": 0.04416,
        "bertscore": {
            "precision": 0.90675,
            "recall": 0.90262,
            "f1": 0.90347
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "mT5_large/xsum_test",
        "N": 106,
        "msttr-100": 0.71476,
        "msttr-100_nopunct": 0.73368,
        "total_length": 2128,
        "mean_pred_length": 20.07547169811321,
        "std_pred_length": 4.297208644689184,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.4130639097744361,
        "vocab_size-1": 879,
        "unique-1": 650,
        "entropy-1": 8.223932850033991,
        "distinct-2": 0.8308605341246291,
        "vocab_size-2": 1680,
        "unique-2": 1530,
        "entropy-2": 10.482831146748351,
        "cond_entropy-2": 2.0546270246447094,
        "distinct-3": 0.9556367432150313,
        "vocab_size-3": 1831,
        "unique-3": 1770,
        "entropy-3": 10.798992551941584,
        "cond_entropy-3": 0.3272555543854176,
        "total_length-nopunct": 1977,
        "mean_pred_length-nopunct": 18.650943396226417,
        "std_pred_length-nopunct": 4.191281275772966,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.44157814871016693,
        "vocab_size-1-nopunct": 873,
        "unique-1-nopunct": 650,
        "entropy-1-nopunct": 8.356539065819662,
        "distinct-2-nopunct": 0.8353821485836451,
        "vocab_size-2-nopunct": 1563,
        "unique-2-nopunct": 1430,
        "entropy-2-nopunct": 10.381028493772188,
        "cond_entropy-2-nopunct": 2.1225373672997,
        "distinct-3-nopunct": 0.9637393767705382,
        "vocab_size-3-nopunct": 1701,
        "unique-3-nopunct": 1650,
        "entropy-3-nopunct": 10.705569341552394,
        "cond_entropy-3-nopunct": 0.3276401792898297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "rouge1": {
            "precision": 0.47186,
            "recall": 0.41358,
            "fmeasure": 0.43317
        },
        "rouge2": {
            "precision": 0.21867,
            "recall": 0.19014,
            "fmeasure": 0.19959
        },
        "rougeL": {
            "precision": 0.36737,
            "recall": 0.32117,
            "fmeasure": 0.33689
        },
        "rougeLsum": {
            "precision": 0.36737,
            "recall": 0.32117,
            "fmeasure": 0.33689
        },
        "bleu": 12.33773,
        "nist": 3.781489788912218,
        "local_recall": {
            "1": 0.3860729512079583
        },
        "nubia": {
            "semantic_relation": 3.24761,
            "contradiction": 23.17833,
            "irrelevancy": 58.12397,
            "logical_agreement": 18.6977,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.65348,
            "nubia_score": 0.50615
        },
        "meteor": 0.19481848892741974,
        "bleurt": -0.22345,
        "bertscore": {
            "precision": 0.85085,
            "recall": 0.83192,
            "f1": 0.84096
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.20139,
            "recall": 0.40486,
            "fmeasure": 0.26785
        },
        "rouge2": {
            "precision": 0.07801,
            "recall": 0.16222,
            "fmeasure": 0.10484
        },
        "rougeL": {
            "precision": 0.20139,
            "recall": 0.40486,
            "fmeasure": 0.26785
        },
        "rougeLsum": {
            "precision": 0.20139,
            "recall": 0.40486,
            "fmeasure": 0.26785
        },
        "bleu": 11.18816,
        "nist": 1.1193054427717808,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 2.19609,
            "contradiction": 1.04509,
            "irrelevancy": 74.46232,
            "logical_agreement": 24.49259,
            "grammar_ref": 4.75948,
            "grammar_hyp": 3.75059,
            "nubia_score": 0.02481
        },
        "meteor": 0.1623818070603364,
        "bleurt": -1.08662,
        "bertscore": {
            "precision": 0.76267,
            "recall": 0.8086,
            "f1": 0.78497
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.52118,
        "msttr-100_nopunct": 0.52935,
        "total_length": 3485,
        "mean_pred_length": 43.5625,
        "std_pred_length": 11.856268120703074,
        "median_pred_length": 42.0,
        "min_pred_length": 21,
        "max_pred_length": 78,
        "distinct-1": 0.18479196556671448,
        "vocab_size-1": 644,
        "unique-1": 251,
        "entropy-1": 7.454511900292546,
        "distinct-2": 0.42555066079295156,
        "vocab_size-2": 1449,
        "unique-2": 824,
        "entropy-2": 9.83879073663806,
        "cond_entropy-2": 2.3041926537140713,
        "distinct-3": 0.5864661654135338,
        "vocab_size-3": 1950,
        "unique-3": 1344,
        "entropy-3": 10.538247291670467,
        "cond_entropy-3": 0.7195537766085632,
        "total_length-nopunct": 3123,
        "mean_pred_length-nopunct": 39.0375,
        "std_pred_length-nopunct": 10.826407241093419,
        "median_pred_length-nopunct": 37.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 69,
        "distinct-1-nopunct": 0.20365033621517772,
        "vocab_size-1-nopunct": 636,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.616823925999807,
        "distinct-2-nopunct": 0.44429838974696023,
        "vocab_size-2-nopunct": 1352,
        "unique-2-nopunct": 795,
        "entropy-2-nopunct": 9.7810724290647,
        "cond_entropy-2-nopunct": 2.2222562871963185,
        "distinct-3-nopunct": 0.6024299696253796,
        "vocab_size-3-nopunct": 1785,
        "unique-3-nopunct": 1258,
        "entropy-3-nopunct": 10.421919201633647,
        "cond_entropy-3-nopunct": 0.6540744772422875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.70865,
            "recall": 0.68233,
            "fmeasure": 0.68703
        },
        "rouge2": {
            "precision": 0.42068,
            "recall": 0.40453,
            "fmeasure": 0.40734
        },
        "rougeL": {
            "precision": 0.48631,
            "recall": 0.47691,
            "fmeasure": 0.47564
        },
        "rougeLsum": {
            "precision": 0.48631,
            "recall": 0.47691,
            "fmeasure": 0.47564
        },
        "bleu": 42.03958,
        "nist": 7.783654235027163,
        "local_recall": {
            "1": 0.2078907435508346,
            "2": 0.5603217158176944,
            "3": 0.8360323886639676
        },
        "nubia": {
            "semantic_relation": 4.04933,
            "contradiction": 8.3996,
            "irrelevancy": 15.15456,
            "logical_agreement": 76.44584,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.07026,
            "nubia_score": 0.69605
        },
        "meteor": 0.3366989272782378,
        "bleurt": 0.00806,
        "bertscore": {
            "precision": 0.89762,
            "recall": 0.88581,
            "f1": 0.88991
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62815,
            "recall": 0.42281,
            "fmeasure": 0.50355
        },
        "rouge2": {
            "precision": 0.20913,
            "recall": 0.13506,
            "fmeasure": 0.16344
        },
        "rougeL": {
            "precision": 0.39076,
            "recall": 0.25789,
            "fmeasure": 0.30948
        },
        "rougeLsum": {
            "precision": 0.39076,
            "recall": 0.25789,
            "fmeasure": 0.30948
        },
        "bleu": 4.27836,
        "nist": 0.43241761877470514,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.3181818181818182
        },
        "nubia": {
            "semantic_relation": 3.40921,
            "contradiction": 48.0035,
            "irrelevancy": 39.92798,
            "logical_agreement": 12.06852,
            "grammar_ref": 3.96887,
            "grammar_hyp": 5.26193,
            "nubia_score": 0.30683
        },
        "meteor": 0.2060959604235614,
        "bleurt": -0.21345,
        "bertscore": {
            "precision": 0.8767,
            "recall": 0.82517,
            "f1": 0.84669
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "mT5_large/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.53059,
        "msttr-100_nopunct": 0.55438,
        "total_length": 1799,
        "mean_pred_length": 43.8780487804878,
        "std_pred_length": 11.153464127633214,
        "median_pred_length": 42.0,
        "min_pred_length": 25,
        "max_pred_length": 69,
        "distinct-1": 0.2490272373540856,
        "vocab_size-1": 448,
        "unique-1": 222,
        "entropy-1": 7.213651947152876,
        "distinct-2": 0.5091012514220705,
        "vocab_size-2": 895,
        "unique-2": 562,
        "entropy-2": 9.313729918891152,
        "cond_entropy-2": 2.025260495449091,
        "distinct-3": 0.6528829353523588,
        "vocab_size-3": 1121,
        "unique-3": 817,
        "entropy-3": 9.838590125523877,
        "cond_entropy-3": 0.5422973116176375,
        "total_length-nopunct": 1615,
        "mean_pred_length-nopunct": 39.390243902439025,
        "std_pred_length-nopunct": 10.330815963760896,
        "median_pred_length-nopunct": 38.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 63,
        "distinct-1-nopunct": 0.2743034055727554,
        "vocab_size-1-nopunct": 443,
        "unique-1-nopunct": 221,
        "entropy-1-nopunct": 7.363078307536574,
        "distinct-2-nopunct": 0.5266836086404066,
        "vocab_size-2-nopunct": 829,
        "unique-2-nopunct": 534,
        "entropy-2-nopunct": 9.246682647867468,
        "cond_entropy-2-nopunct": 1.9404538464278753,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 1022,
        "unique-3-nopunct": 760,
        "entropy-3-nopunct": 9.718861840537606,
        "cond_entropy-3-nopunct": 0.4840063581939895,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "rouge1": {
            "precision": 0.73813,
            "recall": 0.68165,
            "fmeasure": 0.70151
        },
        "rouge2": {
            "precision": 0.44536,
            "recall": 0.41228,
            "fmeasure": 0.42336
        },
        "rougeL": {
            "precision": 0.50634,
            "recall": 0.45995,
            "fmeasure": 0.476
        },
        "rougeLsum": {
            "precision": 0.50634,
            "recall": 0.45995,
            "fmeasure": 0.476
        },
        "bleu": 43.55374,
        "nist": 7.520613213815897,
        "local_recall": {
            "1": 0.20090634441087613,
            "2": 0.5025510204081632,
            "3": 0.8176733780760627
        },
        "nubia": {
            "semantic_relation": 3.94526,
            "contradiction": 9.59307,
            "irrelevancy": 8.91946,
            "logical_agreement": 81.48746,
            "grammar_ref": 3.92594,
            "grammar_hyp": 3.94343,
            "nubia_score": 0.67764
        },
        "meteor": 0.3420581895043186,
        "bleurt": 0.02629,
        "bertscore": {
            "precision": 0.90142,
            "recall": 0.88436,
            "f1": 0.89145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "mT5_large/totto_test",
        "N": 62,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77676,
            "recall": 0.7443,
            "fmeasure": 0.75192
        },
        "rouge2": {
            "precision": 0.55629,
            "recall": 0.53791,
            "fmeasure": 0.54139
        },
        "rougeL": {
            "precision": 0.67494,
            "recall": 0.65409,
            "fmeasure": 0.65724
        },
        "rougeLsum": {
            "precision": 0.67494,
            "recall": 0.65409,
            "fmeasure": 0.65724
        },
        "bleu": 51.27229,
        "nist": 7.455339866364526,
        "local_recall": {
            "1": 0.1569767441860465,
            "2": 0.3785310734463277,
            "3": 0.8061224489795918
        },
        "nubia": {
            "semantic_relation": 4.30176,
            "contradiction": 6.22396,
            "irrelevancy": 29.59534,
            "logical_agreement": 64.1807,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.5509,
            "nubia_score": 0.76994
        },
        "meteor": 0.40709932612362754,
        "bleurt": 0.29443,
        "bertscore": {
            "precision": 0.9369,
            "recall": 0.92925,
            "f1": 0.93066
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.15,
            "recall": 0.2,
            "fmeasure": 0.17143
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.07143,
            "fmeasure": 0.06061
        },
        "rougeL": {
            "precision": 0.1,
            "recall": 0.13333,
            "fmeasure": 0.11429
        },
        "rougeLsum": {
            "precision": 0.1,
            "recall": 0.13333,
            "fmeasure": 0.11429
        },
        "bleu": 4.3194,
        "nist": 0.7619047619047619,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nubia": {
            "semantic_relation": 2.54676,
            "contradiction": 0.23115,
            "irrelevancy": 99.35725,
            "logical_agreement": 0.4116,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.26415,
            "nubia_score": 0.3099
        },
        "meteor": 0.10975885904381236,
        "bleurt": -0.56148,
        "bertscore": {
            "precision": 0.74679,
            "recall": 0.77097,
            "f1": 0.75727
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.2,
            "fmeasure": 0.24
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.2,
            "fmeasure": 0.24
        },
        "bleu": 3.6042,
        "nist": 0.8668322752333701,
        "local_recall": {
            "1": 0,
            "2": 0.3076923076923077
        },
        "nubia": {
            "semantic_relation": 2.20022,
            "contradiction": 98.31739,
            "irrelevancy": 1.2874,
            "logical_agreement": 0.3952,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.98314,
            "nubia_score": 0.15203
        },
        "meteor": 0.11594202898550726,
        "bleurt": -0.96766,
        "bertscore": {
            "precision": 0.77882,
            "recall": 0.77192,
            "f1": 0.77535
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64444,
            "recall": 0.79744,
            "fmeasure": 0.71048
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.55556,
            "fmeasure": 0.43305
        },
        "rougeL": {
            "precision": 0.62222,
            "recall": 0.7641,
            "fmeasure": 0.68381
        },
        "rougeLsum": {
            "precision": 0.62222,
            "recall": 0.7641,
            "fmeasure": 0.68381
        },
        "bleu": 49.58272,
        "nist": 2.9927068734107967,
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.16025,
            "contradiction": 85.23708,
            "irrelevancy": 8.46851,
            "logical_agreement": 6.29441,
            "grammar_ref": 6.66832,
            "grammar_hyp": 5.22346,
            "nubia_score": 0.47192
        },
        "meteor": 0.4583736498074521,
        "bleurt": 0.33398,
        "bertscore": {
            "precision": 0.94576,
            "recall": 0.97017,
            "f1": 0.95488
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.74,
            "fmeasure": 0.55403
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.28968,
            "fmeasure": 0.20182
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.55667,
            "fmeasure": 0.41596
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.55667,
            "fmeasure": 0.41596
        },
        "bleu": 7.2324,
        "nist": 2.34080182327708,
        "local_recall": {
            "1": 1.0,
            "2": 0.75,
            "3": 0.5833333333333334
        },
        "nubia": {
            "semantic_relation": 2.37631,
            "contradiction": 2.69727,
            "irrelevancy": 97.15199,
            "logical_agreement": 0.15073,
            "grammar_ref": 4.19943,
            "grammar_hyp": 3.78957,
            "nubia_score": 0.16875
        },
        "meteor": 0.3100768671096405,
        "bleurt": -0.45039,
        "bertscore": {
            "precision": 0.86942,
            "recall": 0.89136,
            "f1": 0.88025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "mT5_large/totto_test",
        "N": 35,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77117,
            "recall": 0.73466,
            "fmeasure": 0.74394
        },
        "rouge2": {
            "precision": 0.53169,
            "recall": 0.50862,
            "fmeasure": 0.51363
        },
        "rougeL": {
            "precision": 0.68347,
            "recall": 0.66211,
            "fmeasure": 0.66387
        },
        "rougeLsum": {
            "precision": 0.68347,
            "recall": 0.66211,
            "fmeasure": 0.66387
        },
        "bleu": 45.89073,
        "nist": 6.6384340180606385,
        "local_recall": {
            "1": 0.20212765957446807,
            "2": 0.4778761061946903,
            "3": 0.7632241813602015
        },
        "nubia": {
            "semantic_relation": 4.09332,
            "contradiction": 11.79161,
            "irrelevancy": 22.78976,
            "logical_agreement": 65.41862,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.54266,
            "nubia_score": 0.69826
        },
        "meteor": 0.402705687143884,
        "bleurt": 0.2876,
        "bertscore": {
            "precision": 0.93461,
            "recall": 0.92418,
            "f1": 0.92723
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.47143,
            "fmeasure": 0.59704
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.29591,
            "fmeasure": 0.37742
        },
        "rougeL": {
            "precision": 0.56818,
            "recall": 0.32619,
            "fmeasure": 0.41365
        },
        "rougeLsum": {
            "precision": 0.56818,
            "recall": 0.32619,
            "fmeasure": 0.41365
        },
        "bleu": 34.85133,
        "nist": 1.8850941315424428,
        "local_recall": {
            "1": 0.0,
            "2": 0.6071428571428571
        },
        "nubia": {
            "semantic_relation": 3.29323,
            "contradiction": 1.69813,
            "irrelevancy": 1.14851,
            "logical_agreement": 97.15335,
            "grammar_ref": 3.72412,
            "grammar_hyp": 3.47257,
            "nubia_score": 0.47033
        },
        "meteor": 0.30469849406961863,
        "bleurt": 0.02714,
        "bertscore": {
            "precision": 0.92715,
            "recall": 0.8749,
            "f1": 0.89839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "mT5_large/totto_test",
        "N": 54,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74255,
            "recall": 0.69253,
            "fmeasure": 0.70268
        },
        "rouge2": {
            "precision": 0.49106,
            "recall": 0.46129,
            "fmeasure": 0.46611
        },
        "rougeL": {
            "precision": 0.62408,
            "recall": 0.59178,
            "fmeasure": 0.59375
        },
        "rougeLsum": {
            "precision": 0.62408,
            "recall": 0.59178,
            "fmeasure": 0.59375
        },
        "bleu": 38.98751,
        "nist": 6.630813217854663,
        "local_recall": {
            "1": 0.21787709497206703,
            "2": 0.37142857142857144,
            "3": 0.7322580645161291
        },
        "nubia": {
            "semantic_relation": 4.15918,
            "contradiction": 8.04336,
            "irrelevancy": 30.56234,
            "logical_agreement": 61.39431,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.70491,
            "nubia_score": 0.70213
        },
        "meteor": 0.37272049398304413,
        "bleurt": 0.20301,
        "bertscore": {
            "precision": 0.92203,
            "recall": 0.91693,
            "f1": 0.91869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93855,
            "recall": 0.90524,
            "fmeasure": 0.9205
        },
        "rouge2": {
            "precision": 0.85119,
            "recall": 0.82778,
            "fmeasure": 0.83844
        },
        "rougeL": {
            "precision": 0.92131,
            "recall": 0.88911,
            "fmeasure": 0.90383
        },
        "rougeLsum": {
            "precision": 0.92131,
            "recall": 0.88911,
            "fmeasure": 0.90383
        },
        "bleu": 65.3479,
        "nist": 5.023609310008057,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8378378378378378
        },
        "nubia": {
            "semantic_relation": 4.75725,
            "contradiction": 1.09325,
            "irrelevancy": 23.6129,
            "logical_agreement": 75.29385,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.13491,
            "nubia_score": 0.87371
        },
        "meteor": 0.5113892474977115,
        "bleurt": 0.78243,
        "bertscore": {
            "precision": 0.98099,
            "recall": 0.97757,
            "f1": 0.97927
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88542,
            "recall": 0.73076,
            "fmeasure": 0.79473
        },
        "rouge2": {
            "precision": 0.70909,
            "recall": 0.5727,
            "fmeasure": 0.62754
        },
        "rougeL": {
            "precision": 0.71181,
            "recall": 0.53522,
            "fmeasure": 0.60724
        },
        "rougeLsum": {
            "precision": 0.71181,
            "recall": 0.53522,
            "fmeasure": 0.60724
        },
        "bleu": 52.8842,
        "nist": 3.782510083838885,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7333333333333333
        },
        "nubia": {
            "semantic_relation": 3.5469,
            "contradiction": 0.69494,
            "irrelevancy": 30.27131,
            "logical_agreement": 69.03374,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.73932,
            "nubia_score": 0.5242
        },
        "meteor": 0.39680003191498947,
        "bleurt": -0.01245,
        "bertscore": {
            "precision": 0.9512,
            "recall": 0.90168,
            "f1": 0.92264
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.32143,
            "recall": 0.53125,
            "fmeasure": 0.4002
        },
        "rouge2": {
            "precision": 0.14815,
            "recall": 0.25098,
            "fmeasure": 0.18615
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.35417,
            "fmeasure": 0.2668
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.35417,
            "fmeasure": 0.2668
        },
        "bleu": 6.75788,
        "nist": 1.5939808820574735,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 2.73159,
            "contradiction": 1.92504,
            "irrelevancy": 97.11463,
            "logical_agreement": 0.96033,
            "grammar_ref": 4.60656,
            "grammar_hyp": 4.19657,
            "nubia_score": 0.37338
        },
        "meteor": 0.26924350330236574,
        "bleurt": -0.5105,
        "bertscore": {
            "precision": 0.81822,
            "recall": 0.85049,
            "f1": 0.83404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "mT5_large/totto_test",
        "N": 28,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76855,
            "recall": 0.71986,
            "fmeasure": 0.73916
        },
        "rouge2": {
            "precision": 0.56077,
            "recall": 0.52787,
            "fmeasure": 0.54023
        },
        "rougeL": {
            "precision": 0.67764,
            "recall": 0.64078,
            "fmeasure": 0.65395
        },
        "rougeLsum": {
            "precision": 0.67764,
            "recall": 0.64078,
            "fmeasure": 0.65395
        },
        "bleu": 47.82509,
        "nist": 6.454087130186135,
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.4533333333333333,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.11419,
            "contradiction": 4.68592,
            "irrelevancy": 33.04185,
            "logical_agreement": 62.27223,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.55338,
            "nubia_score": 0.71684
        },
        "meteor": 0.39503735497316356,
        "bleurt": 0.30545,
        "bertscore": {
            "precision": 0.93078,
            "recall": 0.9248,
            "f1": 0.92426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "mT5_large/totto_test",
        "N": 48,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75834,
            "recall": 0.69482,
            "fmeasure": 0.71318
        },
        "rouge2": {
            "precision": 0.49509,
            "recall": 0.461,
            "fmeasure": 0.46889
        },
        "rougeL": {
            "precision": 0.64177,
            "recall": 0.59304,
            "fmeasure": 0.60687
        },
        "rougeLsum": {
            "precision": 0.64177,
            "recall": 0.59304,
            "fmeasure": 0.60687
        },
        "bleu": 37.88627,
        "nist": 6.624497596659299,
        "local_recall": {
            "1": 0.24561403508771928,
            "2": 0.5769230769230769,
            "3": 0.7084942084942085
        },
        "nubia": {
            "semantic_relation": 4.12163,
            "contradiction": 6.80414,
            "irrelevancy": 35.07566,
            "logical_agreement": 58.1202,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.72348,
            "nubia_score": 0.69708
        },
        "meteor": 0.36411270541837354,
        "bleurt": 0.17916,
        "bertscore": {
            "precision": 0.9233,
            "recall": 0.91282,
            "f1": 0.91562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41026,
            "recall": 0.47037,
            "fmeasure": 0.42424
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.30263,
            "fmeasure": 0.26452
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.47037,
            "fmeasure": 0.42424
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.47037,
            "fmeasure": 0.42424
        },
        "bleu": 13.67441,
        "nist": 1.4219432376577597,
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 2.882,
            "contradiction": 93.89892,
            "irrelevancy": 4.47915,
            "logical_agreement": 1.62193,
            "grammar_ref": 4.8547,
            "grammar_hyp": 5.22943,
            "nubia_score": 0.23991
        },
        "meteor": 0.20575465389579325,
        "bleurt": -0.74933,
        "bertscore": {
            "precision": 0.8788,
            "recall": 0.89502,
            "f1": 0.88403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "mT5_large/totto_test",
        "N": 71,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75929,
            "recall": 0.7674,
            "fmeasure": 0.74709
        },
        "rouge2": {
            "precision": 0.58121,
            "recall": 0.59555,
            "fmeasure": 0.57446
        },
        "rougeL": {
            "precision": 0.71994,
            "recall": 0.73219,
            "fmeasure": 0.71088
        },
        "rougeLsum": {
            "precision": 0.71994,
            "recall": 0.73219,
            "fmeasure": 0.71088
        },
        "bleu": 56.00479,
        "nist": 7.238804624434931,
        "local_recall": {
            "1": 0.30726256983240224,
            "2": 0.5894736842105263,
            "3": 0.7951807228915663
        },
        "nubia": {
            "semantic_relation": 4.05169,
            "contradiction": 9.13815,
            "irrelevancy": 41.36847,
            "logical_agreement": 49.49338,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.26323,
            "nubia_score": 0.67285
        },
        "meteor": 0.42829417967692496,
        "bleurt": 0.37397,
        "bertscore": {
            "precision": 0.94435,
            "recall": 0.94338,
            "f1": 0.94268
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.575,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.38596,
            "fmeasure": 0.40476
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "bleu": 49.61683,
        "nist": 1.6094187269665412,
        "local_recall": {
            "1": 0.2,
            "2": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.38092,
            "contradiction": 85.28887,
            "irrelevancy": 6.42908,
            "logical_agreement": 8.28205,
            "grammar_ref": 5.69136,
            "grammar_hyp": 6.66827,
            "nubia_score": 0.27846
        },
        "meteor": 0.49279527996382966,
        "bleurt": 0.29871,
        "bertscore": {
            "precision": 0.98046,
            "recall": 0.98046,
            "f1": 0.98046
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.43182,
            "recall": 0.24091,
            "fmeasure": 0.30295
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.04374,
            "fmeasure": 0.05333
        },
        "rougeL": {
            "precision": 0.38636,
            "recall": 0.20758,
            "fmeasure": 0.26449
        },
        "rougeLsum": {
            "precision": 0.38636,
            "recall": 0.20758,
            "fmeasure": 0.26449
        },
        "bleu": 5.11139,
        "nist": 0.3859643878021576,
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.2727272727272727
        },
        "nubia": {
            "semantic_relation": 2.12939,
            "contradiction": 61.14778,
            "irrelevancy": 37.85231,
            "logical_agreement": 0.99992,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.30016,
            "nubia_score": 0.11576
        },
        "meteor": 0.13954002883933014,
        "bleurt": -0.19898,
        "bertscore": {
            "precision": 0.89688,
            "recall": 0.82874,
            "f1": 0.85239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "mT5_large/totto_test",
        "N": 47,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.771,
            "recall": 0.71086,
            "fmeasure": 0.72917
        },
        "rouge2": {
            "precision": 0.51071,
            "recall": 0.46941,
            "fmeasure": 0.48231
        },
        "rougeL": {
            "precision": 0.65916,
            "recall": 0.60591,
            "fmeasure": 0.6226
        },
        "rougeLsum": {
            "precision": 0.65916,
            "recall": 0.60591,
            "fmeasure": 0.6226
        },
        "bleu": 40.43194,
        "nist": 6.398747581087863,
        "local_recall": {
            "1": 0.20353982300884957,
            "2": 0.4823529411764706,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.21036,
            "contradiction": 9.82921,
            "irrelevancy": 31.08186,
            "logical_agreement": 59.08894,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.98004,
            "nubia_score": 0.68128
        },
        "meteor": 0.36787752850372196,
        "bleurt": 0.26937,
        "bertscore": {
            "precision": 0.92988,
            "recall": 0.91648,
            "f1": 0.92167
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.29825,
            "recall": 0.3635,
            "fmeasure": 0.32639
        },
        "rouge2": {
            "precision": 0.05556,
            "recall": 0.07639,
            "fmeasure": 0.06405
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.31222,
            "fmeasure": 0.28472
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.31222,
            "fmeasure": 0.28472
        },
        "bleu": 6.10856,
        "nist": 1.6758113988473455,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 1.79871,
            "contradiction": 17.53804,
            "irrelevancy": 78.0347,
            "logical_agreement": 4.42725,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.23235,
            "nubia_score": 0.23408
        },
        "meteor": 0.1578647274797024,
        "bleurt": -0.53989,
        "bertscore": {
            "precision": 0.68701,
            "recall": 0.67856,
            "f1": 0.68276
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.62393,
            "fmeasure": 0.65821
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.8022,
            "fmeasure": 0.84308
        },
        "bleu": 57.72609,
        "nist": 3.5326561416927635,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9
        },
        "nubia": {
            "semantic_relation": 2.1241,
            "contradiction": 99.51378,
            "irrelevancy": 0.42538,
            "logical_agreement": 0.06084,
            "grammar_ref": 4.48671,
            "grammar_hyp": 3.95934,
            "nubia_score": 0.20881
        },
        "meteor": 0.46990451422352364,
        "bleurt": 0.27347,
        "bertscore": {
            "precision": 0.98745,
            "recall": 0.97676,
            "f1": 0.98208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "mT5_large/totto_test",
        "N": 44,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76449,
            "recall": 0.73753,
            "fmeasure": 0.74068
        },
        "rouge2": {
            "precision": 0.54838,
            "recall": 0.53668,
            "fmeasure": 0.53525
        },
        "rougeL": {
            "precision": 0.69066,
            "recall": 0.67266,
            "fmeasure": 0.67099
        },
        "rougeLsum": {
            "precision": 0.69066,
            "recall": 0.67266,
            "fmeasure": 0.67099
        },
        "bleu": 49.68535,
        "nist": 6.942970678612939,
        "local_recall": {
            "1": 0.22142857142857142,
            "2": 0.6153846153846154,
            "3": 0.782608695652174
        },
        "nubia": {
            "semantic_relation": 4.29575,
            "contradiction": 3.46979,
            "irrelevancy": 30.06623,
            "logical_agreement": 66.46398,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.55075,
            "nubia_score": 0.75924
        },
        "meteor": 0.4117250095126174,
        "bleurt": 0.33293,
        "bertscore": {
            "precision": 0.93776,
            "recall": 0.93441,
            "f1": 0.93352
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.25,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "bleu": 19.07733,
        "nist": 1.0738270250535529,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 2.3931,
            "contradiction": 44.11333,
            "irrelevancy": 54.89031,
            "logical_agreement": 0.99636,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.21765,
            "nubia_score": 0.18356
        },
        "meteor": 0.19198335664587465,
        "bleurt": -0.17539,
        "bertscore": {
            "precision": 0.86153,
            "recall": 0.77393,
            "f1": 0.81539
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5835,
            "recall": 0.62213,
            "fmeasure": 0.5818
        },
        "rouge2": {
            "precision": 0.38152,
            "recall": 0.43682,
            "fmeasure": 0.39529
        },
        "rougeL": {
            "precision": 0.49308,
            "recall": 0.5329,
            "fmeasure": 0.49432
        },
        "rougeLsum": {
            "precision": 0.49308,
            "recall": 0.5329,
            "fmeasure": 0.49432
        },
        "bleu": 30.56455,
        "nist": 4.04103598837682,
        "local_recall": {
            "1": 0.7,
            "2": 0.09090909090909091,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.08175,
            "contradiction": 0.35415,
            "irrelevancy": 61.56746,
            "logical_agreement": 38.07839,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.85312,
            "nubia_score": 0.66879
        },
        "meteor": 0.29924628291166816,
        "bleurt": -0.06662,
        "bertscore": {
            "precision": 0.90092,
            "recall": 0.90367,
            "f1": 0.89321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "mT5_large/totto_test",
        "N": 78,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77042,
            "recall": 0.73888,
            "fmeasure": 0.74523
        },
        "rouge2": {
            "precision": 0.53998,
            "recall": 0.51608,
            "fmeasure": 0.52131
        },
        "rougeL": {
            "precision": 0.69742,
            "recall": 0.66808,
            "fmeasure": 0.67467
        },
        "rougeLsum": {
            "precision": 0.69742,
            "recall": 0.66808,
            "fmeasure": 0.67467
        },
        "bleu": 51.38546,
        "nist": 7.53033698612548,
        "local_recall": {
            "1": 0.1888412017167382,
            "2": 0.502127659574468,
            "3": 0.8029197080291971
        },
        "nubia": {
            "semantic_relation": 4.33003,
            "contradiction": 5.32366,
            "irrelevancy": 30.1559,
            "logical_agreement": 64.52044,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.6929,
            "nubia_score": 0.76283
        },
        "meteor": 0.4159207571664871,
        "bleurt": 0.32984,
        "bertscore": {
            "precision": 0.93317,
            "recall": 0.93249,
            "f1": 0.93164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "mT5_large/totto_test",
        "N": 36,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78617,
            "recall": 0.71783,
            "fmeasure": 0.73853
        },
        "rouge2": {
            "precision": 0.52234,
            "recall": 0.47483,
            "fmeasure": 0.48936
        },
        "rougeL": {
            "precision": 0.6636,
            "recall": 0.60697,
            "fmeasure": 0.62371
        },
        "rougeLsum": {
            "precision": 0.6636,
            "recall": 0.60697,
            "fmeasure": 0.62371
        },
        "bleu": 44.66235,
        "nist": 6.739172901167691,
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.3146067415730337,
            "3": 0.774818401937046
        },
        "nubia": {
            "semantic_relation": 4.33315,
            "contradiction": 1.13329,
            "irrelevancy": 24.20795,
            "logical_agreement": 74.65876,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.01817,
            "nubia_score": 0.74353
        },
        "meteor": 0.3782478398724873,
        "bleurt": 0.29011,
        "bertscore": {
            "precision": 0.93669,
            "recall": 0.92109,
            "f1": 0.92801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "mT5_large/totto_test",
        "N": 15,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82235,
            "recall": 0.75511,
            "fmeasure": 0.77813
        },
        "rouge2": {
            "precision": 0.61301,
            "recall": 0.55228,
            "fmeasure": 0.57455
        },
        "rougeL": {
            "precision": 0.77627,
            "recall": 0.7052,
            "fmeasure": 0.73048
        },
        "rougeLsum": {
            "precision": 0.77627,
            "recall": 0.7052,
            "fmeasure": 0.73048
        },
        "bleu": 49.81363,
        "nist": 5.935082724846538,
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.5384615384615384,
            "3": 0.7864583333333334
        },
        "nubia": {
            "semantic_relation": 4.2209,
            "contradiction": 8.94188,
            "irrelevancy": 32.89507,
            "logical_agreement": 58.16305,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.51303,
            "nubia_score": 0.70348
        },
        "meteor": 0.41478308381446694,
        "bleurt": 0.35742,
        "bertscore": {
            "precision": 0.94136,
            "recall": 0.93254,
            "f1": 0.93574
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "mT5_large/totto_test",
        "N": 20,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81604,
            "recall": 0.78958,
            "fmeasure": 0.79489
        },
        "rouge2": {
            "precision": 0.6423,
            "recall": 0.62512,
            "fmeasure": 0.62788
        },
        "rougeL": {
            "precision": 0.70975,
            "recall": 0.68695,
            "fmeasure": 0.69138
        },
        "rougeLsum": {
            "precision": 0.70975,
            "recall": 0.68695,
            "fmeasure": 0.69138
        },
        "bleu": 57.2078,
        "nist": 6.39329964018175,
        "local_recall": {
            "1": 0.13725490196078433,
            "2": 0.46296296296296297,
            "3": 0.8355555555555556
        },
        "nubia": {
            "semantic_relation": 4.41222,
            "contradiction": 6.3949,
            "irrelevancy": 26.5371,
            "logical_agreement": 67.068,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.62591,
            "nubia_score": 0.80033
        },
        "meteor": 0.43725866997489066,
        "bleurt": 0.4566,
        "bertscore": {
            "precision": 0.94558,
            "recall": 0.94086,
            "f1": 0.94189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71807,
            "recall": 0.58508,
            "fmeasure": 0.64017
        },
        "rouge2": {
            "precision": 0.41092,
            "recall": 0.32687,
            "fmeasure": 0.36045
        },
        "rougeL": {
            "precision": 0.54687,
            "recall": 0.44785,
            "fmeasure": 0.48851
        },
        "rougeLsum": {
            "precision": 0.54687,
            "recall": 0.44785,
            "fmeasure": 0.48851
        },
        "bleu": 29.43114,
        "nist": 4.544892311985245,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5384615384615384,
            "3": 0.6724137931034483
        },
        "nubia": {
            "semantic_relation": 4.26499,
            "contradiction": 0.20712,
            "irrelevancy": 51.51896,
            "logical_agreement": 48.27392,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.17303,
            "nubia_score": 0.79191
        },
        "meteor": 0.31135540031054404,
        "bleurt": 0.16408,
        "bertscore": {
            "precision": 0.91503,
            "recall": 0.88759,
            "f1": 0.90084
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.56667,
            "fmeasure": 0.56667
        },
        "rougeL": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "rougeLsum": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "bleu": 44.87502,
        "nist": 3.8370475980386485,
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 2.49992,
            "contradiction": 84.83945,
            "irrelevancy": 12.11439,
            "logical_agreement": 3.04617,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.6764,
            "nubia_score": 0.27803
        },
        "meteor": 0.3864569947061297,
        "bleurt": -0.10033,
        "bertscore": {
            "precision": 0.97877,
            "recall": 0.97655,
            "f1": 0.97766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85004,
            "recall": 0.79733,
            "fmeasure": 0.81617
        },
        "rouge2": {
            "precision": 0.61496,
            "recall": 0.56798,
            "fmeasure": 0.5858
        },
        "rougeL": {
            "precision": 0.77841,
            "recall": 0.7233,
            "fmeasure": 0.74339
        },
        "rougeLsum": {
            "precision": 0.77841,
            "recall": 0.7233,
            "fmeasure": 0.74339
        },
        "bleu": 50.1125,
        "nist": 6.493499916176538,
        "local_recall": {
            "1": 0.0625,
            "2": 0.5,
            "3": 0.8038277511961722
        },
        "nubia": {
            "semantic_relation": 4.15805,
            "contradiction": 14.88433,
            "irrelevancy": 17.211,
            "logical_agreement": 67.90467,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.57431,
            "nubia_score": 0.70527
        },
        "meteor": 0.4291364701907532,
        "bleurt": 0.34757,
        "bertscore": {
            "precision": 0.94868,
            "recall": 0.94011,
            "f1": 0.94403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70727,
            "recall": 0.71608,
            "fmeasure": 0.70706
        },
        "rouge2": {
            "precision": 0.4598,
            "recall": 0.47688,
            "fmeasure": 0.4643
        },
        "rougeL": {
            "precision": 0.59578,
            "recall": 0.62018,
            "fmeasure": 0.60345
        },
        "rougeLsum": {
            "precision": 0.59578,
            "recall": 0.62018,
            "fmeasure": 0.60345
        },
        "bleu": 39.50712,
        "nist": 5.75347176384444,
        "local_recall": {
            "1": 0.1836734693877551,
            "2": 0.5178571428571429,
            "3": 0.788235294117647
        },
        "nubia": {
            "semantic_relation": 4.32012,
            "contradiction": 1.43109,
            "irrelevancy": 33.48663,
            "logical_agreement": 65.08228,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.63176,
            "nubia_score": 0.77075
        },
        "meteor": 0.3805876758814965,
        "bleurt": 0.27923,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.92538,
            "f1": 0.92223
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "mT5_large/totto_test",
        "N": 42,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7697,
            "recall": 0.77233,
            "fmeasure": 0.76642
        },
        "rouge2": {
            "precision": 0.544,
            "recall": 0.55251,
            "fmeasure": 0.5435
        },
        "rougeL": {
            "precision": 0.64358,
            "recall": 0.64653,
            "fmeasure": 0.64113
        },
        "rougeLsum": {
            "precision": 0.64358,
            "recall": 0.64653,
            "fmeasure": 0.64113
        },
        "bleu": 45.45701,
        "nist": 6.977455544437637,
        "local_recall": {
            "1": 0.21551724137931033,
            "2": 0.44339622641509435,
            "3": 0.8112359550561797
        },
        "nubia": {
            "semantic_relation": 4.34513,
            "contradiction": 9.22989,
            "irrelevancy": 32.00817,
            "logical_agreement": 58.76193,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.50229,
            "nubia_score": 0.78228
        },
        "meteor": 0.4150896529369846,
        "bleurt": 0.28908,
        "bertscore": {
            "precision": 0.93496,
            "recall": 0.93365,
            "f1": 0.93174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78342,
            "recall": 0.70373,
            "fmeasure": 0.73853
        },
        "rouge2": {
            "precision": 0.47629,
            "recall": 0.43316,
            "fmeasure": 0.45201
        },
        "rougeL": {
            "precision": 0.6447,
            "recall": 0.58474,
            "fmeasure": 0.61112
        },
        "rougeLsum": {
            "precision": 0.6447,
            "recall": 0.58474,
            "fmeasure": 0.61112
        },
        "bleu": 36.43127,
        "nist": 4.5398895100859,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.35661,
            "contradiction": 19.67696,
            "irrelevancy": 20.68059,
            "logical_agreement": 59.64244,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.62684,
            "nubia_score": 0.79112
        },
        "meteor": 0.36459435845140814,
        "bleurt": 0.20684,
        "bertscore": {
            "precision": 0.91329,
            "recall": 0.90767,
            "f1": 0.91042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7467,
            "recall": 0.75549,
            "fmeasure": 0.7333
        },
        "rouge2": {
            "precision": 0.51633,
            "recall": 0.50016,
            "fmeasure": 0.49491
        },
        "rougeL": {
            "precision": 0.58693,
            "recall": 0.56956,
            "fmeasure": 0.56486
        },
        "rougeLsum": {
            "precision": 0.58693,
            "recall": 0.56956,
            "fmeasure": 0.56486
        },
        "bleu": 34.91101,
        "nist": 5.592289951346997,
        "local_recall": {
            "1": 0.3,
            "2": 0.5641025641025641,
            "3": 0.7816091954022989
        },
        "nubia": {
            "semantic_relation": 3.84172,
            "contradiction": 17.22551,
            "irrelevancy": 47.28443,
            "logical_agreement": 35.49005,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.27949,
            "nubia_score": 0.62185
        },
        "meteor": 0.3901781970623266,
        "bleurt": 0.11907,
        "bertscore": {
            "precision": 0.91566,
            "recall": 0.91259,
            "f1": 0.91282
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75181,
            "recall": 0.79689,
            "fmeasure": 0.76894
        },
        "rouge2": {
            "precision": 0.55334,
            "recall": 0.60415,
            "fmeasure": 0.57289
        },
        "rougeL": {
            "precision": 0.65895,
            "recall": 0.71971,
            "fmeasure": 0.68328
        },
        "rougeLsum": {
            "precision": 0.65895,
            "recall": 0.71971,
            "fmeasure": 0.68328
        },
        "bleu": 53.41347,
        "nist": 5.12072215497082,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.0,
            "3": 0.8076923076923077
        },
        "nubia": {
            "semantic_relation": 4.35517,
            "contradiction": 0.5902,
            "irrelevancy": 20.4714,
            "logical_agreement": 78.9384,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.56548,
            "nubia_score": 0.78581
        },
        "meteor": 0.44684381997316003,
        "bleurt": 0.40185,
        "bertscore": {
            "precision": 0.94503,
            "recall": 0.94713,
            "f1": 0.94404
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "mT5_large/totto_test",
        "N": 52,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72478,
            "recall": 0.759,
            "fmeasure": 0.72364
        },
        "rouge2": {
            "precision": 0.52832,
            "recall": 0.51973,
            "fmeasure": 0.51116
        },
        "rougeL": {
            "precision": 0.6688,
            "recall": 0.69967,
            "fmeasure": 0.66628
        },
        "rougeLsum": {
            "precision": 0.6688,
            "recall": 0.69967,
            "fmeasure": 0.66628
        },
        "bleu": 47.34518,
        "nist": 6.493109927731074,
        "local_recall": {
            "1": 0.32894736842105265,
            "2": 0.5459459459459459,
            "3": 0.7840616966580977
        },
        "nubia": {
            "semantic_relation": 4.16141,
            "contradiction": 8.29133,
            "irrelevancy": 32.5556,
            "logical_agreement": 59.15307,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.95511,
            "nubia_score": 0.70425
        },
        "meteor": 0.41732698347933445,
        "bleurt": 0.37681,
        "bertscore": {
            "precision": 0.93271,
            "recall": 0.93926,
            "f1": 0.93364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69354,
            "recall": 0.75692,
            "fmeasure": 0.71422
        },
        "rouge2": {
            "precision": 0.48161,
            "recall": 0.51297,
            "fmeasure": 0.48961
        },
        "rougeL": {
            "precision": 0.59479,
            "recall": 0.62744,
            "fmeasure": 0.60023
        },
        "rougeLsum": {
            "precision": 0.59479,
            "recall": 0.62744,
            "fmeasure": 0.60023
        },
        "bleu": 35.5507,
        "nist": 5.093698858722889,
        "local_recall": {
            "1": 0.4838709677419355,
            "2": 0.4,
            "3": 0.7567567567567568
        },
        "nubia": {
            "semantic_relation": 3.95339,
            "contradiction": 4.75098,
            "irrelevancy": 56.09298,
            "logical_agreement": 39.15604,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.79805,
            "nubia_score": 0.62846
        },
        "meteor": 0.3575930479716099,
        "bleurt": 0.07691,
        "bertscore": {
            "precision": 0.91202,
            "recall": 0.92164,
            "f1": 0.91566
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "mT5_large/totto_test",
        "N": 22,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72037,
            "recall": 0.74282,
            "fmeasure": 0.72328
        },
        "rouge2": {
            "precision": 0.48057,
            "recall": 0.49081,
            "fmeasure": 0.4774
        },
        "rougeL": {
            "precision": 0.6227,
            "recall": 0.64399,
            "fmeasure": 0.62342
        },
        "rougeLsum": {
            "precision": 0.6227,
            "recall": 0.64399,
            "fmeasure": 0.62342
        },
        "bleu": 43.27503,
        "nist": 5.940276181657836,
        "local_recall": {
            "1": 0.32,
            "2": 0.509090909090909,
            "3": 0.782608695652174
        },
        "nubia": {
            "semantic_relation": 4.25164,
            "contradiction": 4.94473,
            "irrelevancy": 27.38987,
            "logical_agreement": 67.66541,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.91949,
            "nubia_score": 0.74404
        },
        "meteor": 0.38681960556282524,
        "bleurt": 0.22489,
        "bertscore": {
            "precision": 0.90996,
            "recall": 0.92317,
            "f1": 0.91372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67747,
            "recall": 0.59281,
            "fmeasure": 0.60522
        },
        "rouge2": {
            "precision": 0.40302,
            "recall": 0.35796,
            "fmeasure": 0.36829
        },
        "rougeL": {
            "precision": 0.53077,
            "recall": 0.46975,
            "fmeasure": 0.47914
        },
        "rougeLsum": {
            "precision": 0.53077,
            "recall": 0.46975,
            "fmeasure": 0.47914
        },
        "bleu": 21.18778,
        "nist": 3.5648426802442437,
        "local_recall": {
            "1": 0.13559322033898305,
            "2": 0.15384615384615385,
            "3": 0.5784313725490197
        },
        "nubia": {
            "semantic_relation": 3.92974,
            "contradiction": 10.53352,
            "irrelevancy": 38.12116,
            "logical_agreement": 51.34533,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.83052,
            "nubia_score": 0.60614
        },
        "meteor": 0.26815647662523556,
        "bleurt": 0.15257,
        "bertscore": {
            "precision": 0.90195,
            "recall": 0.88347,
            "f1": 0.88939
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77192,
            "recall": 0.90358,
            "fmeasure": 0.8203
        },
        "rouge2": {
            "precision": 0.58544,
            "recall": 0.66342,
            "fmeasure": 0.61311
        },
        "rougeL": {
            "precision": 0.74115,
            "recall": 0.86901,
            "fmeasure": 0.78764
        },
        "rougeLsum": {
            "precision": 0.74115,
            "recall": 0.86901,
            "fmeasure": 0.78764
        },
        "bleu": 64.82463,
        "nist": 5.6632747157201475,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.75,
            "3": 0.9565217391304348
        },
        "nubia": {
            "semantic_relation": 4.21702,
            "contradiction": 2.78638,
            "irrelevancy": 36.37067,
            "logical_agreement": 60.84295,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.43911,
            "nubia_score": 0.7653
        },
        "meteor": 0.47202525822437835,
        "bleurt": 0.39487,
        "bertscore": {
            "precision": 0.93414,
            "recall": 0.96691,
            "f1": 0.9489
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.09091,
            "fmeasure": 0.11111
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.25,
            "fmeasure": 0.3
        },
        "bleu": 7.68785,
        "nist": 1.1074954636563787,
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "nubia": {
            "semantic_relation": 2.42531,
            "contradiction": 6.57438,
            "irrelevancy": 93.22366,
            "logical_agreement": 0.20196,
            "grammar_ref": 3.85254,
            "grammar_hyp": 5.65364,
            "nubia_score": 0.11927
        },
        "meteor": 0.1591575311673776,
        "bleurt": -0.85128,
        "bertscore": {
            "precision": 0.84187,
            "recall": 0.84277,
            "f1": 0.84232
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "mT5_large/totto_test",
        "N": 36,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74375,
            "recall": 0.68151,
            "fmeasure": 0.6922
        },
        "rouge2": {
            "precision": 0.50588,
            "recall": 0.44988,
            "fmeasure": 0.46171
        },
        "rougeL": {
            "precision": 0.66301,
            "recall": 0.60044,
            "fmeasure": 0.61381
        },
        "rougeLsum": {
            "precision": 0.66301,
            "recall": 0.60044,
            "fmeasure": 0.61381
        },
        "bleu": 39.29245,
        "nist": 6.067563555419872,
        "local_recall": {
            "1": 0.15841584158415842,
            "2": 0.5396825396825397,
            "3": 0.7155425219941349
        },
        "nubia": {
            "semantic_relation": 3.94567,
            "contradiction": 17.34537,
            "irrelevancy": 29.37821,
            "logical_agreement": 53.27642,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.6418,
            "nubia_score": 0.65143
        },
        "meteor": 0.3603237165465691,
        "bleurt": 0.20406,
        "bertscore": {
            "precision": 0.93001,
            "recall": 0.91023,
            "f1": 0.91723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77333,
            "recall": 0.713,
            "fmeasure": 0.74174
        },
        "rouge2": {
            "precision": 0.56944,
            "recall": 0.52494,
            "fmeasure": 0.54609
        },
        "rougeL": {
            "precision": 0.75333,
            "recall": 0.69515,
            "fmeasure": 0.72287
        },
        "rougeLsum": {
            "precision": 0.75333,
            "recall": 0.69515,
            "fmeasure": 0.72287
        },
        "bleu": 67.23384,
        "nist": 5.38655542441896,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7037037037037037
        },
        "nubia": {
            "semantic_relation": 4.52534,
            "contradiction": 0.42544,
            "irrelevancy": 12.75373,
            "logical_agreement": 86.82083,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.55431,
            "nubia_score": 0.82416
        },
        "meteor": 0.431509750269441,
        "bleurt": 0.36647,
        "bertscore": {
            "precision": 0.95133,
            "recall": 0.9075,
            "f1": 0.92868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74285,
            "recall": 0.73133,
            "fmeasure": 0.73256
        },
        "rouge2": {
            "precision": 0.48311,
            "recall": 0.47282,
            "fmeasure": 0.47349
        },
        "rougeL": {
            "precision": 0.67055,
            "recall": 0.64538,
            "fmeasure": 0.65418
        },
        "rougeLsum": {
            "precision": 0.67055,
            "recall": 0.64538,
            "fmeasure": 0.65418
        },
        "bleu": 42.56001,
        "nist": 5.032882418961803,
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.4444444444444444,
            "3": 0.7936507936507936
        },
        "nubia": {
            "semantic_relation": 4.37308,
            "contradiction": 11.96959,
            "irrelevancy": 14.41141,
            "logical_agreement": 73.619,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.29855,
            "nubia_score": 0.80381
        },
        "meteor": 0.37399655370021756,
        "bleurt": 0.24461,
        "bertscore": {
            "precision": 0.91448,
            "recall": 0.93503,
            "f1": 0.92308
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "mT5_large/totto_test",
        "N": 15,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79542,
            "recall": 0.73499,
            "fmeasure": 0.75403
        },
        "rouge2": {
            "precision": 0.51103,
            "recall": 0.49509,
            "fmeasure": 0.49885
        },
        "rougeL": {
            "precision": 0.63998,
            "recall": 0.60352,
            "fmeasure": 0.6143
        },
        "rougeLsum": {
            "precision": 0.63998,
            "recall": 0.60352,
            "fmeasure": 0.6143
        },
        "bleu": 43.03881,
        "nist": 5.430874116532721,
        "local_recall": {
            "1": 0.09615384615384616,
            "2": 0.3409090909090909,
            "3": 0.7961783439490446
        },
        "nubia": {
            "semantic_relation": 4.32634,
            "contradiction": 4.53278,
            "irrelevancy": 35.78665,
            "logical_agreement": 59.68056,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.81472,
            "nubia_score": 0.73716
        },
        "meteor": 0.3732771440945122,
        "bleurt": 0.28651,
        "bertscore": {
            "precision": 0.92713,
            "recall": 0.92018,
            "f1": 0.92341
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59956,
            "recall": 0.72161,
            "fmeasure": 0.64148
        },
        "rouge2": {
            "precision": 0.3601,
            "recall": 0.43753,
            "fmeasure": 0.38571
        },
        "rougeL": {
            "precision": 0.50381,
            "recall": 0.62255,
            "fmeasure": 0.5449
        },
        "rougeLsum": {
            "precision": 0.50381,
            "recall": 0.62255,
            "fmeasure": 0.5449
        },
        "bleu": 27.04504,
        "nist": 4.473395150893897,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.2857142857142857,
            "3": 0.7007874015748031
        },
        "nubia": {
            "semantic_relation": 3.94546,
            "contradiction": 13.37502,
            "irrelevancy": 52.63024,
            "logical_agreement": 33.99475,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.14644,
            "nubia_score": 0.6605
        },
        "meteor": 0.3321653913315499,
        "bleurt": 0.18273,
        "bertscore": {
            "precision": 0.89099,
            "recall": 0.91827,
            "f1": 0.90109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "mT5_large/totto_test",
        "N": 21,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72691,
            "recall": 0.70842,
            "fmeasure": 0.70875
        },
        "rouge2": {
            "precision": 0.47977,
            "recall": 0.47073,
            "fmeasure": 0.47003
        },
        "rougeL": {
            "precision": 0.60016,
            "recall": 0.58864,
            "fmeasure": 0.58863
        },
        "rougeLsum": {
            "precision": 0.60016,
            "recall": 0.58864,
            "fmeasure": 0.58863
        },
        "bleu": 41.40474,
        "nist": 6.256062011275589,
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.5,
            "3": 0.7525773195876289
        },
        "nubia": {
            "semantic_relation": 4.06667,
            "contradiction": 12.52902,
            "irrelevancy": 32.69077,
            "logical_agreement": 54.78021,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.55878,
            "nubia_score": 0.70481
        },
        "meteor": 0.38208585246963545,
        "bleurt": 0.23956,
        "bertscore": {
            "precision": 0.92783,
            "recall": 0.92514,
            "f1": 0.9253
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76253,
            "recall": 0.76473,
            "fmeasure": 0.75018
        },
        "rouge2": {
            "precision": 0.53335,
            "recall": 0.54615,
            "fmeasure": 0.52799
        },
        "rougeL": {
            "precision": 0.67152,
            "recall": 0.67776,
            "fmeasure": 0.66238
        },
        "rougeLsum": {
            "precision": 0.67152,
            "recall": 0.67776,
            "fmeasure": 0.66238
        },
        "bleu": 47.37639,
        "nist": 5.9084905011007836,
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.3793103448275862,
            "3": 0.8097826086956522
        },
        "nubia": {
            "semantic_relation": 4.16981,
            "contradiction": 5.38248,
            "irrelevancy": 33.12198,
            "logical_agreement": 61.49554,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.68711,
            "nubia_score": 0.71918
        },
        "meteor": 0.4278461438782536,
        "bleurt": 0.24767,
        "bertscore": {
            "precision": 0.9274,
            "recall": 0.9343,
            "f1": 0.92914
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79362,
            "recall": 0.80274,
            "fmeasure": 0.78857
        },
        "rouge2": {
            "precision": 0.61572,
            "recall": 0.62813,
            "fmeasure": 0.61476
        },
        "rougeL": {
            "precision": 0.69614,
            "recall": 0.70819,
            "fmeasure": 0.6937
        },
        "rougeLsum": {
            "precision": 0.69614,
            "recall": 0.70819,
            "fmeasure": 0.6937
        },
        "bleu": 60.71012,
        "nist": 7.374292369473504,
        "local_recall": {
            "1": 0.2920353982300885,
            "2": 0.47959183673469385,
            "3": 0.837465564738292
        },
        "nubia": {
            "semantic_relation": 4.25805,
            "contradiction": 10.15704,
            "irrelevancy": 26.71147,
            "logical_agreement": 63.13149,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.75549,
            "nubia_score": 0.73486
        },
        "meteor": 0.46021535146853,
        "bleurt": 0.40318,
        "bertscore": {
            "precision": 0.94127,
            "recall": 0.94047,
            "f1": 0.94009
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "mT5_large/totto_test",
        "N": 79,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73102,
            "recall": 0.66523,
            "fmeasure": 0.68053
        },
        "rouge2": {
            "precision": 0.47065,
            "recall": 0.43255,
            "fmeasure": 0.43669
        },
        "rougeL": {
            "precision": 0.61476,
            "recall": 0.5634,
            "fmeasure": 0.57298
        },
        "rougeLsum": {
            "precision": 0.61476,
            "recall": 0.5634,
            "fmeasure": 0.57298
        },
        "bleu": 38.42511,
        "nist": 6.686233406756647,
        "local_recall": {
            "1": 0.22508038585209003,
            "2": 0.4315068493150685,
            "3": 0.7167325428194994
        },
        "nubia": {
            "semantic_relation": 4.08232,
            "contradiction": 9.49758,
            "irrelevancy": 32.80792,
            "logical_agreement": 57.6945,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.97727,
            "nubia_score": 0.67559
        },
        "meteor": 0.35945860931919066,
        "bleurt": 0.16129,
        "bertscore": {
            "precision": 0.91981,
            "recall": 0.90896,
            "f1": 0.91251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "mT5_large/totto_test",
        "N": 81,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75475,
            "recall": 0.7574,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.55471,
            "recall": 0.55421,
            "fmeasure": 0.543
        },
        "rougeL": {
            "precision": 0.64389,
            "recall": 0.64358,
            "fmeasure": 0.63106
        },
        "rougeLsum": {
            "precision": 0.64389,
            "recall": 0.64358,
            "fmeasure": 0.63106
        },
        "bleu": 50.93744,
        "nist": 7.487730642222129,
        "local_recall": {
            "1": 0.24573378839590443,
            "2": 0.5348837209302325,
            "3": 0.819672131147541
        },
        "nubia": {
            "semantic_relation": 4.21907,
            "contradiction": 7.46429,
            "irrelevancy": 32.93948,
            "logical_agreement": 59.59622,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.51153,
            "nubia_score": 0.7432
        },
        "meteor": 0.4171739956619219,
        "bleurt": 0.26927,
        "bertscore": {
            "precision": 0.92943,
            "recall": 0.93361,
            "f1": 0.92954
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66424,
            "recall": 0.66815,
            "fmeasure": 0.65319
        },
        "rouge2": {
            "precision": 0.40762,
            "recall": 0.39807,
            "fmeasure": 0.39467
        },
        "rougeL": {
            "precision": 0.55611,
            "recall": 0.55491,
            "fmeasure": 0.54448
        },
        "rougeLsum": {
            "precision": 0.55611,
            "recall": 0.55491,
            "fmeasure": 0.54448
        },
        "bleu": 35.5326,
        "nist": 5.51435090865147,
        "local_recall": {
            "1": 0.25,
            "2": 0.5492957746478874,
            "3": 0.6774193548387096
        },
        "nubia": {
            "semantic_relation": 3.88004,
            "contradiction": 12.17681,
            "irrelevancy": 42.03758,
            "logical_agreement": 45.78561,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.39691,
            "nubia_score": 0.63811
        },
        "meteor": 0.36685715398548446,
        "bleurt": 0.11139,
        "bertscore": {
            "precision": 0.90577,
            "recall": 0.90506,
            "f1": 0.90389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "mT5_large/totto_test",
        "N": 46,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73383,
            "recall": 0.73582,
            "fmeasure": 0.72292
        },
        "rouge2": {
            "precision": 0.51011,
            "recall": 0.51405,
            "fmeasure": 0.50189
        },
        "rougeL": {
            "precision": 0.631,
            "recall": 0.63363,
            "fmeasure": 0.62148
        },
        "rougeLsum": {
            "precision": 0.631,
            "recall": 0.63363,
            "fmeasure": 0.62148
        },
        "bleu": 42.05958,
        "nist": 6.357702189111803,
        "local_recall": {
            "1": 0.2636363636363636,
            "2": 0.41605839416058393,
            "3": 0.733201581027668
        },
        "nubia": {
            "semantic_relation": 4.19061,
            "contradiction": 7.47609,
            "irrelevancy": 34.57106,
            "logical_agreement": 57.95285,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.58733,
            "nubia_score": 0.71085
        },
        "meteor": 0.3629479394572057,
        "bleurt": 0.29394,
        "bertscore": {
            "precision": 0.91732,
            "recall": 0.91772,
            "f1": 0.91587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "mT5_large/totto_test",
        "N": 25,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81118,
            "recall": 0.83871,
            "fmeasure": 0.81883
        },
        "rouge2": {
            "precision": 0.63998,
            "recall": 0.66169,
            "fmeasure": 0.64671
        },
        "rougeL": {
            "precision": 0.73843,
            "recall": 0.75945,
            "fmeasure": 0.74396
        },
        "rougeLsum": {
            "precision": 0.73843,
            "recall": 0.75945,
            "fmeasure": 0.74396
        },
        "bleu": 56.60774,
        "nist": 6.651246684058823,
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.3953488372093023,
            "3": 0.8766233766233766
        },
        "nubia": {
            "semantic_relation": 4.42693,
            "contradiction": 6.3081,
            "irrelevancy": 26.20178,
            "logical_agreement": 67.49011,
            "grammar_ref": 4.85173,
            "grammar_hyp": 4.83524,
            "nubia_score": 0.79199
        },
        "meteor": 0.4693593500305297,
        "bleurt": 0.47215,
        "bertscore": {
            "precision": 0.94712,
            "recall": 0.95117,
            "f1": 0.94881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61925,
            "recall": 0.63415,
            "fmeasure": 0.6223
        },
        "rouge2": {
            "precision": 0.36174,
            "recall": 0.4202,
            "fmeasure": 0.37951
        },
        "rougeL": {
            "precision": 0.47407,
            "recall": 0.53444,
            "fmeasure": 0.48875
        },
        "rougeLsum": {
            "precision": 0.47407,
            "recall": 0.53444,
            "fmeasure": 0.48875
        },
        "bleu": 30.59199,
        "nist": 4.446037293823222,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.34375,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 3.66044,
            "contradiction": 26.23005,
            "irrelevancy": 32.5803,
            "logical_agreement": 41.18964,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.1545,
            "nubia_score": 0.55769
        },
        "meteor": 0.34547416744145487,
        "bleurt": -0.04312,
        "bertscore": {
            "precision": 0.89878,
            "recall": 0.91078,
            "f1": 0.89515
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "mT5_large/totto_test",
        "N": 75,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75943,
            "recall": 0.73703,
            "fmeasure": 0.73839
        },
        "rouge2": {
            "precision": 0.55042,
            "recall": 0.54132,
            "fmeasure": 0.5374
        },
        "rougeL": {
            "precision": 0.65381,
            "recall": 0.64319,
            "fmeasure": 0.63969
        },
        "rougeLsum": {
            "precision": 0.65381,
            "recall": 0.64319,
            "fmeasure": 0.63969
        },
        "bleu": 48.83362,
        "nist": 7.618313639276101,
        "local_recall": {
            "1": 0.2830188679245283,
            "2": 0.48148148148148145,
            "3": 0.7770700636942676
        },
        "nubia": {
            "semantic_relation": 4.1184,
            "contradiction": 11.05267,
            "irrelevancy": 35.47169,
            "logical_agreement": 53.47565,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.9294,
            "nubia_score": 0.69536
        },
        "meteor": 0.3975696402077629,
        "bleurt": 0.24147,
        "bertscore": {
            "precision": 0.93043,
            "recall": 0.92649,
            "f1": 0.9263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "mT5_large/totto_test",
        "N": 169,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7603,
            "recall": 0.75335,
            "fmeasure": 0.74719
        },
        "rouge2": {
            "precision": 0.54254,
            "recall": 0.53412,
            "fmeasure": 0.53128
        },
        "rougeL": {
            "precision": 0.66096,
            "recall": 0.65745,
            "fmeasure": 0.65052
        },
        "rougeLsum": {
            "precision": 0.66096,
            "recall": 0.65745,
            "fmeasure": 0.65052
        },
        "bleu": 46.42318,
        "nist": 7.985790550578168,
        "local_recall": {
            "1": 0.19246861924686193,
            "2": 0.47415730337078654,
            "3": 0.7879273504273504
        },
        "nubia": {
            "semantic_relation": 4.21894,
            "contradiction": 8.66276,
            "irrelevancy": 28.59893,
            "logical_agreement": 62.73832,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.63046,
            "nubia_score": 0.74131
        },
        "meteor": 0.39804963009279914,
        "bleurt": 0.31375,
        "bertscore": {
            "precision": 0.92843,
            "recall": 0.92789,
            "f1": 0.92672
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66111,
            "recall": 0.7272,
            "fmeasure": 0.68581
        },
        "rouge2": {
            "precision": 0.3542,
            "recall": 0.42425,
            "fmeasure": 0.38233
        },
        "rougeL": {
            "precision": 0.5596,
            "recall": 0.63494,
            "fmeasure": 0.58958
        },
        "rougeLsum": {
            "precision": 0.5596,
            "recall": 0.63494,
            "fmeasure": 0.58958
        },
        "bleu": 27.07478,
        "nist": 3.5007765302014966,
        "local_recall": {
            "1": 0.125,
            "2": 0.5714285714285714,
            "3": 0.6486486486486487
        },
        "nubia": {
            "semantic_relation": 4.0982,
            "contradiction": 8.25972,
            "irrelevancy": 52.53837,
            "logical_agreement": 39.2019,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.39199,
            "nubia_score": 0.72023
        },
        "meteor": 0.3643221985423432,
        "bleurt": 0.33806,
        "bertscore": {
            "precision": 0.91105,
            "recall": 0.92021,
            "f1": 0.91432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "mT5_large/totto_test",
        "N": 23,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77034,
            "recall": 0.75364,
            "fmeasure": 0.75173
        },
        "rouge2": {
            "precision": 0.55003,
            "recall": 0.528,
            "fmeasure": 0.53156
        },
        "rougeL": {
            "precision": 0.65938,
            "recall": 0.6653,
            "fmeasure": 0.65172
        },
        "rougeLsum": {
            "precision": 0.65938,
            "recall": 0.6653,
            "fmeasure": 0.65172
        },
        "bleu": 50.12488,
        "nist": 6.60712631561769,
        "local_recall": {
            "1": 0.2191780821917808,
            "2": 0.37209302325581395,
            "3": 0.8247863247863247
        },
        "nubia": {
            "semantic_relation": 4.38075,
            "contradiction": 5.93366,
            "irrelevancy": 22.46609,
            "logical_agreement": 71.60025,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.59068,
            "nubia_score": 0.77405
        },
        "meteor": 0.4041888258574604,
        "bleurt": 0.37695,
        "bertscore": {
            "precision": 0.94049,
            "recall": 0.93456,
            "f1": 0.93318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77943,
            "recall": 0.74132,
            "fmeasure": 0.74999
        },
        "rouge2": {
            "precision": 0.52466,
            "recall": 0.51804,
            "fmeasure": 0.51513
        },
        "rougeL": {
            "precision": 0.65463,
            "recall": 0.63396,
            "fmeasure": 0.63606
        },
        "rougeLsum": {
            "precision": 0.65463,
            "recall": 0.63396,
            "fmeasure": 0.63606
        },
        "bleu": 40.90891,
        "nist": 6.177274954371627,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.5614035087719298,
            "3": 0.8197674418604651
        },
        "nubia": {
            "semantic_relation": 4.27336,
            "contradiction": 8.95579,
            "irrelevancy": 27.50242,
            "logical_agreement": 63.5418,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.94317,
            "nubia_score": 0.73205
        },
        "meteor": 0.39955434870311485,
        "bleurt": 0.25224,
        "bertscore": {
            "precision": 0.9367,
            "recall": 0.9342,
            "f1": 0.93355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.48148,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "bleu": 18.29565,
        "nist": 1.7503473569799732,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.99409,
            "contradiction": 0.26568,
            "irrelevancy": 22.76223,
            "logical_agreement": 76.97209,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.24002,
            "nubia_score": 0.64181
        },
        "meteor": 0.35356235305705724,
        "bleurt": 0.12284,
        "bertscore": {
            "precision": 0.87103,
            "recall": 0.90546,
            "f1": 0.88791
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78896,
            "recall": 0.83751,
            "fmeasure": 0.80849
        },
        "rouge2": {
            "precision": 0.61973,
            "recall": 0.67995,
            "fmeasure": 0.64619
        },
        "rougeL": {
            "precision": 0.70058,
            "recall": 0.77846,
            "fmeasure": 0.73603
        },
        "rougeLsum": {
            "precision": 0.70058,
            "recall": 0.77846,
            "fmeasure": 0.73603
        },
        "bleu": 52.22009,
        "nist": 5.232167304295946,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.8367346938775511
        },
        "nubia": {
            "semantic_relation": 4.25146,
            "contradiction": 8.84281,
            "irrelevancy": 32.92473,
            "logical_agreement": 58.23246,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.87498,
            "nubia_score": 0.81725
        },
        "meteor": 0.4396321368648527,
        "bleurt": 0.44779,
        "bertscore": {
            "precision": 0.94973,
            "recall": 0.95086,
            "f1": 0.95018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88675,
            "recall": 0.86549,
            "fmeasure": 0.87538
        },
        "rouge2": {
            "precision": 0.70539,
            "recall": 0.67275,
            "fmeasure": 0.68792
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.76872,
            "fmeasure": 0.78595
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.76872,
            "fmeasure": 0.78595
        },
        "bleu": 56.71024,
        "nist": 5.485995698070114,
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.42857142857142855,
            "3": 0.8928571428571429
        },
        "nubia": {
            "semantic_relation": 4.82957,
            "contradiction": 2.03614,
            "irrelevancy": 1.19007,
            "logical_agreement": 96.7738,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.86389,
            "nubia_score": 0.89535
        },
        "meteor": 0.49062506898887487,
        "bleurt": 0.47721,
        "bertscore": {
            "precision": 0.9633,
            "recall": 0.96039,
            "f1": 0.95972
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78928,
            "recall": 0.7511,
            "fmeasure": 0.75978
        },
        "rouge2": {
            "precision": 0.56917,
            "recall": 0.56617,
            "fmeasure": 0.55524
        },
        "rougeL": {
            "precision": 0.68697,
            "recall": 0.66607,
            "fmeasure": 0.66628
        },
        "rougeLsum": {
            "precision": 0.68697,
            "recall": 0.66607,
            "fmeasure": 0.66628
        },
        "bleu": 48.48681,
        "nist": 6.4285923677617,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.46938775510204084,
            "3": 0.8010752688172043
        },
        "nubia": {
            "semantic_relation": 4.31431,
            "contradiction": 13.63465,
            "irrelevancy": 29.68801,
            "logical_agreement": 56.67734,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.07109,
            "nubia_score": 0.78069
        },
        "meteor": 0.40318686330857084,
        "bleurt": 0.30634,
        "bertscore": {
            "precision": 0.94076,
            "recall": 0.93705,
            "f1": 0.937
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "mT5_large/totto_test",
        "N": 50,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75737,
            "recall": 0.70077,
            "fmeasure": 0.71625
        },
        "rouge2": {
            "precision": 0.50883,
            "recall": 0.47409,
            "fmeasure": 0.48242
        },
        "rougeL": {
            "precision": 0.67294,
            "recall": 0.62368,
            "fmeasure": 0.63703
        },
        "rougeLsum": {
            "precision": 0.67294,
            "recall": 0.62368,
            "fmeasure": 0.63703
        },
        "bleu": 39.10134,
        "nist": 6.437394003281402,
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.46540880503144655,
            "3": 0.7098540145985401
        },
        "nubia": {
            "semantic_relation": 4.22961,
            "contradiction": 12.90292,
            "irrelevancy": 25.23342,
            "logical_agreement": 61.86366,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.80266,
            "nubia_score": 0.71821
        },
        "meteor": 0.35360128923281076,
        "bleurt": 0.2515,
        "bertscore": {
            "precision": 0.92665,
            "recall": 0.91515,
            "f1": 0.91978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "mT5_large/totto_test",
        "N": 41,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75143,
            "recall": 0.76,
            "fmeasure": 0.74402
        },
        "rouge2": {
            "precision": 0.53021,
            "recall": 0.53609,
            "fmeasure": 0.52548
        },
        "rougeL": {
            "precision": 0.63231,
            "recall": 0.64169,
            "fmeasure": 0.6272
        },
        "rougeLsum": {
            "precision": 0.63231,
            "recall": 0.64169,
            "fmeasure": 0.6272
        },
        "bleu": 46.31117,
        "nist": 6.429912229662858,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5537190082644629,
            "3": 0.7848484848484848
        },
        "nubia": {
            "semantic_relation": 4.10799,
            "contradiction": 6.55074,
            "irrelevancy": 42.38596,
            "logical_agreement": 51.06329,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.39709,
            "nubia_score": 0.72639
        },
        "meteor": 0.41190015043613226,
        "bleurt": 0.35146,
        "bertscore": {
            "precision": 0.93141,
            "recall": 0.93742,
            "f1": 0.93283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72779,
            "recall": 0.75105,
            "fmeasure": 0.72285
        },
        "rouge2": {
            "precision": 0.44156,
            "recall": 0.45686,
            "fmeasure": 0.43764
        },
        "rougeL": {
            "precision": 0.6212,
            "recall": 0.63279,
            "fmeasure": 0.61526
        },
        "rougeLsum": {
            "precision": 0.6212,
            "recall": 0.63279,
            "fmeasure": 0.61526
        },
        "bleu": 35.5981,
        "nist": 5.059398342113566,
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.47058823529411764,
            "3": 0.7830188679245284
        },
        "nubia": {
            "semantic_relation": 4.56312,
            "contradiction": 1.4862,
            "irrelevancy": 22.00371,
            "logical_agreement": 76.51009,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.20056,
            "nubia_score": 0.7655
        },
        "meteor": 0.3847755447047716,
        "bleurt": 0.31045,
        "bertscore": {
            "precision": 0.92254,
            "recall": 0.93716,
            "f1": 0.92919
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77459,
            "recall": 0.71436,
            "fmeasure": 0.7321
        },
        "rouge2": {
            "precision": 0.54616,
            "recall": 0.49728,
            "fmeasure": 0.51325
        },
        "rougeL": {
            "precision": 0.64368,
            "recall": 0.60757,
            "fmeasure": 0.61597
        },
        "rougeLsum": {
            "precision": 0.64368,
            "recall": 0.60757,
            "fmeasure": 0.61597
        },
        "bleu": 43.3638,
        "nist": 5.3507138819189155,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.37037037037037035,
            "3": 0.7235294117647059
        },
        "nubia": {
            "semantic_relation": 4.32435,
            "contradiction": 8.66503,
            "irrelevancy": 20.49024,
            "logical_agreement": 70.84474,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.82964,
            "nubia_score": 0.76419
        },
        "meteor": 0.3657101487271029,
        "bleurt": 0.33077,
        "bertscore": {
            "precision": 0.93122,
            "recall": 0.9255,
            "f1": 0.92757
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "mT5_large/totto_test",
        "N": 42,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76524,
            "recall": 0.80528,
            "fmeasure": 0.77731
        },
        "rouge2": {
            "precision": 0.53594,
            "recall": 0.56244,
            "fmeasure": 0.54407
        },
        "rougeL": {
            "precision": 0.65161,
            "recall": 0.68725,
            "fmeasure": 0.66252
        },
        "rougeLsum": {
            "precision": 0.65161,
            "recall": 0.68725,
            "fmeasure": 0.66252
        },
        "bleu": 45.96365,
        "nist": 6.711544255717919,
        "local_recall": {
            "1": 0.16521739130434782,
            "2": 0.5268817204301075,
            "3": 0.8305785123966942
        },
        "nubia": {
            "semantic_relation": 4.38637,
            "contradiction": 10.0241,
            "irrelevancy": 20.53176,
            "logical_agreement": 69.44414,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.49937,
            "nubia_score": 0.79196
        },
        "meteor": 0.42041576028266453,
        "bleurt": 0.39494,
        "bertscore": {
            "precision": 0.9355,
            "recall": 0.94126,
            "f1": 0.93785
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83394,
            "recall": 0.82239,
            "fmeasure": 0.82699
        },
        "rouge2": {
            "precision": 0.58399,
            "recall": 0.58822,
            "fmeasure": 0.58536
        },
        "rougeL": {
            "precision": 0.72996,
            "recall": 0.72759,
            "fmeasure": 0.72768
        },
        "rougeLsum": {
            "precision": 0.72996,
            "recall": 0.72759,
            "fmeasure": 0.72768
        },
        "bleu": 43.62099,
        "nist": 5.132972636953304,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.3333333333333333,
            "3": 0.9012345679012346
        },
        "nubia": {
            "semantic_relation": 4.52816,
            "contradiction": 1.56683,
            "irrelevancy": 35.86924,
            "logical_agreement": 62.56393,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.75417,
            "nubia_score": 0.85494
        },
        "meteor": 0.42034013285100363,
        "bleurt": 0.40966,
        "bertscore": {
            "precision": 0.93596,
            "recall": 0.94574,
            "f1": 0.94045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77104,
            "recall": 0.69992,
            "fmeasure": 0.7282
        },
        "rouge2": {
            "precision": 0.50706,
            "recall": 0.44374,
            "fmeasure": 0.46819
        },
        "rougeL": {
            "precision": 0.67163,
            "recall": 0.59587,
            "fmeasure": 0.62458
        },
        "rougeLsum": {
            "precision": 0.67163,
            "recall": 0.59587,
            "fmeasure": 0.62458
        },
        "bleu": 33.98869,
        "nist": 5.40315476808003,
        "local_recall": {
            "1": 0.12,
            "2": 0.15384615384615385,
            "3": 0.7588235294117647
        },
        "nubia": {
            "semantic_relation": 4.14111,
            "contradiction": 22.16072,
            "irrelevancy": 31.86782,
            "logical_agreement": 45.97146,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.44654,
            "nubia_score": 0.7217
        },
        "meteor": 0.33941530644035484,
        "bleurt": 0.2195,
        "bertscore": {
            "precision": 0.91678,
            "recall": 0.90746,
            "f1": 0.90885
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80593,
            "recall": 0.74002,
            "fmeasure": 0.76381
        },
        "rouge2": {
            "precision": 0.55737,
            "recall": 0.50844,
            "fmeasure": 0.5251
        },
        "rougeL": {
            "precision": 0.63792,
            "recall": 0.55656,
            "fmeasure": 0.58853
        },
        "rougeLsum": {
            "precision": 0.63792,
            "recall": 0.55656,
            "fmeasure": 0.58853
        },
        "bleu": 41.66714,
        "nist": 5.803029448034988,
        "local_recall": {
            "1": 0.2558139534883721,
            "2": 0.42105263157894735,
            "3": 0.7426470588235294
        },
        "nubia": {
            "semantic_relation": 4.48577,
            "contradiction": 9.88561,
            "irrelevancy": 16.99161,
            "logical_agreement": 73.12278,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.58764,
            "nubia_score": 0.81899
        },
        "meteor": 0.42154607756242063,
        "bleurt": 0.36565,
        "bertscore": {
            "precision": 0.93579,
            "recall": 0.92598,
            "f1": 0.93044
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83689,
            "recall": 0.75673,
            "fmeasure": 0.78311
        },
        "rouge2": {
            "precision": 0.66597,
            "recall": 0.61285,
            "fmeasure": 0.62843
        },
        "rougeL": {
            "precision": 0.75748,
            "recall": 0.70118,
            "fmeasure": 0.71819
        },
        "rougeLsum": {
            "precision": 0.75748,
            "recall": 0.70118,
            "fmeasure": 0.71819
        },
        "bleu": 52.05132,
        "nist": 4.23518450623618,
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nubia": {
            "semantic_relation": 4.4052,
            "contradiction": 0.7647,
            "irrelevancy": 24.61395,
            "logical_agreement": 74.62135,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.42169,
            "nubia_score": 0.72413
        },
        "meteor": 0.45301486945381325,
        "bleurt": 0.48547,
        "bertscore": {
            "precision": 0.96576,
            "recall": 0.9624,
            "f1": 0.96371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69038,
            "recall": 0.67987,
            "fmeasure": 0.67232
        },
        "rouge2": {
            "precision": 0.41701,
            "recall": 0.38182,
            "fmeasure": 0.39332
        },
        "rougeL": {
            "precision": 0.58825,
            "recall": 0.57046,
            "fmeasure": 0.56649
        },
        "rougeLsum": {
            "precision": 0.58825,
            "recall": 0.57046,
            "fmeasure": 0.56649
        },
        "bleu": 33.44182,
        "nist": 4.98714837368795,
        "local_recall": {
            "1": 0.22950819672131148,
            "2": 0.34285714285714286,
            "3": 0.6415094339622641
        },
        "nubia": {
            "semantic_relation": 4.12963,
            "contradiction": 7.56393,
            "irrelevancy": 44.1596,
            "logical_agreement": 48.27647,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.3268,
            "nubia_score": 0.74364
        },
        "meteor": 0.34061464768162475,
        "bleurt": 0.20599,
        "bertscore": {
            "precision": 0.90903,
            "recall": 0.90246,
            "f1": 0.90394
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83262,
            "recall": 0.76075,
            "fmeasure": 0.78637
        },
        "rouge2": {
            "precision": 0.57831,
            "recall": 0.52316,
            "fmeasure": 0.54399
        },
        "rougeL": {
            "precision": 0.74563,
            "recall": 0.66706,
            "fmeasure": 0.69757
        },
        "rougeLsum": {
            "precision": 0.74563,
            "recall": 0.66706,
            "fmeasure": 0.69757
        },
        "bleu": 48.49412,
        "nist": 5.787664375190041,
        "local_recall": {
            "1": 0.2,
            "2": 0.3793103448275862,
            "3": 0.7933884297520661
        },
        "nubia": {
            "semantic_relation": 4.61961,
            "contradiction": 6.17542,
            "irrelevancy": 3.0755,
            "logical_agreement": 90.74908,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.19689,
            "nubia_score": 0.88625
        },
        "meteor": 0.40063922741949687,
        "bleurt": 0.49021,
        "bertscore": {
            "precision": 0.95792,
            "recall": 0.94544,
            "f1": 0.95025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60317,
            "recall": 0.66518,
            "fmeasure": 0.595
        },
        "rouge2": {
            "precision": 0.45556,
            "recall": 0.42222,
            "fmeasure": 0.43504
        },
        "rougeL": {
            "precision": 0.60317,
            "recall": 0.66518,
            "fmeasure": 0.595
        },
        "rougeLsum": {
            "precision": 0.60317,
            "recall": 0.66518,
            "fmeasure": 0.595
        },
        "bleu": 41.98753,
        "nist": 3.1649913310167017,
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444,
            "3": 0.8181818181818182
        },
        "nubia": {
            "semantic_relation": 4.04002,
            "contradiction": 1.1324,
            "irrelevancy": 45.91091,
            "logical_agreement": 52.95668,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.96447,
            "nubia_score": 0.60183
        },
        "meteor": 0.3786694626059327,
        "bleurt": 0.22591,
        "bertscore": {
            "precision": 0.87699,
            "recall": 0.89161,
            "f1": 0.88349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "mT5_large/totto_test",
        "N": 76,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71182,
            "recall": 0.6887,
            "fmeasure": 0.68522
        },
        "rouge2": {
            "precision": 0.44699,
            "recall": 0.42708,
            "fmeasure": 0.42542
        },
        "rougeL": {
            "precision": 0.61149,
            "recall": 0.59327,
            "fmeasure": 0.5885
        },
        "rougeLsum": {
            "precision": 0.61149,
            "recall": 0.59327,
            "fmeasure": 0.5885
        },
        "bleu": 39.64829,
        "nist": 6.797811798471216,
        "local_recall": {
            "1": 0.1939799331103679,
            "2": 0.4878048780487805,
            "3": 0.739612188365651
        },
        "nubia": {
            "semantic_relation": 4.10014,
            "contradiction": 5.90798,
            "irrelevancy": 36.42265,
            "logical_agreement": 57.66937,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.78359,
            "nubia_score": 0.6732
        },
        "meteor": 0.3705028500897024,
        "bleurt": 0.1988,
        "bertscore": {
            "precision": 0.91763,
            "recall": 0.91796,
            "f1": 0.91551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.68421,
            "fmeasure": 0.63415
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.33333,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.47368,
            "fmeasure": 0.43902
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.47368,
            "fmeasure": 0.43902
        },
        "bleu": 11.32836,
        "nist": 2.6094856200856147,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6470588235294118
        },
        "nubia": {
            "semantic_relation": 4.46171,
            "contradiction": 0.41127,
            "irrelevancy": 11.78259,
            "logical_agreement": 87.80614,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.49407,
            "nubia_score": 0.8021
        },
        "meteor": 0.3320513522423183,
        "bleurt": 0.25055,
        "bertscore": {
            "precision": 0.91163,
            "recall": 0.90045,
            "f1": 0.9058
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "bleu": 22.08959,
        "nist": 1.6476388007204534,
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "meteor": 0.3387350864807313,
        "bleurt": 0.27507,
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65064,
            "recall": 0.63508,
            "fmeasure": 0.62507
        },
        "rouge2": {
            "precision": 0.36875,
            "recall": 0.37182,
            "fmeasure": 0.35395
        },
        "rougeL": {
            "precision": 0.52589,
            "recall": 0.52742,
            "fmeasure": 0.50962
        },
        "rougeLsum": {
            "precision": 0.52589,
            "recall": 0.52742,
            "fmeasure": 0.50962
        },
        "bleu": 28.87133,
        "nist": 5.002185711970621,
        "local_recall": {
            "1": 0.2033898305084746,
            "2": 0.21739130434782608,
            "3": 0.6848484848484848
        },
        "nubia": {
            "semantic_relation": 3.77634,
            "contradiction": 10.26256,
            "irrelevancy": 32.31228,
            "logical_agreement": 57.42516,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.36119,
            "nubia_score": 0.59677
        },
        "meteor": 0.34480633936328686,
        "bleurt": -0.04137,
        "bertscore": {
            "precision": 0.88937,
            "recall": 0.89356,
            "f1": 0.88776
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.375,
            "fmeasure": 0.46154
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.14286,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.375,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.375,
            "fmeasure": 0.46154
        },
        "bleu": 11.709,
        "nist": 0.5638228410832963,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.78935,
            "contradiction": 1.27286,
            "irrelevancy": 10.51267,
            "logical_agreement": 88.21447,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.4601,
            "nubia_score": 0.68779
        },
        "meteor": 0.2848405734952927,
        "bleurt": -0.57007,
        "bertscore": {
            "precision": 0.86251,
            "recall": 0.84957,
            "f1": 0.85143
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77381,
            "recall": 0.86147,
            "fmeasure": 0.81238
        },
        "rouge2": {
            "precision": 0.60577,
            "recall": 0.675,
            "fmeasure": 0.63587
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.79221,
            "fmeasure": 0.74857
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.79221,
            "fmeasure": 0.74857
        },
        "bleu": 54.60873,
        "nist": 3.7402909848303785,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8846153846153846
        },
        "nubia": {
            "semantic_relation": 4.61732,
            "contradiction": 0.25048,
            "irrelevancy": 50.12327,
            "logical_agreement": 49.62626,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.49636,
            "nubia_score": 0.92504
        },
        "meteor": 0.44486475854639074,
        "bleurt": 0.55392,
        "bertscore": {
            "precision": 0.94284,
            "recall": 0.96494,
            "f1": 0.95363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "mT5_large/totto_test",
        "N": 57,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75924,
            "recall": 0.75758,
            "fmeasure": 0.74764
        },
        "rouge2": {
            "precision": 0.56071,
            "recall": 0.56229,
            "fmeasure": 0.55279
        },
        "rougeL": {
            "precision": 0.67591,
            "recall": 0.67157,
            "fmeasure": 0.66403
        },
        "rougeLsum": {
            "precision": 0.67591,
            "recall": 0.67157,
            "fmeasure": 0.66403
        },
        "bleu": 46.83637,
        "nist": 7.088693467234339,
        "local_recall": {
            "1": 0.23963133640552994,
            "2": 0.5024390243902439,
            "3": 0.8311195445920304
        },
        "nubia": {
            "semantic_relation": 4.19717,
            "contradiction": 7.42003,
            "irrelevancy": 36.87553,
            "logical_agreement": 55.70444,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.71704,
            "nubia_score": 0.73729
        },
        "meteor": 0.4215243314214833,
        "bleurt": 0.26473,
        "bertscore": {
            "precision": 0.92695,
            "recall": 0.92906,
            "f1": 0.92582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "mT5_large/totto_test",
        "N": 23,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76934,
            "recall": 0.76277,
            "fmeasure": 0.75706
        },
        "rouge2": {
            "precision": 0.54039,
            "recall": 0.53297,
            "fmeasure": 0.53128
        },
        "rougeL": {
            "precision": 0.6582,
            "recall": 0.65758,
            "fmeasure": 0.65129
        },
        "rougeLsum": {
            "precision": 0.6582,
            "recall": 0.65758,
            "fmeasure": 0.65129
        },
        "bleu": 46.56774,
        "nist": 6.273682950275638,
        "local_recall": {
            "1": 0.18666666666666668,
            "2": 0.5737704918032787,
            "3": 0.7796610169491526
        },
        "nubia": {
            "semantic_relation": 4.36104,
            "contradiction": 7.30355,
            "irrelevancy": 23.9478,
            "logical_agreement": 68.74865,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.14731,
            "nubia_score": 0.81312
        },
        "meteor": 0.413257887269648,
        "bleurt": 0.29708,
        "bertscore": {
            "precision": 0.92326,
            "recall": 0.926,
            "f1": 0.92357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.33333,
            "fmeasure": 0.36364
        },
        "bleu": 16.51582,
        "nist": 2.0052535157554314,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.12986,
            "contradiction": 71.68311,
            "irrelevancy": 20.1839,
            "logical_agreement": 8.133,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.78582,
            "nubia_score": 0.30685
        },
        "meteor": 0.31253823342571707,
        "bleurt": -0.06824,
        "bertscore": {
            "precision": 0.87519,
            "recall": 0.87347,
            "f1": 0.87433
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "mT5_large/totto_test",
        "N": 56,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76306,
            "recall": 0.71813,
            "fmeasure": 0.72971
        },
        "rouge2": {
            "precision": 0.53124,
            "recall": 0.49633,
            "fmeasure": 0.50608
        },
        "rougeL": {
            "precision": 0.67962,
            "recall": 0.63598,
            "fmeasure": 0.64805
        },
        "rougeLsum": {
            "precision": 0.67962,
            "recall": 0.63598,
            "fmeasure": 0.64805
        },
        "bleu": 45.49333,
        "nist": 7.032438967475375,
        "local_recall": {
            "1": 0.20634920634920634,
            "2": 0.4430379746835443,
            "3": 0.764797507788162
        },
        "nubia": {
            "semantic_relation": 4.14318,
            "contradiction": 10.65385,
            "irrelevancy": 32.85701,
            "logical_agreement": 56.48914,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.74399,
            "nubia_score": 0.71123
        },
        "meteor": 0.39737202039391484,
        "bleurt": 0.23062,
        "bertscore": {
            "precision": 0.92572,
            "recall": 0.92285,
            "f1": 0.92311
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "bleu": 25.21194,
        "nist": 2.415947705372627,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.9393,
            "contradiction": 0.50698,
            "irrelevancy": 97.97126,
            "logical_agreement": 1.52176,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.93182,
            "nubia_score": 0.68311
        },
        "meteor": 0.4235494540099438,
        "bleurt": 0.64341,
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.96605,
            "f1": 0.95235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73812,
            "recall": 0.73934,
            "fmeasure": 0.73621
        },
        "rouge2": {
            "precision": 0.55526,
            "recall": 0.5578,
            "fmeasure": 0.55505
        },
        "rougeL": {
            "precision": 0.68588,
            "recall": 0.68845,
            "fmeasure": 0.68478
        },
        "rougeLsum": {
            "precision": 0.68588,
            "recall": 0.68845,
            "fmeasure": 0.68478
        },
        "bleu": 58.47989,
        "nist": 5.878479385784606,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.6111111111111112,
            "3": 0.8057553956834532
        },
        "nubia": {
            "semantic_relation": 4.1715,
            "contradiction": 5.35354,
            "irrelevancy": 25.10206,
            "logical_agreement": 69.5444,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.90752,
            "nubia_score": 0.76944
        },
        "meteor": 0.44638326964439506,
        "bleurt": 0.38295,
        "bertscore": {
            "precision": 0.9292,
            "recall": 0.92896,
            "f1": 0.92811
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "mT5_large/totto_test",
        "N": 37,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.73222,
            "fmeasure": 0.70906
        },
        "rouge2": {
            "precision": 0.48263,
            "recall": 0.49744,
            "fmeasure": 0.48177
        },
        "rougeL": {
            "precision": 0.61843,
            "recall": 0.64418,
            "fmeasure": 0.619
        },
        "rougeLsum": {
            "precision": 0.61843,
            "recall": 0.64418,
            "fmeasure": 0.619
        },
        "bleu": 40.49246,
        "nist": 6.287728169498322,
        "local_recall": {
            "1": 0.16911764705882354,
            "2": 0.42857142857142855,
            "3": 0.748792270531401
        },
        "nubia": {
            "semantic_relation": 4.00743,
            "contradiction": 12.77387,
            "irrelevancy": 37.10016,
            "logical_agreement": 50.12597,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.91189,
            "nubia_score": 0.65843
        },
        "meteor": 0.37928769383292027,
        "bleurt": 0.1615,
        "bertscore": {
            "precision": 0.91799,
            "recall": 0.91991,
            "f1": 0.91726
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8323,
            "recall": 0.80589,
            "fmeasure": 0.81085
        },
        "rouge2": {
            "precision": 0.63957,
            "recall": 0.61449,
            "fmeasure": 0.62027
        },
        "rougeL": {
            "precision": 0.77498,
            "recall": 0.74909,
            "fmeasure": 0.75486
        },
        "rougeLsum": {
            "precision": 0.77498,
            "recall": 0.74909,
            "fmeasure": 0.75486
        },
        "bleu": 63.1364,
        "nist": 7.167811451969484,
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.4117647058823529,
            "3": 0.8384279475982532
        },
        "nubia": {
            "semantic_relation": 4.42387,
            "contradiction": 4.69249,
            "irrelevancy": 23.27849,
            "logical_agreement": 72.02902,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.47805,
            "nubia_score": 0.78611
        },
        "meteor": 0.4770383792072305,
        "bleurt": 0.41887,
        "bertscore": {
            "precision": 0.95538,
            "recall": 0.95507,
            "f1": 0.95451
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77372,
            "recall": 0.75606,
            "fmeasure": 0.75177
        },
        "rouge2": {
            "precision": 0.51524,
            "recall": 0.51674,
            "fmeasure": 0.50583
        },
        "rougeL": {
            "precision": 0.64869,
            "recall": 0.64953,
            "fmeasure": 0.63585
        },
        "rougeLsum": {
            "precision": 0.64869,
            "recall": 0.64953,
            "fmeasure": 0.63585
        },
        "bleu": 46.2504,
        "nist": 6.73718672830875,
        "local_recall": {
            "1": 0.2653061224489796,
            "2": 0.4948453608247423,
            "3": 0.8489932885906041
        },
        "nubia": {
            "semantic_relation": 4.3139,
            "contradiction": 8.98392,
            "irrelevancy": 32.31754,
            "logical_agreement": 58.69854,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.37853,
            "nubia_score": 0.77291
        },
        "meteor": 0.40803781183459575,
        "bleurt": 0.35531,
        "bertscore": {
            "precision": 0.93866,
            "recall": 0.94015,
            "f1": 0.93747
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "mT5_large/totto_test",
        "N": 44,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76838,
            "recall": 0.77637,
            "fmeasure": 0.76365
        },
        "rouge2": {
            "precision": 0.54315,
            "recall": 0.55239,
            "fmeasure": 0.54205
        },
        "rougeL": {
            "precision": 0.67903,
            "recall": 0.68911,
            "fmeasure": 0.67629
        },
        "rougeLsum": {
            "precision": 0.67903,
            "recall": 0.68911,
            "fmeasure": 0.67629
        },
        "bleu": 49.69382,
        "nist": 6.982371111405003,
        "local_recall": {
            "1": 0.2079207920792079,
            "2": 0.56,
            "3": 0.816414686825054
        },
        "nubia": {
            "semantic_relation": 4.39281,
            "contradiction": 6.476,
            "irrelevancy": 32.90732,
            "logical_agreement": 60.61668,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.7618,
            "nubia_score": 0.7777
        },
        "meteor": 0.4161748769866427,
        "bleurt": 0.36396,
        "bertscore": {
            "precision": 0.93027,
            "recall": 0.93433,
            "f1": 0.93112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8024,
            "recall": 0.72893,
            "fmeasure": 0.75508
        },
        "rouge2": {
            "precision": 0.5676,
            "recall": 0.53076,
            "fmeasure": 0.54232
        },
        "rougeL": {
            "precision": 0.68643,
            "recall": 0.63947,
            "fmeasure": 0.65516
        },
        "rougeLsum": {
            "precision": 0.68643,
            "recall": 0.63947,
            "fmeasure": 0.65516
        },
        "bleu": 47.57531,
        "nist": 4.852672341495216,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.2,
            "3": 0.7619047619047619
        },
        "nubia": {
            "semantic_relation": 4.18814,
            "contradiction": 11.46501,
            "irrelevancy": 13.6838,
            "logical_agreement": 74.85119,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.28807,
            "nubia_score": 0.71322
        },
        "meteor": 0.403555246891945,
        "bleurt": 0.32325,
        "bertscore": {
            "precision": 0.93955,
            "recall": 0.92329,
            "f1": 0.92938
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "mT5_large/totto_test",
        "N": 20,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72221,
            "recall": 0.76396,
            "fmeasure": 0.73037
        },
        "rouge2": {
            "precision": 0.5012,
            "recall": 0.51144,
            "fmeasure": 0.49973
        },
        "rougeL": {
            "precision": 0.61325,
            "recall": 0.65204,
            "fmeasure": 0.62236
        },
        "rougeLsum": {
            "precision": 0.61325,
            "recall": 0.65204,
            "fmeasure": 0.62236
        },
        "bleu": 43.06086,
        "nist": 5.62716836503825,
        "local_recall": {
            "1": 0.26,
            "2": 0.5245901639344263,
            "3": 0.7696335078534031
        },
        "nubia": {
            "semantic_relation": 4.28663,
            "contradiction": 8.11502,
            "irrelevancy": 27.59472,
            "logical_agreement": 64.29026,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.50736,
            "nubia_score": 0.75464
        },
        "meteor": 0.4028262625984365,
        "bleurt": 0.3282,
        "bertscore": {
            "precision": 0.92198,
            "recall": 0.9316,
            "f1": 0.92548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "mT5_large/totto_test",
        "N": 144,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74845,
            "recall": 0.71241,
            "fmeasure": 0.71257
        },
        "rouge2": {
            "precision": 0.51524,
            "recall": 0.48615,
            "fmeasure": 0.48707
        },
        "rougeL": {
            "precision": 0.64225,
            "recall": 0.61614,
            "fmeasure": 0.61217
        },
        "rougeLsum": {
            "precision": 0.64225,
            "recall": 0.61614,
            "fmeasure": 0.61217
        },
        "bleu": 45.01791,
        "nist": 7.428356453058549,
        "local_recall": {
            "1": 0.23540856031128404,
            "2": 0.45695364238410596,
            "3": 0.7595330739299611
        },
        "nubia": {
            "semantic_relation": 4.08379,
            "contradiction": 7.50062,
            "irrelevancy": 31.77507,
            "logical_agreement": 60.72431,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.74932,
            "nubia_score": 0.70243
        },
        "meteor": 0.3961184406391781,
        "bleurt": 0.24472,
        "bertscore": {
            "precision": 0.92364,
            "recall": 0.9182,
            "f1": 0.91873
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72298,
            "recall": 0.78891,
            "fmeasure": 0.7455
        },
        "rouge2": {
            "precision": 0.54634,
            "recall": 0.57032,
            "fmeasure": 0.55358
        },
        "rougeL": {
            "precision": 0.59709,
            "recall": 0.64917,
            "fmeasure": 0.61359
        },
        "rougeLsum": {
            "precision": 0.59709,
            "recall": 0.64917,
            "fmeasure": 0.61359
        },
        "bleu": 48.79304,
        "nist": 5.635514534134812,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.5,
            "3": 0.8492063492063492
        },
        "nubia": {
            "semantic_relation": 4.22993,
            "contradiction": 8.97136,
            "irrelevancy": 37.87616,
            "logical_agreement": 53.15248,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.40945,
            "nubia_score": 0.76673
        },
        "meteor": 0.4381653516023138,
        "bleurt": 0.29626,
        "bertscore": {
            "precision": 0.91792,
            "recall": 0.93732,
            "f1": 0.92656
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "mT5_large/totto_test",
        "N": 300,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78627,
            "recall": 0.76184,
            "fmeasure": 0.7645
        },
        "rouge2": {
            "precision": 0.55167,
            "recall": 0.53214,
            "fmeasure": 0.53449
        },
        "rougeL": {
            "precision": 0.67071,
            "recall": 0.65365,
            "fmeasure": 0.65359
        },
        "rougeLsum": {
            "precision": 0.67071,
            "recall": 0.65365,
            "fmeasure": 0.65359
        },
        "bleu": 45.03451,
        "nist": 8.524977483750082,
        "local_recall": {
            "1": 0.19369894982497082,
            "2": 0.4148527528809219,
            "3": 0.8051829268292683
        },
        "nubia": {
            "semantic_relation": 4.38742,
            "contradiction": 5.75967,
            "irrelevancy": 25.36425,
            "logical_agreement": 68.87608,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.84223,
            "nubia_score": 0.78224
        },
        "meteor": 0.40455520995413624,
        "bleurt": 0.36602,
        "bertscore": {
            "precision": 0.93818,
            "recall": 0.93461,
            "f1": 0.93513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.52222,
            "fmeasure": 0.58554
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.32698,
            "fmeasure": 0.36923
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.39167,
            "fmeasure": 0.43915
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.39167,
            "fmeasure": 0.43915
        },
        "bleu": 22.36609,
        "nist": 2.2088210426859223,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "nubia": {
            "semantic_relation": 3.03831,
            "contradiction": 99.81984,
            "irrelevancy": 0.11729,
            "logical_agreement": 0.06287,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.7952,
            "nubia_score": 0.27165
        },
        "meteor": 0.2650373912860318,
        "bleurt": -0.02965,
        "bertscore": {
            "precision": 0.88397,
            "recall": 0.8952,
            "f1": 0.88955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "mT5_large/totto_test",
        "N": 48,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78412,
            "recall": 0.77216,
            "fmeasure": 0.76757
        },
        "rouge2": {
            "precision": 0.55527,
            "recall": 0.55119,
            "fmeasure": 0.54483
        },
        "rougeL": {
            "precision": 0.65958,
            "recall": 0.64599,
            "fmeasure": 0.6429
        },
        "rougeLsum": {
            "precision": 0.65958,
            "recall": 0.64599,
            "fmeasure": 0.6429
        },
        "bleu": 46.32814,
        "nist": 7.219832539078183,
        "local_recall": {
            "1": 0.16778523489932887,
            "2": 0.525,
            "3": 0.807920792079208
        },
        "nubia": {
            "semantic_relation": 4.32465,
            "contradiction": 7.03145,
            "irrelevancy": 26.05255,
            "logical_agreement": 66.916,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.80512,
            "nubia_score": 0.76332
        },
        "meteor": 0.41163333178494615,
        "bleurt": 0.3429,
        "bertscore": {
            "precision": 0.93652,
            "recall": 0.93831,
            "f1": 0.93635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86855,
            "recall": 0.70852,
            "fmeasure": 0.77846
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.42945,
            "fmeasure": 0.47673
        },
        "rougeL": {
            "precision": 0.62092,
            "recall": 0.51886,
            "fmeasure": 0.56409
        },
        "rougeLsum": {
            "precision": 0.62092,
            "recall": 0.51886,
            "fmeasure": 0.56409
        },
        "bleu": 31.31199,
        "nist": 3.54463892361511,
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.7575757575757576
        },
        "nubia": {
            "semantic_relation": 4.64852,
            "contradiction": 1.29816,
            "irrelevancy": 23.44932,
            "logical_agreement": 75.25251,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.85504,
            "nubia_score": 0.76355
        },
        "meteor": 0.3975433505214824,
        "bleurt": 0.38988,
        "bertscore": {
            "precision": 0.9555,
            "recall": 0.94279,
            "f1": 0.94907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "mT5_large/totto_test",
        "N": 15,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70861,
            "recall": 0.67386,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.47001,
            "recall": 0.44878,
            "fmeasure": 0.4533
        },
        "rougeL": {
            "precision": 0.61339,
            "recall": 0.59057,
            "fmeasure": 0.59393
        },
        "rougeLsum": {
            "precision": 0.61339,
            "recall": 0.59057,
            "fmeasure": 0.59393
        },
        "bleu": 42.71712,
        "nist": 5.513391317191737,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.375,
            "3": 0.7426900584795322
        },
        "nubia": {
            "semantic_relation": 4.23112,
            "contradiction": 10.36279,
            "irrelevancy": 37.33855,
            "logical_agreement": 52.29866,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.63328,
            "nubia_score": 0.72288
        },
        "meteor": 0.3657075061393202,
        "bleurt": 0.20466,
        "bertscore": {
            "precision": 0.90945,
            "recall": 0.91369,
            "f1": 0.9086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "mT5_large/totto_test",
        "N": 24,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77323,
            "recall": 0.75317,
            "fmeasure": 0.75341
        },
        "rouge2": {
            "precision": 0.5232,
            "recall": 0.50907,
            "fmeasure": 0.50898
        },
        "rougeL": {
            "precision": 0.66445,
            "recall": 0.63086,
            "fmeasure": 0.63909
        },
        "rougeLsum": {
            "precision": 0.66445,
            "recall": 0.63086,
            "fmeasure": 0.63909
        },
        "bleu": 51.18821,
        "nist": 6.694315546628835,
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.3870967741935484,
            "3": 0.8641975308641975
        },
        "nubia": {
            "semantic_relation": 4.18479,
            "contradiction": 5.12222,
            "irrelevancy": 30.31084,
            "logical_agreement": 64.56694,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.46808,
            "nubia_score": 0.75144
        },
        "meteor": 0.4161047324972799,
        "bleurt": 0.23905,
        "bertscore": {
            "precision": 0.9357,
            "recall": 0.93039,
            "f1": 0.93046
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "mT5_large/totto_test",
        "N": 47,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7336,
            "recall": 0.73425,
            "fmeasure": 0.71708
        },
        "rouge2": {
            "precision": 0.49005,
            "recall": 0.48236,
            "fmeasure": 0.47351
        },
        "rougeL": {
            "precision": 0.65037,
            "recall": 0.63894,
            "fmeasure": 0.6292
        },
        "rougeLsum": {
            "precision": 0.65037,
            "recall": 0.63894,
            "fmeasure": 0.6292
        },
        "bleu": 42.52743,
        "nist": 6.147107184698722,
        "local_recall": {
            "1": 0.2482758620689655,
            "2": 0.39568345323741005,
            "3": 0.7161290322580646
        },
        "nubia": {
            "semantic_relation": 3.98009,
            "contradiction": 10.14498,
            "irrelevancy": 30.27521,
            "logical_agreement": 59.57981,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.36011,
            "nubia_score": 0.68559
        },
        "meteor": 0.36682357984795977,
        "bleurt": 0.25848,
        "bertscore": {
            "precision": 0.91795,
            "recall": 0.91523,
            "f1": 0.91442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78592,
            "recall": 0.60685,
            "fmeasure": 0.65947
        },
        "rouge2": {
            "precision": 0.3677,
            "recall": 0.33401,
            "fmeasure": 0.34304
        },
        "rougeL": {
            "precision": 0.6383,
            "recall": 0.51108,
            "fmeasure": 0.54998
        },
        "rougeLsum": {
            "precision": 0.6383,
            "recall": 0.51108,
            "fmeasure": 0.54998
        },
        "bleu": 30.84859,
        "nist": 4.638372492007984,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.2222222222222222,
            "3": 0.6363636363636364
        },
        "nubia": {
            "semantic_relation": 4.11156,
            "contradiction": 12.79891,
            "irrelevancy": 22.98845,
            "logical_agreement": 64.21264,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.37283,
            "nubia_score": 0.57915
        },
        "meteor": 0.3370507671279246,
        "bleurt": 0.15007,
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.90252,
            "f1": 0.91499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80213,
            "recall": 0.75041,
            "fmeasure": 0.76919
        },
        "rouge2": {
            "precision": 0.56292,
            "recall": 0.53416,
            "fmeasure": 0.54369
        },
        "rougeL": {
            "precision": 0.68306,
            "recall": 0.64109,
            "fmeasure": 0.65576
        },
        "rougeLsum": {
            "precision": 0.68306,
            "recall": 0.64109,
            "fmeasure": 0.65576
        },
        "bleu": 48.48113,
        "nist": 7.074578071052026,
        "local_recall": {
            "1": 0.2336448598130841,
            "2": 0.34177215189873417,
            "3": 0.7902097902097902
        },
        "nubia": {
            "semantic_relation": 4.29139,
            "contradiction": 6.64894,
            "irrelevancy": 20.45162,
            "logical_agreement": 72.89944,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.66206,
            "nubia_score": 0.75522
        },
        "meteor": 0.4134642903964566,
        "bleurt": 0.33743,
        "bertscore": {
            "precision": 0.94255,
            "recall": 0.93599,
            "f1": 0.93818
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70073,
            "recall": 0.69368,
            "fmeasure": 0.68407
        },
        "rouge2": {
            "precision": 0.43256,
            "recall": 0.44901,
            "fmeasure": 0.43054
        },
        "rougeL": {
            "precision": 0.59144,
            "recall": 0.57827,
            "fmeasure": 0.57464
        },
        "rougeLsum": {
            "precision": 0.59144,
            "recall": 0.57827,
            "fmeasure": 0.57464
        },
        "bleu": 39.31262,
        "nist": 5.873383729347922,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.4576271186440678,
            "3": 0.7453416149068323
        },
        "nubia": {
            "semantic_relation": 4.25404,
            "contradiction": 1.90159,
            "irrelevancy": 52.75651,
            "logical_agreement": 45.34191,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.78383,
            "nubia_score": 0.74
        },
        "meteor": 0.37334590971677795,
        "bleurt": 0.25249,
        "bertscore": {
            "precision": 0.92077,
            "recall": 0.91967,
            "f1": 0.9164
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "mT5_large/totto_test",
        "N": 24,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76687,
            "recall": 0.73831,
            "fmeasure": 0.7401
        },
        "rouge2": {
            "precision": 0.50601,
            "recall": 0.47712,
            "fmeasure": 0.48212
        },
        "rougeL": {
            "precision": 0.70042,
            "recall": 0.66764,
            "fmeasure": 0.67219
        },
        "rougeLsum": {
            "precision": 0.70042,
            "recall": 0.66764,
            "fmeasure": 0.67219
        },
        "bleu": 40.73871,
        "nist": 5.981583459290124,
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.3953488372093023,
            "3": 0.8059071729957806
        },
        "nubia": {
            "semantic_relation": 4.305,
            "contradiction": 4.49986,
            "irrelevancy": 31.87058,
            "logical_agreement": 63.62956,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.75207,
            "nubia_score": 0.74861
        },
        "meteor": 0.3929772788973885,
        "bleurt": 0.28759,
        "bertscore": {
            "precision": 0.92675,
            "recall": 0.92589,
            "f1": 0.92427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "mT5_large/totto_test",
        "N": 13,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86928,
            "recall": 0.87549,
            "fmeasure": 0.86829
        },
        "rouge2": {
            "precision": 0.70618,
            "recall": 0.69759,
            "fmeasure": 0.70081
        },
        "rougeL": {
            "precision": 0.80444,
            "recall": 0.808,
            "fmeasure": 0.80194
        },
        "rougeLsum": {
            "precision": 0.80444,
            "recall": 0.808,
            "fmeasure": 0.80194
        },
        "bleu": 66.82025,
        "nist": 6.785041897448239,
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.2727272727272727,
            "3": 0.9407894736842105
        },
        "nubia": {
            "semantic_relation": 4.71464,
            "contradiction": 0.32548,
            "irrelevancy": 20.28635,
            "logical_agreement": 79.38817,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.00442,
            "nubia_score": 0.90453
        },
        "meteor": 0.5159759878107648,
        "bleurt": 0.63121,
        "bertscore": {
            "precision": 0.95901,
            "recall": 0.96807,
            "f1": 0.96228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "mT5_large/totto_test",
        "N": 35,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74576,
            "recall": 0.72279,
            "fmeasure": 0.72296
        },
        "rouge2": {
            "precision": 0.52622,
            "recall": 0.50257,
            "fmeasure": 0.50646
        },
        "rougeL": {
            "precision": 0.65066,
            "recall": 0.63165,
            "fmeasure": 0.63213
        },
        "rougeLsum": {
            "precision": 0.65066,
            "recall": 0.63165,
            "fmeasure": 0.63213
        },
        "bleu": 49.39281,
        "nist": 7.048293432251549,
        "local_recall": {
            "1": 0.29381443298969073,
            "2": 0.44144144144144143,
            "3": 0.7737430167597765
        },
        "nubia": {
            "semantic_relation": 4.09082,
            "contradiction": 9.89288,
            "irrelevancy": 34.21977,
            "logical_agreement": 55.88735,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.74948,
            "nubia_score": 0.68215
        },
        "meteor": 0.3913037629688586,
        "bleurt": 0.2325,
        "bertscore": {
            "precision": 0.93464,
            "recall": 0.9271,
            "f1": 0.92897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "mT5_large/totto_test",
        "N": 40,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78751,
            "recall": 0.76489,
            "fmeasure": 0.76711
        },
        "rouge2": {
            "precision": 0.58527,
            "recall": 0.57109,
            "fmeasure": 0.57015
        },
        "rougeL": {
            "precision": 0.69746,
            "recall": 0.67815,
            "fmeasure": 0.68011
        },
        "rougeLsum": {
            "precision": 0.69746,
            "recall": 0.67815,
            "fmeasure": 0.68011
        },
        "bleu": 51.85796,
        "nist": 6.778586598694576,
        "local_recall": {
            "1": 0.3504273504273504,
            "2": 0.4461538461538462,
            "3": 0.7801418439716312
        },
        "nubia": {
            "semantic_relation": 4.23784,
            "contradiction": 7.59515,
            "irrelevancy": 30.41322,
            "logical_agreement": 61.99163,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.38781,
            "nubia_score": 0.74287
        },
        "meteor": 0.40606954789196886,
        "bleurt": 0.36011,
        "bertscore": {
            "precision": 0.93444,
            "recall": 0.93589,
            "f1": 0.93329
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5771,
            "recall": 0.6914,
            "fmeasure": 0.62484
        },
        "rouge2": {
            "precision": 0.28075,
            "recall": 0.34132,
            "fmeasure": 0.30475
        },
        "rougeL": {
            "precision": 0.42475,
            "recall": 0.51521,
            "fmeasure": 0.46086
        },
        "rougeLsum": {
            "precision": 0.42475,
            "recall": 0.51521,
            "fmeasure": 0.46086
        },
        "bleu": 18.01353,
        "nist": 3.1818762925716966,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6,
            "3": 0.6944444444444444
        },
        "nubia": {
            "semantic_relation": 4.0033,
            "contradiction": 0.48414,
            "irrelevancy": 77.78371,
            "logical_agreement": 21.73215,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.36026,
            "nubia_score": 0.66532
        },
        "meteor": 0.3442829036498824,
        "bleurt": -0.14884,
        "bertscore": {
            "precision": 0.85539,
            "recall": 0.91446,
            "f1": 0.8815
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "mT5_large/totto_test",
        "N": 33,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81544,
            "recall": 0.77597,
            "fmeasure": 0.78934
        },
        "rouge2": {
            "precision": 0.57136,
            "recall": 0.54482,
            "fmeasure": 0.55303
        },
        "rougeL": {
            "precision": 0.68221,
            "recall": 0.65606,
            "fmeasure": 0.66324
        },
        "rougeLsum": {
            "precision": 0.68221,
            "recall": 0.65606,
            "fmeasure": 0.66324
        },
        "bleu": 50.12062,
        "nist": 7.096578516330379,
        "local_recall": {
            "1": 0.1375,
            "2": 0.2835820895522388,
            "3": 0.8414634146341463
        },
        "nubia": {
            "semantic_relation": 4.58014,
            "contradiction": 0.53172,
            "irrelevancy": 16.2903,
            "logical_agreement": 83.17798,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.02926,
            "nubia_score": 0.82787
        },
        "meteor": 0.42304767407501825,
        "bleurt": 0.38763,
        "bertscore": {
            "precision": 0.94214,
            "recall": 0.93884,
            "f1": 0.93924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "bleu": 100.0,
        "nist": 5.016137706633773,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95532,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66432,
            "recall": 0.71045,
            "fmeasure": 0.6732
        },
        "rouge2": {
            "precision": 0.4415,
            "recall": 0.47434,
            "fmeasure": 0.44465
        },
        "rougeL": {
            "precision": 0.59521,
            "recall": 0.64413,
            "fmeasure": 0.6037
        },
        "rougeLsum": {
            "precision": 0.59521,
            "recall": 0.64413,
            "fmeasure": 0.6037
        },
        "bleu": 36.39541,
        "nist": 4.615032476482175,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.27586206896551724,
            "3": 0.7526881720430108
        },
        "nubia": {
            "semantic_relation": 4.07891,
            "contradiction": 9.2319,
            "irrelevancy": 63.90201,
            "logical_agreement": 26.86609,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.83072,
            "nubia_score": 0.67153
        },
        "meteor": 0.3638411289172171,
        "bleurt": 0.181,
        "bertscore": {
            "precision": 0.90261,
            "recall": 0.91229,
            "f1": 0.90551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "mT5_large/totto_test",
        "N": 43,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82458,
            "recall": 0.77532,
            "fmeasure": 0.79167
        },
        "rouge2": {
            "precision": 0.60597,
            "recall": 0.57428,
            "fmeasure": 0.5833
        },
        "rougeL": {
            "precision": 0.71257,
            "recall": 0.6781,
            "fmeasure": 0.68815
        },
        "rougeLsum": {
            "precision": 0.71257,
            "recall": 0.6781,
            "fmeasure": 0.68815
        },
        "bleu": 51.84034,
        "nist": 7.495633908178801,
        "local_recall": {
            "1": 0.24031007751937986,
            "2": 0.6206896551724138,
            "3": 0.8296943231441049
        },
        "nubia": {
            "semantic_relation": 4.49,
            "contradiction": 2.01088,
            "irrelevancy": 17.27699,
            "logical_agreement": 80.71214,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.61774,
            "nubia_score": 0.82028
        },
        "meteor": 0.4239441980602835,
        "bleurt": 0.40703,
        "bertscore": {
            "precision": 0.9455,
            "recall": 0.93776,
            "f1": 0.94081
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "mT5_large/totto_test",
        "N": 29,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73489,
            "recall": 0.72154,
            "fmeasure": 0.71532
        },
        "rouge2": {
            "precision": 0.50806,
            "recall": 0.49143,
            "fmeasure": 0.49016
        },
        "rougeL": {
            "precision": 0.65179,
            "recall": 0.63787,
            "fmeasure": 0.63331
        },
        "rougeLsum": {
            "precision": 0.65179,
            "recall": 0.63787,
            "fmeasure": 0.63331
        },
        "bleu": 42.86317,
        "nist": 6.358783008422685,
        "local_recall": {
            "1": 0.23300970873786409,
            "2": 0.43023255813953487,
            "3": 0.7450331125827815
        },
        "nubia": {
            "semantic_relation": 4.30067,
            "contradiction": 7.98868,
            "irrelevancy": 33.38507,
            "logical_agreement": 58.62625,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.51697,
            "nubia_score": 0.77405
        },
        "meteor": 0.3846596968191267,
        "bleurt": 0.3318,
        "bertscore": {
            "precision": 0.92639,
            "recall": 0.92444,
            "f1": 0.9228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "mT5_large/totto_test",
        "N": 16,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79282,
            "recall": 0.79488,
            "fmeasure": 0.78195
        },
        "rouge2": {
            "precision": 0.57118,
            "recall": 0.58245,
            "fmeasure": 0.56565
        },
        "rougeL": {
            "precision": 0.69263,
            "recall": 0.70233,
            "fmeasure": 0.68783
        },
        "rougeLsum": {
            "precision": 0.69263,
            "recall": 0.70233,
            "fmeasure": 0.68783
        },
        "bleu": 48.32529,
        "nist": 6.312139339867497,
        "local_recall": {
            "1": 0.29545454545454547,
            "2": 0.4,
            "3": 0.8342245989304813
        },
        "nubia": {
            "semantic_relation": 4.31511,
            "contradiction": 1.12041,
            "irrelevancy": 32.45573,
            "logical_agreement": 66.42386,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.68078,
            "nubia_score": 0.78209
        },
        "meteor": 0.4085749586006663,
        "bleurt": 0.31579,
        "bertscore": {
            "precision": 0.94059,
            "recall": 0.93872,
            "f1": 0.93674
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "mT5_large/totto_test",
        "N": 59,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7954,
            "recall": 0.75565,
            "fmeasure": 0.76671
        },
        "rouge2": {
            "precision": 0.57573,
            "recall": 0.54751,
            "fmeasure": 0.55551
        },
        "rougeL": {
            "precision": 0.68378,
            "recall": 0.65262,
            "fmeasure": 0.66094
        },
        "rougeLsum": {
            "precision": 0.68378,
            "recall": 0.65262,
            "fmeasure": 0.66094
        },
        "bleu": 49.48558,
        "nist": 7.322015444097215,
        "local_recall": {
            "1": 0.2138364779874214,
            "2": 0.48872180451127817,
            "3": 0.8137715179968701
        },
        "nubia": {
            "semantic_relation": 4.33339,
            "contradiction": 4.94585,
            "irrelevancy": 23.65289,
            "logical_agreement": 71.40126,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.57148,
            "nubia_score": 0.77908
        },
        "meteor": 0.41369745010507913,
        "bleurt": 0.36307,
        "bertscore": {
            "precision": 0.94135,
            "recall": 0.93227,
            "f1": 0.93542
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76027,
            "recall": 0.71487,
            "fmeasure": 0.72774
        },
        "rouge2": {
            "precision": 0.52782,
            "recall": 0.48709,
            "fmeasure": 0.50095
        },
        "rougeL": {
            "precision": 0.67328,
            "recall": 0.62678,
            "fmeasure": 0.63944
        },
        "rougeLsum": {
            "precision": 0.67328,
            "recall": 0.62678,
            "fmeasure": 0.63944
        },
        "bleu": 38.27039,
        "nist": 5.29729106667036,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.13636363636363635,
            "3": 0.7380952380952381
        },
        "nubia": {
            "semantic_relation": 4.06912,
            "contradiction": 12.83201,
            "irrelevancy": 26.4871,
            "logical_agreement": 60.68089,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.35579,
            "nubia_score": 0.71324
        },
        "meteor": 0.38287250049248245,
        "bleurt": 0.15264,
        "bertscore": {
            "precision": 0.91502,
            "recall": 0.91141,
            "f1": 0.91169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65308,
            "recall": 0.63742,
            "fmeasure": 0.6355
        },
        "rouge2": {
            "precision": 0.38446,
            "recall": 0.36371,
            "fmeasure": 0.36792
        },
        "rougeL": {
            "precision": 0.49401,
            "recall": 0.48152,
            "fmeasure": 0.47692
        },
        "rougeLsum": {
            "precision": 0.49401,
            "recall": 0.48152,
            "fmeasure": 0.47692
        },
        "bleu": 27.34214,
        "nist": 4.930272032502912,
        "local_recall": {
            "1": 0.25,
            "2": 0.2459016393442623,
            "3": 0.7080745341614907
        },
        "nubia": {
            "semantic_relation": 3.92461,
            "contradiction": 12.6223,
            "irrelevancy": 43.34054,
            "logical_agreement": 44.03717,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.62086,
            "nubia_score": 0.67175
        },
        "meteor": 0.32312077732018274,
        "bleurt": 0.13183,
        "bertscore": {
            "precision": 0.90324,
            "recall": 0.89568,
            "f1": 0.89748
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.26923,
            "recall": 0.31667,
            "fmeasure": 0.29043
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.19231,
            "recall": 0.225,
            "fmeasure": 0.20696
        },
        "rougeLsum": {
            "precision": 0.19231,
            "recall": 0.225,
            "fmeasure": 0.20696
        },
        "bleu": 4.24655,
        "nist": 1.3517723216861275,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.375
        },
        "nubia": {
            "semantic_relation": 2.80861,
            "contradiction": 6.23288,
            "irrelevancy": 17.42081,
            "logical_agreement": 76.34631,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.55431,
            "nubia_score": 0.27579
        },
        "meteor": 0.2064516129032258,
        "bleurt": -0.42364,
        "bertscore": {
            "precision": 0.82494,
            "recall": 0.81369,
            "f1": 0.81928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "mT5_large/totto_test",
        "N": 114,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73921,
            "recall": 0.70596,
            "fmeasure": 0.71036
        },
        "rouge2": {
            "precision": 0.48498,
            "recall": 0.46225,
            "fmeasure": 0.4651
        },
        "rougeL": {
            "precision": 0.61656,
            "recall": 0.59006,
            "fmeasure": 0.59357
        },
        "rougeLsum": {
            "precision": 0.61656,
            "recall": 0.59006,
            "fmeasure": 0.59357
        },
        "bleu": 40.86882,
        "nist": 7.344497170051197,
        "local_recall": {
            "1": 0.1890547263681592,
            "2": 0.49238578680203043,
            "3": 0.7559262510974539
        },
        "nubia": {
            "semantic_relation": 4.13619,
            "contradiction": 10.1798,
            "irrelevancy": 31.60494,
            "logical_agreement": 58.21525,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.64471,
            "nubia_score": 0.70656
        },
        "meteor": 0.3776699235047885,
        "bleurt": 0.20765,
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.92025,
            "f1": 0.9202
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74132,
            "recall": 0.72845,
            "fmeasure": 0.72154
        },
        "rouge2": {
            "precision": 0.55777,
            "recall": 0.5496,
            "fmeasure": 0.54277
        },
        "rougeL": {
            "precision": 0.59813,
            "recall": 0.60496,
            "fmeasure": 0.58929
        },
        "rougeLsum": {
            "precision": 0.59813,
            "recall": 0.60496,
            "fmeasure": 0.58929
        },
        "bleu": 24.20805,
        "nist": 3.6912024362742457,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7380952380952381
        },
        "nubia": {
            "semantic_relation": 4.08263,
            "contradiction": 9.67338,
            "irrelevancy": 50.33196,
            "logical_agreement": 39.99465,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.58925,
            "nubia_score": 0.76254
        },
        "meteor": 0.3436665781232059,
        "bleurt": 0.17862,
        "bertscore": {
            "precision": 0.90442,
            "recall": 0.90608,
            "f1": 0.90074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "mT5_large/totto_test",
        "N": 23,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74495,
            "recall": 0.77154,
            "fmeasure": 0.75139
        },
        "rouge2": {
            "precision": 0.54921,
            "recall": 0.57612,
            "fmeasure": 0.55661
        },
        "rougeL": {
            "precision": 0.66026,
            "recall": 0.68618,
            "fmeasure": 0.66749
        },
        "rougeLsum": {
            "precision": 0.66026,
            "recall": 0.68618,
            "fmeasure": 0.66749
        },
        "bleu": 47.5519,
        "nist": 6.22785092614456,
        "local_recall": {
            "1": 0.2597402597402597,
            "2": 0.5217391304347826,
            "3": 0.8596491228070176
        },
        "nubia": {
            "semantic_relation": 4.31849,
            "contradiction": 4.45842,
            "irrelevancy": 33.56519,
            "logical_agreement": 61.97639,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.67128,
            "nubia_score": 0.77725
        },
        "meteor": 0.438633315932185,
        "bleurt": 0.28361,
        "bertscore": {
            "precision": 0.93102,
            "recall": 0.93813,
            "f1": 0.93326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66328,
            "recall": 0.61403,
            "fmeasure": 0.6176
        },
        "rouge2": {
            "precision": 0.39337,
            "recall": 0.36487,
            "fmeasure": 0.36881
        },
        "rougeL": {
            "precision": 0.5515,
            "recall": 0.49649,
            "fmeasure": 0.50795
        },
        "rougeLsum": {
            "precision": 0.5515,
            "recall": 0.49649,
            "fmeasure": 0.50795
        },
        "bleu": 30.76394,
        "nist": 5.286413869553505,
        "local_recall": {
            "1": 0.2815533980582524,
            "2": 0.2727272727272727,
            "3": 0.6938775510204082
        },
        "nubia": {
            "semantic_relation": 3.84308,
            "contradiction": 3.04823,
            "irrelevancy": 55.46152,
            "logical_agreement": 41.49025,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.46416,
            "nubia_score": 0.62299
        },
        "meteor": 0.3327797348987205,
        "bleurt": -0.01313,
        "bertscore": {
            "precision": 0.89526,
            "recall": 0.88344,
            "f1": 0.88732
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "mT5_large/totto_test",
        "N": 483,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74141,
            "recall": 0.73144,
            "fmeasure": 0.72717
        },
        "rouge2": {
            "precision": 0.48596,
            "recall": 0.48044,
            "fmeasure": 0.47695
        },
        "rougeL": {
            "precision": 0.59873,
            "recall": 0.59249,
            "fmeasure": 0.5874
        },
        "rougeLsum": {
            "precision": 0.59873,
            "recall": 0.59249,
            "fmeasure": 0.5874
        },
        "bleu": 41.57715,
        "nist": 8.765677147094449,
        "local_recall": {
            "1": 0.22629435718440954,
            "2": 0.4174193548387097,
            "3": 0.7704319906596614
        },
        "nubia": {
            "semantic_relation": 4.14412,
            "contradiction": 9.76913,
            "irrelevancy": 34.18577,
            "logical_agreement": 56.0451,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.26686,
            "nubia_score": 0.72287
        },
        "meteor": 0.3850453351051846,
        "bleurt": 0.19999,
        "bertscore": {
            "precision": 0.92118,
            "recall": 0.91999,
            "f1": 0.91859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66863,
            "recall": 0.63857,
            "fmeasure": 0.63324
        },
        "rouge2": {
            "precision": 0.38514,
            "recall": 0.35084,
            "fmeasure": 0.35791
        },
        "rougeL": {
            "precision": 0.50392,
            "recall": 0.46804,
            "fmeasure": 0.47146
        },
        "rougeLsum": {
            "precision": 0.50392,
            "recall": 0.46804,
            "fmeasure": 0.47146
        },
        "bleu": 26.8517,
        "nist": 4.473049730610571,
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.6,
            "3": 0.6554621848739496
        },
        "nubia": {
            "semantic_relation": 3.39758,
            "contradiction": 12.15903,
            "irrelevancy": 33.4425,
            "logical_agreement": 54.39847,
            "grammar_ref": 4.70623,
            "grammar_hyp": 4.9792,
            "nubia_score": 0.51257
        },
        "meteor": 0.3131346366962631,
        "bleurt": -0.09384,
        "bertscore": {
            "precision": 0.8943,
            "recall": 0.89588,
            "f1": 0.89385
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77523,
            "recall": 0.75872,
            "fmeasure": 0.75612
        },
        "rouge2": {
            "precision": 0.57747,
            "recall": 0.57157,
            "fmeasure": 0.56696
        },
        "rougeL": {
            "precision": 0.68679,
            "recall": 0.6803,
            "fmeasure": 0.67369
        },
        "rougeLsum": {
            "precision": 0.68679,
            "recall": 0.6803,
            "fmeasure": 0.67369
        },
        "bleu": 57.84453,
        "nist": 6.790963616977663,
        "local_recall": {
            "1": 0.23404255319148937,
            "2": 0.3157894736842105,
            "3": 0.8064516129032258
        },
        "nubia": {
            "semantic_relation": 4.28166,
            "contradiction": 7.05366,
            "irrelevancy": 27.93299,
            "logical_agreement": 65.01334,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.51152,
            "nubia_score": 0.76599
        },
        "meteor": 0.44685127314543105,
        "bleurt": 0.37875,
        "bertscore": {
            "precision": 0.93527,
            "recall": 0.92921,
            "f1": 0.93176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72539,
            "recall": 0.6876,
            "fmeasure": 0.68334
        },
        "rouge2": {
            "precision": 0.51306,
            "recall": 0.49546,
            "fmeasure": 0.48321
        },
        "rougeL": {
            "precision": 0.60879,
            "recall": 0.58628,
            "fmeasure": 0.57338
        },
        "rougeLsum": {
            "precision": 0.60879,
            "recall": 0.58628,
            "fmeasure": 0.57338
        },
        "bleu": 42.81078,
        "nist": 6.06063364219248,
        "local_recall": {
            "1": 0.35555555555555557,
            "2": 0.32,
            "3": 0.7070707070707071
        },
        "nubia": {
            "semantic_relation": 4.0228,
            "contradiction": 17.26886,
            "irrelevancy": 24.98992,
            "logical_agreement": 57.74122,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.29976,
            "nubia_score": 0.67808
        },
        "meteor": 0.39349072740953933,
        "bleurt": 0.12692,
        "bertscore": {
            "precision": 0.91673,
            "recall": 0.91331,
            "f1": 0.91066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "mT5_large/totto_test",
        "N": 77,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76922,
            "recall": 0.7176,
            "fmeasure": 0.73377
        },
        "rouge2": {
            "precision": 0.53798,
            "recall": 0.49834,
            "fmeasure": 0.51082
        },
        "rougeL": {
            "precision": 0.67458,
            "recall": 0.63129,
            "fmeasure": 0.64379
        },
        "rougeLsum": {
            "precision": 0.67458,
            "recall": 0.63129,
            "fmeasure": 0.64379
        },
        "bleu": 47.91548,
        "nist": 7.385203726787904,
        "local_recall": {
            "1": 0.23735408560311283,
            "2": 0.4263565891472868,
            "3": 0.7815344603381015
        },
        "nubia": {
            "semantic_relation": 4.13614,
            "contradiction": 6.42531,
            "irrelevancy": 28.46897,
            "logical_agreement": 65.10572,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.72344,
            "nubia_score": 0.71391
        },
        "meteor": 0.39553632955154877,
        "bleurt": 0.26035,
        "bertscore": {
            "precision": 0.93246,
            "recall": 0.9247,
            "f1": 0.92677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75311,
            "recall": 0.77568,
            "fmeasure": 0.75422
        },
        "rouge2": {
            "precision": 0.54289,
            "recall": 0.57305,
            "fmeasure": 0.54969
        },
        "rougeL": {
            "precision": 0.66607,
            "recall": 0.68161,
            "fmeasure": 0.66408
        },
        "rougeLsum": {
            "precision": 0.66607,
            "recall": 0.68161,
            "fmeasure": 0.66408
        },
        "bleu": 51.93146,
        "nist": 6.539041084978404,
        "local_recall": {
            "1": 0.22,
            "2": 0.38095238095238093,
            "3": 0.8443396226415094
        },
        "nubia": {
            "semantic_relation": 4.21918,
            "contradiction": 9.41786,
            "irrelevancy": 43.5622,
            "logical_agreement": 47.01994,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.60728,
            "nubia_score": 0.7204
        },
        "meteor": 0.4342372260481659,
        "bleurt": 0.23576,
        "bertscore": {
            "precision": 0.92253,
            "recall": 0.93128,
            "f1": 0.9238
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "mT5_large/totto_test",
        "N": 36,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72409,
            "recall": 0.76604,
            "fmeasure": 0.73611
        },
        "rouge2": {
            "precision": 0.50551,
            "recall": 0.53628,
            "fmeasure": 0.51221
        },
        "rougeL": {
            "precision": 0.62099,
            "recall": 0.66797,
            "fmeasure": 0.63394
        },
        "rougeLsum": {
            "precision": 0.62099,
            "recall": 0.66797,
            "fmeasure": 0.63394
        },
        "bleu": 44.40886,
        "nist": 6.422457562365021,
        "local_recall": {
            "1": 0.17901234567901234,
            "2": 0.6271186440677966,
            "3": 0.7907692307692308
        },
        "nubia": {
            "semantic_relation": 4.14569,
            "contradiction": 6.86054,
            "irrelevancy": 44.01296,
            "logical_agreement": 49.1265,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.32276,
            "nubia_score": 0.71929
        },
        "meteor": 0.4069630402709744,
        "bleurt": 0.20902,
        "bertscore": {
            "precision": 0.91951,
            "recall": 0.92969,
            "f1": 0.92279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67391,
            "recall": 0.68763,
            "fmeasure": 0.66752
        },
        "rouge2": {
            "precision": 0.53182,
            "recall": 0.52885,
            "fmeasure": 0.51803
        },
        "rougeL": {
            "precision": 0.61397,
            "recall": 0.63065,
            "fmeasure": 0.60959
        },
        "rougeLsum": {
            "precision": 0.61397,
            "recall": 0.63065,
            "fmeasure": 0.60959
        },
        "bleu": 42.44212,
        "nist": 3.82362592367483,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.15069,
            "contradiction": 0.28859,
            "irrelevancy": 50.10979,
            "logical_agreement": 49.60161,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.03067,
            "nubia_score": 0.72877
        },
        "meteor": 0.3428298405090871,
        "bleurt": 0.28131,
        "bertscore": {
            "precision": 0.87249,
            "recall": 0.9189,
            "f1": 0.89378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77898,
            "recall": 0.79807,
            "fmeasure": 0.77669
        },
        "rouge2": {
            "precision": 0.55084,
            "recall": 0.56665,
            "fmeasure": 0.54973
        },
        "rougeL": {
            "precision": 0.63075,
            "recall": 0.64055,
            "fmeasure": 0.62658
        },
        "rougeLsum": {
            "precision": 0.63075,
            "recall": 0.64055,
            "fmeasure": 0.62658
        },
        "bleu": 50.10741,
        "nist": 5.971063641947146,
        "local_recall": {
            "1": 0.1875,
            "2": 0.47368421052631576,
            "3": 0.8285714285714286
        },
        "nubia": {
            "semantic_relation": 4.25117,
            "contradiction": 10.63725,
            "irrelevancy": 33.21117,
            "logical_agreement": 56.15159,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.21245,
            "nubia_score": 0.74963
        },
        "meteor": 0.4442723985675737,
        "bleurt": 0.2564,
        "bertscore": {
            "precision": 0.92556,
            "recall": 0.92839,
            "f1": 0.92445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75898,
            "recall": 0.69324,
            "fmeasure": 0.71076
        },
        "rouge2": {
            "precision": 0.57502,
            "recall": 0.52262,
            "fmeasure": 0.53574
        },
        "rougeL": {
            "precision": 0.67724,
            "recall": 0.62243,
            "fmeasure": 0.63545
        },
        "rougeLsum": {
            "precision": 0.67724,
            "recall": 0.62243,
            "fmeasure": 0.63545
        },
        "bleu": 39.83038,
        "nist": 4.283432531838896,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.4482758620689655,
            "3": 0.711864406779661
        },
        "nubia": {
            "semantic_relation": 4.28279,
            "contradiction": 10.63112,
            "irrelevancy": 14.48291,
            "logical_agreement": 74.88597,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.48446,
            "nubia_score": 0.78362
        },
        "meteor": 0.3161684389149445,
        "bleurt": 0.32313,
        "bertscore": {
            "precision": 0.92474,
            "recall": 0.9119,
            "f1": 0.91764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69417,
            "recall": 0.71467,
            "fmeasure": 0.69371
        },
        "rouge2": {
            "precision": 0.47269,
            "recall": 0.48961,
            "fmeasure": 0.47288
        },
        "rougeL": {
            "precision": 0.5692,
            "recall": 0.59376,
            "fmeasure": 0.57067
        },
        "rougeLsum": {
            "precision": 0.5692,
            "recall": 0.59376,
            "fmeasure": 0.57067
        },
        "bleu": 37.67402,
        "nist": 5.758136758002453,
        "local_recall": {
            "1": 0.24050632911392406,
            "2": 0.5,
            "3": 0.7154929577464789
        },
        "nubia": {
            "semantic_relation": 4.09338,
            "contradiction": 6.00757,
            "irrelevancy": 37.11264,
            "logical_agreement": 56.87979,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.50764,
            "nubia_score": 0.67905
        },
        "meteor": 0.3770825825627568,
        "bleurt": 0.17479,
        "bertscore": {
            "precision": 0.90991,
            "recall": 0.91228,
            "f1": 0.90988
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "mT5_large/totto_test",
        "N": 23,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79186,
            "recall": 0.7377,
            "fmeasure": 0.75121
        },
        "rouge2": {
            "precision": 0.56572,
            "recall": 0.54895,
            "fmeasure": 0.54822
        },
        "rougeL": {
            "precision": 0.69467,
            "recall": 0.66257,
            "fmeasure": 0.66645
        },
        "rougeLsum": {
            "precision": 0.69467,
            "recall": 0.66257,
            "fmeasure": 0.66645
        },
        "bleu": 47.2535,
        "nist": 6.464487660594016,
        "local_recall": {
            "1": 0.25,
            "2": 0.39759036144578314,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.183,
            "contradiction": 5.6782,
            "irrelevancy": 30.9975,
            "logical_agreement": 63.32429,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.53955,
            "nubia_score": 0.71503
        },
        "meteor": 0.39744443211367503,
        "bleurt": 0.25332,
        "bertscore": {
            "precision": 0.93117,
            "recall": 0.92356,
            "f1": 0.9251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77197,
            "recall": 0.75197,
            "fmeasure": 0.7529
        },
        "rouge2": {
            "precision": 0.53938,
            "recall": 0.53879,
            "fmeasure": 0.53286
        },
        "rougeL": {
            "precision": 0.67364,
            "recall": 0.67486,
            "fmeasure": 0.66655
        },
        "rougeLsum": {
            "precision": 0.67364,
            "recall": 0.67486,
            "fmeasure": 0.66655
        },
        "bleu": 55.4976,
        "nist": 6.217985756402081,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.45161290322580644,
            "3": 0.8673469387755102
        },
        "nubia": {
            "semantic_relation": 4.46612,
            "contradiction": 0.4333,
            "irrelevancy": 41.02681,
            "logical_agreement": 58.53989,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.52843,
            "nubia_score": 0.79055
        },
        "meteor": 0.44948699272459747,
        "bleurt": 0.36216,
        "bertscore": {
            "precision": 0.93662,
            "recall": 0.92903,
            "f1": 0.9316
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "mT5_large/totto_test",
        "N": 30,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7416,
            "recall": 0.71601,
            "fmeasure": 0.71582
        },
        "rouge2": {
            "precision": 0.49036,
            "recall": 0.48235,
            "fmeasure": 0.47377
        },
        "rougeL": {
            "precision": 0.61304,
            "recall": 0.61222,
            "fmeasure": 0.59838
        },
        "rougeLsum": {
            "precision": 0.61304,
            "recall": 0.61222,
            "fmeasure": 0.59838
        },
        "bleu": 43.24644,
        "nist": 6.30992475075496,
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.411214953271028,
            "3": 0.7850746268656716
        },
        "nubia": {
            "semantic_relation": 4.10078,
            "contradiction": 14.27169,
            "irrelevancy": 24.51712,
            "logical_agreement": 61.21119,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.7564,
            "nubia_score": 0.69364
        },
        "meteor": 0.3888664684868909,
        "bleurt": 0.22074,
        "bertscore": {
            "precision": 0.92374,
            "recall": 0.91745,
            "f1": 0.91697
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71918,
            "recall": 0.71025,
            "fmeasure": 0.70711
        },
        "rouge2": {
            "precision": 0.46933,
            "recall": 0.45086,
            "fmeasure": 0.45535
        },
        "rougeL": {
            "precision": 0.5816,
            "recall": 0.55638,
            "fmeasure": 0.56388
        },
        "rougeLsum": {
            "precision": 0.5816,
            "recall": 0.55638,
            "fmeasure": 0.56388
        },
        "bleu": 45.63681,
        "nist": 5.316069709903886,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.6052631578947368,
            "3": 0.7920792079207921
        },
        "nubia": {
            "semantic_relation": 4.19766,
            "contradiction": 23.68832,
            "irrelevancy": 28.31601,
            "logical_agreement": 47.99567,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.75306,
            "nubia_score": 0.73889
        },
        "meteor": 0.40860288984949605,
        "bleurt": 0.24103,
        "bertscore": {
            "precision": 0.91746,
            "recall": 0.91922,
            "f1": 0.91692
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "mT5_large/totto_test",
        "N": 9,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65138,
            "recall": 0.71137,
            "fmeasure": 0.65896
        },
        "rouge2": {
            "precision": 0.45653,
            "recall": 0.5238,
            "fmeasure": 0.47115
        },
        "rougeL": {
            "precision": 0.61824,
            "recall": 0.68443,
            "fmeasure": 0.62983
        },
        "rougeLsum": {
            "precision": 0.61824,
            "recall": 0.68443,
            "fmeasure": 0.62983
        },
        "bleu": 37.06961,
        "nist": 4.620479789577562,
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.39285714285714285,
            "3": 0.7402597402597403
        },
        "nubia": {
            "semantic_relation": 3.96391,
            "contradiction": 12.43716,
            "irrelevancy": 35.25982,
            "logical_agreement": 52.30302,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.76256,
            "nubia_score": 0.66895
        },
        "meteor": 0.3543761699410813,
        "bleurt": 0.28594,
        "bertscore": {
            "precision": 0.90607,
            "recall": 0.90817,
            "f1": 0.90517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "mT5_large/totto_test",
        "N": 32,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75432,
            "recall": 0.75089,
            "fmeasure": 0.74401
        },
        "rouge2": {
            "precision": 0.51658,
            "recall": 0.53308,
            "fmeasure": 0.51818
        },
        "rougeL": {
            "precision": 0.62571,
            "recall": 0.64438,
            "fmeasure": 0.6264
        },
        "rougeLsum": {
            "precision": 0.62571,
            "recall": 0.64438,
            "fmeasure": 0.6264
        },
        "bleu": 46.31818,
        "nist": 6.655481976716012,
        "local_recall": {
            "1": 0.25510204081632654,
            "2": 0.4578313253012048,
            "3": 0.798469387755102
        },
        "nubia": {
            "semantic_relation": 4.28543,
            "contradiction": 14.8895,
            "irrelevancy": 31.12748,
            "logical_agreement": 53.98303,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.32105,
            "nubia_score": 0.75158
        },
        "meteor": 0.4008775244356949,
        "bleurt": 0.29316,
        "bertscore": {
            "precision": 0.92639,
            "recall": 0.93089,
            "f1": 0.9273
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76087,
            "recall": 0.78504,
            "fmeasure": 0.75811
        },
        "rouge2": {
            "precision": 0.50679,
            "recall": 0.50148,
            "fmeasure": 0.49253
        },
        "rougeL": {
            "precision": 0.61718,
            "recall": 0.6354,
            "fmeasure": 0.61493
        },
        "rougeLsum": {
            "precision": 0.61718,
            "recall": 0.6354,
            "fmeasure": 0.61493
        },
        "bleu": 48.74743,
        "nist": 5.343651408967411,
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.3333333333333333,
            "3": 0.82
        },
        "nubia": {
            "semantic_relation": 4.467,
            "contradiction": 6.9467,
            "irrelevancy": 11.38112,
            "logical_agreement": 81.67218,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.60705,
            "nubia_score": 0.81448
        },
        "meteor": 0.4089816243432972,
        "bleurt": 0.34571,
        "bertscore": {
            "precision": 0.94337,
            "recall": 0.93437,
            "f1": 0.93868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "mT5_large/totto_test",
        "N": 55,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71651,
            "recall": 0.69516,
            "fmeasure": 0.69679
        },
        "rouge2": {
            "precision": 0.47269,
            "recall": 0.45342,
            "fmeasure": 0.45743
        },
        "rougeL": {
            "precision": 0.61274,
            "recall": 0.5966,
            "fmeasure": 0.59705
        },
        "rougeLsum": {
            "precision": 0.61274,
            "recall": 0.5966,
            "fmeasure": 0.59705
        },
        "bleu": 44.23899,
        "nist": 6.843849393742103,
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.3551912568306011,
            "3": 0.7527881040892194
        },
        "nubia": {
            "semantic_relation": 4.1236,
            "contradiction": 5.35344,
            "irrelevancy": 37.53581,
            "logical_agreement": 57.11074,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.91751,
            "nubia_score": 0.68981
        },
        "meteor": 0.38250391173312315,
        "bleurt": 0.14986,
        "bertscore": {
            "precision": 0.91439,
            "recall": 0.91415,
            "f1": 0.91356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.44565,
            "recall": 0.50198,
            "fmeasure": 0.46051
        },
        "rouge2": {
            "precision": 0.28734,
            "recall": 0.35556,
            "fmeasure": 0.31062
        },
        "rougeL": {
            "precision": 0.40217,
            "recall": 0.46972,
            "fmeasure": 0.42348
        },
        "rougeLsum": {
            "precision": 0.40217,
            "recall": 0.46972,
            "fmeasure": 0.42348
        },
        "bleu": 16.91991,
        "nist": 2.5261864836551267,
        "local_recall": {
            "1": 0.25,
            "2": 0.6363636363636364,
            "3": 0.4230769230769231
        },
        "nubia": {
            "semantic_relation": 3.02253,
            "contradiction": 46.86716,
            "irrelevancy": 52.28106,
            "logical_agreement": 0.85178,
            "grammar_ref": 4.83168,
            "grammar_hyp": 4.86059,
            "nubia_score": 0.34555
        },
        "meteor": 0.2339711915796056,
        "bleurt": -0.61243,
        "bertscore": {
            "precision": 0.82585,
            "recall": 0.83825,
            "f1": 0.83052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "mT5_large/totto_test",
        "N": 51,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79425,
            "recall": 0.77609,
            "fmeasure": 0.77103
        },
        "rouge2": {
            "precision": 0.56481,
            "recall": 0.54884,
            "fmeasure": 0.54687
        },
        "rougeL": {
            "precision": 0.6633,
            "recall": 0.6516,
            "fmeasure": 0.64641
        },
        "rougeLsum": {
            "precision": 0.6633,
            "recall": 0.6516,
            "fmeasure": 0.64641
        },
        "bleu": 52.18088,
        "nist": 7.478062264107159,
        "local_recall": {
            "1": 0.234375,
            "2": 0.43478260869565216,
            "3": 0.8300180831826401
        },
        "nubia": {
            "semantic_relation": 4.21053,
            "contradiction": 6.45909,
            "irrelevancy": 29.53722,
            "logical_agreement": 64.00369,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.82414,
            "nubia_score": 0.70997
        },
        "meteor": 0.41761942758065146,
        "bleurt": 0.30253,
        "bertscore": {
            "precision": 0.93306,
            "recall": 0.93074,
            "f1": 0.93022
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "mT5_large/totto_test",
        "N": 16,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80203,
            "recall": 0.78921,
            "fmeasure": 0.78909
        },
        "rouge2": {
            "precision": 0.57315,
            "recall": 0.55851,
            "fmeasure": 0.55976
        },
        "rougeL": {
            "precision": 0.69522,
            "recall": 0.67696,
            "fmeasure": 0.67997
        },
        "rougeLsum": {
            "precision": 0.69522,
            "recall": 0.67696,
            "fmeasure": 0.67997
        },
        "bleu": 49.1828,
        "nist": 6.044729469892384,
        "local_recall": {
            "1": 0.14634146341463414,
            "2": 0.34782608695652173,
            "3": 0.8292682926829268
        },
        "nubia": {
            "semantic_relation": 4.60963,
            "contradiction": 0.64942,
            "irrelevancy": 26.41178,
            "logical_agreement": 72.9388,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.46379,
            "nubia_score": 0.86155
        },
        "meteor": 0.42708768547774884,
        "bleurt": 0.42913,
        "bertscore": {
            "precision": 0.93643,
            "recall": 0.9431,
            "f1": 0.93923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "mT5_large/totto_test",
        "N": 19,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73687,
            "recall": 0.64458,
            "fmeasure": 0.67846
        },
        "rouge2": {
            "precision": 0.54213,
            "recall": 0.48534,
            "fmeasure": 0.5064
        },
        "rougeL": {
            "precision": 0.64486,
            "recall": 0.57877,
            "fmeasure": 0.60374
        },
        "rougeLsum": {
            "precision": 0.64486,
            "recall": 0.57877,
            "fmeasure": 0.60374
        },
        "bleu": 45.41847,
        "nist": 5.384327449719813,
        "local_recall": {
            "1": 0.22077922077922077,
            "2": 0.27450980392156865,
            "3": 0.6594827586206896
        },
        "nubia": {
            "semantic_relation": 4.08603,
            "contradiction": 14.03484,
            "irrelevancy": 24.58819,
            "logical_agreement": 61.37696,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.60727,
            "nubia_score": 0.67913
        },
        "meteor": 0.38251242175922945,
        "bleurt": 0.25963,
        "bertscore": {
            "precision": 0.93,
            "recall": 0.90755,
            "f1": 0.917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76229,
            "recall": 0.72965,
            "fmeasure": 0.73772
        },
        "rouge2": {
            "precision": 0.54433,
            "recall": 0.51743,
            "fmeasure": 0.52578
        },
        "rougeL": {
            "precision": 0.64508,
            "recall": 0.65156,
            "fmeasure": 0.64022
        },
        "rougeLsum": {
            "precision": 0.64508,
            "recall": 0.65156,
            "fmeasure": 0.64022
        },
        "bleu": 51.46402,
        "nist": 5.795544942556376,
        "local_recall": {
            "1": 0.24074074074074073,
            "2": 0.5161290322580645,
            "3": 0.8260869565217391
        },
        "nubia": {
            "semantic_relation": 3.99274,
            "contradiction": 19.70114,
            "irrelevancy": 26.49387,
            "logical_agreement": 53.80499,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.50455,
            "nubia_score": 0.70466
        },
        "meteor": 0.4321085753305482,
        "bleurt": 0.2654,
        "bertscore": {
            "precision": 0.93485,
            "recall": 0.94645,
            "f1": 0.93923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7625,
            "recall": 0.7162,
            "fmeasure": 0.73429
        },
        "rouge2": {
            "precision": 0.6119,
            "recall": 0.58861,
            "fmeasure": 0.59691
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.6857,
            "fmeasure": 0.68875
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.6857,
            "fmeasure": 0.68875
        },
        "bleu": 46.45328,
        "nist": 4.3073415008875795,
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 4.55851,
            "contradiction": 21.725,
            "irrelevancy": 2.93147,
            "logical_agreement": 75.34353,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.67836,
            "nubia_score": 0.82062
        },
        "meteor": 0.3821260848067577,
        "bleurt": 0.43726,
        "bertscore": {
            "precision": 0.94853,
            "recall": 0.94125,
            "f1": 0.94465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "mT5_large/totto_test",
        "N": 22,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83478,
            "recall": 0.84786,
            "fmeasure": 0.83337
        },
        "rouge2": {
            "precision": 0.68381,
            "recall": 0.68898,
            "fmeasure": 0.68112
        },
        "rougeL": {
            "precision": 0.76782,
            "recall": 0.7812,
            "fmeasure": 0.76742
        },
        "rougeLsum": {
            "precision": 0.76782,
            "recall": 0.7812,
            "fmeasure": 0.76742
        },
        "bleu": 63.74219,
        "nist": 6.70169601544634,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.8774703557312253
        },
        "nubia": {
            "semantic_relation": 4.53558,
            "contradiction": 0.47169,
            "irrelevancy": 27.22235,
            "logical_agreement": 72.30595,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.29764,
            "nubia_score": 0.84316
        },
        "meteor": 0.499108264311747,
        "bleurt": 0.52016,
        "bertscore": {
            "precision": 0.95378,
            "recall": 0.95426,
            "f1": 0.95331
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "mT5_large/totto_test",
        "N": 9,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72746,
            "recall": 0.71208,
            "fmeasure": 0.71317
        },
        "rouge2": {
            "precision": 0.45006,
            "recall": 0.45151,
            "fmeasure": 0.44657
        },
        "rougeL": {
            "precision": 0.57958,
            "recall": 0.59991,
            "fmeasure": 0.58069
        },
        "rougeLsum": {
            "precision": 0.57958,
            "recall": 0.59991,
            "fmeasure": 0.58069
        },
        "bleu": 32.04953,
        "nist": 5.211268835659019,
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.25,
            "3": 0.7565217391304347
        },
        "nubia": {
            "semantic_relation": 4.24033,
            "contradiction": 0.81969,
            "irrelevancy": 46.45993,
            "logical_agreement": 52.72038,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.53975,
            "nubia_score": 0.7589
        },
        "meteor": 0.3636726284314257,
        "bleurt": 0.18933,
        "bertscore": {
            "precision": 0.91396,
            "recall": 0.91494,
            "f1": 0.91415
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "mT5_large/totto_test",
        "N": 29,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83064,
            "recall": 0.78694,
            "fmeasure": 0.79982
        },
        "rouge2": {
            "precision": 0.63916,
            "recall": 0.60493,
            "fmeasure": 0.61331
        },
        "rougeL": {
            "precision": 0.73191,
            "recall": 0.68682,
            "fmeasure": 0.70102
        },
        "rougeLsum": {
            "precision": 0.73191,
            "recall": 0.68682,
            "fmeasure": 0.70102
        },
        "bleu": 59.13217,
        "nist": 7.3045234572185365,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.40816326530612246,
            "3": 0.8059701492537313
        },
        "nubia": {
            "semantic_relation": 4.55806,
            "contradiction": 3.29781,
            "irrelevancy": 17.9584,
            "logical_agreement": 78.74379,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.55054,
            "nubia_score": 0.85799
        },
        "meteor": 0.4499122524878123,
        "bleurt": 0.45489,
        "bertscore": {
            "precision": 0.95215,
            "recall": 0.94575,
            "f1": 0.94664
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6648,
            "recall": 0.71871,
            "fmeasure": 0.67706
        },
        "rouge2": {
            "precision": 0.48429,
            "recall": 0.53268,
            "fmeasure": 0.49678
        },
        "rougeL": {
            "precision": 0.57886,
            "recall": 0.64627,
            "fmeasure": 0.59809
        },
        "rougeLsum": {
            "precision": 0.57886,
            "recall": 0.64627,
            "fmeasure": 0.59809
        },
        "bleu": 41.00523,
        "nist": 5.078653203423322,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5161290322580645,
            "3": 0.6870229007633588
        },
        "nubia": {
            "semantic_relation": 3.81086,
            "contradiction": 10.8774,
            "irrelevancy": 49.81405,
            "logical_agreement": 39.30855,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.52472,
            "nubia_score": 0.59881
        },
        "meteor": 0.3539214151429383,
        "bleurt": -0.0014,
        "bertscore": {
            "precision": 0.90421,
            "recall": 0.90956,
            "f1": 0.90593
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.56746,
            "recall": 0.50524,
            "fmeasure": 0.51913
        },
        "rouge2": {
            "precision": 0.35256,
            "recall": 0.32906,
            "fmeasure": 0.32282
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.48718,
            "fmeasure": 0.47116
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.48718,
            "fmeasure": 0.47116
        },
        "bleu": 23.85172,
        "nist": 2.8639033885545797,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "nubia": {
            "semantic_relation": 3.17452,
            "contradiction": 42.29725,
            "irrelevancy": 24.14846,
            "logical_agreement": 33.55428,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.9308,
            "nubia_score": 0.42222
        },
        "meteor": 0.29628002897498557,
        "bleurt": 0.14561,
        "bertscore": {
            "precision": 0.88531,
            "recall": 0.87041,
            "f1": 0.87499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64912,
            "recall": 0.59837,
            "fmeasure": 0.61889
        },
        "rouge2": {
            "precision": 0.42593,
            "recall": 0.39506,
            "fmeasure": 0.40741
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.28571,
            "fmeasure": 0.34043
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.28571,
            "fmeasure": 0.34043
        },
        "bleu": 33.12499,
        "nist": 2.4372986010776865,
        "local_recall": {
            "1": 0.625,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 3.43927,
            "contradiction": 96.79032,
            "irrelevancy": 3.05921,
            "logical_agreement": 0.15047,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.90995,
            "nubia_score": 0.30622
        },
        "meteor": 0.3675807088454891,
        "bleurt": -0.30472,
        "bertscore": {
            "precision": 0.91896,
            "recall": 0.92799,
            "f1": 0.92345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "mT5_large/totto_test",
        "N": 9,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6981,
            "recall": 0.71699,
            "fmeasure": 0.6923
        },
        "rouge2": {
            "precision": 0.42988,
            "recall": 0.44281,
            "fmeasure": 0.42662
        },
        "rougeL": {
            "precision": 0.61998,
            "recall": 0.63044,
            "fmeasure": 0.61061
        },
        "rougeLsum": {
            "precision": 0.61998,
            "recall": 0.63044,
            "fmeasure": 0.61061
        },
        "bleu": 34.85346,
        "nist": 5.213944818801146,
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.5454545454545454,
            "3": 0.7910447761194029
        },
        "nubia": {
            "semantic_relation": 4.03825,
            "contradiction": 5.95421,
            "irrelevancy": 36.2038,
            "logical_agreement": 57.84199,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.80376,
            "nubia_score": 0.68148
        },
        "meteor": 0.3647671056004605,
        "bleurt": 0.18391,
        "bertscore": {
            "precision": 0.90662,
            "recall": 0.9061,
            "f1": 0.90525
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74381,
            "recall": 0.76724,
            "fmeasure": 0.74544
        },
        "rouge2": {
            "precision": 0.52794,
            "recall": 0.5362,
            "fmeasure": 0.52606
        },
        "rougeL": {
            "precision": 0.64858,
            "recall": 0.66607,
            "fmeasure": 0.65018
        },
        "rougeLsum": {
            "precision": 0.64858,
            "recall": 0.66607,
            "fmeasure": 0.65018
        },
        "bleu": 49.87697,
        "nist": 6.993172794778565,
        "local_recall": {
            "1": 0.27927927927927926,
            "2": 0.4578313253012048,
            "3": 0.808
        },
        "nubia": {
            "semantic_relation": 4.34955,
            "contradiction": 1.56314,
            "irrelevancy": 33.74977,
            "logical_agreement": 64.6871,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.55338,
            "nubia_score": 0.80284
        },
        "meteor": 0.4124316781117253,
        "bleurt": 0.34664,
        "bertscore": {
            "precision": 0.93371,
            "recall": 0.93441,
            "f1": 0.93271
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "mT5_large/totto_test",
        "N": 13,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74085,
            "recall": 0.74601,
            "fmeasure": 0.74075
        },
        "rouge2": {
            "precision": 0.54587,
            "recall": 0.54677,
            "fmeasure": 0.54466
        },
        "rougeL": {
            "precision": 0.6283,
            "recall": 0.6298,
            "fmeasure": 0.62684
        },
        "rougeLsum": {
            "precision": 0.6283,
            "recall": 0.6298,
            "fmeasure": 0.62684
        },
        "bleu": 46.97479,
        "nist": 5.50324827372484,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.17647058823529413,
            "3": 0.803921568627451
        },
        "nubia": {
            "semantic_relation": 4.46442,
            "contradiction": 6.85464,
            "irrelevancy": 15.10112,
            "logical_agreement": 78.04424,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.68887,
            "nubia_score": 0.80642
        },
        "meteor": 0.4117998018600288,
        "bleurt": 0.49312,
        "bertscore": {
            "precision": 0.93489,
            "recall": 0.9346,
            "f1": 0.9345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83959,
            "recall": 0.6228,
            "fmeasure": 0.70048
        },
        "rouge2": {
            "precision": 0.57506,
            "recall": 0.44575,
            "fmeasure": 0.49246
        },
        "rougeL": {
            "precision": 0.74435,
            "recall": 0.56746,
            "fmeasure": 0.63194
        },
        "rougeLsum": {
            "precision": 0.74435,
            "recall": 0.56746,
            "fmeasure": 0.63194
        },
        "bleu": 46.51039,
        "nist": 3.907836081081238,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3404255319148936,
            "3": 0.7258064516129032
        },
        "nubia": {
            "semantic_relation": 3.86584,
            "contradiction": 7.77538,
            "irrelevancy": 30.15608,
            "logical_agreement": 62.06854,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.80045,
            "nubia_score": 0.60562
        },
        "meteor": 0.3655884091733962,
        "bleurt": 0.11409,
        "bertscore": {
            "precision": 0.94146,
            "recall": 0.90132,
            "f1": 0.92047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81431,
            "recall": 0.67095,
            "fmeasure": 0.72629
        },
        "rouge2": {
            "precision": 0.59278,
            "recall": 0.49076,
            "fmeasure": 0.5296
        },
        "rougeL": {
            "precision": 0.73946,
            "recall": 0.60338,
            "fmeasure": 0.65631
        },
        "rougeLsum": {
            "precision": 0.73946,
            "recall": 0.60338,
            "fmeasure": 0.65631
        },
        "bleu": 48.91509,
        "nist": 4.471361852184917,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.08333333333333333,
            "3": 0.7692307692307693
        },
        "nubia": {
            "semantic_relation": 3.98955,
            "contradiction": 0.16953,
            "irrelevancy": 18.19109,
            "logical_agreement": 81.63938,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.61149,
            "nubia_score": 0.68024
        },
        "meteor": 0.3981826137148833,
        "bleurt": 0.19836,
        "bertscore": {
            "precision": 0.93326,
            "recall": 0.90846,
            "f1": 0.92018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.66369,
            "fmeasure": 0.70072
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.24957,
            "fmeasure": 0.26272
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.59524,
            "fmeasure": 0.62835
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.59524,
            "fmeasure": 0.62835
        },
        "bleu": 20.24206,
        "nist": 2.824251740100122,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.41223,
            "contradiction": 0.54071,
            "irrelevancy": 0.67662,
            "logical_agreement": 98.78267,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.90642,
            "nubia_score": 0.83753
        },
        "meteor": 0.3475140135278828,
        "bleurt": 0.41424,
        "bertscore": {
            "precision": 0.93653,
            "recall": 0.92441,
            "f1": 0.93043
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73067,
            "recall": 0.7217,
            "fmeasure": 0.71089
        },
        "rouge2": {
            "precision": 0.49213,
            "recall": 0.51183,
            "fmeasure": 0.4948
        },
        "rougeL": {
            "precision": 0.65101,
            "recall": 0.65963,
            "fmeasure": 0.64166
        },
        "rougeLsum": {
            "precision": 0.65101,
            "recall": 0.65963,
            "fmeasure": 0.64166
        },
        "bleu": 44.34206,
        "nist": 5.361490170860575,
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.5,
            "3": 0.7265625
        },
        "nubia": {
            "semantic_relation": 4.16997,
            "contradiction": 9.11502,
            "irrelevancy": 22.24835,
            "logical_agreement": 68.63663,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.27878,
            "nubia_score": 0.74352
        },
        "meteor": 0.4109634220970758,
        "bleurt": 0.28484,
        "bertscore": {
            "precision": 0.935,
            "recall": 0.92626,
            "f1": 0.92834
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75787,
            "recall": 0.79647,
            "fmeasure": 0.77052
        },
        "rouge2": {
            "precision": 0.48483,
            "recall": 0.52105,
            "fmeasure": 0.49919
        },
        "rougeL": {
            "precision": 0.64495,
            "recall": 0.67148,
            "fmeasure": 0.65219
        },
        "rougeLsum": {
            "precision": 0.64495,
            "recall": 0.67148,
            "fmeasure": 0.65219
        },
        "bleu": 42.88441,
        "nist": 5.67040579083103,
        "local_recall": {
            "1": 0.2,
            "2": 0.5428571428571428,
            "3": 0.8985507246376812
        },
        "nubia": {
            "semantic_relation": 4.44031,
            "contradiction": 12.10486,
            "irrelevancy": 17.00659,
            "logical_agreement": 70.88855,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.13098,
            "nubia_score": 0.85667
        },
        "meteor": 0.4362333315746065,
        "bleurt": 0.36417,
        "bertscore": {
            "precision": 0.93577,
            "recall": 0.95007,
            "f1": 0.94011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74718,
            "recall": 0.77516,
            "fmeasure": 0.74906
        },
        "rouge2": {
            "precision": 0.48152,
            "recall": 0.51312,
            "fmeasure": 0.48994
        },
        "rougeL": {
            "precision": 0.60706,
            "recall": 0.65268,
            "fmeasure": 0.62198
        },
        "rougeLsum": {
            "precision": 0.60706,
            "recall": 0.65268,
            "fmeasure": 0.62198
        },
        "bleu": 49.61497,
        "nist": 5.2640916197602845,
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.7142857142857143,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 4.16215,
            "contradiction": 7.66532,
            "irrelevancy": 44.85059,
            "logical_agreement": 47.48409,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.05071,
            "nubia_score": 0.75236
        },
        "meteor": 0.39282042339198253,
        "bleurt": 0.06174,
        "bertscore": {
            "precision": 0.93119,
            "recall": 0.91997,
            "f1": 0.92208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72288,
            "recall": 0.71505,
            "fmeasure": 0.71314
        },
        "rouge2": {
            "precision": 0.5337,
            "recall": 0.51209,
            "fmeasure": 0.5192
        },
        "rougeL": {
            "precision": 0.66467,
            "recall": 0.65945,
            "fmeasure": 0.65614
        },
        "rougeLsum": {
            "precision": 0.66467,
            "recall": 0.65945,
            "fmeasure": 0.65614
        },
        "bleu": 46.44985,
        "nist": 5.020186897998213,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.35,
            "3": 0.8153846153846154
        },
        "nubia": {
            "semantic_relation": 4.19228,
            "contradiction": 12.85198,
            "irrelevancy": 41.37084,
            "logical_agreement": 45.77717,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.96586,
            "nubia_score": 0.6906
        },
        "meteor": 0.3645065725457751,
        "bleurt": 0.19486,
        "bertscore": {
            "precision": 0.91492,
            "recall": 0.92358,
            "f1": 0.91595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.51888,
            "fmeasure": 0.54095
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.30476,
            "fmeasure": 0.31667
        },
        "rougeL": {
            "precision": 0.50794,
            "recall": 0.46415,
            "fmeasure": 0.48254
        },
        "rougeLsum": {
            "precision": 0.50794,
            "recall": 0.46415,
            "fmeasure": 0.48254
        },
        "bleu": 19.46452,
        "nist": 2.5788891534714424,
        "local_recall": {
            "1": 0.25,
            "2": 0.2857142857142857,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.74206,
            "contradiction": 0.23965,
            "irrelevancy": 92.8418,
            "logical_agreement": 6.91855,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.64504,
            "nubia_score": 0.63385
        },
        "meteor": 0.26983762599257377,
        "bleurt": -0.24939,
        "bertscore": {
            "precision": 0.88269,
            "recall": 0.85015,
            "f1": 0.86611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71296,
            "recall": 0.74306,
            "fmeasure": 0.72601
        },
        "rouge2": {
            "precision": 0.43838,
            "recall": 0.4625,
            "fmeasure": 0.44868
        },
        "rougeL": {
            "precision": 0.52546,
            "recall": 0.54537,
            "fmeasure": 0.53394
        },
        "rougeLsum": {
            "precision": 0.52546,
            "recall": 0.54537,
            "fmeasure": 0.53394
        },
        "bleu": 34.83354,
        "nist": 3.420692611531476,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6842105263157895
        },
        "nubia": {
            "semantic_relation": 4.17786,
            "contradiction": 33.83495,
            "irrelevancy": 48.16601,
            "logical_agreement": 17.99904,
            "grammar_ref": 4.97036,
            "grammar_hyp": 5.18306,
            "nubia_score": 0.6173
        },
        "meteor": 0.34773032381331287,
        "bleurt": 0.08807,
        "bertscore": {
            "precision": 0.90629,
            "recall": 0.91805,
            "f1": 0.91203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72465,
            "recall": 0.63872,
            "fmeasure": 0.6717
        },
        "rouge2": {
            "precision": 0.43713,
            "recall": 0.39118,
            "fmeasure": 0.40822
        },
        "rougeL": {
            "precision": 0.60532,
            "recall": 0.55129,
            "fmeasure": 0.57178
        },
        "rougeLsum": {
            "precision": 0.60532,
            "recall": 0.55129,
            "fmeasure": 0.57178
        },
        "bleu": 38.59551,
        "nist": 4.8224201240126074,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5833333333333334,
            "3": 0.6901408450704225
        },
        "nubia": {
            "semantic_relation": 4.05328,
            "contradiction": 19.34638,
            "irrelevancy": 33.02917,
            "logical_agreement": 47.62445,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.33784,
            "nubia_score": 0.70503
        },
        "meteor": 0.34344673453352154,
        "bleurt": 0.3006,
        "bertscore": {
            "precision": 0.91508,
            "recall": 0.91745,
            "f1": 0.91442
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "mT5_large/totto_test",
        "N": 300,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80188,
            "recall": 0.76431,
            "fmeasure": 0.77457
        },
        "rouge2": {
            "precision": 0.55702,
            "recall": 0.52919,
            "fmeasure": 0.53647
        },
        "rougeL": {
            "precision": 0.67492,
            "recall": 0.64604,
            "fmeasure": 0.65296
        },
        "rougeLsum": {
            "precision": 0.67492,
            "recall": 0.64604,
            "fmeasure": 0.65296
        },
        "bleu": 46.09555,
        "nist": 8.695062367600903,
        "local_recall": {
            "1": 0.19182746878547105,
            "2": 0.3757062146892655,
            "3": 0.8055254604550379
        },
        "nubia": {
            "semantic_relation": 4.44094,
            "contradiction": 5.10189,
            "irrelevancy": 23.93814,
            "logical_agreement": 70.95997,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.94433,
            "nubia_score": 0.78132
        },
        "meteor": 0.409341493745071,
        "bleurt": 0.348,
        "bertscore": {
            "precision": 0.93936,
            "recall": 0.93494,
            "f1": 0.93582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "mT5_large/totto_test",
        "N": 26,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73402,
            "recall": 0.74356,
            "fmeasure": 0.72691
        },
        "rouge2": {
            "precision": 0.50612,
            "recall": 0.5133,
            "fmeasure": 0.50032
        },
        "rougeL": {
            "precision": 0.61347,
            "recall": 0.62955,
            "fmeasure": 0.6118
        },
        "rougeLsum": {
            "precision": 0.61347,
            "recall": 0.62955,
            "fmeasure": 0.6118
        },
        "bleu": 46.6667,
        "nist": 6.415089436342375,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.5895522388059702,
            "3": 0.7559055118110236
        },
        "nubia": {
            "semantic_relation": 4.10958,
            "contradiction": 19.1809,
            "irrelevancy": 37.63381,
            "logical_agreement": 43.18529,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.45187,
            "nubia_score": 0.71016
        },
        "meteor": 0.3919301427894141,
        "bleurt": 0.20908,
        "bertscore": {
            "precision": 0.92157,
            "recall": 0.92554,
            "f1": 0.92162
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85633,
            "recall": 0.87062,
            "fmeasure": 0.85544
        },
        "rouge2": {
            "precision": 0.70094,
            "recall": 0.71198,
            "fmeasure": 0.69994
        },
        "rougeL": {
            "precision": 0.78666,
            "recall": 0.80739,
            "fmeasure": 0.78997
        },
        "rougeLsum": {
            "precision": 0.78666,
            "recall": 0.80739,
            "fmeasure": 0.78997
        },
        "bleu": 63.85523,
        "nist": 6.4736200406033,
        "local_recall": {
            "1": 0.28125,
            "2": 0.5,
            "3": 0.8861788617886179
        },
        "nubia": {
            "semantic_relation": 4.6522,
            "contradiction": 4.34463,
            "irrelevancy": 16.50261,
            "logical_agreement": 79.15275,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.23782,
            "nubia_score": 0.88535
        },
        "meteor": 0.47379182524290264,
        "bleurt": 0.53356,
        "bertscore": {
            "precision": 0.96536,
            "recall": 0.95737,
            "f1": 0.96098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79077,
            "recall": 0.7348,
            "fmeasure": 0.75031
        },
        "rouge2": {
            "precision": 0.48699,
            "recall": 0.44896,
            "fmeasure": 0.45956
        },
        "rougeL": {
            "precision": 0.67084,
            "recall": 0.61912,
            "fmeasure": 0.63504
        },
        "rougeLsum": {
            "precision": 0.67084,
            "recall": 0.61912,
            "fmeasure": 0.63504
        },
        "bleu": 38.96169,
        "nist": 5.281755252885253,
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.47619047619047616,
            "3": 0.7570093457943925
        },
        "nubia": {
            "semantic_relation": 4.29539,
            "contradiction": 18.21994,
            "irrelevancy": 11.65174,
            "logical_agreement": 70.12833,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.14043,
            "nubia_score": 0.71227
        },
        "meteor": 0.3840543347021171,
        "bleurt": 0.19971,
        "bertscore": {
            "precision": 0.91809,
            "recall": 0.91773,
            "f1": 0.91526
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67551,
            "recall": 0.71186,
            "fmeasure": 0.67527
        },
        "rouge2": {
            "precision": 0.44265,
            "recall": 0.48643,
            "fmeasure": 0.45339
        },
        "rougeL": {
            "precision": 0.55981,
            "recall": 0.57689,
            "fmeasure": 0.55425
        },
        "rougeLsum": {
            "precision": 0.55981,
            "recall": 0.57689,
            "fmeasure": 0.55425
        },
        "bleu": 33.90912,
        "nist": 4.134704002182398,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5294117647058824,
            "3": 0.7246376811594203
        },
        "nubia": {
            "semantic_relation": 3.91261,
            "contradiction": 11.05357,
            "irrelevancy": 49.0598,
            "logical_agreement": 39.88662,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.25306,
            "nubia_score": 0.64957
        },
        "meteor": 0.3712841645572482,
        "bleurt": 0.1331,
        "bertscore": {
            "precision": 0.90092,
            "recall": 0.91073,
            "f1": 0.90334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "mT5_large/totto_test",
        "N": 105,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66038,
            "recall": 0.61617,
            "fmeasure": 0.62384
        },
        "rouge2": {
            "precision": 0.41304,
            "recall": 0.3979,
            "fmeasure": 0.39715
        },
        "rougeL": {
            "precision": 0.55438,
            "recall": 0.52784,
            "fmeasure": 0.52889
        },
        "rougeLsum": {
            "precision": 0.55438,
            "recall": 0.52784,
            "fmeasure": 0.52889
        },
        "bleu": 38.21897,
        "nist": 6.659646669498596,
        "local_recall": {
            "1": 0.21098265895953758,
            "2": 0.4117647058823529,
            "3": 0.6935483870967742
        },
        "nubia": {
            "semantic_relation": 3.62773,
            "contradiction": 18.5358,
            "irrelevancy": 32.18982,
            "logical_agreement": 49.27439,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.98677,
            "nubia_score": 0.60079
        },
        "meteor": 0.34682040378607787,
        "bleurt": 0.10595,
        "bertscore": {
            "precision": 0.89538,
            "recall": 0.89254,
            "f1": 0.8925
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "mT5_large/totto_test",
        "N": 43,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78019,
            "recall": 0.77077,
            "fmeasure": 0.76026
        },
        "rouge2": {
            "precision": 0.5781,
            "recall": 0.56908,
            "fmeasure": 0.56417
        },
        "rougeL": {
            "precision": 0.69003,
            "recall": 0.69409,
            "fmeasure": 0.6774
        },
        "rougeLsum": {
            "precision": 0.69003,
            "recall": 0.69409,
            "fmeasure": 0.6774
        },
        "bleu": 49.2147,
        "nist": 6.77708032595203,
        "local_recall": {
            "1": 0.25,
            "2": 0.44360902255639095,
            "3": 0.8207547169811321
        },
        "nubia": {
            "semantic_relation": 4.23376,
            "contradiction": 8.78966,
            "irrelevancy": 21.61057,
            "logical_agreement": 69.59977,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.53338,
            "nubia_score": 0.73015
        },
        "meteor": 0.41075306004672113,
        "bleurt": 0.30641,
        "bertscore": {
            "precision": 0.93153,
            "recall": 0.93244,
            "f1": 0.92974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "mT5_large/totto_test",
        "N": 19,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71751,
            "recall": 0.74512,
            "fmeasure": 0.721
        },
        "rouge2": {
            "precision": 0.46805,
            "recall": 0.49304,
            "fmeasure": 0.47203
        },
        "rougeL": {
            "precision": 0.62119,
            "recall": 0.64393,
            "fmeasure": 0.62343
        },
        "rougeLsum": {
            "precision": 0.62119,
            "recall": 0.64393,
            "fmeasure": 0.62343
        },
        "bleu": 42.67558,
        "nist": 6.043299614931856,
        "local_recall": {
            "1": 0.29508196721311475,
            "2": 0.4576271186440678,
            "3": 0.7439613526570048
        },
        "nubia": {
            "semantic_relation": 3.97717,
            "contradiction": 15.52435,
            "irrelevancy": 38.95569,
            "logical_agreement": 45.51996,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.24668,
            "nubia_score": 0.70724
        },
        "meteor": 0.37727204391560726,
        "bleurt": 0.1864,
        "bertscore": {
            "precision": 0.91714,
            "recall": 0.92225,
            "f1": 0.91742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "mT5_large/totto_test",
        "N": 66,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7348,
            "recall": 0.7363,
            "fmeasure": 0.72232
        },
        "rouge2": {
            "precision": 0.5194,
            "recall": 0.52803,
            "fmeasure": 0.51314
        },
        "rougeL": {
            "precision": 0.64651,
            "recall": 0.65389,
            "fmeasure": 0.63729
        },
        "rougeLsum": {
            "precision": 0.64651,
            "recall": 0.65389,
            "fmeasure": 0.63729
        },
        "bleu": 43.41387,
        "nist": 6.927125656582428,
        "local_recall": {
            "1": 0.24875621890547264,
            "2": 0.4336734693877551,
            "3": 0.7772988505747126
        },
        "nubia": {
            "semantic_relation": 4.25729,
            "contradiction": 6.0089,
            "irrelevancy": 32.9039,
            "logical_agreement": 61.0872,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.21143,
            "nubia_score": 0.76668
        },
        "meteor": 0.3992779071202936,
        "bleurt": 0.29355,
        "bertscore": {
            "precision": 0.92321,
            "recall": 0.92715,
            "f1": 0.92332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53022,
            "recall": 0.73611,
            "fmeasure": 0.60222
        },
        "rouge2": {
            "precision": 0.37179,
            "recall": 0.48788,
            "fmeasure": 0.41392
        },
        "rougeL": {
            "precision": 0.4533,
            "recall": 0.64773,
            "fmeasure": 0.52
        },
        "rougeLsum": {
            "precision": 0.4533,
            "recall": 0.64773,
            "fmeasure": 0.52
        },
        "bleu": 30.6675,
        "nist": 2.545606241582759,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nubia": {
            "semantic_relation": 3.42238,
            "contradiction": 46.01912,
            "irrelevancy": 23.55357,
            "logical_agreement": 30.4273,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.61809,
            "nubia_score": 0.56156
        },
        "meteor": 0.40774870658732015,
        "bleurt": 0.13505,
        "bertscore": {
            "precision": 0.86373,
            "recall": 0.9263,
            "f1": 0.8933
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.49206,
            "fmeasure": 0.56383
        },
        "rouge2": {
            "precision": 0.42593,
            "recall": 0.30556,
            "fmeasure": 0.35439
        },
        "rougeL": {
            "precision": 0.5614,
            "recall": 0.4127,
            "fmeasure": 0.47376
        },
        "rougeLsum": {
            "precision": 0.5614,
            "recall": 0.4127,
            "fmeasure": 0.47376
        },
        "bleu": 32.87006,
        "nist": 2.5957444023922194,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 3.4026,
            "contradiction": 0.179,
            "irrelevancy": 54.22359,
            "logical_agreement": 45.59741,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.915,
            "nubia_score": 0.50181
        },
        "meteor": 0.27303048725639173,
        "bleurt": 0.04952,
        "bertscore": {
            "precision": 0.92788,
            "recall": 0.87873,
            "f1": 0.90263
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "mT5_large/totto_test",
        "N": 122,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74015,
            "recall": 0.71516,
            "fmeasure": 0.7154
        },
        "rouge2": {
            "precision": 0.50087,
            "recall": 0.47912,
            "fmeasure": 0.48177
        },
        "rougeL": {
            "precision": 0.63982,
            "recall": 0.61862,
            "fmeasure": 0.61899
        },
        "rougeLsum": {
            "precision": 0.63982,
            "recall": 0.61862,
            "fmeasure": 0.61899
        },
        "bleu": 44.23758,
        "nist": 7.549729434303993,
        "local_recall": {
            "1": 0.20898876404494382,
            "2": 0.42136498516320475,
            "3": 0.7520355292376018
        },
        "nubia": {
            "semantic_relation": 4.13032,
            "contradiction": 8.04194,
            "irrelevancy": 30.62801,
            "logical_agreement": 61.33005,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.69996,
            "nubia_score": 0.70614
        },
        "meteor": 0.3843889426228725,
        "bleurt": 0.23172,
        "bertscore": {
            "precision": 0.92399,
            "recall": 0.91902,
            "f1": 0.91967
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.77576,
            "fmeasure": 0.68599
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.53704,
            "fmeasure": 0.46898
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.67879,
            "fmeasure": 0.60024
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.67879,
            "fmeasure": 0.60024
        },
        "bleu": 20.7806,
        "nist": 2.442351343829763,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.99944,
            "contradiction": 0.87845,
            "irrelevancy": 97.56778,
            "logical_agreement": 1.55376,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.22045,
            "nubia_score": 0.75283
        },
        "meteor": 0.3596655312847328,
        "bleurt": 0.04166,
        "bertscore": {
            "precision": 0.88505,
            "recall": 0.9408,
            "f1": 0.90978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "mT5_large/totto_test",
        "N": 9,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82758,
            "recall": 0.76912,
            "fmeasure": 0.78882
        },
        "rouge2": {
            "precision": 0.64335,
            "recall": 0.60285,
            "fmeasure": 0.61575
        },
        "rougeL": {
            "precision": 0.78247,
            "recall": 0.73137,
            "fmeasure": 0.74852
        },
        "rougeLsum": {
            "precision": 0.78247,
            "recall": 0.73137,
            "fmeasure": 0.74852
        },
        "bleu": 54.9749,
        "nist": 5.643347741768213,
        "local_recall": {
            "1": 0.35135135135135137,
            "2": 0.6,
            "3": 0.8235294117647058
        },
        "nubia": {
            "semantic_relation": 4.24388,
            "contradiction": 2.16662,
            "irrelevancy": 24.03719,
            "logical_agreement": 73.79619,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.22894,
            "nubia_score": 0.7115
        },
        "meteor": 0.4199153771733697,
        "bleurt": 0.32479,
        "bertscore": {
            "precision": 0.95813,
            "recall": 0.9342,
            "f1": 0.94561
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6648,
            "recall": 0.71472,
            "fmeasure": 0.67827
        },
        "rouge2": {
            "precision": 0.4299,
            "recall": 0.50129,
            "fmeasure": 0.45612
        },
        "rougeL": {
            "precision": 0.5623,
            "recall": 0.6143,
            "fmeasure": 0.57971
        },
        "rougeLsum": {
            "precision": 0.5623,
            "recall": 0.6143,
            "fmeasure": 0.57971
        },
        "bleu": 41.99711,
        "nist": 5.531423125336885,
        "local_recall": {
            "1": 0.25862068965517243,
            "2": 0.4418604651162791,
            "3": 0.8029197080291971
        },
        "nubia": {
            "semantic_relation": 4.06197,
            "contradiction": 15.10175,
            "irrelevancy": 41.97232,
            "logical_agreement": 42.92593,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.42811,
            "nubia_score": 0.68535
        },
        "meteor": 0.400983618125078,
        "bleurt": 0.25344,
        "bertscore": {
            "precision": 0.91717,
            "recall": 0.92689,
            "f1": 0.9203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76723,
            "recall": 0.87389,
            "fmeasure": 0.80941
        },
        "rouge2": {
            "precision": 0.55391,
            "recall": 0.64631,
            "fmeasure": 0.58971
        },
        "rougeL": {
            "precision": 0.64663,
            "recall": 0.75204,
            "fmeasure": 0.68658
        },
        "rougeLsum": {
            "precision": 0.64663,
            "recall": 0.75204,
            "fmeasure": 0.68658
        },
        "bleu": 57.71985,
        "nist": 5.252446732549958,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6363636363636364,
            "3": 0.9333333333333333
        },
        "nubia": {
            "semantic_relation": 4.19049,
            "contradiction": 9.35524,
            "irrelevancy": 65.90276,
            "logical_agreement": 24.742,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.30419,
            "nubia_score": 0.73735
        },
        "meteor": 0.479499312619373,
        "bleurt": 0.40327,
        "bertscore": {
            "precision": 0.94367,
            "recall": 0.96574,
            "f1": 0.95339
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "mT5_large/totto_test",
        "N": 47,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76283,
            "recall": 0.73439,
            "fmeasure": 0.73773
        },
        "rouge2": {
            "precision": 0.53489,
            "recall": 0.5151,
            "fmeasure": 0.51695
        },
        "rougeL": {
            "precision": 0.65325,
            "recall": 0.63416,
            "fmeasure": 0.63408
        },
        "rougeLsum": {
            "precision": 0.65325,
            "recall": 0.63416,
            "fmeasure": 0.63408
        },
        "bleu": 46.42235,
        "nist": 6.800638082573434,
        "local_recall": {
            "1": 0.1953125,
            "2": 0.3953488372093023,
            "3": 0.7763636363636364
        },
        "nubia": {
            "semantic_relation": 4.23571,
            "contradiction": 6.16823,
            "irrelevancy": 27.79133,
            "logical_agreement": 66.04044,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.27097,
            "nubia_score": 0.75394
        },
        "meteor": 0.40447050204931856,
        "bleurt": 0.28343,
        "bertscore": {
            "precision": 0.92834,
            "recall": 0.92336,
            "f1": 0.9247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71187,
            "recall": 0.67855,
            "fmeasure": 0.69211
        },
        "rouge2": {
            "precision": 0.43981,
            "recall": 0.44444,
            "fmeasure": 0.44143
        },
        "rougeL": {
            "precision": 0.66187,
            "recall": 0.6331,
            "fmeasure": 0.64449
        },
        "rougeLsum": {
            "precision": 0.66187,
            "recall": 0.6331,
            "fmeasure": 0.64449
        },
        "bleu": 57.09831,
        "nist": 4.427628983916348,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5625,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 3.87647,
            "contradiction": 0.16631,
            "irrelevancy": 45.68034,
            "logical_agreement": 54.15335,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.64263,
            "nubia_score": 0.6972
        },
        "meteor": 0.4306372582456833,
        "bleurt": 0.379,
        "bertscore": {
            "precision": 0.92453,
            "recall": 0.92247,
            "f1": 0.92334
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82295,
            "recall": 0.87869,
            "fmeasure": 0.84482
        },
        "rouge2": {
            "precision": 0.63643,
            "recall": 0.68668,
            "fmeasure": 0.65599
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.79562,
            "fmeasure": 0.75908
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.79562,
            "fmeasure": 0.75908
        },
        "bleu": 55.19656,
        "nist": 5.704396927088215,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.5625,
            "3": 0.8987341772151899
        },
        "nubia": {
            "semantic_relation": 4.40341,
            "contradiction": 8.61802,
            "irrelevancy": 35.6621,
            "logical_agreement": 55.71988,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.51415,
            "nubia_score": 0.78911
        },
        "meteor": 0.45024468654598615,
        "bleurt": 0.53329,
        "bertscore": {
            "precision": 0.95493,
            "recall": 0.96487,
            "f1": 0.95978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77249
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "bleu": 34.38931,
        "nist": 2.210473320391313,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.97174,
            "contradiction": 0.18493,
            "irrelevancy": 28.82608,
            "logical_agreement": 70.98899,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.7485,
            "nubia_score": 0.90007
        },
        "meteor": 0.5228493300640051,
        "bleurt": 0.72139,
        "bertscore": {
            "precision": 0.95642,
            "recall": 0.96183,
            "f1": 0.95427
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78916,
            "recall": 0.75544,
            "fmeasure": 0.75897
        },
        "rouge2": {
            "precision": 0.58122,
            "recall": 0.56339,
            "fmeasure": 0.56294
        },
        "rougeL": {
            "precision": 0.66929,
            "recall": 0.64681,
            "fmeasure": 0.6447
        },
        "rougeLsum": {
            "precision": 0.66929,
            "recall": 0.64681,
            "fmeasure": 0.6447
        },
        "bleu": 48.64241,
        "nist": 6.675479818401663,
        "local_recall": {
            "1": 0.2,
            "2": 0.5316455696202531,
            "3": 0.796875
        },
        "nubia": {
            "semantic_relation": 4.29446,
            "contradiction": 3.61421,
            "irrelevancy": 32.79586,
            "logical_agreement": 63.58992,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.61108,
            "nubia_score": 0.768
        },
        "meteor": 0.4137408092587336,
        "bleurt": 0.33588,
        "bertscore": {
            "precision": 0.93456,
            "recall": 0.92494,
            "f1": 0.92835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "mT5_large/totto_test",
        "N": 49,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74274,
            "recall": 0.69797,
            "fmeasure": 0.70795
        },
        "rouge2": {
            "precision": 0.51552,
            "recall": 0.48071,
            "fmeasure": 0.48673
        },
        "rougeL": {
            "precision": 0.65581,
            "recall": 0.61764,
            "fmeasure": 0.62474
        },
        "rougeLsum": {
            "precision": 0.65581,
            "recall": 0.61764,
            "fmeasure": 0.62474
        },
        "bleu": 45.38845,
        "nist": 7.088421253825048,
        "local_recall": {
            "1": 0.26288659793814434,
            "2": 0.4393063583815029,
            "3": 0.7495256166982922
        },
        "nubia": {
            "semantic_relation": 4.15907,
            "contradiction": 3.12632,
            "irrelevancy": 34.10103,
            "logical_agreement": 62.77265,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.78678,
            "nubia_score": 0.71646
        },
        "meteor": 0.3844166031689467,
        "bleurt": 0.24794,
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.91748,
            "f1": 0.9208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8324,
            "recall": 0.81392,
            "fmeasure": 0.81528
        },
        "rouge2": {
            "precision": 0.64382,
            "recall": 0.62166,
            "fmeasure": 0.62597
        },
        "rougeL": {
            "precision": 0.7656,
            "recall": 0.75232,
            "fmeasure": 0.75212
        },
        "rougeLsum": {
            "precision": 0.7656,
            "recall": 0.75232,
            "fmeasure": 0.75212
        },
        "bleu": 55.19703,
        "nist": 5.096142477085107,
        "local_recall": {
            "1": 0.4375,
            "2": 0.6923076923076923,
            "3": 0.7678571428571429
        },
        "nubia": {
            "semantic_relation": 4.3994,
            "contradiction": 20.78137,
            "irrelevancy": 29.45669,
            "logical_agreement": 49.76193,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.00812,
            "nubia_score": 0.80996
        },
        "meteor": 0.43534149715453974,
        "bleurt": 0.49179,
        "bertscore": {
            "precision": 0.95092,
            "recall": 0.9516,
            "f1": 0.9501
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "mT5_large/totto_test",
        "N": 128,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79265,
            "recall": 0.76789,
            "fmeasure": 0.77225
        },
        "rouge2": {
            "precision": 0.54893,
            "recall": 0.53729,
            "fmeasure": 0.53705
        },
        "rougeL": {
            "precision": 0.6719,
            "recall": 0.65736,
            "fmeasure": 0.65769
        },
        "rougeLsum": {
            "precision": 0.6719,
            "recall": 0.65736,
            "fmeasure": 0.65769
        },
        "bleu": 46.87388,
        "nist": 7.568019243902953,
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.33554817275747506,
            "3": 0.7914691943127962
        },
        "nubia": {
            "semantic_relation": 4.41765,
            "contradiction": 5.90138,
            "irrelevancy": 26.19811,
            "logical_agreement": 67.90051,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.21745,
            "nubia_score": 0.82232
        },
        "meteor": 0.40083625473874906,
        "bleurt": 0.3541,
        "bertscore": {
            "precision": 0.93387,
            "recall": 0.93295,
            "f1": 0.93151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "mT5_large/totto_test",
        "N": 31,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80514,
            "recall": 0.81218,
            "fmeasure": 0.80399
        },
        "rouge2": {
            "precision": 0.60711,
            "recall": 0.62524,
            "fmeasure": 0.61104
        },
        "rougeL": {
            "precision": 0.69213,
            "recall": 0.71779,
            "fmeasure": 0.69885
        },
        "rougeLsum": {
            "precision": 0.69213,
            "recall": 0.71779,
            "fmeasure": 0.69885
        },
        "bleu": 60.17485,
        "nist": 7.6175444806421115,
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.325,
            "3": 0.9162162162162162
        },
        "nubia": {
            "semantic_relation": 4.4255,
            "contradiction": 5.25593,
            "irrelevancy": 15.35035,
            "logical_agreement": 79.39372,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.59898,
            "nubia_score": 0.79957
        },
        "meteor": 0.4745816014217778,
        "bleurt": 0.43466,
        "bertscore": {
            "precision": 0.94644,
            "recall": 0.9498,
            "f1": 0.94636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "mT5_large/totto_test",
        "N": 80,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68929,
            "recall": 0.70546,
            "fmeasure": 0.68316
        },
        "rouge2": {
            "precision": 0.44165,
            "recall": 0.4545,
            "fmeasure": 0.4375
        },
        "rougeL": {
            "precision": 0.56732,
            "recall": 0.5962,
            "fmeasure": 0.56802
        },
        "rougeLsum": {
            "precision": 0.56732,
            "recall": 0.5962,
            "fmeasure": 0.56802
        },
        "bleu": 39.15051,
        "nist": 6.805613931441227,
        "local_recall": {
            "1": 0.2627118644067797,
            "2": 0.47368421052631576,
            "3": 0.7399741267787839
        },
        "nubia": {
            "semantic_relation": 3.938,
            "contradiction": 8.83545,
            "irrelevancy": 40.72945,
            "logical_agreement": 50.43511,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.38803,
            "nubia_score": 0.65694
        },
        "meteor": 0.3522630432815875,
        "bleurt": 0.10704,
        "bertscore": {
            "precision": 0.9027,
            "recall": 0.90797,
            "f1": 0.90315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "mT5_large/totto_test",
        "N": 29,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83255,
            "recall": 0.79829,
            "fmeasure": 0.80833
        },
        "rouge2": {
            "precision": 0.65145,
            "recall": 0.62291,
            "fmeasure": 0.63113
        },
        "rougeL": {
            "precision": 0.76811,
            "recall": 0.73479,
            "fmeasure": 0.74513
        },
        "rougeLsum": {
            "precision": 0.76811,
            "recall": 0.73479,
            "fmeasure": 0.74513
        },
        "bleu": 52.55893,
        "nist": 6.924508419750947,
        "local_recall": {
            "1": 0.19736842105263158,
            "2": 0.44776119402985076,
            "3": 0.831858407079646
        },
        "nubia": {
            "semantic_relation": 4.35336,
            "contradiction": 7.56337,
            "irrelevancy": 23.68544,
            "logical_agreement": 68.75119,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.77548,
            "nubia_score": 0.78161
        },
        "meteor": 0.43003043286428994,
        "bleurt": 0.42717,
        "bertscore": {
            "precision": 0.94642,
            "recall": 0.93943,
            "f1": 0.94234
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.91931,
            "fmeasure": 0.78095
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.7402,
            "fmeasure": 0.65284
        },
        "rougeL": {
            "precision": 0.67857,
            "recall": 0.84788,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.67857,
            "recall": 0.84788,
            "fmeasure": 0.73333
        },
        "bleu": 58.73243,
        "nist": 3.282123085860083,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nubia": {
            "semantic_relation": 4.39991,
            "contradiction": 0.13157,
            "irrelevancy": 42.51217,
            "logical_agreement": 57.35625,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.60947,
            "nubia_score": 0.79537
        },
        "meteor": 0.5491769063362668,
        "bleurt": 0.46251,
        "bertscore": {
            "precision": 0.92909,
            "recall": 0.96265,
            "f1": 0.94524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67664,
            "recall": 0.63981,
            "fmeasure": 0.64287
        },
        "rouge2": {
            "precision": 0.43134,
            "recall": 0.37974,
            "fmeasure": 0.39445
        },
        "rougeL": {
            "precision": 0.55647,
            "recall": 0.51361,
            "fmeasure": 0.52235
        },
        "rougeLsum": {
            "precision": 0.55647,
            "recall": 0.51361,
            "fmeasure": 0.52235
        },
        "bleu": 31.48957,
        "nist": 4.974919195316939,
        "local_recall": {
            "1": 0.2602739726027397,
            "2": 0.5384615384615384,
            "3": 0.6782608695652174
        },
        "nubia": {
            "semantic_relation": 3.70766,
            "contradiction": 11.96767,
            "irrelevancy": 47.7887,
            "logical_agreement": 40.24363,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.06446,
            "nubia_score": 0.6427
        },
        "meteor": 0.33029132349096835,
        "bleurt": 0.02619,
        "bertscore": {
            "precision": 0.91025,
            "recall": 0.90077,
            "f1": 0.90388
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.53161,
            "fmeasure": 0.59959
        },
        "rouge2": {
            "precision": 0.30163,
            "recall": 0.2444,
            "fmeasure": 0.26952
        },
        "rougeL": {
            "precision": 0.39583,
            "recall": 0.30131,
            "fmeasure": 0.34064
        },
        "rougeLsum": {
            "precision": 0.39583,
            "recall": 0.30131,
            "fmeasure": 0.34064
        },
        "bleu": 13.4687,
        "nist": 2.528589401657092,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6470588235294118
        },
        "nubia": {
            "semantic_relation": 3.66411,
            "contradiction": 0.30112,
            "irrelevancy": 49.25794,
            "logical_agreement": 50.44094,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.91398,
            "nubia_score": 0.51833
        },
        "meteor": 0.2815587761022859,
        "bleurt": 0.05702,
        "bertscore": {
            "precision": 0.90141,
            "recall": 0.88074,
            "f1": 0.8909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78241,
            "recall": 0.69018,
            "fmeasure": 0.72742
        },
        "rouge2": {
            "precision": 0.5351,
            "recall": 0.46858,
            "fmeasure": 0.49505
        },
        "rougeL": {
            "precision": 0.63066,
            "recall": 0.56173,
            "fmeasure": 0.58975
        },
        "rougeLsum": {
            "precision": 0.63066,
            "recall": 0.56173,
            "fmeasure": 0.58975
        },
        "bleu": 50.08226,
        "nist": 5.4390864453500525,
        "local_recall": {
            "1": 0.12,
            "2": 0.36363636363636365,
            "3": 0.7659574468085106
        },
        "nubia": {
            "semantic_relation": 3.89961,
            "contradiction": 40.27099,
            "irrelevancy": 10.39329,
            "logical_agreement": 49.33572,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.98419,
            "nubia_score": 0.61684
        },
        "meteor": 0.398228573308684,
        "bleurt": 0.20463,
        "bertscore": {
            "precision": 0.94312,
            "recall": 0.92712,
            "f1": 0.93264
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.44444,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "bleu": 26.91109,
        "nist": 2.5092629064746266,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.90242,
            "contradiction": 0.21474,
            "irrelevancy": 0.43396,
            "logical_agreement": 99.35131,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.62619,
            "nubia_score": 0.93524
        },
        "meteor": 0.46600466392966616,
        "bleurt": 0.78782,
        "bertscore": {
            "precision": 0.96059,
            "recall": 0.96399,
            "f1": 0.96229
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "mT5_large/totto_test",
        "N": 13,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64712,
            "recall": 0.65352,
            "fmeasure": 0.63069
        },
        "rouge2": {
            "precision": 0.38003,
            "recall": 0.40694,
            "fmeasure": 0.381
        },
        "rougeL": {
            "precision": 0.51613,
            "recall": 0.52842,
            "fmeasure": 0.50529
        },
        "rougeLsum": {
            "precision": 0.51613,
            "recall": 0.52842,
            "fmeasure": 0.50529
        },
        "bleu": 31.61988,
        "nist": 4.822879527563075,
        "local_recall": {
            "1": 0.23943661971830985,
            "2": 0.3584905660377358,
            "3": 0.7063492063492064
        },
        "nubia": {
            "semantic_relation": 3.70698,
            "contradiction": 38.38804,
            "irrelevancy": 33.69523,
            "logical_agreement": 27.91673,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.31421,
            "nubia_score": 0.55454
        },
        "meteor": 0.3357687208130733,
        "bleurt": 0.01275,
        "bertscore": {
            "precision": 0.90203,
            "recall": 0.89443,
            "f1": 0.8972
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85035,
            "recall": 0.80726,
            "fmeasure": 0.82528
        },
        "rouge2": {
            "precision": 0.59362,
            "recall": 0.57123,
            "fmeasure": 0.57961
        },
        "rougeL": {
            "precision": 0.68603,
            "recall": 0.68212,
            "fmeasure": 0.67829
        },
        "rougeLsum": {
            "precision": 0.68603,
            "recall": 0.68212,
            "fmeasure": 0.67829
        },
        "bleu": 55.09982,
        "nist": 5.952004384539565,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.2222222222222222,
            "3": 0.8611111111111112
        },
        "nubia": {
            "semantic_relation": 4.48399,
            "contradiction": 16.26173,
            "irrelevancy": 21.00614,
            "logical_agreement": 62.73214,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.91037,
            "nubia_score": 0.75666
        },
        "meteor": 0.44720563665423263,
        "bleurt": 0.25431,
        "bertscore": {
            "precision": 0.95137,
            "recall": 0.94426,
            "f1": 0.94769
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "mT5_large/totto_test",
        "N": 128,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79686,
            "recall": 0.77706,
            "fmeasure": 0.77882
        },
        "rouge2": {
            "precision": 0.55715,
            "recall": 0.54596,
            "fmeasure": 0.54537
        },
        "rougeL": {
            "precision": 0.68531,
            "recall": 0.67553,
            "fmeasure": 0.67313
        },
        "rougeLsum": {
            "precision": 0.68531,
            "recall": 0.67553,
            "fmeasure": 0.67313
        },
        "bleu": 46.4852,
        "nist": 7.790118729228324,
        "local_recall": {
            "1": 0.18584070796460178,
            "2": 0.32653061224489793,
            "3": 0.8049932523616734
        },
        "nubia": {
            "semantic_relation": 4.47037,
            "contradiction": 5.86421,
            "irrelevancy": 18.99518,
            "logical_agreement": 75.14061,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.56051,
            "nubia_score": 0.81548
        },
        "meteor": 0.4068625744312323,
        "bleurt": 0.3859,
        "bertscore": {
            "precision": 0.93525,
            "recall": 0.93538,
            "f1": 0.93395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80364,
            "recall": 0.69561,
            "fmeasure": 0.72041
        },
        "rouge2": {
            "precision": 0.55988,
            "recall": 0.47389,
            "fmeasure": 0.49531
        },
        "rougeL": {
            "precision": 0.65833,
            "recall": 0.59181,
            "fmeasure": 0.59688
        },
        "rougeLsum": {
            "precision": 0.65833,
            "recall": 0.59181,
            "fmeasure": 0.59688
        },
        "bleu": 41.72308,
        "nist": 4.979665775092978,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.1533,
            "contradiction": 1.23496,
            "irrelevancy": 27.30981,
            "logical_agreement": 71.45522,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.34576,
            "nubia_score": 0.75246
        },
        "meteor": 0.3647165906041653,
        "bleurt": 0.13057,
        "bertscore": {
            "precision": 0.91816,
            "recall": 0.89249,
            "f1": 0.90259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "mT5_large/totto_test",
        "N": 18,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72081,
            "recall": 0.73193,
            "fmeasure": 0.71747
        },
        "rouge2": {
            "precision": 0.49605,
            "recall": 0.49104,
            "fmeasure": 0.48851
        },
        "rougeL": {
            "precision": 0.63241,
            "recall": 0.64534,
            "fmeasure": 0.63107
        },
        "rougeLsum": {
            "precision": 0.63241,
            "recall": 0.64534,
            "fmeasure": 0.63107
        },
        "bleu": 43.52524,
        "nist": 5.6077721715565145,
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.32142857142857145,
            "3": 0.7684210526315789
        },
        "nubia": {
            "semantic_relation": 4.1207,
            "contradiction": 5.27667,
            "irrelevancy": 38.02167,
            "logical_agreement": 56.70166,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.87916,
            "nubia_score": 0.72169
        },
        "meteor": 0.38352105304818374,
        "bleurt": 0.31008,
        "bertscore": {
            "precision": 0.91615,
            "recall": 0.91605,
            "f1": 0.91506
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "mT5_large/totto_test",
        "N": 21,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72613,
            "recall": 0.7238,
            "fmeasure": 0.71621
        },
        "rouge2": {
            "precision": 0.5227,
            "recall": 0.51326,
            "fmeasure": 0.51164
        },
        "rougeL": {
            "precision": 0.60648,
            "recall": 0.61198,
            "fmeasure": 0.60103
        },
        "rougeLsum": {
            "precision": 0.60648,
            "recall": 0.61198,
            "fmeasure": 0.60103
        },
        "bleu": 43.18587,
        "nist": 5.659481578150567,
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.41509433962264153,
            "3": 0.7553191489361702
        },
        "nubia": {
            "semantic_relation": 4.02363,
            "contradiction": 4.68758,
            "irrelevancy": 42.00207,
            "logical_agreement": 53.31035,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.9323,
            "nubia_score": 0.68172
        },
        "meteor": 0.38378410211002933,
        "bleurt": 0.1895,
        "bertscore": {
            "precision": 0.91961,
            "recall": 0.92261,
            "f1": 0.91995
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "mT5_large/totto_test",
        "N": 379,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74572,
            "recall": 0.71601,
            "fmeasure": 0.72066
        },
        "rouge2": {
            "precision": 0.48472,
            "recall": 0.46758,
            "fmeasure": 0.46917
        },
        "rougeL": {
            "precision": 0.59812,
            "recall": 0.57721,
            "fmeasure": 0.57887
        },
        "rougeLsum": {
            "precision": 0.59812,
            "recall": 0.57721,
            "fmeasure": 0.57887
        },
        "bleu": 39.6149,
        "nist": 8.51051728007531,
        "local_recall": {
            "1": 0.2261904761904762,
            "2": 0.4305750350631136,
            "3": 0.7628437047756874
        },
        "nubia": {
            "semantic_relation": 4.05865,
            "contradiction": 11.62709,
            "irrelevancy": 30.48473,
            "logical_agreement": 57.88819,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.24066,
            "nubia_score": 0.69242
        },
        "meteor": 0.3722038159790633,
        "bleurt": 0.17589,
        "bertscore": {
            "precision": 0.92076,
            "recall": 0.91443,
            "f1": 0.91597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87061,
            "recall": 0.89383,
            "fmeasure": 0.88135
        },
        "rouge2": {
            "precision": 0.74402,
            "recall": 0.77626,
            "fmeasure": 0.7552
        },
        "rougeL": {
            "precision": 0.77686,
            "recall": 0.8257,
            "fmeasure": 0.79403
        },
        "rougeLsum": {
            "precision": 0.77686,
            "recall": 0.8257,
            "fmeasure": 0.79403
        },
        "bleu": 70.23787,
        "nist": 5.831539487171956,
        "local_recall": {
            "1": 0.4,
            "2": 0.8333333333333334,
            "3": 0.9574468085106383
        },
        "nubia": {
            "semantic_relation": 4.62158,
            "contradiction": 12.99418,
            "irrelevancy": 24.86854,
            "logical_agreement": 62.13729,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.16756,
            "nubia_score": 0.85628
        },
        "meteor": 0.5294790227300775,
        "bleurt": 0.65153,
        "bertscore": {
            "precision": 0.97909,
            "recall": 0.97828,
            "f1": 0.97854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73611,
            "recall": 0.75618,
            "fmeasure": 0.71206
        },
        "rouge2": {
            "precision": 0.34866,
            "recall": 0.35755,
            "fmeasure": 0.33478
        },
        "rougeL": {
            "precision": 0.46111,
            "recall": 0.50585,
            "fmeasure": 0.4602
        },
        "rougeLsum": {
            "precision": 0.46111,
            "recall": 0.50585,
            "fmeasure": 0.4602
        },
        "bleu": 15.72475,
        "nist": 3.6065649976497363,
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.57382,
            "contradiction": 4.91381,
            "irrelevancy": 54.92511,
            "logical_agreement": 40.16108,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.31619,
            "nubia_score": 0.81303
        },
        "meteor": 0.3687435697681289,
        "bleurt": 0.09027,
        "bertscore": {
            "precision": 0.89852,
            "recall": 0.92955,
            "f1": 0.91295
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "mT5_large/totto_test",
        "N": 83,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76762,
            "recall": 0.73669,
            "fmeasure": 0.7411
        },
        "rouge2": {
            "precision": 0.52967,
            "recall": 0.51512,
            "fmeasure": 0.51565
        },
        "rougeL": {
            "precision": 0.6589,
            "recall": 0.63639,
            "fmeasure": 0.63828
        },
        "rougeLsum": {
            "precision": 0.6589,
            "recall": 0.63639,
            "fmeasure": 0.63828
        },
        "bleu": 48.26848,
        "nist": 7.589374832482703,
        "local_recall": {
            "1": 0.2217741935483871,
            "2": 0.508130081300813,
            "3": 0.7756410256410257
        },
        "nubia": {
            "semantic_relation": 4.27083,
            "contradiction": 7.75344,
            "irrelevancy": 25.54147,
            "logical_agreement": 66.70509,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.69024,
            "nubia_score": 0.73745
        },
        "meteor": 0.39977166397602404,
        "bleurt": 0.3044,
        "bertscore": {
            "precision": 0.93178,
            "recall": 0.9276,
            "f1": 0.9285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.80096,
            "fmeasure": 0.78159
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.65,
            "fmeasure": 0.66407
        },
        "rougeL": {
            "precision": 0.74444,
            "recall": 0.76272,
            "fmeasure": 0.74669
        },
        "rougeLsum": {
            "precision": 0.74444,
            "recall": 0.76272,
            "fmeasure": 0.74669
        },
        "bleu": 72.06508,
        "nist": 5.115347537229088,
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.1067,
            "contradiction": 45.12344,
            "irrelevancy": 12.48204,
            "logical_agreement": 42.39452,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.24189,
            "nubia_score": 0.67958
        },
        "meteor": 0.5210210399876202,
        "bleurt": 0.29407,
        "bertscore": {
            "precision": 0.95077,
            "recall": 0.96048,
            "f1": 0.95158
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53321,
            "recall": 0.61527,
            "fmeasure": 0.55976
        },
        "rouge2": {
            "precision": 0.21609,
            "recall": 0.27695,
            "fmeasure": 0.23757
        },
        "rougeL": {
            "precision": 0.37878,
            "recall": 0.46624,
            "fmeasure": 0.40904
        },
        "rougeLsum": {
            "precision": 0.37878,
            "recall": 0.46624,
            "fmeasure": 0.40904
        },
        "bleu": 13.42726,
        "nist": 3.171070246512513,
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.6521739130434783,
            "3": 0.5614035087719298
        },
        "nubia": {
            "semantic_relation": 3.69708,
            "contradiction": 4.99333,
            "irrelevancy": 59.61977,
            "logical_agreement": 35.38689,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.37338,
            "nubia_score": 0.60287
        },
        "meteor": 0.2632444661930419,
        "bleurt": 0.04732,
        "bertscore": {
            "precision": 0.87605,
            "recall": 0.90217,
            "f1": 0.88771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86184,
            "recall": 0.84495,
            "fmeasure": 0.84826
        },
        "rouge2": {
            "precision": 0.73471,
            "recall": 0.72638,
            "fmeasure": 0.72722
        },
        "rougeL": {
            "precision": 0.7896,
            "recall": 0.782,
            "fmeasure": 0.78081
        },
        "rougeLsum": {
            "precision": 0.7896,
            "recall": 0.782,
            "fmeasure": 0.78081
        },
        "bleu": 68.5632,
        "nist": 6.841085731139953,
        "local_recall": {
            "1": 0.3939393939393939,
            "2": 0.6363636363636364,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.42212,
            "contradiction": 5.23478,
            "irrelevancy": 29.74864,
            "logical_agreement": 65.01658,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.70573,
            "nubia_score": 0.7991
        },
        "meteor": 0.4719007764967026,
        "bleurt": 0.46951,
        "bertscore": {
            "precision": 0.96439,
            "recall": 0.95959,
            "f1": 0.96034
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "mT5_large/totto_test",
        "N": 45,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81172,
            "recall": 0.782,
            "fmeasure": 0.78602
        },
        "rouge2": {
            "precision": 0.58399,
            "recall": 0.56716,
            "fmeasure": 0.56726
        },
        "rougeL": {
            "precision": 0.6524,
            "recall": 0.63314,
            "fmeasure": 0.63277
        },
        "rougeLsum": {
            "precision": 0.6524,
            "recall": 0.63314,
            "fmeasure": 0.63277
        },
        "bleu": 47.76021,
        "nist": 7.334548203536155,
        "local_recall": {
            "1": 0.19333333333333333,
            "2": 0.5078125,
            "3": 0.8036437246963563
        },
        "nubia": {
            "semantic_relation": 4.44512,
            "contradiction": 2.82597,
            "irrelevancy": 21.80646,
            "logical_agreement": 75.36756,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.85041,
            "nubia_score": 0.78771
        },
        "meteor": 0.41945632085019624,
        "bleurt": 0.36629,
        "bertscore": {
            "precision": 0.9421,
            "recall": 0.93739,
            "f1": 0.93909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88528,
            "recall": 0.80697,
            "fmeasure": 0.83918
        },
        "rouge2": {
            "precision": 0.74069,
            "recall": 0.69887,
            "fmeasure": 0.71631
        },
        "rougeL": {
            "precision": 0.84486,
            "recall": 0.77886,
            "fmeasure": 0.80608
        },
        "rougeLsum": {
            "precision": 0.84486,
            "recall": 0.77886,
            "fmeasure": 0.80608
        },
        "bleu": 56.7953,
        "nist": 5.114041442994488,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.25,
            "3": 0.7446808510638298
        },
        "nubia": {
            "semantic_relation": 4.60229,
            "contradiction": 0.19453,
            "irrelevancy": 17.09651,
            "logical_agreement": 82.70896,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.55995,
            "nubia_score": 0.89006
        },
        "meteor": 0.43922318652709874,
        "bleurt": 0.65332,
        "bertscore": {
            "precision": 0.9664,
            "recall": 0.94537,
            "f1": 0.95523
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "mT5_large/totto_test",
        "N": 20,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76294,
            "recall": 0.74277,
            "fmeasure": 0.73756
        },
        "rouge2": {
            "precision": 0.57717,
            "recall": 0.55971,
            "fmeasure": 0.55353
        },
        "rougeL": {
            "precision": 0.68292,
            "recall": 0.65868,
            "fmeasure": 0.65693
        },
        "rougeLsum": {
            "precision": 0.68292,
            "recall": 0.65868,
            "fmeasure": 0.65693
        },
        "bleu": 50.77026,
        "nist": 6.3128930685762965,
        "local_recall": {
            "1": 0.29545454545454547,
            "2": 0.48484848484848486,
            "3": 0.8106796116504854
        },
        "nubia": {
            "semantic_relation": 4.30088,
            "contradiction": 8.20577,
            "irrelevancy": 23.32314,
            "logical_agreement": 68.47108,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.64337,
            "nubia_score": 0.75436
        },
        "meteor": 0.4144026617907208,
        "bleurt": 0.33329,
        "bertscore": {
            "precision": 0.93169,
            "recall": 0.92842,
            "f1": 0.92764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6881,
            "recall": 0.70706,
            "fmeasure": 0.69689
        },
        "rouge2": {
            "precision": 0.40283,
            "recall": 0.42666,
            "fmeasure": 0.41432
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.528,
            "fmeasure": 0.51353
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.528,
            "fmeasure": 0.51353
        },
        "bleu": 30.6486,
        "nist": 3.457632529732203,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6896551724137931
        },
        "nubia": {
            "semantic_relation": 4.19344,
            "contradiction": 48.59902,
            "irrelevancy": 1.30231,
            "logical_agreement": 50.09866,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.25276,
            "nubia_score": 0.77459
        },
        "meteor": 0.3779520393619759,
        "bleurt": 0.37367,
        "bertscore": {
            "precision": 0.91015,
            "recall": 0.91801,
            "f1": 0.91405
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82918,
            "recall": 0.82434,
            "fmeasure": 0.82133
        },
        "rouge2": {
            "precision": 0.61481,
            "recall": 0.63886,
            "fmeasure": 0.62097
        },
        "rougeL": {
            "precision": 0.7489,
            "recall": 0.78722,
            "fmeasure": 0.76118
        },
        "rougeLsum": {
            "precision": 0.7489,
            "recall": 0.78722,
            "fmeasure": 0.76118
        },
        "bleu": 47.61104,
        "nist": 4.904803440666687,
        "local_recall": {
            "1": 0.25,
            "2": 0.625,
            "3": 0.8775510204081632
        },
        "nubia": {
            "semantic_relation": 4.29242,
            "contradiction": 21.56389,
            "irrelevancy": 38.03197,
            "logical_agreement": 40.40414,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.51344,
            "nubia_score": 0.7021
        },
        "meteor": 0.4462541296172973,
        "bleurt": 0.441,
        "bertscore": {
            "precision": 0.95061,
            "recall": 0.95749,
            "f1": 0.95204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "bleu": 65.8037,
        "nist": 3.7574673462380614,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.34708,
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72489,
            "recall": 0.76212,
            "fmeasure": 0.73595
        },
        "rouge2": {
            "precision": 0.49628,
            "recall": 0.50802,
            "fmeasure": 0.49701
        },
        "rougeL": {
            "precision": 0.64718,
            "recall": 0.66009,
            "fmeasure": 0.64666
        },
        "rougeLsum": {
            "precision": 0.64718,
            "recall": 0.66009,
            "fmeasure": 0.64666
        },
        "bleu": 43.28967,
        "nist": 5.582969782079769,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4,
            "3": 0.8156028368794326
        },
        "nubia": {
            "semantic_relation": 4.33405,
            "contradiction": 4.92218,
            "irrelevancy": 37.83064,
            "logical_agreement": 57.24717,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.55655,
            "nubia_score": 0.78468
        },
        "meteor": 0.4116161063405127,
        "bleurt": 0.25222,
        "bertscore": {
            "precision": 0.91698,
            "recall": 0.93201,
            "f1": 0.92352
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "mT5_large/totto_test",
        "N": 124,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7198,
            "recall": 0.69976,
            "fmeasure": 0.70088
        },
        "rouge2": {
            "precision": 0.44631,
            "recall": 0.44813,
            "fmeasure": 0.4401
        },
        "rougeL": {
            "precision": 0.56117,
            "recall": 0.56057,
            "fmeasure": 0.55278
        },
        "rougeLsum": {
            "precision": 0.56117,
            "recall": 0.56057,
            "fmeasure": 0.55278
        },
        "bleu": 37.5162,
        "nist": 7.53697086100167,
        "local_recall": {
            "1": 0.2277432712215321,
            "2": 0.44469525959367945,
            "3": 0.7403846153846154
        },
        "nubia": {
            "semantic_relation": 3.96606,
            "contradiction": 11.00268,
            "irrelevancy": 37.48647,
            "logical_agreement": 51.51085,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.22552,
            "nubia_score": 0.67
        },
        "meteor": 0.3586215409614113,
        "bleurt": 0.12243,
        "bertscore": {
            "precision": 0.9111,
            "recall": 0.9098,
            "f1": 0.90844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78937,
            "recall": 0.80639,
            "fmeasure": 0.79504
        },
        "rouge2": {
            "precision": 0.64807,
            "recall": 0.67646,
            "fmeasure": 0.65981
        },
        "rougeL": {
            "precision": 0.72429,
            "recall": 0.74879,
            "fmeasure": 0.73481
        },
        "rougeLsum": {
            "precision": 0.72429,
            "recall": 0.74879,
            "fmeasure": 0.73481
        },
        "bleu": 68.01024,
        "nist": 6.005318786129348,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.75,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.33094,
            "contradiction": 15.23377,
            "irrelevancy": 25.10892,
            "logical_agreement": 59.65732,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.42522,
            "nubia_score": 0.78881
        },
        "meteor": 0.49284529295074603,
        "bleurt": 0.40588,
        "bertscore": {
            "precision": 0.93962,
            "recall": 0.94675,
            "f1": 0.94256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.57143,
            "fmeasure": 0.47059
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.875,
            "fmeasure": 0.73684
        },
        "bleu": 37.70064,
        "nist": 2.113283334294875,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.43705,
            "contradiction": 0.07529,
            "irrelevancy": 99.69939,
            "logical_agreement": 0.22532,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.41048,
            "nubia_score": 0.91331
        },
        "meteor": 0.4776740326875079,
        "bleurt": 0.68967,
        "bertscore": {
            "precision": 0.92189,
            "recall": 0.96274,
            "f1": 0.94187
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6362,
            "recall": 0.73255,
            "fmeasure": 0.66474
        },
        "rouge2": {
            "precision": 0.40232,
            "recall": 0.46686,
            "fmeasure": 0.41963
        },
        "rougeL": {
            "precision": 0.51971,
            "recall": 0.62576,
            "fmeasure": 0.55345
        },
        "rougeLsum": {
            "precision": 0.51971,
            "recall": 0.62576,
            "fmeasure": 0.55345
        },
        "bleu": 30.18388,
        "nist": 4.513903063952417,
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.5483870967741935,
            "3": 0.6538461538461539
        },
        "nubia": {
            "semantic_relation": 3.98001,
            "contradiction": 10.14306,
            "irrelevancy": 44.88091,
            "logical_agreement": 44.97602,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.36411,
            "nubia_score": 0.63974
        },
        "meteor": 0.3693158697215556,
        "bleurt": 0.13458,
        "bertscore": {
            "precision": 0.89544,
            "recall": 0.91624,
            "f1": 0.90079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86167,
            "recall": 0.76371,
            "fmeasure": 0.79604
        },
        "rouge2": {
            "precision": 0.61998,
            "recall": 0.56512,
            "fmeasure": 0.58028
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63986,
            "fmeasure": 0.67444
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63986,
            "fmeasure": 0.67444
        },
        "bleu": 36.17649,
        "nist": 4.055422924365121,
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.7586206896551724
        },
        "nubia": {
            "semantic_relation": 4.43585,
            "contradiction": 6.17867,
            "irrelevancy": 37.23793,
            "logical_agreement": 56.58341,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.4467,
            "nubia_score": 0.83166
        },
        "meteor": 0.3696614736911033,
        "bleurt": 0.32596,
        "bertscore": {
            "precision": 0.94876,
            "recall": 0.91269,
            "f1": 0.92736
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8097,
            "recall": 0.77077,
            "fmeasure": 0.78254
        },
        "rouge2": {
            "precision": 0.53153,
            "recall": 0.52375,
            "fmeasure": 0.52254
        },
        "rougeL": {
            "precision": 0.72752,
            "recall": 0.71243,
            "fmeasure": 0.71493
        },
        "rougeLsum": {
            "precision": 0.72752,
            "recall": 0.71243,
            "fmeasure": 0.71493
        },
        "bleu": 49.1464,
        "nist": 6.231508732740439,
        "local_recall": {
            "1": 0.39285714285714285,
            "2": 0.52,
            "3": 0.8526315789473684
        },
        "nubia": {
            "semantic_relation": 4.40066,
            "contradiction": 0.91466,
            "irrelevancy": 37.39298,
            "logical_agreement": 61.69236,
            "grammar_ref": 4.94279,
            "grammar_hyp": 5.03318,
            "nubia_score": 0.75027
        },
        "meteor": 0.41383121050654104,
        "bleurt": 0.29008,
        "bertscore": {
            "precision": 0.94746,
            "recall": 0.94306,
            "f1": 0.9428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.71717,
            "fmeasure": 0.70677
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "bleu": 61.15381,
        "nist": 3.054710144537756,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.875
        },
        "nubia": {
            "semantic_relation": 4.35347,
            "contradiction": 0.52359,
            "irrelevancy": 95.76836,
            "logical_agreement": 3.70805,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.00611,
            "nubia_score": 0.86795
        },
        "meteor": 0.4828313957069677,
        "bleurt": 0.5308,
        "bertscore": {
            "precision": 0.85732,
            "recall": 0.92802,
            "f1": 0.89127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "mT5_large/totto_test",
        "N": 162,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.71667,
            "fmeasure": 0.71842
        },
        "rouge2": {
            "precision": 0.48938,
            "recall": 0.46774,
            "fmeasure": 0.47071
        },
        "rougeL": {
            "precision": 0.62384,
            "recall": 0.59686,
            "fmeasure": 0.60108
        },
        "rougeLsum": {
            "precision": 0.62384,
            "recall": 0.59686,
            "fmeasure": 0.60108
        },
        "bleu": 42.20901,
        "nist": 7.492603184434241,
        "local_recall": {
            "1": 0.17737003058103976,
            "2": 0.3665158371040724,
            "3": 0.7635092180546726
        },
        "nubia": {
            "semantic_relation": 4.15247,
            "contradiction": 14.76027,
            "irrelevancy": 24.86833,
            "logical_agreement": 60.3714,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.53666,
            "nubia_score": 0.73152
        },
        "meteor": 0.3861682558330641,
        "bleurt": 0.27932,
        "bertscore": {
            "precision": 0.92917,
            "recall": 0.92401,
            "f1": 0.92454
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79627,
            "recall": 0.78586,
            "fmeasure": 0.78942
        },
        "rouge2": {
            "precision": 0.6254,
            "recall": 0.61971,
            "fmeasure": 0.62115
        },
        "rougeL": {
            "precision": 0.7677,
            "recall": 0.76364,
            "fmeasure": 0.76442
        },
        "rougeLsum": {
            "precision": 0.7677,
            "recall": 0.76364,
            "fmeasure": 0.76442
        },
        "bleu": 55.79836,
        "nist": 4.761119241324722,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.875,
            "3": 0.8157894736842105
        },
        "nubia": {
            "semantic_relation": 4.61455,
            "contradiction": 0.52635,
            "irrelevancy": 3.99461,
            "logical_agreement": 95.47903,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.6789,
            "nubia_score": 0.91172
        },
        "meteor": 0.45725165343264673,
        "bleurt": 0.56066,
        "bertscore": {
            "precision": 0.95469,
            "recall": 0.94531,
            "f1": 0.94912
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "mT5_large/totto_test",
        "N": 25,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75798,
            "recall": 0.77763,
            "fmeasure": 0.7576
        },
        "rouge2": {
            "precision": 0.54261,
            "recall": 0.5519,
            "fmeasure": 0.53951
        },
        "rougeL": {
            "precision": 0.62859,
            "recall": 0.63257,
            "fmeasure": 0.62264
        },
        "rougeLsum": {
            "precision": 0.62859,
            "recall": 0.63257,
            "fmeasure": 0.62264
        },
        "bleu": 47.50121,
        "nist": 6.6288883246948185,
        "local_recall": {
            "1": 0.21739130434782608,
            "2": 0.546875,
            "3": 0.8064516129032258
        },
        "nubia": {
            "semantic_relation": 4.26876,
            "contradiction": 2.85429,
            "irrelevancy": 34.86303,
            "logical_agreement": 62.28268,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.69413,
            "nubia_score": 0.76045
        },
        "meteor": 0.4130172141089813,
        "bleurt": 0.27376,
        "bertscore": {
            "precision": 0.92998,
            "recall": 0.93465,
            "f1": 0.92987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7988,
            "recall": 0.74152,
            "fmeasure": 0.76501
        },
        "rouge2": {
            "precision": 0.64658,
            "recall": 0.61227,
            "fmeasure": 0.62564
        },
        "rougeL": {
            "precision": 0.70786,
            "recall": 0.66663,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.70786,
            "recall": 0.66663,
            "fmeasure": 0.68132
        },
        "bleu": 56.31414,
        "nist": 5.385386458604412,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4090909090909091,
            "3": 0.855072463768116
        },
        "nubia": {
            "semantic_relation": 4.34225,
            "contradiction": 20.8876,
            "irrelevancy": 29.5818,
            "logical_agreement": 49.53059,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.88068,
            "nubia_score": 0.74594
        },
        "meteor": 0.4500365735544848,
        "bleurt": 0.34608,
        "bertscore": {
            "precision": 0.94467,
            "recall": 0.92363,
            "f1": 0.93397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80798,
            "recall": 0.82334,
            "fmeasure": 0.8119
        },
        "rouge2": {
            "precision": 0.65265,
            "recall": 0.65642,
            "fmeasure": 0.65171
        },
        "rougeL": {
            "precision": 0.69471,
            "recall": 0.70629,
            "fmeasure": 0.69698
        },
        "rougeLsum": {
            "precision": 0.69471,
            "recall": 0.70629,
            "fmeasure": 0.69698
        },
        "bleu": 61.29748,
        "nist": 6.190535584623632,
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.40625,
            "3": 0.8974358974358975
        },
        "nubia": {
            "semantic_relation": 4.28723,
            "contradiction": 9.75269,
            "irrelevancy": 24.72041,
            "logical_agreement": 65.5269,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.90997,
            "nubia_score": 0.74841
        },
        "meteor": 0.4513294790749598,
        "bleurt": 0.45021,
        "bertscore": {
            "precision": 0.94151,
            "recall": 0.93354,
            "f1": 0.93723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.1986532337201607,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0,
        "bleurt": 0.99035,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60203,
            "recall": 0.6279,
            "fmeasure": 0.59855
        },
        "rouge2": {
            "precision": 0.31359,
            "recall": 0.32841,
            "fmeasure": 0.31115
        },
        "rougeL": {
            "precision": 0.41815,
            "recall": 0.47049,
            "fmeasure": 0.43309
        },
        "rougeLsum": {
            "precision": 0.41815,
            "recall": 0.47049,
            "fmeasure": 0.43309
        },
        "bleu": 25.22217,
        "nist": 4.419039250408799,
        "local_recall": {
            "1": 0.2830188679245283,
            "2": 0.6756756756756757,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.93254,
            "contradiction": 7.24435,
            "irrelevancy": 53.75044,
            "logical_agreement": 39.00522,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.87445,
            "nubia_score": 0.61375
        },
        "meteor": 0.3246594271697211,
        "bleurt": -0.10734,
        "bertscore": {
            "precision": 0.89028,
            "recall": 0.90349,
            "f1": 0.89451
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74516,
            "recall": 0.65234,
            "fmeasure": 0.67943
        },
        "rouge2": {
            "precision": 0.44491,
            "recall": 0.36586,
            "fmeasure": 0.39233
        },
        "rougeL": {
            "precision": 0.57841,
            "recall": 0.50932,
            "fmeasure": 0.52951
        },
        "rougeLsum": {
            "precision": 0.57841,
            "recall": 0.50932,
            "fmeasure": 0.52951
        },
        "bleu": 39.89768,
        "nist": 4.85074838226784,
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.7428571428571429,
            "3": 0.7101449275362319
        },
        "nubia": {
            "semantic_relation": 4.18816,
            "contradiction": 17.01422,
            "irrelevancy": 31.58879,
            "logical_agreement": 51.39699,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.62769,
            "nubia_score": 0.72665
        },
        "meteor": 0.3400695761265753,
        "bleurt": -0.01611,
        "bertscore": {
            "precision": 0.91445,
            "recall": 0.89438,
            "f1": 0.90315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77002,
            "recall": 0.70971,
            "fmeasure": 0.73047
        },
        "rouge2": {
            "precision": 0.49796,
            "recall": 0.44789,
            "fmeasure": 0.46614
        },
        "rougeL": {
            "precision": 0.58526,
            "recall": 0.53453,
            "fmeasure": 0.55382
        },
        "rougeLsum": {
            "precision": 0.58526,
            "recall": 0.53453,
            "fmeasure": 0.55382
        },
        "bleu": 37.07813,
        "nist": 5.593601363823521,
        "local_recall": {
            "1": 0.19642857142857142,
            "2": 0.3,
            "3": 0.7846153846153846
        },
        "nubia": {
            "semantic_relation": 4.18397,
            "contradiction": 5.89219,
            "irrelevancy": 28.66283,
            "logical_agreement": 65.44498,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.37928,
            "nubia_score": 0.77785
        },
        "meteor": 0.3466544525996325,
        "bleurt": 0.212,
        "bertscore": {
            "precision": 0.9242,
            "recall": 0.92297,
            "f1": 0.92322
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7218,
            "recall": 0.70354,
            "fmeasure": 0.6933
        },
        "rouge2": {
            "precision": 0.47752,
            "recall": 0.43718,
            "fmeasure": 0.43856
        },
        "rougeL": {
            "precision": 0.59364,
            "recall": 0.60167,
            "fmeasure": 0.57944
        },
        "rougeLsum": {
            "precision": 0.59364,
            "recall": 0.60167,
            "fmeasure": 0.57944
        },
        "bleu": 38.25922,
        "nist": 5.012154151597878,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.4166666666666667,
            "3": 0.8289473684210527
        },
        "nubia": {
            "semantic_relation": 4.10868,
            "contradiction": 12.16237,
            "irrelevancy": 37.03011,
            "logical_agreement": 50.80753,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.71528,
            "nubia_score": 0.69645
        },
        "meteor": 0.3931312452339906,
        "bleurt": 0.24793,
        "bertscore": {
            "precision": 0.90913,
            "recall": 0.91557,
            "f1": 0.90779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46377,
            "recall": 0.6627,
            "fmeasure": 0.52297
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.37619,
            "fmeasure": 0.29119
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.49405,
            "fmeasure": 0.38025
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.49405,
            "fmeasure": 0.38025
        },
        "bleu": 14.50682,
        "nist": 2.9496805585526578,
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.94732,
            "contradiction": 0.09361,
            "irrelevancy": 94.81242,
            "logical_agreement": 5.09397,
            "grammar_ref": 5.89248,
            "grammar_hyp": 4.60117,
            "nubia_score": 0.58381
        },
        "meteor": 0.3117561857875757,
        "bleurt": 0.00491,
        "bertscore": {
            "precision": 0.88019,
            "recall": 0.94838,
            "f1": 0.89102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.875
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "bleu": 56.93894,
        "nist": 1.74452959791945,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.97645,
            "contradiction": 0.28052,
            "irrelevancy": 33.53402,
            "logical_agreement": 66.18545,
            "grammar_ref": 6.47099,
            "grammar_hyp": 7.14333,
            "nubia_score": 0.64258
        },
        "meteor": 0.46313401627446604,
        "bleurt": 0.27445,
        "bertscore": {
            "precision": 0.96384,
            "recall": 0.9356,
            "f1": 0.94951
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "mT5_large/totto_test",
        "N": 128,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73019,
            "recall": 0.71889,
            "fmeasure": 0.71428
        },
        "rouge2": {
            "precision": 0.51019,
            "recall": 0.49682,
            "fmeasure": 0.49667
        },
        "rougeL": {
            "precision": 0.61391,
            "recall": 0.60259,
            "fmeasure": 0.5992
        },
        "rougeLsum": {
            "precision": 0.61391,
            "recall": 0.60259,
            "fmeasure": 0.5992
        },
        "bleu": 49.94461,
        "nist": 8.069385592236294,
        "local_recall": {
            "1": 0.20861678004535147,
            "2": 0.43023255813953487,
            "3": 0.7795918367346939
        },
        "nubia": {
            "semantic_relation": 3.835,
            "contradiction": 12.31003,
            "irrelevancy": 30.05502,
            "logical_agreement": 57.63495,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.03073,
            "nubia_score": 0.63968
        },
        "meteor": 0.39389534132206094,
        "bleurt": 0.13672,
        "bertscore": {
            "precision": 0.92035,
            "recall": 0.91426,
            "f1": 0.91571
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "mT5_large/totto_test",
        "N": 9,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61283,
            "recall": 0.61309,
            "fmeasure": 0.59439
        },
        "rouge2": {
            "precision": 0.35146,
            "recall": 0.35195,
            "fmeasure": 0.33729
        },
        "rougeL": {
            "precision": 0.51947,
            "recall": 0.52822,
            "fmeasure": 0.50444
        },
        "rougeLsum": {
            "precision": 0.51947,
            "recall": 0.52822,
            "fmeasure": 0.50444
        },
        "bleu": 27.79223,
        "nist": 4.329916978515876,
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.5306122448979592,
            "3": 0.7323943661971831
        },
        "nubia": {
            "semantic_relation": 3.35042,
            "contradiction": 11.1331,
            "irrelevancy": 43.57756,
            "logical_agreement": 45.28933,
            "grammar_ref": 4.84583,
            "grammar_hyp": 5.03223,
            "nubia_score": 0.48855
        },
        "meteor": 0.3089328173442912,
        "bleurt": -0.08223,
        "bertscore": {
            "precision": 0.88401,
            "recall": 0.88381,
            "f1": 0.8823
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "mT5_large/totto_test",
        "N": 20,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.81669,
            "fmeasure": 0.80896
        },
        "rouge2": {
            "precision": 0.63787,
            "recall": 0.65057,
            "fmeasure": 0.63827
        },
        "rougeL": {
            "precision": 0.69849,
            "recall": 0.70358,
            "fmeasure": 0.69489
        },
        "rougeLsum": {
            "precision": 0.69849,
            "recall": 0.70358,
            "fmeasure": 0.69489
        },
        "bleu": 55.02999,
        "nist": 6.622704173755495,
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5692307692307692,
            "3": 0.8526315789473684
        },
        "nubia": {
            "semantic_relation": 4.40755,
            "contradiction": 4.33172,
            "irrelevancy": 19.4366,
            "logical_agreement": 76.23168,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.34432,
            "nubia_score": 0.80201
        },
        "meteor": 0.459201050134165,
        "bleurt": 0.46809,
        "bertscore": {
            "precision": 0.95206,
            "recall": 0.94816,
            "f1": 0.94848
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86806,
            "recall": 0.96278,
            "fmeasure": 0.90861
        },
        "rouge2": {
            "precision": 0.76087,
            "recall": 0.82767,
            "fmeasure": 0.78897
        },
        "rougeL": {
            "precision": 0.86806,
            "recall": 0.96278,
            "fmeasure": 0.90861
        },
        "rougeLsum": {
            "precision": 0.86806,
            "recall": 0.96278,
            "fmeasure": 0.90861
        },
        "bleu": 70.62386,
        "nist": 5.101194169779777,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.89522,
            "contradiction": 0.30445,
            "irrelevancy": 38.27089,
            "logical_agreement": 61.42467,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.68322,
            "nubia_score": 0.92497
        },
        "meteor": 0.5744150524777378,
        "bleurt": 0.7065,
        "bertscore": {
            "precision": 0.96959,
            "recall": 0.98646,
            "f1": 0.97788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.70955,
            "fmeasure": 0.64472
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.34641,
            "fmeasure": 0.31309
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.43665,
            "fmeasure": 0.39675
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.43665,
            "fmeasure": 0.39675
        },
        "bleu": 9.13442,
        "nist": 1.7464139064884268,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "nubia": {
            "semantic_relation": 4.90575,
            "contradiction": 0.13341,
            "irrelevancy": 6.64021,
            "logical_agreement": 93.22638,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.70872,
            "nubia_score": 0.91926
        },
        "meteor": 0.3154750841641103,
        "bleurt": 0.37707,
        "bertscore": {
            "precision": 0.86881,
            "recall": 0.88602,
            "f1": 0.87626
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46377,
            "recall": 0.39981,
            "fmeasure": 0.42939
        },
        "rouge2": {
            "precision": 0.13636,
            "recall": 0.12,
            "fmeasure": 0.12766
        },
        "rougeL": {
            "precision": 0.30435,
            "recall": 0.26923,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.30435,
            "recall": 0.26923,
            "fmeasure": 0.28571
        },
        "bleu": 4.24579,
        "nist": 1.4322680667325387,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.35294117647058826
        },
        "nubia": {
            "semantic_relation": 3.00265,
            "contradiction": 0.51173,
            "irrelevancy": 98.37949,
            "logical_agreement": 1.10878,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.2352,
            "nubia_score": 0.26701
        },
        "meteor": 0.2280700466110574,
        "bleurt": -0.4302,
        "bertscore": {
            "precision": 0.82224,
            "recall": 0.8639,
            "f1": 0.8424
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "mT5_large/totto_test",
        "N": 150,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81146,
            "recall": 0.80264,
            "fmeasure": 0.80018
        },
        "rouge2": {
            "precision": 0.59059,
            "recall": 0.58958,
            "fmeasure": 0.58465
        },
        "rougeL": {
            "precision": 0.69589,
            "recall": 0.69177,
            "fmeasure": 0.68792
        },
        "rougeLsum": {
            "precision": 0.69589,
            "recall": 0.69177,
            "fmeasure": 0.68792
        },
        "bleu": 50.16951,
        "nist": 8.434107567261893,
        "local_recall": {
            "1": 0.2017738359201774,
            "2": 0.46216216216216216,
            "3": 0.8247422680412371
        },
        "nubia": {
            "semantic_relation": 4.54942,
            "contradiction": 4.70007,
            "irrelevancy": 24.67142,
            "logical_agreement": 70.62851,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.11795,
            "nubia_score": 0.81867
        },
        "meteor": 0.4279642394872132,
        "bleurt": 0.42484,
        "bertscore": {
            "precision": 0.95071,
            "recall": 0.94784,
            "f1": 0.94807
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71249,
            "recall": 0.51577,
            "fmeasure": 0.59232
        },
        "rouge2": {
            "precision": 0.38194,
            "recall": 0.27162,
            "fmeasure": 0.3138
        },
        "rougeL": {
            "precision": 0.6067,
            "recall": 0.44718,
            "fmeasure": 0.50919
        },
        "rougeLsum": {
            "precision": 0.6067,
            "recall": 0.44718,
            "fmeasure": 0.50919
        },
        "bleu": 15.41927,
        "nist": 2.313954560143657,
        "local_recall": {
            "1": 0.1,
            "2": 0.16666666666666666,
            "3": 0.625
        },
        "nubia": {
            "semantic_relation": 4.01414,
            "contradiction": 1.04412,
            "irrelevancy": 27.46109,
            "logical_agreement": 71.49479,
            "grammar_ref": 4.84918,
            "grammar_hyp": 6.2991,
            "nubia_score": 0.52262
        },
        "meteor": 0.26576102248732975,
        "bleurt": 0.15087,
        "bertscore": {
            "precision": 0.93719,
            "recall": 0.89539,
            "f1": 0.91562
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7999,
            "recall": 0.91375,
            "fmeasure": 0.85036
        },
        "rouge2": {
            "precision": 0.68519,
            "recall": 0.78904,
            "fmeasure": 0.73068
        },
        "rougeL": {
            "precision": 0.7999,
            "recall": 0.91375,
            "fmeasure": 0.85036
        },
        "rougeLsum": {
            "precision": 0.7999,
            "recall": 0.91375,
            "fmeasure": 0.85036
        },
        "bleu": 62.21798,
        "nist": 4.546415636946433,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.8,
            "3": 0.9310344827586207
        },
        "nubia": {
            "semantic_relation": 4.67226,
            "contradiction": 0.19905,
            "irrelevancy": 22.72178,
            "logical_agreement": 77.07917,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.1346,
            "nubia_score": 0.88095
        },
        "meteor": 0.5328088271334966,
        "bleurt": 0.54186,
        "bertscore": {
            "precision": 0.94251,
            "recall": 0.97142,
            "f1": 0.95546
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70391,
            "recall": 0.79973,
            "fmeasure": 0.74019
        },
        "rouge2": {
            "precision": 0.45652,
            "recall": 0.47441,
            "fmeasure": 0.45936
        },
        "rougeL": {
            "precision": 0.57402,
            "recall": 0.65505,
            "fmeasure": 0.60569
        },
        "rougeLsum": {
            "precision": 0.57402,
            "recall": 0.65505,
            "fmeasure": 0.60569
        },
        "bleu": 49.50533,
        "nist": 5.399229464390435,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4666666666666667,
            "3": 0.8205128205128205
        },
        "nubia": {
            "semantic_relation": 4.11622,
            "contradiction": 8.59964,
            "irrelevancy": 43.09598,
            "logical_agreement": 48.30438,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.23045,
            "nubia_score": 0.76148
        },
        "meteor": 0.41262157488551304,
        "bleurt": 0.30571,
        "bertscore": {
            "precision": 0.93248,
            "recall": 0.93978,
            "f1": 0.92948
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77476,
            "recall": 0.75472,
            "fmeasure": 0.75879
        },
        "rouge2": {
            "precision": 0.49304,
            "recall": 0.47183,
            "fmeasure": 0.4791
        },
        "rougeL": {
            "precision": 0.58103,
            "recall": 0.56,
            "fmeasure": 0.56624
        },
        "rougeLsum": {
            "precision": 0.58103,
            "recall": 0.56,
            "fmeasure": 0.56624
        },
        "bleu": 38.42982,
        "nist": 5.046727374909353,
        "local_recall": {
            "1": 0.13043478260869565,
            "2": 0.4230769230769231,
            "3": 0.7788461538461539
        },
        "nubia": {
            "semantic_relation": 4.30267,
            "contradiction": 15.36689,
            "irrelevancy": 21.14002,
            "logical_agreement": 63.49309,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.56212,
            "nubia_score": 0.74853
        },
        "meteor": 0.38324694942944154,
        "bleurt": 0.26522,
        "bertscore": {
            "precision": 0.93374,
            "recall": 0.92839,
            "f1": 0.92989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "mT5_large/totto_test",
        "N": 73,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78838,
            "recall": 0.76238,
            "fmeasure": 0.76341
        },
        "rouge2": {
            "precision": 0.5841,
            "recall": 0.56401,
            "fmeasure": 0.5643
        },
        "rougeL": {
            "precision": 0.70502,
            "recall": 0.68692,
            "fmeasure": 0.68484
        },
        "rougeLsum": {
            "precision": 0.70502,
            "recall": 0.68692,
            "fmeasure": 0.68484
        },
        "bleu": 51.78501,
        "nist": 7.617170343132827,
        "local_recall": {
            "1": 0.2558139534883721,
            "2": 0.4457831325301205,
            "3": 0.7866666666666666
        },
        "nubia": {
            "semantic_relation": 4.21492,
            "contradiction": 5.7717,
            "irrelevancy": 32.62504,
            "logical_agreement": 61.60326,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.55691,
            "nubia_score": 0.74509
        },
        "meteor": 0.4143162619577307,
        "bleurt": 0.28552,
        "bertscore": {
            "precision": 0.93716,
            "recall": 0.93129,
            "f1": 0.93244
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "mT5_large/totto_test",
        "N": 13,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77467,
            "recall": 0.76673,
            "fmeasure": 0.76157
        },
        "rouge2": {
            "precision": 0.53046,
            "recall": 0.5535,
            "fmeasure": 0.53451
        },
        "rougeL": {
            "precision": 0.63912,
            "recall": 0.63379,
            "fmeasure": 0.62825
        },
        "rougeLsum": {
            "precision": 0.63912,
            "recall": 0.63379,
            "fmeasure": 0.62825
        },
        "bleu": 40.23621,
        "nist": 5.522928346615733,
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.6470588235294118,
            "3": 0.8292682926829268
        },
        "nubia": {
            "semantic_relation": 4.40216,
            "contradiction": 4.02178,
            "irrelevancy": 34.70725,
            "logical_agreement": 61.27097,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.87459,
            "nubia_score": 0.78474
        },
        "meteor": 0.42397473599891755,
        "bleurt": 0.16673,
        "bertscore": {
            "precision": 0.91754,
            "recall": 0.92449,
            "f1": 0.91963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "mT5_large/totto_test",
        "N": 16,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77836,
            "recall": 0.76589,
            "fmeasure": 0.76665
        },
        "rouge2": {
            "precision": 0.5255,
            "recall": 0.52968,
            "fmeasure": 0.52398
        },
        "rougeL": {
            "precision": 0.65541,
            "recall": 0.64915,
            "fmeasure": 0.64777
        },
        "rougeLsum": {
            "precision": 0.65541,
            "recall": 0.64915,
            "fmeasure": 0.64777
        },
        "bleu": 52.02116,
        "nist": 6.585101741076689,
        "local_recall": {
            "1": 0.24074074074074073,
            "2": 0.3170731707317073,
            "3": 0.8162162162162162
        },
        "nubia": {
            "semantic_relation": 4.42484,
            "contradiction": 0.585,
            "irrelevancy": 26.55884,
            "logical_agreement": 72.85615,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.52859,
            "nubia_score": 0.81177
        },
        "meteor": 0.4374145019108486,
        "bleurt": 0.45953,
        "bertscore": {
            "precision": 0.94478,
            "recall": 0.94853,
            "f1": 0.94576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "bleu": 91.46912,
        "nist": 4.20271956237473,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.61375,
            "irrelevancy": 0.83168,
            "logical_agreement": 98.55457,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.55122,
            "nubia_score": 0.97788
        },
        "meteor": 0.5118198837985161,
        "bleurt": 0.8833,
        "bertscore": {
            "precision": 0.9928,
            "recall": 0.9928,
            "f1": 0.9928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "mT5_large/totto_test",
        "N": 36,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74625,
            "recall": 0.77784,
            "fmeasure": 0.7554
        },
        "rouge2": {
            "precision": 0.53249,
            "recall": 0.5641,
            "fmeasure": 0.54297
        },
        "rougeL": {
            "precision": 0.65703,
            "recall": 0.69218,
            "fmeasure": 0.66877
        },
        "rougeLsum": {
            "precision": 0.65703,
            "recall": 0.69218,
            "fmeasure": 0.66877
        },
        "bleu": 49.6485,
        "nist": 6.550946350868693,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.6320754716981132,
            "3": 0.7712609970674487
        },
        "nubia": {
            "semantic_relation": 4.20929,
            "contradiction": 7.61638,
            "irrelevancy": 36.45062,
            "logical_agreement": 55.933,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.83287,
            "nubia_score": 0.78808
        },
        "meteor": 0.4468440713034572,
        "bleurt": 0.43928,
        "bertscore": {
            "precision": 0.94188,
            "recall": 0.94656,
            "f1": 0.943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76143,
            "recall": 0.74252,
            "fmeasure": 0.74801
        },
        "rouge2": {
            "precision": 0.46111,
            "recall": 0.46155,
            "fmeasure": 0.45873
        },
        "rougeL": {
            "precision": 0.61558,
            "recall": 0.61592,
            "fmeasure": 0.61291
        },
        "rougeLsum": {
            "precision": 0.61558,
            "recall": 0.61592,
            "fmeasure": 0.61291
        },
        "bleu": 45.79105,
        "nist": 5.415375877533609,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.8387096774193549,
            "3": 0.7283950617283951
        },
        "nubia": {
            "semantic_relation": 4.26822,
            "contradiction": 3.43982,
            "irrelevancy": 29.28967,
            "logical_agreement": 67.27051,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.6799,
            "nubia_score": 0.7285
        },
        "meteor": 0.4005164236287567,
        "bleurt": 0.22034,
        "bertscore": {
            "precision": 0.9212,
            "recall": 0.90929,
            "f1": 0.91435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "mT5_large/totto_test",
        "N": 19,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6883,
            "recall": 0.62985,
            "fmeasure": 0.65282
        },
        "rouge2": {
            "precision": 0.40245,
            "recall": 0.37026,
            "fmeasure": 0.38309
        },
        "rougeL": {
            "precision": 0.57846,
            "recall": 0.52592,
            "fmeasure": 0.54641
        },
        "rougeLsum": {
            "precision": 0.57846,
            "recall": 0.52592,
            "fmeasure": 0.54641
        },
        "bleu": 31.47534,
        "nist": 4.757084289712749,
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3956043956043956,
            "3": 0.7225433526011561
        },
        "nubia": {
            "semantic_relation": 3.91783,
            "contradiction": 12.6313,
            "irrelevancy": 36.1985,
            "logical_agreement": 51.17019,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.93809,
            "nubia_score": 0.60399
        },
        "meteor": 0.3112271582307379,
        "bleurt": 0.08531,
        "bertscore": {
            "precision": 0.89849,
            "recall": 0.89402,
            "f1": 0.89526
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80962,
            "recall": 0.79429,
            "fmeasure": 0.7935
        },
        "rouge2": {
            "precision": 0.62792,
            "recall": 0.65158,
            "fmeasure": 0.62719
        },
        "rougeL": {
            "precision": 0.73254,
            "recall": 0.72338,
            "fmeasure": 0.72102
        },
        "rougeLsum": {
            "precision": 0.73254,
            "recall": 0.72338,
            "fmeasure": 0.72102
        },
        "bleu": 63.9675,
        "nist": 5.824470048718919,
        "local_recall": {
            "1": 0.24390243902439024,
            "2": 0.8095238095238095,
            "3": 0.8541666666666666
        },
        "nubia": {
            "semantic_relation": 3.99852,
            "contradiction": 25.82394,
            "irrelevancy": 17.24993,
            "logical_agreement": 56.92613,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.9361,
            "nubia_score": 0.68654
        },
        "meteor": 0.4741939660615709,
        "bleurt": 0.3432,
        "bertscore": {
            "precision": 0.95332,
            "recall": 0.95606,
            "f1": 0.95151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74702,
            "recall": 0.66418,
            "fmeasure": 0.68317
        },
        "rouge2": {
            "precision": 0.54682,
            "recall": 0.50112,
            "fmeasure": 0.5076
        },
        "rougeL": {
            "precision": 0.72619,
            "recall": 0.65192,
            "fmeasure": 0.66776
        },
        "rougeLsum": {
            "precision": 0.72619,
            "recall": 0.65192,
            "fmeasure": 0.66776
        },
        "bleu": 40.7122,
        "nist": 3.309008906187042,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.5526315789473685
        },
        "nubia": {
            "semantic_relation": 3.6063,
            "contradiction": 20.50346,
            "irrelevancy": 66.42271,
            "logical_agreement": 13.07383,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.1121,
            "nubia_score": 0.47529
        },
        "meteor": 0.30154322217684365,
        "bleurt": -0.04843,
        "bertscore": {
            "precision": 0.95081,
            "recall": 0.92721,
            "f1": 0.93801
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "mT5_large/totto_test",
        "N": 61,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68249,
            "recall": 0.67821,
            "fmeasure": 0.67217
        },
        "rouge2": {
            "precision": 0.42465,
            "recall": 0.42153,
            "fmeasure": 0.41721
        },
        "rougeL": {
            "precision": 0.5609,
            "recall": 0.56121,
            "fmeasure": 0.5528
        },
        "rougeLsum": {
            "precision": 0.5609,
            "recall": 0.56121,
            "fmeasure": 0.5528
        },
        "bleu": 38.57003,
        "nist": 6.6823948632994465,
        "local_recall": {
            "1": 0.1827956989247312,
            "2": 0.39819004524886875,
            "3": 0.7275574112734864
        },
        "nubia": {
            "semantic_relation": 3.91471,
            "contradiction": 9.12835,
            "irrelevancy": 34.27271,
            "logical_agreement": 56.59895,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.14428,
            "nubia_score": 0.65468
        },
        "meteor": 0.3549261373612774,
        "bleurt": 0.09668,
        "bertscore": {
            "precision": 0.90706,
            "recall": 0.90763,
            "f1": 0.90622
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "bleu": 81.96501,
        "nist": 4.00193538757769,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "meteor": 0.5249299242820813,
        "bleurt": 0.86304,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.67932,
            "fmeasure": 0.72566
        },
        "rouge2": {
            "precision": 0.60067,
            "recall": 0.47487,
            "fmeasure": 0.51959
        },
        "rougeL": {
            "precision": 0.76488,
            "recall": 0.61682,
            "fmeasure": 0.67096
        },
        "rougeLsum": {
            "precision": 0.76488,
            "recall": 0.61682,
            "fmeasure": 0.67096
        },
        "bleu": 31.96782,
        "nist": 3.474968577455352,
        "local_recall": {
            "1": 0.4,
            "2": 0.2857142857142857,
            "3": 0.6774193548387096
        },
        "nubia": {
            "semantic_relation": 4.44249,
            "contradiction": 1.11674,
            "irrelevancy": 14.27717,
            "logical_agreement": 84.60608,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.13761,
            "nubia_score": 0.86276
        },
        "meteor": 0.3353189762110098,
        "bleurt": 0.40937,
        "bertscore": {
            "precision": 0.9498,
            "recall": 0.92202,
            "f1": 0.93392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.90909,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.7,
            "fmeasure": 0.53846
        },
        "rougeL": {
            "precision": 0.52941,
            "recall": 0.81818,
            "fmeasure": 0.64286
        },
        "rougeLsum": {
            "precision": 0.52941,
            "recall": 0.81818,
            "fmeasure": 0.64286
        },
        "bleu": 38.27674,
        "nist": 2.427412278284812,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 4.28631,
            "contradiction": 0.10665,
            "irrelevancy": 99.77967,
            "logical_agreement": 0.11369,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.37521,
            "nubia_score": 0.86905
        },
        "meteor": 0.43896932283088275,
        "bleurt": -0.04274,
        "bertscore": {
            "precision": 0.83731,
            "recall": 0.93277,
            "f1": 0.88247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72804,
            "recall": 0.71717,
            "fmeasure": 0.71173
        },
        "rouge2": {
            "precision": 0.41891,
            "recall": 0.41799,
            "fmeasure": 0.411
        },
        "rougeL": {
            "precision": 0.57119,
            "recall": 0.58233,
            "fmeasure": 0.56739
        },
        "rougeLsum": {
            "precision": 0.57119,
            "recall": 0.58233,
            "fmeasure": 0.56739
        },
        "bleu": 36.32484,
        "nist": 4.814027636509207,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.3333333333333333,
            "3": 0.7571428571428571
        },
        "nubia": {
            "semantic_relation": 4.12635,
            "contradiction": 8.11926,
            "irrelevancy": 37.3993,
            "logical_agreement": 54.48144,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.00667,
            "nubia_score": 0.72187
        },
        "meteor": 0.3589972204794704,
        "bleurt": 0.19163,
        "bertscore": {
            "precision": 0.91551,
            "recall": 0.90583,
            "f1": 0.9093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74137,
            "recall": 0.80147,
            "fmeasure": 0.76831
        },
        "rouge2": {
            "precision": 0.45437,
            "recall": 0.50598,
            "fmeasure": 0.47741
        },
        "rougeL": {
            "precision": 0.54554,
            "recall": 0.59121,
            "fmeasure": 0.56601
        },
        "rougeLsum": {
            "precision": 0.54554,
            "recall": 0.59121,
            "fmeasure": 0.56601
        },
        "bleu": 34.08794,
        "nist": 4.267720436148328,
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7941176470588235
        },
        "nubia": {
            "semantic_relation": 4.84262,
            "contradiction": 1.1156,
            "irrelevancy": 0.69809,
            "logical_agreement": 98.18631,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.02833,
            "nubia_score": 0.9663
        },
        "meteor": 0.4322662403575139,
        "bleurt": 0.55398,
        "bertscore": {
            "precision": 0.93186,
            "recall": 0.94269,
            "f1": 0.93715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8096,
            "recall": 0.88094,
            "fmeasure": 0.83539
        },
        "rouge2": {
            "precision": 0.64062,
            "recall": 0.69812,
            "fmeasure": 0.66053
        },
        "rougeL": {
            "precision": 0.75241,
            "recall": 0.81581,
            "fmeasure": 0.77572
        },
        "rougeLsum": {
            "precision": 0.75241,
            "recall": 0.81581,
            "fmeasure": 0.77572
        },
        "bleu": 59.39231,
        "nist": 4.981707228398093,
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "nubia": {
            "semantic_relation": 4.54484,
            "contradiction": 9.70937,
            "irrelevancy": 37.59332,
            "logical_agreement": 52.69731,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.31831,
            "nubia_score": 0.78963
        },
        "meteor": 0.4750397522430111,
        "bleurt": 0.5259,
        "bertscore": {
            "precision": 0.95738,
            "recall": 0.97042,
            "f1": 0.9636
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79588,
            "recall": 0.67277,
            "fmeasure": 0.70061
        },
        "rouge2": {
            "precision": 0.59921,
            "recall": 0.46429,
            "fmeasure": 0.50489
        },
        "rougeL": {
            "precision": 0.6931,
            "recall": 0.55295,
            "fmeasure": 0.59579
        },
        "rougeLsum": {
            "precision": 0.6931,
            "recall": 0.55295,
            "fmeasure": 0.59579
        },
        "bleu": 46.65,
        "nist": 4.90066264282659,
        "local_recall": {
            "1": 0.06521739130434782,
            "2": 0.6296296296296297,
            "3": 0.7263157894736842
        },
        "nubia": {
            "semantic_relation": 4.10939,
            "contradiction": 4.99387,
            "irrelevancy": 30.44436,
            "logical_agreement": 64.56177,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.67109,
            "nubia_score": 0.63639
        },
        "meteor": 0.37652068651658716,
        "bleurt": 0.13997,
        "bertscore": {
            "precision": 0.92049,
            "recall": 0.89498,
            "f1": 0.90442
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "mT5_large/totto_test",
        "N": 11,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78666,
            "recall": 0.81768,
            "fmeasure": 0.79633
        },
        "rouge2": {
            "precision": 0.61177,
            "recall": 0.62969,
            "fmeasure": 0.61685
        },
        "rougeL": {
            "precision": 0.71316,
            "recall": 0.73539,
            "fmeasure": 0.71857
        },
        "rougeLsum": {
            "precision": 0.71316,
            "recall": 0.73539,
            "fmeasure": 0.71857
        },
        "bleu": 53.44237,
        "nist": 5.869169042543174,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.42105263157894735,
            "3": 0.8709677419354839
        },
        "nubia": {
            "semantic_relation": 4.48463,
            "contradiction": 2.62573,
            "irrelevancy": 30.18798,
            "logical_agreement": 67.18629,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.38912,
            "nubia_score": 0.84834
        },
        "meteor": 0.4552363481487318,
        "bleurt": 0.46236,
        "bertscore": {
            "precision": 0.93944,
            "recall": 0.94159,
            "f1": 0.93878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84195,
            "recall": 0.67797,
            "fmeasure": 0.75033
        },
        "rouge2": {
            "precision": 0.57744,
            "recall": 0.45674,
            "fmeasure": 0.50942
        },
        "rougeL": {
            "precision": 0.7069,
            "recall": 0.56725,
            "fmeasure": 0.6287
        },
        "rougeLsum": {
            "precision": 0.7069,
            "recall": 0.56725,
            "fmeasure": 0.6287
        },
        "bleu": 39.30233,
        "nist": 4.09190198324155,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6507936507936508
        },
        "nubia": {
            "semantic_relation": 3.87515,
            "contradiction": 0.85851,
            "irrelevancy": 29.18935,
            "logical_agreement": 69.95214,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.8959,
            "nubia_score": 0.66283
        },
        "meteor": 0.34971383083351937,
        "bleurt": 0.18455,
        "bertscore": {
            "precision": 0.92487,
            "recall": 0.88104,
            "f1": 0.90198
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80202,
            "recall": 0.69577,
            "fmeasure": 0.73761
        },
        "rouge2": {
            "precision": 0.60247,
            "recall": 0.51873,
            "fmeasure": 0.55054
        },
        "rougeL": {
            "precision": 0.68081,
            "recall": 0.57951,
            "fmeasure": 0.61869
        },
        "rougeLsum": {
            "precision": 0.68081,
            "recall": 0.57951,
            "fmeasure": 0.61869
        },
        "bleu": 48.56144,
        "nist": 4.641992093869751,
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.4,
            "3": 0.7428571428571429
        },
        "nubia": {
            "semantic_relation": 4.37338,
            "contradiction": 1.29021,
            "irrelevancy": 21.90675,
            "logical_agreement": 76.80304,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.46427,
            "nubia_score": 0.72926
        },
        "meteor": 0.4220150313280181,
        "bleurt": 0.12246,
        "bertscore": {
            "precision": 0.93278,
            "recall": 0.91596,
            "f1": 0.92421
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7775,
            "recall": 0.8128,
            "fmeasure": 0.79425
        },
        "rouge2": {
            "precision": 0.60833,
            "recall": 0.63469,
            "fmeasure": 0.62074
        },
        "rougeL": {
            "precision": 0.7175,
            "recall": 0.74849,
            "fmeasure": 0.73217
        },
        "rougeLsum": {
            "precision": 0.7175,
            "recall": 0.74849,
            "fmeasure": 0.73217
        },
        "bleu": 44.24847,
        "nist": 3.8413959268730817,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "nubia": {
            "semantic_relation": 3.474,
            "contradiction": 83.43092,
            "irrelevancy": 3.76148,
            "logical_agreement": 12.8076,
            "grammar_ref": 3.82725,
            "grammar_hyp": 3.49909,
            "nubia_score": 0.576
        },
        "meteor": 0.4198726177020986,
        "bleurt": 0.43797,
        "bertscore": {
            "precision": 0.93401,
            "recall": 0.93372,
            "f1": 0.93133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76197,
            "recall": 0.82588,
            "fmeasure": 0.78659
        },
        "rouge2": {
            "precision": 0.57113,
            "recall": 0.63172,
            "fmeasure": 0.59462
        },
        "rougeL": {
            "precision": 0.69947,
            "recall": 0.74437,
            "fmeasure": 0.71543
        },
        "rougeLsum": {
            "precision": 0.69947,
            "recall": 0.74437,
            "fmeasure": 0.71543
        },
        "bleu": 44.0887,
        "nist": 4.585697673426434,
        "local_recall": {
            "1": 0.16,
            "2": 0.75,
            "3": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 3.88592,
            "contradiction": 22.95547,
            "irrelevancy": 23.71793,
            "logical_agreement": 53.3266,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.93783,
            "nubia_score": 0.59147
        },
        "meteor": 0.43132890465817836,
        "bleurt": 0.35324,
        "bertscore": {
            "precision": 0.93968,
            "recall": 0.94303,
            "f1": 0.94128
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "mT5_large/totto_test",
        "N": 40,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76182,
            "recall": 0.71278,
            "fmeasure": 0.7241
        },
        "rouge2": {
            "precision": 0.51647,
            "recall": 0.48754,
            "fmeasure": 0.49402
        },
        "rougeL": {
            "precision": 0.59198,
            "recall": 0.55947,
            "fmeasure": 0.5659
        },
        "rougeLsum": {
            "precision": 0.59198,
            "recall": 0.55947,
            "fmeasure": 0.5659
        },
        "bleu": 43.30412,
        "nist": 7.04809278219562,
        "local_recall": {
            "1": 0.2054794520547945,
            "2": 0.41420118343195267,
            "3": 0.7577639751552795
        },
        "nubia": {
            "semantic_relation": 3.88567,
            "contradiction": 15.14182,
            "irrelevancy": 26.34791,
            "logical_agreement": 58.51027,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.14387,
            "nubia_score": 0.6473
        },
        "meteor": 0.37490453620904723,
        "bleurt": 0.18074,
        "bertscore": {
            "precision": 0.92572,
            "recall": 0.91987,
            "f1": 0.92145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.88405,
            "fmeasure": 0.87931
        },
        "rouge2": {
            "precision": 0.76023,
            "recall": 0.75389,
            "fmeasure": 0.75282
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.82386,
            "fmeasure": 0.81498
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.82386,
            "fmeasure": 0.81498
        },
        "bleu": 66.78054,
        "nist": 4.603224890553335,
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.78099,
            "contradiction": 0.52266,
            "irrelevancy": 16.54867,
            "logical_agreement": 82.92866,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.43807,
            "nubia_score": 0.93536
        },
        "meteor": 0.5162461822929045,
        "bleurt": 0.59187,
        "bertscore": {
            "precision": 0.96345,
            "recall": 0.97635,
            "f1": 0.96765
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "mT5_large/totto_test",
        "N": 150,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78527,
            "recall": 0.75641,
            "fmeasure": 0.76051
        },
        "rouge2": {
            "precision": 0.54858,
            "recall": 0.52707,
            "fmeasure": 0.52969
        },
        "rougeL": {
            "precision": 0.66849,
            "recall": 0.64783,
            "fmeasure": 0.64843
        },
        "rougeLsum": {
            "precision": 0.66849,
            "recall": 0.64783,
            "fmeasure": 0.64843
        },
        "bleu": 46.52084,
        "nist": 8.093948048969327,
        "local_recall": {
            "1": 0.16379310344827586,
            "2": 0.4189189189189189,
            "3": 0.8119349005424955
        },
        "nubia": {
            "semantic_relation": 4.41787,
            "contradiction": 8.97517,
            "irrelevancy": 21.94468,
            "logical_agreement": 69.08015,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.79279,
            "nubia_score": 0.78568
        },
        "meteor": 0.40804614422677776,
        "bleurt": 0.35532,
        "bertscore": {
            "precision": 0.93637,
            "recall": 0.93432,
            "f1": 0.93353
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "bleu": 61.0195,
        "nist": 2.9898332363522426,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.83294,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62108,
            "recall": 0.52039,
            "fmeasure": 0.56196
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.23982,
            "fmeasure": 0.25546
        },
        "rougeL": {
            "precision": 0.47806,
            "recall": 0.40963,
            "fmeasure": 0.43785
        },
        "rougeLsum": {
            "precision": 0.47806,
            "recall": 0.40963,
            "fmeasure": 0.43785
        },
        "bleu": 32.8216,
        "nist": 3.9111837875646684,
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.38095238095238093,
            "3": 0.6818181818181818
        },
        "nubia": {
            "semantic_relation": 3.69833,
            "contradiction": 14.01847,
            "irrelevancy": 28.01017,
            "logical_agreement": 57.97136,
            "grammar_ref": 4.68806,
            "grammar_hyp": 5.28423,
            "nubia_score": 0.58608
        },
        "meteor": 0.3009880934114251,
        "bleurt": 0.19184,
        "bertscore": {
            "precision": 0.91012,
            "recall": 0.87599,
            "f1": 0.89174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.56818,
            "fmeasure": 0.45635
        },
        "rouge2": {
            "precision": 0.13889,
            "recall": 0.22381,
            "fmeasure": 0.17065
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.45455,
            "fmeasure": 0.36508
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.45455,
            "fmeasure": 0.36508
        },
        "bleu": 6.75431,
        "nist": 1.1842541123824948,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 3.84194,
            "contradiction": 0.44988,
            "irrelevancy": 97.10356,
            "logical_agreement": 2.44656,
            "grammar_ref": 4.68733,
            "grammar_hyp": 5.39957,
            "nubia_score": 0.48313
        },
        "meteor": 0.26049129866424353,
        "bleurt": -0.33156,
        "bertscore": {
            "precision": 0.81931,
            "recall": 0.89211,
            "f1": 0.85416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.58333,
            "fmeasure": 0.62222
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.26087,
            "fmeasure": 0.27907
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.44444,
            "fmeasure": 0.36094
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.44444,
            "fmeasure": 0.36094
        },
        "bleu": 9.61918,
        "nist": 2.6619626704777057,
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.4166666666666667
        },
        "nubia": {
            "semantic_relation": 3.20369,
            "contradiction": 56.57379,
            "irrelevancy": 30.99835,
            "logical_agreement": 12.42785,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.82299,
            "nubia_score": 0.42297
        },
        "meteor": 0.2919258253944676,
        "bleurt": -0.3093,
        "bertscore": {
            "precision": 0.85646,
            "recall": 0.85416,
            "f1": 0.85531
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "mT5_large/totto_test",
        "N": 15,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78829,
            "recall": 0.77278,
            "fmeasure": 0.77453
        },
        "rouge2": {
            "precision": 0.59602,
            "recall": 0.58084,
            "fmeasure": 0.58338
        },
        "rougeL": {
            "precision": 0.66855,
            "recall": 0.66663,
            "fmeasure": 0.66218
        },
        "rougeLsum": {
            "precision": 0.66855,
            "recall": 0.66663,
            "fmeasure": 0.66218
        },
        "bleu": 48.80731,
        "nist": 6.19792043923265,
        "local_recall": {
            "1": 0.23404255319148937,
            "2": 0.4444444444444444,
            "3": 0.832258064516129
        },
        "nubia": {
            "semantic_relation": 4.31756,
            "contradiction": 12.56434,
            "irrelevancy": 27.67398,
            "logical_agreement": 59.76168,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.91253,
            "nubia_score": 0.74708
        },
        "meteor": 0.43523214161969814,
        "bleurt": 0.25444,
        "bertscore": {
            "precision": 0.94687,
            "recall": 0.94356,
            "f1": 0.94243
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "mT5_large/totto_test",
        "N": 20,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70113,
            "recall": 0.63649,
            "fmeasure": 0.65684
        },
        "rouge2": {
            "precision": 0.40906,
            "recall": 0.39389,
            "fmeasure": 0.38881
        },
        "rougeL": {
            "precision": 0.53575,
            "recall": 0.50809,
            "fmeasure": 0.50756
        },
        "rougeLsum": {
            "precision": 0.53575,
            "recall": 0.50809,
            "fmeasure": 0.50756
        },
        "bleu": 38.69084,
        "nist": 6.030416693537197,
        "local_recall": {
            "1": 0.14942528735632185,
            "2": 0.42857142857142855,
            "3": 0.7259036144578314
        },
        "nubia": {
            "semantic_relation": 3.69919,
            "contradiction": 20.37162,
            "irrelevancy": 33.05925,
            "logical_agreement": 46.56913,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.30888,
            "nubia_score": 0.56868
        },
        "meteor": 0.34852328863321347,
        "bleurt": 0.06096,
        "bertscore": {
            "precision": 0.91275,
            "recall": 0.90262,
            "f1": 0.90059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "mT5_large/totto_test",
        "N": 64,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7538,
            "recall": 0.72709,
            "fmeasure": 0.73201
        },
        "rouge2": {
            "precision": 0.49044,
            "recall": 0.48333,
            "fmeasure": 0.48057
        },
        "rougeL": {
            "precision": 0.62219,
            "recall": 0.61286,
            "fmeasure": 0.61023
        },
        "rougeLsum": {
            "precision": 0.62219,
            "recall": 0.61286,
            "fmeasure": 0.61023
        },
        "bleu": 42.65466,
        "nist": 7.196901147210833,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.44933920704845814,
            "3": 0.7706293706293706
        },
        "nubia": {
            "semantic_relation": 4.26713,
            "contradiction": 5.1303,
            "irrelevancy": 29.1843,
            "logical_agreement": 65.6854,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.66513,
            "nubia_score": 0.74902
        },
        "meteor": 0.3893062415884062,
        "bleurt": 0.2901,
        "bertscore": {
            "precision": 0.92967,
            "recall": 0.92219,
            "f1": 0.92441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89103,
            "recall": 0.7364,
            "fmeasure": 0.804
        },
        "rouge2": {
            "precision": 0.63095,
            "recall": 0.53558,
            "fmeasure": 0.57787
        },
        "rougeL": {
            "precision": 0.77404,
            "recall": 0.67188,
            "fmeasure": 0.7183
        },
        "rougeLsum": {
            "precision": 0.77404,
            "recall": 0.67188,
            "fmeasure": 0.7183
        },
        "bleu": 62.97962,
        "nist": 4.773697852885129,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "nubia": {
            "semantic_relation": 4.40136,
            "contradiction": 0.81816,
            "irrelevancy": 0.65198,
            "logical_agreement": 98.52986,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.30794,
            "nubia_score": 0.75388
        },
        "meteor": 0.4455636432289685,
        "bleurt": 0.36649,
        "bertscore": {
            "precision": 0.95269,
            "recall": 0.92672,
            "f1": 0.93924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "mT5_large/totto_test",
        "N": 80,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72407,
            "recall": 0.68731,
            "fmeasure": 0.69313
        },
        "rouge2": {
            "precision": 0.47184,
            "recall": 0.44582,
            "fmeasure": 0.45029
        },
        "rougeL": {
            "precision": 0.62229,
            "recall": 0.58507,
            "fmeasure": 0.59222
        },
        "rougeLsum": {
            "precision": 0.62229,
            "recall": 0.58507,
            "fmeasure": 0.59222
        },
        "bleu": 41.30666,
        "nist": 7.0617008002204,
        "local_recall": {
            "1": 0.2033898305084746,
            "2": 0.38497652582159625,
            "3": 0.7358490566037735
        },
        "nubia": {
            "semantic_relation": 4.14951,
            "contradiction": 7.95668,
            "irrelevancy": 30.36664,
            "logical_agreement": 61.67668,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.82926,
            "nubia_score": 0.70777
        },
        "meteor": 0.37074508720266297,
        "bleurt": 0.22916,
        "bertscore": {
            "precision": 0.91788,
            "recall": 0.91771,
            "f1": 0.91571
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83126,
            "recall": 0.87468,
            "fmeasure": 0.84147
        },
        "rouge2": {
            "precision": 0.66919,
            "recall": 0.6944,
            "fmeasure": 0.67352
        },
        "rougeL": {
            "precision": 0.68933,
            "recall": 0.73628,
            "fmeasure": 0.7052
        },
        "rougeLsum": {
            "precision": 0.68933,
            "recall": 0.73628,
            "fmeasure": 0.7052
        },
        "bleu": 63.24555,
        "nist": 6.495491884978558,
        "local_recall": {
            "1": 0.5,
            "2": 0.6923076923076923,
            "3": 0.908256880733945
        },
        "nubia": {
            "semantic_relation": 4.46224,
            "contradiction": 8.2669,
            "irrelevancy": 26.3192,
            "logical_agreement": 65.41391,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.63446,
            "nubia_score": 0.81778
        },
        "meteor": 0.4891541112367154,
        "bleurt": 0.53487,
        "bertscore": {
            "precision": 0.95677,
            "recall": 0.96632,
            "f1": 0.96014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72436,
            "recall": 0.78462,
            "fmeasure": 0.74783
        },
        "rouge2": {
            "precision": 0.38636,
            "recall": 0.475,
            "fmeasure": 0.42443
        },
        "rougeL": {
            "precision": 0.5438,
            "recall": 0.6296,
            "fmeasure": 0.58029
        },
        "rougeLsum": {
            "precision": 0.5438,
            "recall": 0.6296,
            "fmeasure": 0.58029
        },
        "bleu": 33.81584,
        "nist": 3.5533691631047892,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7333333333333333
        },
        "nubia": {
            "semantic_relation": 3.81032,
            "contradiction": 31.09833,
            "irrelevancy": 29.93174,
            "logical_agreement": 38.96993,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.21727,
            "nubia_score": 0.58985
        },
        "meteor": 0.35646989703158616,
        "bleurt": 0.1925,
        "bertscore": {
            "precision": 0.90802,
            "recall": 0.92276,
            "f1": 0.91501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "mT5_large/totto_test",
        "N": 17,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7321,
            "recall": 0.69172,
            "fmeasure": 0.6952
        },
        "rouge2": {
            "precision": 0.4966,
            "recall": 0.46064,
            "fmeasure": 0.46605
        },
        "rougeL": {
            "precision": 0.63033,
            "recall": 0.61102,
            "fmeasure": 0.60652
        },
        "rougeLsum": {
            "precision": 0.63033,
            "recall": 0.61102,
            "fmeasure": 0.60652
        },
        "bleu": 38.8528,
        "nist": 5.686718160996324,
        "local_recall": {
            "1": 0.2,
            "2": 0.4470588235294118,
            "3": 0.7103825136612022
        },
        "nubia": {
            "semantic_relation": 4.06226,
            "contradiction": 8.29657,
            "irrelevancy": 35.76743,
            "logical_agreement": 55.936,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.28089,
            "nubia_score": 0.68233
        },
        "meteor": 0.3735058024459485,
        "bleurt": 0.18176,
        "bertscore": {
            "precision": 0.92618,
            "recall": 0.91788,
            "f1": 0.91936
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.99123,
            "recall": 0.92121,
            "fmeasure": 0.95482
        },
        "rouge2": {
            "precision": 0.89815,
            "recall": 0.82982,
            "fmeasure": 0.86249
        },
        "rougeL": {
            "precision": 0.99123,
            "recall": 0.92121,
            "fmeasure": 0.95482
        },
        "rougeLsum": {
            "precision": 0.99123,
            "recall": 0.92121,
            "fmeasure": 0.95482
        },
        "bleu": 90.71221,
        "nist": 5.417673557503956,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.50303,
            "irrelevancy": 0.65906,
            "logical_agreement": 98.83792,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.48185,
            "nubia_score": 0.98386
        },
        "meteor": 0.5655163028981782,
        "bleurt": 0.78575,
        "bertscore": {
            "precision": 0.99493,
            "recall": 0.98769,
            "f1": 0.99129
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.82639,
            "fmeasure": 0.84926
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.60714,
            "fmeasure": 0.62381
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.71528,
            "fmeasure": 0.73162
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.71528,
            "fmeasure": 0.73162
        },
        "bleu": 59.69492,
        "nist": 3.4905844441572156,
        "local_recall": {
            "1": 0.2,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.27456,
            "irrelevancy": 0.45406,
            "logical_agreement": 99.27139,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.28318,
            "nubia_score": 0.9848
        },
        "meteor": 0.9304347826086956,
        "bleurt": 0.74386,
        "bertscore": {
            "precision": 0.97429,
            "recall": 0.97429,
            "f1": 0.97429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77083,
            "recall": 0.57855,
            "fmeasure": 0.64309
        },
        "rouge2": {
            "precision": 0.35498,
            "recall": 0.29202,
            "fmeasure": 0.31113
        },
        "rougeL": {
            "precision": 0.63194,
            "recall": 0.51171,
            "fmeasure": 0.54956
        },
        "rougeLsum": {
            "precision": 0.63194,
            "recall": 0.51171,
            "fmeasure": 0.54956
        },
        "bleu": 14.86975,
        "nist": 2.594340167859721,
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.90667,
            "contradiction": 3.82479,
            "irrelevancy": 42.11341,
            "logical_agreement": 54.0618,
            "grammar_ref": 4.46073,
            "grammar_hyp": 5.31138,
            "nubia_score": 0.52827
        },
        "meteor": 0.3541638574103501,
        "bleurt": 0.03344,
        "bertscore": {
            "precision": 0.9063,
            "recall": 0.90467,
            "f1": 0.90071
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.52381,
            "fmeasure": 0.5641
        },
        "rouge2": {
            "precision": 0.39216,
            "recall": 0.33333,
            "fmeasure": 0.36036
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.47619,
            "fmeasure": 0.51282
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.47619,
            "fmeasure": 0.51282
        },
        "bleu": 31.06558,
        "nist": 2.7033745786639494,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.25169,
            "contradiction": 8.37068,
            "irrelevancy": 60.38628,
            "logical_agreement": 31.24304,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.13576,
            "nubia_score": 0.44501
        },
        "meteor": 0.24396404709315603,
        "bleurt": 0.24912,
        "bertscore": {
            "precision": 0.87785,
            "recall": 0.84205,
            "f1": 0.85844
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.89583,
            "fmeasure": 0.90217
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 0.94231,
            "fmeasure": 0.95
        },
        "bleu": 88.72965,
        "nist": 5.568493488866189,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9387755102040817
        },
        "nubia": {
            "semantic_relation": 4.97356,
            "contradiction": 0.47127,
            "irrelevancy": 0.65888,
            "logical_agreement": 98.86985,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.09026,
            "nubia_score": 0.97561
        },
        "meteor": 0.6320486238977993,
        "bleurt": 0.92747,
        "bertscore": {
            "precision": 0.98953,
            "recall": 0.98667,
            "f1": 0.98809
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82068,
            "recall": 0.83689,
            "fmeasure": 0.82287
        },
        "rouge2": {
            "precision": 0.59979,
            "recall": 0.61058,
            "fmeasure": 0.60004
        },
        "rougeL": {
            "precision": 0.72927,
            "recall": 0.75736,
            "fmeasure": 0.73535
        },
        "rougeLsum": {
            "precision": 0.72927,
            "recall": 0.75736,
            "fmeasure": 0.73535
        },
        "bleu": 49.84401,
        "nist": 5.751583089084588,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.4,
            "3": 0.8701298701298701
        },
        "nubia": {
            "semantic_relation": 4.35618,
            "contradiction": 4.83595,
            "irrelevancy": 26.36924,
            "logical_agreement": 68.79481,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.88474,
            "nubia_score": 0.79275
        },
        "meteor": 0.45016492771052213,
        "bleurt": 0.45823,
        "bertscore": {
            "precision": 0.94904,
            "recall": 0.94878,
            "f1": 0.9467
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "mT5_large/totto_test",
        "N": 103,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76377,
            "recall": 0.74396,
            "fmeasure": 0.74189
        },
        "rouge2": {
            "precision": 0.54402,
            "recall": 0.53033,
            "fmeasure": 0.528
        },
        "rougeL": {
            "precision": 0.67803,
            "recall": 0.66393,
            "fmeasure": 0.66007
        },
        "rougeLsum": {
            "precision": 0.67803,
            "recall": 0.66393,
            "fmeasure": 0.66007
        },
        "bleu": 52.15423,
        "nist": 7.895844160359849,
        "local_recall": {
            "1": 0.25,
            "2": 0.45454545454545453,
            "3": 0.8042704626334519
        },
        "nubia": {
            "semantic_relation": 4.20564,
            "contradiction": 10.10935,
            "irrelevancy": 25.51798,
            "logical_agreement": 64.37266,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.52799,
            "nubia_score": 0.73396
        },
        "meteor": 0.413030009544159,
        "bleurt": 0.31226,
        "bertscore": {
            "precision": 0.93375,
            "recall": 0.92844,
            "f1": 0.92985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6183,
            "recall": 0.64717,
            "fmeasure": 0.59764
        },
        "rouge2": {
            "precision": 0.35438,
            "recall": 0.434,
            "fmeasure": 0.38052
        },
        "rougeL": {
            "precision": 0.52604,
            "recall": 0.56343,
            "fmeasure": 0.51066
        },
        "rougeLsum": {
            "precision": 0.52604,
            "recall": 0.56343,
            "fmeasure": 0.51066
        },
        "bleu": 39.66342,
        "nist": 3.7711976965263276,
        "local_recall": {
            "1": 0.47058823529411764,
            "2": 0.42105263157894735,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 3.69776,
            "contradiction": 17.0529,
            "irrelevancy": 59.47221,
            "logical_agreement": 23.47489,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.41653,
            "nubia_score": 0.5213
        },
        "meteor": 0.3686729573207738,
        "bleurt": -0.09235,
        "bertscore": {
            "precision": 0.8546,
            "recall": 0.89778,
            "f1": 0.87386
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6683,
            "recall": 0.68679,
            "fmeasure": 0.671
        },
        "rouge2": {
            "precision": 0.33049,
            "recall": 0.33333,
            "fmeasure": 0.33029
        },
        "rougeL": {
            "precision": 0.42729,
            "recall": 0.47661,
            "fmeasure": 0.44892
        },
        "rougeLsum": {
            "precision": 0.42729,
            "recall": 0.47661,
            "fmeasure": 0.44892
        },
        "bleu": 40.92253,
        "nist": 3.957945575280416,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.26909,
            "contradiction": 0.24433,
            "irrelevancy": 1.3354,
            "logical_agreement": 98.42027,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.99408,
            "nubia_score": 0.79794
        },
        "meteor": 0.37150423450728637,
        "bleurt": 0.36765,
        "bertscore": {
            "precision": 0.91867,
            "recall": 0.9162,
            "f1": 0.91209
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80099,
            "recall": 0.85563,
            "fmeasure": 0.80971
        },
        "rouge2": {
            "precision": 0.62731,
            "recall": 0.66145,
            "fmeasure": 0.63103
        },
        "rougeL": {
            "precision": 0.67169,
            "recall": 0.75798,
            "fmeasure": 0.69615
        },
        "rougeLsum": {
            "precision": 0.67169,
            "recall": 0.75798,
            "fmeasure": 0.69615
        },
        "bleu": 52.12549,
        "nist": 5.4828616774361105,
        "local_recall": {
            "1": 0.0625,
            "2": 0.55,
            "3": 0.8712871287128713
        },
        "nubia": {
            "semantic_relation": 4.60303,
            "contradiction": 0.88207,
            "irrelevancy": 29.58299,
            "logical_agreement": 69.53494,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.26645,
            "nubia_score": 0.88895
        },
        "meteor": 0.4613899854828223,
        "bleurt": 0.53251,
        "bertscore": {
            "precision": 0.93454,
            "recall": 0.94303,
            "f1": 0.93742
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96078,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.7381,
            "fmeasure": 0.77143
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.81569,
            "fmeasure": 0.85
        },
        "bleu": 78.67012,
        "nist": 4.997400644669717,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.74121,
            "contradiction": 0.21038,
            "irrelevancy": 0.47513,
            "logical_agreement": 99.31449,
            "grammar_ref": 4.24096,
            "grammar_hyp": 4.22897,
            "nubia_score": 0.92017
        },
        "meteor": 0.5302622459418969,
        "bleurt": 0.63445,
        "bertscore": {
            "precision": 0.96928,
            "recall": 0.96681,
            "f1": 0.96805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77972,
            "recall": 0.7073,
            "fmeasure": 0.73431
        },
        "rouge2": {
            "precision": 0.59557,
            "recall": 0.53153,
            "fmeasure": 0.55699
        },
        "rougeL": {
            "precision": 0.73266,
            "recall": 0.64578,
            "fmeasure": 0.68007
        },
        "rougeLsum": {
            "precision": 0.73266,
            "recall": 0.64578,
            "fmeasure": 0.68007
        },
        "bleu": 44.40977,
        "nist": 4.284807995599014,
        "local_recall": {
            "1": 0.2,
            "2": 0.125,
            "3": 0.6785714285714286
        },
        "nubia": {
            "semantic_relation": 4.03909,
            "contradiction": 21.77124,
            "irrelevancy": 19.46902,
            "logical_agreement": 58.75974,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.56978,
            "nubia_score": 0.69122
        },
        "meteor": 0.366136274888784,
        "bleurt": 0.0657,
        "bertscore": {
            "precision": 0.93339,
            "recall": 0.91919,
            "f1": 0.92537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70667,
            "recall": 0.72989,
            "fmeasure": 0.71394
        },
        "rouge2": {
            "precision": 0.41362,
            "recall": 0.41641,
            "fmeasure": 0.41184
        },
        "rougeL": {
            "precision": 0.66333,
            "recall": 0.68228,
            "fmeasure": 0.66875
        },
        "rougeLsum": {
            "precision": 0.66333,
            "recall": 0.68228,
            "fmeasure": 0.66875
        },
        "bleu": 32.10211,
        "nist": 3.876122233088442,
        "local_recall": {
            "1": 0.3,
            "2": 0.625,
            "3": 0.7368421052631579
        },
        "nubia": {
            "semantic_relation": 4.21838,
            "contradiction": 0.56768,
            "irrelevancy": 54.18453,
            "logical_agreement": 45.24778,
            "grammar_ref": 5.90284,
            "grammar_hyp": 4.73006,
            "nubia_score": 0.83971
        },
        "meteor": 0.39914406895641913,
        "bleurt": 0.30319,
        "bertscore": {
            "precision": 0.92635,
            "recall": 0.92503,
            "f1": 0.9256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64307,
            "recall": 0.61788,
            "fmeasure": 0.58196
        },
        "rouge2": {
            "precision": 0.46936,
            "recall": 0.39504,
            "fmeasure": 0.38889
        },
        "rougeL": {
            "precision": 0.59806,
            "recall": 0.54993,
            "fmeasure": 0.52982
        },
        "rougeLsum": {
            "precision": 0.59806,
            "recall": 0.54993,
            "fmeasure": 0.52982
        },
        "bleu": 30.9652,
        "nist": 3.481200893148708,
        "local_recall": {
            "1": 0.3,
            "2": 0.4166666666666667,
            "3": 0.6458333333333334
        },
        "nubia": {
            "semantic_relation": 3.72593,
            "contradiction": 5.68624,
            "irrelevancy": 57.75089,
            "logical_agreement": 36.56287,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.48762,
            "nubia_score": 0.58438
        },
        "meteor": 0.345017620713165,
        "bleurt": -0.06455,
        "bertscore": {
            "precision": 0.86167,
            "recall": 0.86924,
            "f1": 0.86286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "mT5_large/totto_test",
        "N": 25,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73421,
            "recall": 0.73693,
            "fmeasure": 0.719
        },
        "rouge2": {
            "precision": 0.50133,
            "recall": 0.48724,
            "fmeasure": 0.48233
        },
        "rougeL": {
            "precision": 0.59342,
            "recall": 0.60534,
            "fmeasure": 0.5849
        },
        "rougeLsum": {
            "precision": 0.59342,
            "recall": 0.60534,
            "fmeasure": 0.5849
        },
        "bleu": 41.33694,
        "nist": 6.124325695084092,
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.42028985507246375,
            "3": 0.7667844522968198
        },
        "nubia": {
            "semantic_relation": 3.98857,
            "contradiction": 20.44152,
            "irrelevancy": 23.41152,
            "logical_agreement": 56.14696,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.7861,
            "nubia_score": 0.65065
        },
        "meteor": 0.39023133362896895,
        "bleurt": 0.09818,
        "bertscore": {
            "precision": 0.91,
            "recall": 0.91662,
            "f1": 0.91173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75397,
            "recall": 0.73945,
            "fmeasure": 0.73843
        },
        "rouge2": {
            "precision": 0.48286,
            "recall": 0.45578,
            "fmeasure": 0.46392
        },
        "rougeL": {
            "precision": 0.62963,
            "recall": 0.61273,
            "fmeasure": 0.61453
        },
        "rougeLsum": {
            "precision": 0.62963,
            "recall": 0.61273,
            "fmeasure": 0.61453
        },
        "bleu": 46.77136,
        "nist": 4.269486763602435,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.8571428571428571,
            "3": 0.6818181818181818
        },
        "nubia": {
            "semantic_relation": 4.14801,
            "contradiction": 0.43374,
            "irrelevancy": 33.60277,
            "logical_agreement": 65.9635,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.52356,
            "nubia_score": 0.81879
        },
        "meteor": 0.3822448934353856,
        "bleurt": 0.30064,
        "bertscore": {
            "precision": 0.91773,
            "recall": 0.91703,
            "f1": 0.91701
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "mT5_large/totto_test",
        "N": 150,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81954,
            "recall": 0.78672,
            "fmeasure": 0.79725
        },
        "rouge2": {
            "precision": 0.56865,
            "recall": 0.54586,
            "fmeasure": 0.55263
        },
        "rougeL": {
            "precision": 0.69698,
            "recall": 0.66847,
            "fmeasure": 0.67742
        },
        "rougeLsum": {
            "precision": 0.69698,
            "recall": 0.66847,
            "fmeasure": 0.67742
        },
        "bleu": 48.96091,
        "nist": 8.295760112623869,
        "local_recall": {
            "1": 0.16706443914081145,
            "2": 0.36395759717314485,
            "3": 0.813641245972073
        },
        "nubia": {
            "semantic_relation": 4.53107,
            "contradiction": 2.51886,
            "irrelevancy": 18.37063,
            "logical_agreement": 79.11051,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.62346,
            "nubia_score": 0.82788
        },
        "meteor": 0.41654070129535736,
        "bleurt": 0.39994,
        "bertscore": {
            "precision": 0.94047,
            "recall": 0.93699,
            "f1": 0.93781
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74028,
            "recall": 0.69264,
            "fmeasure": 0.71008
        },
        "rouge2": {
            "precision": 0.50728,
            "recall": 0.46776,
            "fmeasure": 0.48583
        },
        "rougeL": {
            "precision": 0.6491,
            "recall": 0.58794,
            "fmeasure": 0.6154
        },
        "rougeLsum": {
            "precision": 0.6491,
            "recall": 0.58794,
            "fmeasure": 0.6154
        },
        "bleu": 44.42409,
        "nist": 4.631955962334199,
        "local_recall": {
            "1": 0.08,
            "2": 0.6666666666666666,
            "3": 0.7666666666666667
        },
        "nubia": {
            "semantic_relation": 4.00369,
            "contradiction": 21.33737,
            "irrelevancy": 28.11711,
            "logical_agreement": 50.54552,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.47757,
            "nubia_score": 0.65122
        },
        "meteor": 0.41336523855431706,
        "bleurt": 0.2385,
        "bertscore": {
            "precision": 0.92761,
            "recall": 0.92414,
            "f1": 0.9203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74383,
            "recall": 0.7991,
            "fmeasure": 0.76563
        },
        "rouge2": {
            "precision": 0.49811,
            "recall": 0.55209,
            "fmeasure": 0.52119
        },
        "rougeL": {
            "precision": 0.59012,
            "recall": 0.64963,
            "fmeasure": 0.61532
        },
        "rougeLsum": {
            "precision": 0.59012,
            "recall": 0.64963,
            "fmeasure": 0.61532
        },
        "bleu": 52.24674,
        "nist": 4.974213569365624,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8809523809523809
        },
        "nubia": {
            "semantic_relation": 4.71471,
            "contradiction": 0.89827,
            "irrelevancy": 57.82593,
            "logical_agreement": 41.2758,
            "grammar_ref": 4.0888,
            "grammar_hyp": 4.18164,
            "nubia_score": 0.86193
        },
        "meteor": 0.44858802979021417,
        "bleurt": 0.41218,
        "bertscore": {
            "precision": 0.9338,
            "recall": 0.94788,
            "f1": 0.94058
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "mT5_large/totto_test",
        "N": 105,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79282,
            "recall": 0.73735,
            "fmeasure": 0.75497
        },
        "rouge2": {
            "precision": 0.52414,
            "recall": 0.48779,
            "fmeasure": 0.49831
        },
        "rougeL": {
            "precision": 0.66564,
            "recall": 0.61927,
            "fmeasure": 0.63334
        },
        "rougeLsum": {
            "precision": 0.66564,
            "recall": 0.61927,
            "fmeasure": 0.63334
        },
        "bleu": 42.23314,
        "nist": 7.440113405237996,
        "local_recall": {
            "1": 0.1930379746835443,
            "2": 0.2923728813559322,
            "3": 0.7762596071733561
        },
        "nubia": {
            "semantic_relation": 4.40453,
            "contradiction": 3.80322,
            "irrelevancy": 27.1766,
            "logical_agreement": 69.02019,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.16146,
            "nubia_score": 0.76604
        },
        "meteor": 0.38231735082062157,
        "bleurt": 0.33213,
        "bertscore": {
            "precision": 0.93236,
            "recall": 0.92573,
            "f1": 0.9278
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "mT5_large/totto_test",
        "N": 12,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70436,
            "recall": 0.73155,
            "fmeasure": 0.70199
        },
        "rouge2": {
            "precision": 0.47498,
            "recall": 0.48451,
            "fmeasure": 0.46832
        },
        "rougeL": {
            "precision": 0.6111,
            "recall": 0.6155,
            "fmeasure": 0.60001
        },
        "rougeLsum": {
            "precision": 0.6111,
            "recall": 0.6155,
            "fmeasure": 0.60001
        },
        "bleu": 37.15211,
        "nist": 4.699248627689112,
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.5714285714285714,
            "3": 0.7282608695652174
        },
        "nubia": {
            "semantic_relation": 4.18368,
            "contradiction": 3.07563,
            "irrelevancy": 42.80966,
            "logical_agreement": 54.11471,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.13141,
            "nubia_score": 0.75389
        },
        "meteor": 0.3737453320440696,
        "bleurt": 0.15226,
        "bertscore": {
            "precision": 0.89981,
            "recall": 0.91626,
            "f1": 0.907
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65701,
            "recall": 0.68289,
            "fmeasure": 0.66696
        },
        "rouge2": {
            "precision": 0.3857,
            "recall": 0.39027,
            "fmeasure": 0.38784
        },
        "rougeL": {
            "precision": 0.51524,
            "recall": 0.54407,
            "fmeasure": 0.52732
        },
        "rougeLsum": {
            "precision": 0.51524,
            "recall": 0.54407,
            "fmeasure": 0.52732
        },
        "bleu": 29.70223,
        "nist": 4.103672097095407,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.22144,
            "contradiction": 0.94477,
            "irrelevancy": 33.70738,
            "logical_agreement": 65.34786,
            "grammar_ref": 5.27719,
            "grammar_hyp": 4.93617,
            "nubia_score": 0.74195
        },
        "meteor": 0.4017090317942028,
        "bleurt": 0.09746,
        "bertscore": {
            "precision": 0.91693,
            "recall": 0.935,
            "f1": 0.92478
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "mT5_large/totto_test",
        "N": 79,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81625,
            "recall": 0.78188,
            "fmeasure": 0.79193
        },
        "rouge2": {
            "precision": 0.59666,
            "recall": 0.57531,
            "fmeasure": 0.58047
        },
        "rougeL": {
            "precision": 0.69008,
            "recall": 0.65823,
            "fmeasure": 0.6684
        },
        "rougeLsum": {
            "precision": 0.69008,
            "recall": 0.65823,
            "fmeasure": 0.6684
        },
        "bleu": 47.4891,
        "nist": 7.774605096024125,
        "local_recall": {
            "1": 0.19696969696969696,
            "2": 0.4029126213592233,
            "3": 0.8090614886731392
        },
        "nubia": {
            "semantic_relation": 4.46281,
            "contradiction": 4.56618,
            "irrelevancy": 23.9689,
            "logical_agreement": 71.46491,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.80495,
            "nubia_score": 0.80335
        },
        "meteor": 0.41364257001369126,
        "bleurt": 0.44697,
        "bertscore": {
            "precision": 0.94788,
            "recall": 0.94135,
            "f1": 0.94298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.58333,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "bleu": 34.82353,
        "nist": 2.3529411764705883,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6923076923076923
        },
        "nubia": {
            "semantic_relation": 3.67479,
            "contradiction": 0.1674,
            "irrelevancy": 99.71684,
            "logical_agreement": 0.11576,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.9497,
            "nubia_score": 0.65993
        },
        "meteor": 0.3812660427694212,
        "bleurt": 0.07622,
        "bertscore": {
            "precision": 0.889,
            "recall": 0.90096,
            "f1": 0.89494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65119,
            "recall": 0.74082,
            "fmeasure": 0.68946
        },
        "rouge2": {
            "precision": 0.39055,
            "recall": 0.44146,
            "fmeasure": 0.41218
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.60466,
            "fmeasure": 0.56409
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.60466,
            "fmeasure": 0.56409
        },
        "bleu": 30.78733,
        "nist": 4.106856707546698,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.28037,
            "contradiction": 11.44217,
            "irrelevancy": 31.20625,
            "logical_agreement": 57.35158,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.77095,
            "nubia_score": 0.7421
        },
        "meteor": 0.3972527806954123,
        "bleurt": 0.15827,
        "bertscore": {
            "precision": 0.91132,
            "recall": 0.92752,
            "f1": 0.91923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.67236,
            "fmeasure": 0.68695
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.60948,
            "fmeasure": 0.62346
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.45014,
            "fmeasure": 0.45166
        },
        "bleu": 67.78396,
        "nist": 4.617647230689446,
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 2.79024,
            "contradiction": 0.23086,
            "irrelevancy": 64.44683,
            "logical_agreement": 35.32231,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.69524,
            "nubia_score": 0.41859
        },
        "meteor": 0.44297773537248525,
        "bleurt": -0.4264,
        "bertscore": {
            "precision": 0.94157,
            "recall": 0.89045,
            "f1": 0.91529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.92674,
            "fmeasure": 0.79973
        },
        "rouge2": {
            "precision": 0.39216,
            "recall": 0.54274,
            "fmeasure": 0.45517
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "bleu": 24.20288,
        "nist": 3.271197946159184,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29773,
            "irrelevancy": 73.13924,
            "logical_agreement": 26.56303,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.46711,
            "nubia_score": 1.0
        },
        "meteor": 0.47195553976499166,
        "bleurt": 0.48431,
        "bertscore": {
            "precision": 0.91659,
            "recall": 0.94315,
            "f1": 0.92545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.79117,
            "fmeasure": 0.83056
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.68759,
            "fmeasure": 0.71432
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.66897,
            "fmeasure": 0.69316
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.66897,
            "fmeasure": 0.69316
        },
        "bleu": 53.20845,
        "nist": 3.4595376895718895,
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.7692307692307693
        },
        "nubia": {
            "semantic_relation": 4.18405,
            "contradiction": 0.81063,
            "irrelevancy": 45.1213,
            "logical_agreement": 54.06807,
            "grammar_ref": 4.36539,
            "grammar_hyp": 5.51922,
            "nubia_score": 0.61815
        },
        "meteor": 0.4104922698287937,
        "bleurt": 0.21122,
        "bertscore": {
            "precision": 0.93996,
            "recall": 0.92279,
            "f1": 0.9312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62457,
            "recall": 0.62624,
            "fmeasure": 0.61467
        },
        "rouge2": {
            "precision": 0.39934,
            "recall": 0.37857,
            "fmeasure": 0.38012
        },
        "rougeL": {
            "precision": 0.56551,
            "recall": 0.56178,
            "fmeasure": 0.55463
        },
        "rougeLsum": {
            "precision": 0.56551,
            "recall": 0.56178,
            "fmeasure": 0.55463
        },
        "bleu": 28.90714,
        "nist": 4.38177274718542,
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.4444444444444444,
            "3": 0.6307692307692307
        },
        "nubia": {
            "semantic_relation": 4.13747,
            "contradiction": 11.36686,
            "irrelevancy": 28.78087,
            "logical_agreement": 59.85228,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.04305,
            "nubia_score": 0.74548
        },
        "meteor": 0.3154674412363397,
        "bleurt": 0.28302,
        "bertscore": {
            "precision": 0.91494,
            "recall": 0.9132,
            "f1": 0.91387
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "mT5_large/totto_test",
        "N": 26,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77153,
            "recall": 0.70507,
            "fmeasure": 0.72649
        },
        "rouge2": {
            "precision": 0.5073,
            "recall": 0.47106,
            "fmeasure": 0.48194
        },
        "rougeL": {
            "precision": 0.62912,
            "recall": 0.57217,
            "fmeasure": 0.59049
        },
        "rougeLsum": {
            "precision": 0.62912,
            "recall": 0.57217,
            "fmeasure": 0.59049
        },
        "bleu": 43.46621,
        "nist": 6.9024804859292015,
        "local_recall": {
            "1": 0.19166666666666668,
            "2": 0.33613445378151263,
            "3": 0.7775330396475771
        },
        "nubia": {
            "semantic_relation": 3.72415,
            "contradiction": 14.33868,
            "irrelevancy": 27.19284,
            "logical_agreement": 58.46848,
            "grammar_ref": 4.04917,
            "grammar_hyp": 3.92612,
            "nubia_score": 0.61435
        },
        "meteor": 0.37841740769243365,
        "bleurt": 0.15716,
        "bertscore": {
            "precision": 0.92466,
            "recall": 0.91429,
            "f1": 0.91867
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88887,
            "recall": 0.85252,
            "fmeasure": 0.86506
        },
        "rouge2": {
            "precision": 0.72467,
            "recall": 0.69397,
            "fmeasure": 0.70519
        },
        "rougeL": {
            "precision": 0.80539,
            "recall": 0.76785,
            "fmeasure": 0.7817
        },
        "rougeLsum": {
            "precision": 0.80539,
            "recall": 0.76785,
            "fmeasure": 0.7817
        },
        "bleu": 65.47287,
        "nist": 5.854220321701321,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3333333333333333,
            "3": 0.8351648351648352
        },
        "nubia": {
            "semantic_relation": 4.71102,
            "contradiction": 1.41447,
            "irrelevancy": 8.26201,
            "logical_agreement": 90.32352,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.25277,
            "nubia_score": 0.84456
        },
        "meteor": 0.47237384872141935,
        "bleurt": 0.56355,
        "bertscore": {
            "precision": 0.97403,
            "recall": 0.96829,
            "f1": 0.97106
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66454,
            "recall": 0.71856,
            "fmeasure": 0.67411
        },
        "rouge2": {
            "precision": 0.43012,
            "recall": 0.49551,
            "fmeasure": 0.44924
        },
        "rougeL": {
            "precision": 0.521,
            "recall": 0.59503,
            "fmeasure": 0.54203
        },
        "rougeLsum": {
            "precision": 0.521,
            "recall": 0.59503,
            "fmeasure": 0.54203
        },
        "bleu": 41.28119,
        "nist": 5.486396264741499,
        "local_recall": {
            "1": 0.2328767123287671,
            "2": 0.423728813559322,
            "3": 0.7671232876712328
        },
        "nubia": {
            "semantic_relation": 3.79615,
            "contradiction": 13.79253,
            "irrelevancy": 37.66726,
            "logical_agreement": 48.54022,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.27934,
            "nubia_score": 0.5732
        },
        "meteor": 0.391354270533491,
        "bleurt": 0.02836,
        "bertscore": {
            "precision": 0.90583,
            "recall": 0.9224,
            "f1": 0.91128
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82838,
            "recall": 0.77899,
            "fmeasure": 0.80193
        },
        "rouge2": {
            "precision": 0.61517,
            "recall": 0.57941,
            "fmeasure": 0.59592
        },
        "rougeL": {
            "precision": 0.64453,
            "recall": 0.60844,
            "fmeasure": 0.62495
        },
        "rougeLsum": {
            "precision": 0.64453,
            "recall": 0.60844,
            "fmeasure": 0.62495
        },
        "bleu": 45.57428,
        "nist": 5.276630063254037,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 3.99317,
            "contradiction": 45.90221,
            "irrelevancy": 24.35338,
            "logical_agreement": 29.7444,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.42836,
            "nubia_score": 0.67758
        },
        "meteor": 0.3913911763340874,
        "bleurt": 0.34305,
        "bertscore": {
            "precision": 0.94815,
            "recall": 0.93427,
            "f1": 0.94039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.64502,
            "fmeasure": 0.67131
        },
        "rouge2": {
            "precision": 0.40351,
            "recall": 0.39122,
            "fmeasure": 0.3963
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.58201,
            "fmeasure": 0.56483
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.58201,
            "fmeasure": 0.56483
        },
        "bleu": 25.44095,
        "nist": 2.825752541549054,
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7857142857142857
        },
        "nubia": {
            "semantic_relation": 3.96667,
            "contradiction": 0.13346,
            "irrelevancy": 67.44847,
            "logical_agreement": 32.41807,
            "grammar_ref": 4.70322,
            "grammar_hyp": 4.65527,
            "nubia_score": 0.64749
        },
        "meteor": 0.3595290356063612,
        "bleurt": -0.01226,
        "bertscore": {
            "precision": 0.89485,
            "recall": 0.89729,
            "f1": 0.89429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.43478,
            "recall": 0.71795,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.42262,
            "fmeasure": 0.31373
        },
        "rougeL": {
            "precision": 0.23913,
            "recall": 0.40256,
            "fmeasure": 0.29971
        },
        "rougeLsum": {
            "precision": 0.23913,
            "recall": 0.40256,
            "fmeasure": 0.29971
        },
        "bleu": 24.90329,
        "nist": 2.210223349273547,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 3.52869,
            "contradiction": 0.07733,
            "irrelevancy": 99.76214,
            "logical_agreement": 0.16052,
            "grammar_ref": 4.56931,
            "grammar_hyp": 3.11115,
            "nubia_score": 0.68114
        },
        "meteor": 0.3736082570997927,
        "bleurt": -0.14007,
        "bertscore": {
            "precision": 0.81995,
            "recall": 0.8625,
            "f1": 0.83806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "bleu": 45.80519,
        "nist": 2.681857998677189,
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "nubia": {
            "semantic_relation": 2.7998,
            "contradiction": 72.15507,
            "irrelevancy": 27.09541,
            "logical_agreement": 0.74952,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.89406,
            "nubia_score": 0.46446
        },
        "meteor": 0.4761015269167852,
        "bleurt": 0.37657,
        "bertscore": {
            "precision": 0.92669,
            "recall": 0.97769,
            "f1": 0.9515
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87847,
            "recall": 0.82102,
            "fmeasure": 0.83752
        },
        "rouge2": {
            "precision": 0.77113,
            "recall": 0.71425,
            "fmeasure": 0.73035
        },
        "rougeL": {
            "precision": 0.85712,
            "recall": 0.80626,
            "fmeasure": 0.81779
        },
        "rougeLsum": {
            "precision": 0.85712,
            "recall": 0.80626,
            "fmeasure": 0.81779
        },
        "bleu": 68.14747,
        "nist": 5.446200308396936,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.16666666666666666,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.59347,
            "contradiction": 0.53875,
            "irrelevancy": 12.78687,
            "logical_agreement": 86.67439,
            "grammar_ref": 5.07225,
            "grammar_hyp": 5.0825,
            "nubia_score": 0.87746
        },
        "meteor": 0.5123038100753835,
        "bleurt": 0.68592,
        "bertscore": {
            "precision": 0.97,
            "recall": 0.95986,
            "f1": 0.96393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81439,
            "recall": 0.73468,
            "fmeasure": 0.76731
        },
        "rouge2": {
            "precision": 0.55795,
            "recall": 0.51732,
            "fmeasure": 0.53375
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.70466,
            "fmeasure": 0.73241
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.70466,
            "fmeasure": 0.73241
        },
        "bleu": 54.18256,
        "nist": 4.369852729258743,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5384615384615384,
            "3": 0.8518518518518519
        },
        "nubia": {
            "semantic_relation": 4.48142,
            "contradiction": 30.22119,
            "irrelevancy": 11.11389,
            "logical_agreement": 58.66492,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.13246,
            "nubia_score": 0.75635
        },
        "meteor": 0.42925152389853694,
        "bleurt": 0.4819,
        "bertscore": {
            "precision": 0.92989,
            "recall": 0.92018,
            "f1": 0.92465
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.31746,
            "fmeasure": 0.30556
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.71667,
            "fmeasure": 0.68889
        },
        "bleu": 22.82484,
        "nist": 2.9778957842950224,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.19292,
            "contradiction": 0.27325,
            "irrelevancy": 26.50473,
            "logical_agreement": 73.22202,
            "grammar_ref": 5.68329,
            "grammar_hyp": 5.90879,
            "nubia_score": 0.65469
        },
        "meteor": 0.34272262745996446,
        "bleurt": 0.27912,
        "bertscore": {
            "precision": 0.92506,
            "recall": 0.92089,
            "f1": 0.91708
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87593,
            "recall": 0.6864,
            "fmeasure": 0.7692
        },
        "rouge2": {
            "precision": 0.56944,
            "recall": 0.43632,
            "fmeasure": 0.49375
        },
        "rougeL": {
            "precision": 0.63519,
            "recall": 0.53813,
            "fmeasure": 0.57663
        },
        "rougeLsum": {
            "precision": 0.63519,
            "recall": 0.53813,
            "fmeasure": 0.57663
        },
        "bleu": 43.19694,
        "nist": 4.012215720846685,
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 0.8125
        },
        "nubia": {
            "semantic_relation": 3.87398,
            "contradiction": 33.54765,
            "irrelevancy": 16.39616,
            "logical_agreement": 50.05618,
            "grammar_ref": 5.19402,
            "grammar_hyp": 5.3516,
            "nubia_score": 0.57253
        },
        "meteor": 0.3538549566771852,
        "bleurt": 0.03338,
        "bertscore": {
            "precision": 0.94206,
            "recall": 0.93377,
            "f1": 0.93217
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83611,
            "recall": 0.8369,
            "fmeasure": 0.83617
        },
        "rouge2": {
            "precision": 0.5471,
            "recall": 0.53111,
            "fmeasure": 0.53886
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.68923,
            "fmeasure": 0.6985
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.68923,
            "fmeasure": 0.6985
        },
        "bleu": 43.43198,
        "nist": 4.756138202633274,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8709677419354839
        },
        "nubia": {
            "semantic_relation": 3.6089,
            "contradiction": 45.64676,
            "irrelevancy": 1.90102,
            "logical_agreement": 52.45222,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.53539,
            "nubia_score": 0.54658
        },
        "meteor": 0.43676290492638564,
        "bleurt": 0.31938,
        "bertscore": {
            "precision": 0.94729,
            "recall": 0.94147,
            "f1": 0.94436
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74709,
            "recall": 0.73906,
            "fmeasure": 0.73281
        },
        "rouge2": {
            "precision": 0.52221,
            "recall": 0.50914,
            "fmeasure": 0.50899
        },
        "rougeL": {
            "precision": 0.65714,
            "recall": 0.63638,
            "fmeasure": 0.63888
        },
        "rougeLsum": {
            "precision": 0.65714,
            "recall": 0.63638,
            "fmeasure": 0.63888
        },
        "bleu": 37.38091,
        "nist": 4.435978553444528,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 0.7246376811594203
        },
        "nubia": {
            "semantic_relation": 4.08636,
            "contradiction": 33.59313,
            "irrelevancy": 22.61853,
            "logical_agreement": 43.78833,
            "grammar_ref": 4.9652,
            "grammar_hyp": 4.95869,
            "nubia_score": 0.67838
        },
        "meteor": 0.37666823098480967,
        "bleurt": 0.2409,
        "bertscore": {
            "precision": 0.92608,
            "recall": 0.90193,
            "f1": 0.91289
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66863,
            "recall": 0.6642,
            "fmeasure": 0.66147
        },
        "rouge2": {
            "precision": 0.39502,
            "recall": 0.38919,
            "fmeasure": 0.38927
        },
        "rougeL": {
            "precision": 0.55306,
            "recall": 0.56491,
            "fmeasure": 0.55107
        },
        "rougeLsum": {
            "precision": 0.55306,
            "recall": 0.56491,
            "fmeasure": 0.55107
        },
        "bleu": 39.51215,
        "nist": 5.677109332875484,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.37681159420289856,
            "3": 0.6991525423728814
        },
        "nubia": {
            "semantic_relation": 3.61357,
            "contradiction": 28.36026,
            "irrelevancy": 7.82976,
            "logical_agreement": 63.80998,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.03878,
            "nubia_score": 0.60769
        },
        "meteor": 0.34695545492458885,
        "bleurt": 0.15974,
        "bertscore": {
            "precision": 0.91208,
            "recall": 0.90617,
            "f1": 0.90889
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.78571,
            "fmeasure": 0.78571
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.53846,
            "fmeasure": 0.53846
        },
        "rougeL": {
            "precision": 0.65476,
            "recall": 0.65476,
            "fmeasure": 0.65476
        },
        "rougeLsum": {
            "precision": 0.65476,
            "recall": 0.65476,
            "fmeasure": 0.65476
        },
        "bleu": 44.82783,
        "nist": 3.817784566996898,
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "nubia": {
            "semantic_relation": 4.16282,
            "contradiction": 1.99674,
            "irrelevancy": 20.55786,
            "logical_agreement": 77.4454,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.6023,
            "nubia_score": 0.72396
        },
        "meteor": 0.4421792344961915,
        "bleurt": 0.24519,
        "bertscore": {
            "precision": 0.95201,
            "recall": 0.94797,
            "f1": 0.94997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77996,
            "recall": 0.73125,
            "fmeasure": 0.74985
        },
        "rouge2": {
            "precision": 0.57123,
            "recall": 0.52414,
            "fmeasure": 0.54198
        },
        "rougeL": {
            "precision": 0.70433,
            "recall": 0.65606,
            "fmeasure": 0.67388
        },
        "rougeLsum": {
            "precision": 0.70433,
            "recall": 0.65606,
            "fmeasure": 0.67388
        },
        "bleu": 38.78772,
        "nist": 4.597854590566666,
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.7428571428571429
        },
        "nubia": {
            "semantic_relation": 4.71416,
            "contradiction": 0.29188,
            "irrelevancy": 30.61725,
            "logical_agreement": 69.09087,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.53709,
            "nubia_score": 0.8653
        },
        "meteor": 0.39662192308330396,
        "bleurt": 0.36733,
        "bertscore": {
            "precision": 0.93378,
            "recall": 0.92748,
            "f1": 0.93003
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80208,
            "recall": 0.83449,
            "fmeasure": 0.81727
        },
        "rouge2": {
            "precision": 0.68333,
            "recall": 0.72157,
            "fmeasure": 0.70087
        },
        "rougeL": {
            "precision": 0.78454,
            "recall": 0.82986,
            "fmeasure": 0.80543
        },
        "rougeLsum": {
            "precision": 0.78454,
            "recall": 0.82986,
            "fmeasure": 0.80543
        },
        "bleu": 60.75347,
        "nist": 4.04863074322614,
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.45497,
            "contradiction": 49.61737,
            "irrelevancy": 42.78545,
            "logical_agreement": 7.59718,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.24182,
            "nubia_score": 0.62656
        },
        "meteor": 0.480557841993703,
        "bleurt": 0.38428,
        "bertscore": {
            "precision": 0.94034,
            "recall": 0.94516,
            "f1": 0.93951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82952,
            "recall": 0.90741,
            "fmeasure": 0.86275
        },
        "rouge2": {
            "precision": 0.68363,
            "recall": 0.73682,
            "fmeasure": 0.70614
        },
        "rougeL": {
            "precision": 0.71835,
            "recall": 0.78238,
            "fmeasure": 0.74536
        },
        "rougeLsum": {
            "precision": 0.71835,
            "recall": 0.78238,
            "fmeasure": 0.74536
        },
        "bleu": 60.57312,
        "nist": 5.242185462819393,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.42857142857142855,
            "3": 0.90625
        },
        "nubia": {
            "semantic_relation": 4.62011,
            "contradiction": 10.86421,
            "irrelevancy": 20.51837,
            "logical_agreement": 68.61742,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.47636,
            "nubia_score": 0.89507
        },
        "meteor": 0.5057493081889597,
        "bleurt": 0.58736,
        "bertscore": {
            "precision": 0.95087,
            "recall": 0.97168,
            "f1": 0.96078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.69048,
            "fmeasure": 0.71605
        },
        "bleu": 73.11104,
        "nist": 4.777806403564686,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.80674,
            "contradiction": 0.22764,
            "irrelevancy": 0.4644,
            "logical_agreement": 99.30796,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.01094,
            "nubia_score": 0.97119
        },
        "meteor": 0.4718059540396743,
        "bleurt": 0.51047,
        "bertscore": {
            "precision": 0.97601,
            "recall": 0.96838,
            "f1": 0.97218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5947,
            "recall": 0.59552,
            "fmeasure": 0.58669
        },
        "rouge2": {
            "precision": 0.3706,
            "recall": 0.38932,
            "fmeasure": 0.37685
        },
        "rougeL": {
            "precision": 0.45076,
            "recall": 0.54122,
            "fmeasure": 0.47748
        },
        "rougeLsum": {
            "precision": 0.45076,
            "recall": 0.54122,
            "fmeasure": 0.47748
        },
        "bleu": 25.77128,
        "nist": 3.5877955928952256,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3870967741935484,
            "3": 0.72
        },
        "nubia": {
            "semantic_relation": 3.9324,
            "contradiction": 6.92497,
            "irrelevancy": 52.15236,
            "logical_agreement": 40.92267,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.50224,
            "nubia_score": 0.65141
        },
        "meteor": 0.2806623634383486,
        "bleurt": 0.01777,
        "bertscore": {
            "precision": 0.87962,
            "recall": 0.88762,
            "f1": 0.88042
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "mT5_large/totto_test",
        "N": 14,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65704,
            "recall": 0.59982,
            "fmeasure": 0.6113
        },
        "rouge2": {
            "precision": 0.35155,
            "recall": 0.31301,
            "fmeasure": 0.32337
        },
        "rougeL": {
            "precision": 0.50353,
            "recall": 0.46443,
            "fmeasure": 0.4718
        },
        "rougeLsum": {
            "precision": 0.50353,
            "recall": 0.46443,
            "fmeasure": 0.4718
        },
        "bleu": 27.92224,
        "nist": 4.867441828955415,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.17647058823529413,
            "3": 0.6121673003802282
        },
        "nubia": {
            "semantic_relation": 3.5719,
            "contradiction": 16.46521,
            "irrelevancy": 34.49212,
            "logical_agreement": 49.04268,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.16326,
            "nubia_score": 0.5638
        },
        "meteor": 0.2853805012771433,
        "bleurt": -0.09882,
        "bertscore": {
            "precision": 0.89315,
            "recall": 0.87841,
            "f1": 0.88463
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.74332,
            "fmeasure": 0.73077
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.38333,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.65152,
            "fmeasure": 0.5823
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.65152,
            "fmeasure": 0.5823
        },
        "bleu": 27.05411,
        "nist": 3.7757406667184576,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.9
        },
        "nubia": {
            "semantic_relation": 4.56167,
            "contradiction": 2.75275,
            "irrelevancy": 45.25098,
            "logical_agreement": 51.99627,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.69041,
            "nubia_score": 0.74359
        },
        "meteor": 0.3915488909665433,
        "bleurt": 0.3487,
        "bertscore": {
            "precision": 0.91395,
            "recall": 0.93961,
            "f1": 0.91155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.75092,
            "fmeasure": 0.68199
        },
        "rouge2": {
            "precision": 0.17778,
            "recall": 0.23737,
            "fmeasure": 0.20323
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.56838,
            "fmeasure": 0.49425
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.56838,
            "fmeasure": 0.49425
        },
        "bleu": 18.60534,
        "nist": 2.5784391034230167,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.93104,
            "contradiction": 6.06654,
            "irrelevancy": 39.25926,
            "logical_agreement": 54.6742,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.71559,
            "nubia_score": 0.58541
        },
        "meteor": 0.35600332355102254,
        "bleurt": 0.19337,
        "bertscore": {
            "precision": 0.90139,
            "recall": 0.91481,
            "f1": 0.90755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71487,
            "recall": 0.83899,
            "fmeasure": 0.77107
        },
        "rouge2": {
            "precision": 0.50256,
            "recall": 0.61939,
            "fmeasure": 0.55211
        },
        "rougeL": {
            "precision": 0.60376,
            "recall": 0.75845,
            "fmeasure": 0.67086
        },
        "rougeLsum": {
            "precision": 0.60376,
            "recall": 0.75845,
            "fmeasure": 0.67086
        },
        "bleu": 55.96392,
        "nist": 4.746893528573956,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6923076923076923,
            "3": 0.9
        },
        "nubia": {
            "semantic_relation": 4.56017,
            "contradiction": 0.30131,
            "irrelevancy": 46.56786,
            "logical_agreement": 53.13083,
            "grammar_ref": 4.38609,
            "grammar_hyp": 3.77084,
            "nubia_score": 0.80601
        },
        "meteor": 0.4874703750809253,
        "bleurt": 0.40346,
        "bertscore": {
            "precision": 0.93861,
            "recall": 0.95709,
            "f1": 0.94647
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79929,
            "recall": 0.66932,
            "fmeasure": 0.72165
        },
        "rouge2": {
            "precision": 0.46885,
            "recall": 0.41137,
            "fmeasure": 0.43506
        },
        "rougeL": {
            "precision": 0.57709,
            "recall": 0.49378,
            "fmeasure": 0.52701
        },
        "rougeLsum": {
            "precision": 0.57709,
            "recall": 0.49378,
            "fmeasure": 0.52701
        },
        "bleu": 38.60622,
        "nist": 5.06192479061712,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.6166666666666667,
            "3": 0.7065217391304348
        },
        "nubia": {
            "semantic_relation": 3.3417,
            "contradiction": 7.56736,
            "irrelevancy": 42.70945,
            "logical_agreement": 49.72319,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.46403,
            "nubia_score": 0.52012
        },
        "meteor": 0.3541223049044493,
        "bleurt": 0.10468,
        "bertscore": {
            "precision": 0.9229,
            "recall": 0.89406,
            "f1": 0.90734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5625,
            "fmeasure": 0.52778
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.12698,
            "fmeasure": 0.11806
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.45,
            "fmeasure": 0.42222
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.45,
            "fmeasure": 0.42222
        },
        "bleu": 9.66927,
        "nist": 1.57596654466627,
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nubia": {
            "semantic_relation": 3.38397,
            "contradiction": 0.39394,
            "irrelevancy": 1.83703,
            "logical_agreement": 97.76903,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.04195,
            "nubia_score": 0.59272
        },
        "meteor": 0.28252031817294126,
        "bleurt": 0.365,
        "bertscore": {
            "precision": 0.8821,
            "recall": 0.92299,
            "f1": 0.90208
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85497,
            "recall": 0.76243,
            "fmeasure": 0.7952
        },
        "rouge2": {
            "precision": 0.68783,
            "recall": 0.63828,
            "fmeasure": 0.65504
        },
        "rougeL": {
            "precision": 0.74503,
            "recall": 0.68653,
            "fmeasure": 0.70685
        },
        "rougeLsum": {
            "precision": 0.74503,
            "recall": 0.68653,
            "fmeasure": 0.70685
        },
        "bleu": 46.82147,
        "nist": 3.8360164559785503,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6792452830188679
        },
        "nubia": {
            "semantic_relation": 4.24459,
            "contradiction": 0.40388,
            "irrelevancy": 64.10146,
            "logical_agreement": 35.49466,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.65771,
            "nubia_score": 0.69266
        },
        "meteor": 0.3771766772445108,
        "bleurt": 0.47329,
        "bertscore": {
            "precision": 0.9548,
            "recall": 0.93431,
            "f1": 0.94414
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "mT5_large/totto_test",
        "N": 158,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73188,
            "recall": 0.70771,
            "fmeasure": 0.70762
        },
        "rouge2": {
            "precision": 0.48753,
            "recall": 0.47082,
            "fmeasure": 0.47074
        },
        "rougeL": {
            "precision": 0.62297,
            "recall": 0.60297,
            "fmeasure": 0.60225
        },
        "rougeLsum": {
            "precision": 0.62297,
            "recall": 0.60297,
            "fmeasure": 0.60225
        },
        "bleu": 42.62994,
        "nist": 7.54550727633536,
        "local_recall": {
            "1": 0.2332155477031802,
            "2": 0.42292490118577075,
            "3": 0.743894802755166
        },
        "nubia": {
            "semantic_relation": 4.10054,
            "contradiction": 9.01786,
            "irrelevancy": 33.7904,
            "logical_agreement": 57.19173,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.61715,
            "nubia_score": 0.709
        },
        "meteor": 0.38269496417768645,
        "bleurt": 0.22401,
        "bertscore": {
            "precision": 0.92237,
            "recall": 0.91834,
            "f1": 0.91859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.51429,
            "fmeasure": 0.62069
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.19559,
            "fmeasure": 0.24194
        },
        "rougeL": {
            "precision": 0.55072,
            "recall": 0.3619,
            "fmeasure": 0.43678
        },
        "rougeLsum": {
            "precision": 0.55072,
            "recall": 0.3619,
            "fmeasure": 0.43678
        },
        "bleu": 10.46159,
        "nist": 2.5158185957070125,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.782608695652174
        },
        "nubia": {
            "semantic_relation": 3.88917,
            "contradiction": 0.27442,
            "irrelevancy": 84.48861,
            "logical_agreement": 15.23697,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.51638,
            "nubia_score": 0.51585
        },
        "meteor": 0.3008768305562278,
        "bleurt": 0.07952,
        "bertscore": {
            "precision": 0.90885,
            "recall": 0.90062,
            "f1": 0.90191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62222,
            "recall": 0.63431,
            "fmeasure": 0.6222
        },
        "rouge2": {
            "precision": 0.33603,
            "recall": 0.36076,
            "fmeasure": 0.34606
        },
        "rougeL": {
            "precision": 0.53519,
            "recall": 0.55385,
            "fmeasure": 0.54105
        },
        "rougeLsum": {
            "precision": 0.53519,
            "recall": 0.55385,
            "fmeasure": 0.54105
        },
        "bleu": 30.54925,
        "nist": 3.322422084596098,
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.6818181818181818
        },
        "nubia": {
            "semantic_relation": 3.83977,
            "contradiction": 5.87284,
            "irrelevancy": 59.13107,
            "logical_agreement": 34.99608,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.23702,
            "nubia_score": 0.57984
        },
        "meteor": 0.31510004626291754,
        "bleurt": 0.0921,
        "bertscore": {
            "precision": 0.88728,
            "recall": 0.90144,
            "f1": 0.89365
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72667,
            "recall": 0.81371,
            "fmeasure": 0.76518
        },
        "rouge2": {
            "precision": 0.56206,
            "recall": 0.64891,
            "fmeasure": 0.6019
        },
        "rougeL": {
            "precision": 0.69,
            "recall": 0.75292,
            "fmeasure": 0.71775
        },
        "rougeLsum": {
            "precision": 0.69,
            "recall": 0.75292,
            "fmeasure": 0.71775
        },
        "bleu": 50.34596,
        "nist": 4.680771668928704,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.5625,
            "3": 0.9642857142857143
        },
        "nubia": {
            "semantic_relation": 3.95308,
            "contradiction": 33.42339,
            "irrelevancy": 21.73285,
            "logical_agreement": 44.84375,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.26191,
            "nubia_score": 0.67935
        },
        "meteor": 0.43197701626379736,
        "bleurt": 0.39721,
        "bertscore": {
            "precision": 0.93637,
            "recall": 0.95946,
            "f1": 0.9448
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68733,
            "recall": 0.69152,
            "fmeasure": 0.66926
        },
        "rouge2": {
            "precision": 0.53832,
            "recall": 0.51181,
            "fmeasure": 0.51159
        },
        "rougeL": {
            "precision": 0.62817,
            "recall": 0.61717,
            "fmeasure": 0.60431
        },
        "rougeLsum": {
            "precision": 0.62817,
            "recall": 0.61717,
            "fmeasure": 0.60431
        },
        "bleu": 38.98282,
        "nist": 4.514777222478627,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.6666666666666666,
            "3": 0.6902654867256637
        },
        "nubia": {
            "semantic_relation": 3.34018,
            "contradiction": 14.61018,
            "irrelevancy": 32.60895,
            "logical_agreement": 52.78087,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.18124,
            "nubia_score": 0.47078
        },
        "meteor": 0.3626391160966793,
        "bleurt": 0.0709,
        "bertscore": {
            "precision": 0.8915,
            "recall": 0.90786,
            "f1": 0.89689
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75938,
            "recall": 0.83223,
            "fmeasure": 0.78759
        },
        "rouge2": {
            "precision": 0.59714,
            "recall": 0.66267,
            "fmeasure": 0.62014
        },
        "rougeL": {
            "precision": 0.68938,
            "recall": 0.75985,
            "fmeasure": 0.71692
        },
        "rougeLsum": {
            "precision": 0.68938,
            "recall": 0.75985,
            "fmeasure": 0.71692
        },
        "bleu": 50.7063,
        "nist": 4.506293540634618,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nubia": {
            "semantic_relation": 4.10059,
            "contradiction": 39.86911,
            "irrelevancy": 33.39477,
            "logical_agreement": 26.73611,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.02308,
            "nubia_score": 0.71926
        },
        "meteor": 0.4637286201720387,
        "bleurt": 0.50553,
        "bertscore": {
            "precision": 0.95023,
            "recall": 0.96583,
            "f1": 0.95483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.93333,
            "fmeasure": 0.94737
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9697,
            "fmeasure": 0.98413
        },
        "bleu": 100.0,
        "nist": 4.2252432046274455,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.90342,
            "contradiction": 0.51575,
            "irrelevancy": 0.49867,
            "logical_agreement": 98.98557,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.39887,
            "nubia_score": 0.94888
        },
        "meteor": 1.0,
        "bleurt": 0.70774,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58924,
            "recall": 0.54231,
            "fmeasure": 0.54979
        },
        "rouge2": {
            "precision": 0.21602,
            "recall": 0.2056,
            "fmeasure": 0.20714
        },
        "rougeL": {
            "precision": 0.4607,
            "recall": 0.44868,
            "fmeasure": 0.44438
        },
        "rougeLsum": {
            "precision": 0.4607,
            "recall": 0.44868,
            "fmeasure": 0.44438
        },
        "bleu": 12.76987,
        "nist": 3.02961921940125,
        "local_recall": {
            "1": 0.1,
            "2": 0.6666666666666666,
            "3": 0.5151515151515151
        },
        "nubia": {
            "semantic_relation": 3.91853,
            "contradiction": 0.76801,
            "irrelevancy": 35.5645,
            "logical_agreement": 63.66749,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.12828,
            "nubia_score": 0.60015
        },
        "meteor": 0.25920457425032495,
        "bleurt": 0.08132,
        "bertscore": {
            "precision": 0.86489,
            "recall": 0.89392,
            "f1": 0.87822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.97368,
            "recall": 0.91621,
            "fmeasure": 0.94124
        },
        "rouge2": {
            "precision": 0.90278,
            "recall": 0.86591,
            "fmeasure": 0.88268
        },
        "rougeL": {
            "precision": 0.95175,
            "recall": 0.88839,
            "fmeasure": 0.91506
        },
        "rougeLsum": {
            "precision": 0.95175,
            "recall": 0.88839,
            "fmeasure": 0.91506
        },
        "bleu": 70.55666,
        "nist": 5.2067887679237135,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8780487804878049
        },
        "nubia": {
            "semantic_relation": 4.65734,
            "contradiction": 0.27415,
            "irrelevancy": 8.7405,
            "logical_agreement": 90.98535,
            "grammar_ref": 5.18336,
            "grammar_hyp": 4.96941,
            "nubia_score": 0.90085
        },
        "meteor": 0.532019796127944,
        "bleurt": 0.6969,
        "bertscore": {
            "precision": 0.98075,
            "recall": 0.9771,
            "f1": 0.97772
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "mT5_large/totto_test",
        "N": 35,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79854,
            "recall": 0.76412,
            "fmeasure": 0.77531
        },
        "rouge2": {
            "precision": 0.56195,
            "recall": 0.5464,
            "fmeasure": 0.55024
        },
        "rougeL": {
            "precision": 0.69772,
            "recall": 0.67143,
            "fmeasure": 0.67969
        },
        "rougeLsum": {
            "precision": 0.69772,
            "recall": 0.67143,
            "fmeasure": 0.67969
        },
        "bleu": 51.80963,
        "nist": 6.636999173898286,
        "local_recall": {
            "1": 0.21839080459770116,
            "2": 0.49038461538461536,
            "3": 0.8040345821325648
        },
        "nubia": {
            "semantic_relation": 4.32791,
            "contradiction": 1.80035,
            "irrelevancy": 17.10891,
            "logical_agreement": 81.09074,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.17004,
            "nubia_score": 0.8142
        },
        "meteor": 0.426012647212165,
        "bleurt": 0.47205,
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94241,
            "f1": 0.94357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83274,
            "recall": 0.87341,
            "fmeasure": 0.85145
        },
        "rouge2": {
            "precision": 0.71295,
            "recall": 0.74487,
            "fmeasure": 0.72762
        },
        "rougeL": {
            "precision": 0.7994,
            "recall": 0.83319,
            "fmeasure": 0.81505
        },
        "rougeLsum": {
            "precision": 0.7994,
            "recall": 0.83319,
            "fmeasure": 0.81505
        },
        "bleu": 56.7445,
        "nist": 4.667335404865584,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.847457627118644
        },
        "nubia": {
            "semantic_relation": 4.66106,
            "contradiction": 0.47288,
            "irrelevancy": 0.87707,
            "logical_agreement": 98.65005,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.66156,
            "nubia_score": 0.86562
        },
        "meteor": 0.4717088103035567,
        "bleurt": 0.79698,
        "bertscore": {
            "precision": 0.97665,
            "recall": 0.97862,
            "f1": 0.97745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54762,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "bleu": 51.31108,
        "nist": 2.9487445430153727,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.91614,
            "contradiction": 0.68707,
            "irrelevancy": 0.60509,
            "logical_agreement": 98.70784,
            "grammar_ref": 5.94246,
            "grammar_hyp": 6.87586,
            "nubia_score": 0.87589
        },
        "meteor": 0.4561301812414779,
        "bleurt": 0.59368,
        "bertscore": {
            "precision": 0.98804,
            "recall": 0.97187,
            "f1": 0.97989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.3219280948873626,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 1.00634,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71784,
            "recall": 0.77789,
            "fmeasure": 0.73927
        },
        "rouge2": {
            "precision": 0.42705,
            "recall": 0.45852,
            "fmeasure": 0.43745
        },
        "rougeL": {
            "precision": 0.49614,
            "recall": 0.53253,
            "fmeasure": 0.50986
        },
        "rougeLsum": {
            "precision": 0.49614,
            "recall": 0.53253,
            "fmeasure": 0.50986
        },
        "bleu": 35.75498,
        "nist": 4.943882026729428,
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.3125,
            "3": 0.8611111111111112
        },
        "nubia": {
            "semantic_relation": 4.22969,
            "contradiction": 1.08695,
            "irrelevancy": 11.3387,
            "logical_agreement": 87.57435,
            "grammar_ref": 4.10939,
            "grammar_hyp": 3.69956,
            "nubia_score": 0.8017
        },
        "meteor": 0.4086911346681856,
        "bleurt": 0.1945,
        "bertscore": {
            "precision": 0.91431,
            "recall": 0.9334,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90963,
            "recall": 0.92161,
            "fmeasure": 0.91234
        },
        "rouge2": {
            "precision": 0.76834,
            "recall": 0.79139,
            "fmeasure": 0.77658
        },
        "rougeL": {
            "precision": 0.88331,
            "recall": 0.89876,
            "fmeasure": 0.88741
        },
        "rougeLsum": {
            "precision": 0.88331,
            "recall": 0.89876,
            "fmeasure": 0.88741
        },
        "bleu": 74.0399,
        "nist": 5.857923843763493,
        "local_recall": {
            "1": 0.25,
            "2": 0.7692307692307693,
            "3": 0.9761904761904762
        },
        "nubia": {
            "semantic_relation": 4.52623,
            "contradiction": 22.27667,
            "irrelevancy": 22.49295,
            "logical_agreement": 55.23038,
            "grammar_ref": 4.0718,
            "grammar_hyp": 3.98096,
            "nubia_score": 0.88365
        },
        "meteor": 0.5392898868668917,
        "bleurt": 0.64359,
        "bertscore": {
            "precision": 0.97822,
            "recall": 0.98122,
            "f1": 0.97888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76389,
            "recall": 0.58841,
            "fmeasure": 0.66398
        },
        "rouge2": {
            "precision": 0.50568,
            "recall": 0.37619,
            "fmeasure": 0.43086
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.56096,
            "fmeasure": 0.62567
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.56096,
            "fmeasure": 0.62567
        },
        "bleu": 35.44597,
        "nist": 3.207444946768149,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.2,
            "3": 0.65
        },
        "nubia": {
            "semantic_relation": 4.19421,
            "contradiction": 12.32689,
            "irrelevancy": 23.92805,
            "logical_agreement": 63.74505,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.28074,
            "nubia_score": 0.80666
        },
        "meteor": 0.35946041557644015,
        "bleurt": 0.25898,
        "bertscore": {
            "precision": 0.94804,
            "recall": 0.90947,
            "f1": 0.92835
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74239,
            "recall": 0.83069,
            "fmeasure": 0.77082
        },
        "rouge2": {
            "precision": 0.59286,
            "recall": 0.6214,
            "fmeasure": 0.5983
        },
        "rougeL": {
            "precision": 0.68948,
            "recall": 0.78307,
            "fmeasure": 0.72094
        },
        "rougeLsum": {
            "precision": 0.68948,
            "recall": 0.78307,
            "fmeasure": 0.72094
        },
        "bleu": 48.70019,
        "nist": 4.372166554935815,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.5294117647058824,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.20899,
            "contradiction": 0.38801,
            "irrelevancy": 50.06136,
            "logical_agreement": 49.55063,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.89605,
            "nubia_score": 0.75886
        },
        "meteor": 0.3607739373385057,
        "bleurt": 0.4859,
        "bertscore": {
            "precision": 0.95331,
            "recall": 0.96607,
            "f1": 0.95962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.58333,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27273,
            "fmeasure": 0.26087
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "bleu": 12.09034,
        "nist": 1.67298250033654,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.29838,
            "contradiction": 0.39979,
            "irrelevancy": 72.01414,
            "logical_agreement": 27.58608,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.25841,
            "nubia_score": 0.8416
        },
        "meteor": 0.3066423912784973,
        "bleurt": 0.28556,
        "bertscore": {
            "precision": 0.8439,
            "recall": 0.82506,
            "f1": 0.83438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83915,
            "recall": 0.7612,
            "fmeasure": 0.78112
        },
        "rouge2": {
            "precision": 0.55434,
            "recall": 0.49993,
            "fmeasure": 0.51293
        },
        "rougeL": {
            "precision": 0.72473,
            "recall": 0.65117,
            "fmeasure": 0.67035
        },
        "rougeLsum": {
            "precision": 0.72473,
            "recall": 0.65117,
            "fmeasure": 0.67035
        },
        "bleu": 46.47823,
        "nist": 4.95483390687125,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.6666666666666666,
            "3": 0.85
        },
        "nubia": {
            "semantic_relation": 4.26043,
            "contradiction": 3.20821,
            "irrelevancy": 7.38081,
            "logical_agreement": 89.41098,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.31893,
            "nubia_score": 0.74454
        },
        "meteor": 0.4035681165473742,
        "bleurt": 0.36195,
        "bertscore": {
            "precision": 0.9481,
            "recall": 0.92366,
            "f1": 0.93301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92419,
            "recall": 0.86394,
            "fmeasure": 0.88848
        },
        "rouge2": {
            "precision": 0.85701,
            "recall": 0.80542,
            "fmeasure": 0.82581
        },
        "rougeL": {
            "precision": 0.89535,
            "recall": 0.83715,
            "fmeasure": 0.86071
        },
        "rougeLsum": {
            "precision": 0.89535,
            "recall": 0.83715,
            "fmeasure": 0.86071
        },
        "bleu": 72.11722,
        "nist": 6.13559114532913,
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8773584905660378
        },
        "nubia": {
            "semantic_relation": 4.36513,
            "contradiction": 0.60882,
            "irrelevancy": 17.15899,
            "logical_agreement": 82.23219,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.21918,
            "nubia_score": 0.76506
        },
        "meteor": 0.49791053949106107,
        "bleurt": 0.58011,
        "bertscore": {
            "precision": 0.96955,
            "recall": 0.95192,
            "f1": 0.96004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.75962,
            "fmeasure": 0.60282
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.69697,
            "fmeasure": 0.54253
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.75962,
            "fmeasure": 0.60282
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.75962,
            "fmeasure": 0.60282
        },
        "bleu": 34.7725,
        "nist": 1.852434979701663,
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "nubia": {
            "semantic_relation": 2.87982,
            "contradiction": 53.89148,
            "irrelevancy": 45.48232,
            "logical_agreement": 0.6262,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.625,
            "nubia_score": 0.47813
        },
        "meteor": 0.39546473587779346,
        "bleurt": 0.32497,
        "bertscore": {
            "precision": 0.87184,
            "recall": 0.92719,
            "f1": 0.89867
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86461,
            "recall": 0.79444,
            "fmeasure": 0.80218
        },
        "rouge2": {
            "precision": 0.62157,
            "recall": 0.59527,
            "fmeasure": 0.59326
        },
        "rougeL": {
            "precision": 0.79518,
            "recall": 0.7508,
            "fmeasure": 0.75216
        },
        "rougeLsum": {
            "precision": 0.79518,
            "recall": 0.7508,
            "fmeasure": 0.75216
        },
        "bleu": 59.41177,
        "nist": 5.251144167436096,
        "local_recall": {
            "1": 0.125,
            "2": 0.8125,
            "3": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 4.17815,
            "contradiction": 19.54105,
            "irrelevancy": 16.88972,
            "logical_agreement": 63.56923,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.45112,
            "nubia_score": 0.75975
        },
        "meteor": 0.44566575442980455,
        "bleurt": 0.38939,
        "bertscore": {
            "precision": 0.9546,
            "recall": 0.93983,
            "f1": 0.94438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.875,
            "fmeasure": 0.875
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "bleu": 87.25129,
        "nist": 4.688416462507053,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91372,
            "contradiction": 0.60581,
            "irrelevancy": 5.68424,
            "logical_agreement": 93.70995,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.58917,
            "nubia_score": 0.95428
        },
        "meteor": 0.6075503159367284,
        "bleurt": 0.60787,
        "bertscore": {
            "precision": 0.97138,
            "recall": 0.97922,
            "f1": 0.97528
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65584,
            "recall": 0.66545,
            "fmeasure": 0.64099
        },
        "rouge2": {
            "precision": 0.39121,
            "recall": 0.42014,
            "fmeasure": 0.39348
        },
        "rougeL": {
            "precision": 0.54268,
            "recall": 0.56083,
            "fmeasure": 0.53393
        },
        "rougeLsum": {
            "precision": 0.54268,
            "recall": 0.56083,
            "fmeasure": 0.53393
        },
        "bleu": 33.62097,
        "nist": 4.480250575007702,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6666666666666666,
            "3": 0.6933333333333334
        },
        "nubia": {
            "semantic_relation": 3.13234,
            "contradiction": 28.36735,
            "irrelevancy": 48.85156,
            "logical_agreement": 22.78108,
            "grammar_ref": 3.87874,
            "grammar_hyp": 3.96833,
            "nubia_score": 0.50941
        },
        "meteor": 0.314272314837994,
        "bleurt": -0.15041,
        "bertscore": {
            "precision": 0.88666,
            "recall": 0.89759,
            "f1": 0.89112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.45861,
            "recall": 0.73597,
            "fmeasure": 0.5507
        },
        "rouge2": {
            "precision": 0.26865,
            "recall": 0.44446,
            "fmeasure": 0.32191
        },
        "rougeL": {
            "precision": 0.4175,
            "recall": 0.67459,
            "fmeasure": 0.50065
        },
        "rougeLsum": {
            "precision": 0.4175,
            "recall": 0.67459,
            "fmeasure": 0.50065
        },
        "bleu": 21.53445,
        "nist": 2.831129638167086,
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.7692307692307693
        },
        "nubia": {
            "semantic_relation": 3.5619,
            "contradiction": 11.04543,
            "irrelevancy": 65.69111,
            "logical_agreement": 23.26346,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.66275,
            "nubia_score": 0.60734
        },
        "meteor": 0.3825422215509617,
        "bleurt": -0.11764,
        "bertscore": {
            "precision": 0.8068,
            "recall": 0.91507,
            "f1": 0.85147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "bleu": 41.11336,
        "nist": 2.1055161915432032,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543,
        "bleurt": 0.18287,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.55988,
            "fmeasure": 0.60741
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.20875,
            "fmeasure": 0.22704
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.2479,
            "fmeasure": 0.26852
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.2479,
            "fmeasure": 0.26852
        },
        "bleu": 12.65309,
        "nist": 3.2003738496791025,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "nubia": {
            "semantic_relation": 3.73343,
            "contradiction": 6.32617,
            "irrelevancy": 24.63763,
            "logical_agreement": 69.0362,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.24441,
            "nubia_score": 0.42466
        },
        "meteor": 0.2871086767237462,
        "bleurt": -0.42833,
        "bertscore": {
            "precision": 0.84174,
            "recall": 0.83757,
            "f1": 0.83965
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.47013,
            "fmeasure": 0.59183
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.21667,
            "fmeasure": 0.27446
        },
        "rougeL": {
            "precision": 0.50667,
            "recall": 0.28597,
            "fmeasure": 0.36534
        },
        "rougeLsum": {
            "precision": 0.50667,
            "recall": 0.28597,
            "fmeasure": 0.36534
        },
        "bleu": 15.7145,
        "nist": 1.2471332712171332,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.46478,
            "contradiction": 15.82311,
            "irrelevancy": 76.24835,
            "logical_agreement": 7.92853,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.03908,
            "nubia_score": 0.42
        },
        "meteor": 0.23311184530419024,
        "bleurt": -0.24572,
        "bertscore": {
            "precision": 0.90029,
            "recall": 0.84315,
            "f1": 0.86963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87202,
            "recall": 0.83443,
            "fmeasure": 0.85219
        },
        "rouge2": {
            "precision": 0.71736,
            "recall": 0.69174,
            "fmeasure": 0.70379
        },
        "rougeL": {
            "precision": 0.72962,
            "recall": 0.69508,
            "fmeasure": 0.71114
        },
        "rougeLsum": {
            "precision": 0.72962,
            "recall": 0.69508,
            "fmeasure": 0.71114
        },
        "bleu": 65.51486,
        "nist": 6.061056892847404,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.25,
            "3": 0.8701298701298701
        },
        "nubia": {
            "semantic_relation": 4.58178,
            "contradiction": 0.3092,
            "irrelevancy": 13.59978,
            "logical_agreement": 86.09102,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.71562,
            "nubia_score": 0.87037
        },
        "meteor": 0.48795674602229927,
        "bleurt": 0.5478,
        "bertscore": {
            "precision": 0.96071,
            "recall": 0.95781,
            "f1": 0.95923
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4375,
            "recall": 0.63889,
            "fmeasure": 0.51333
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.20192,
            "fmeasure": 0.15839
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.54762,
            "fmeasure": 0.44
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.54762,
            "fmeasure": 0.44
        },
        "bleu": 6.2911,
        "nist": 1.7068565485462488,
        "local_recall": {
            "1": 0.125,
            "2": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.02995,
            "contradiction": 49.38896,
            "irrelevancy": 50.28163,
            "logical_agreement": 0.32941,
            "grammar_ref": 5.58883,
            "grammar_hyp": 3.96675,
            "nubia_score": 0.48088
        },
        "meteor": 0.333711487285593,
        "bleurt": 0.34491,
        "bertscore": {
            "precision": 0.84923,
            "recall": 0.92207,
            "f1": 0.88415
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "bleu": 70.16879,
        "nist": 3.0286497677077553,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "meteor": 0.5613051214200641,
        "bleurt": 0.76221,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.49444,
            "recall": 0.83003,
            "fmeasure": 0.59035
        },
        "rouge2": {
            "precision": 0.29475,
            "recall": 0.52768,
            "fmeasure": 0.3575
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.747,
            "fmeasure": 0.52934
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.747,
            "fmeasure": 0.52934
        },
        "bleu": 18.21424,
        "nist": 2.1548392328925177,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.16666666666666666,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 3.82653,
            "contradiction": 0.41998,
            "irrelevancy": 49.69346,
            "logical_agreement": 49.88656,
            "grammar_ref": 4.76014,
            "grammar_hyp": 4.39993,
            "nubia_score": 0.45279
        },
        "meteor": 0.3584819782898788,
        "bleurt": -0.10793,
        "bertscore": {
            "precision": 0.85591,
            "recall": 0.93932,
            "f1": 0.89441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.79365,
            "fmeasure": 0.67778
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "bleu": 90.3602,
        "nist": 4.35896469898143,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.66049,
            "contradiction": 0.15167,
            "irrelevancy": 97.75078,
            "logical_agreement": 2.09756,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.39823,
            "nubia_score": 0.81537
        },
        "meteor": 0.5330273631654674,
        "bleurt": 0.45305,
        "bertscore": {
            "precision": 0.94724,
            "recall": 0.95307,
            "f1": 0.93621
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "mT5_large/totto_test",
        "N": 131,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76716,
            "recall": 0.72486,
            "fmeasure": 0.73413
        },
        "rouge2": {
            "precision": 0.52577,
            "recall": 0.4973,
            "fmeasure": 0.50235
        },
        "rougeL": {
            "precision": 0.66518,
            "recall": 0.62879,
            "fmeasure": 0.63606
        },
        "rougeLsum": {
            "precision": 0.66518,
            "recall": 0.62879,
            "fmeasure": 0.63606
        },
        "bleu": 44.41036,
        "nist": 7.667072698155828,
        "local_recall": {
            "1": 0.20424403183023873,
            "2": 0.4879807692307692,
            "3": 0.7531556802244039
        },
        "nubia": {
            "semantic_relation": 4.20977,
            "contradiction": 10.574,
            "irrelevancy": 29.5631,
            "logical_agreement": 59.86291,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.73065,
            "nubia_score": 0.70694
        },
        "meteor": 0.3829996379094003,
        "bleurt": 0.2377,
        "bertscore": {
            "precision": 0.9259,
            "recall": 0.92264,
            "f1": 0.92296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88006,
            "recall": 0.9254,
            "fmeasure": 0.89894
        },
        "rouge2": {
            "precision": 0.79488,
            "recall": 0.84528,
            "fmeasure": 0.815
        },
        "rougeL": {
            "precision": 0.81468,
            "recall": 0.86736,
            "fmeasure": 0.83741
        },
        "rougeLsum": {
            "precision": 0.81468,
            "recall": 0.86736,
            "fmeasure": 0.83741
        },
        "bleu": 68.89193,
        "nist": 5.889881958846153,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5454545454545454,
            "3": 0.9245283018867925
        },
        "nubia": {
            "semantic_relation": 4.78745,
            "contradiction": 0.25431,
            "irrelevancy": 19.689,
            "logical_agreement": 80.05669,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.90573,
            "nubia_score": 0.92528
        },
        "meteor": 0.5181885474022824,
        "bleurt": 0.7178,
        "bertscore": {
            "precision": 0.96972,
            "recall": 0.97458,
            "f1": 0.9717
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "bleu": 77.16836,
        "nist": 5.020945219921343,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "nubia": {
            "semantic_relation": 4.50089,
            "contradiction": 0.50269,
            "irrelevancy": 45.65582,
            "logical_agreement": 53.84149,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.88309,
            "nubia_score": 0.81921
        },
        "meteor": 0.5769639229603134,
        "bleurt": 0.65711,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.97968,
            "f1": 0.97166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79327,
            "recall": 0.75907,
            "fmeasure": 0.76692
        },
        "rouge2": {
            "precision": 0.4802,
            "recall": 0.46586,
            "fmeasure": 0.4682
        },
        "rougeL": {
            "precision": 0.67174,
            "recall": 0.61629,
            "fmeasure": 0.63515
        },
        "rougeLsum": {
            "precision": 0.67174,
            "recall": 0.61629,
            "fmeasure": 0.63515
        },
        "bleu": 33.24542,
        "nist": 4.677707906758733,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6,
            "3": 0.7636363636363637
        },
        "nubia": {
            "semantic_relation": 4.14557,
            "contradiction": 0.57386,
            "irrelevancy": 37.90948,
            "logical_agreement": 61.51665,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.58997,
            "nubia_score": 0.67652
        },
        "meteor": 0.3715338408282345,
        "bleurt": 0.24192,
        "bertscore": {
            "precision": 0.9247,
            "recall": 0.91486,
            "f1": 0.91847
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80152,
            "recall": 0.7447,
            "fmeasure": 0.77181
        },
        "rouge2": {
            "precision": 0.55741,
            "recall": 0.51414,
            "fmeasure": 0.53467
        },
        "rougeL": {
            "precision": 0.80152,
            "recall": 0.7447,
            "fmeasure": 0.77181
        },
        "rougeLsum": {
            "precision": 0.80152,
            "recall": 0.7447,
            "fmeasure": 0.77181
        },
        "bleu": 45.98721,
        "nist": 3.97922175393954,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "nubia": {
            "semantic_relation": 4.69877,
            "contradiction": 1.87847,
            "irrelevancy": 0.85506,
            "logical_agreement": 97.26647,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.64848,
            "nubia_score": 0.82856
        },
        "meteor": 0.44406217723607755,
        "bleurt": 0.80943,
        "bertscore": {
            "precision": 0.97123,
            "recall": 0.95448,
            "f1": 0.96275
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80401,
            "recall": 0.75406,
            "fmeasure": 0.76912
        },
        "rouge2": {
            "precision": 0.51696,
            "recall": 0.47471,
            "fmeasure": 0.48914
        },
        "rougeL": {
            "precision": 0.71888,
            "recall": 0.66672,
            "fmeasure": 0.68377
        },
        "rougeLsum": {
            "precision": 0.71888,
            "recall": 0.66672,
            "fmeasure": 0.68377
        },
        "bleu": 43.09292,
        "nist": 5.3054315091906465,
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7611940298507462
        },
        "nubia": {
            "semantic_relation": 4.06503,
            "contradiction": 14.08877,
            "irrelevancy": 54.70584,
            "logical_agreement": 31.20539,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.341,
            "nubia_score": 0.64346
        },
        "meteor": 0.40476005969412576,
        "bleurt": 0.14541,
        "bertscore": {
            "precision": 0.94015,
            "recall": 0.9225,
            "f1": 0.92839
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72378,
            "recall": 0.75126,
            "fmeasure": 0.73574
        },
        "rouge2": {
            "precision": 0.50833,
            "recall": 0.52879,
            "fmeasure": 0.51772
        },
        "rougeL": {
            "precision": 0.72378,
            "recall": 0.75126,
            "fmeasure": 0.73574
        },
        "rougeLsum": {
            "precision": 0.72378,
            "recall": 0.75126,
            "fmeasure": 0.73574
        },
        "bleu": 54.66167,
        "nist": 4.175062544770933,
        "local_recall": {
            "1": 0.1,
            "2": 0.6666666666666666,
            "3": 0.7894736842105263
        },
        "nubia": {
            "semantic_relation": 4.53834,
            "contradiction": 0.44805,
            "irrelevancy": 51.73375,
            "logical_agreement": 47.8182,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.36255,
            "nubia_score": 0.82861
        },
        "meteor": 0.38106742197660076,
        "bleurt": 0.56871,
        "bertscore": {
            "precision": 0.93749,
            "recall": 0.95546,
            "f1": 0.94481
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81151,
            "recall": 0.87817,
            "fmeasure": 0.83929
        },
        "rouge2": {
            "precision": 0.65568,
            "recall": 0.71365,
            "fmeasure": 0.67886
        },
        "rougeL": {
            "precision": 0.81151,
            "recall": 0.87817,
            "fmeasure": 0.83929
        },
        "rougeLsum": {
            "precision": 0.81151,
            "recall": 0.87817,
            "fmeasure": 0.83929
        },
        "bleu": 61.56603,
        "nist": 5.056120791605725,
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.8666666666666667,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 3.65561,
            "contradiction": 50.13532,
            "irrelevancy": 0.60851,
            "logical_agreement": 49.25616,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.07778,
            "nubia_score": 0.62039
        },
        "meteor": 0.4792231401291696,
        "bleurt": 0.52643,
        "bertscore": {
            "precision": 0.95961,
            "recall": 0.95443,
            "f1": 0.95694
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65194,
            "recall": 0.59973,
            "fmeasure": 0.60394
        },
        "rouge2": {
            "precision": 0.33279,
            "recall": 0.29757,
            "fmeasure": 0.29988
        },
        "rougeL": {
            "precision": 0.54769,
            "recall": 0.52158,
            "fmeasure": 0.5176
        },
        "rougeLsum": {
            "precision": 0.54769,
            "recall": 0.52158,
            "fmeasure": 0.5176
        },
        "bleu": 26.7084,
        "nist": 3.5089241293632005,
        "local_recall": {
            "1": 0.038461538461538464,
            "2": 0.625,
            "3": 0.6521739130434783
        },
        "nubia": {
            "semantic_relation": 3.70461,
            "contradiction": 30.24315,
            "irrelevancy": 39.86335,
            "logical_agreement": 29.8935,
            "grammar_ref": 5.09695,
            "grammar_hyp": 5.04342,
            "nubia_score": 0.53764
        },
        "meteor": 0.3076792896599145,
        "bleurt": 0.06237,
        "bertscore": {
            "precision": 0.90679,
            "recall": 0.88337,
            "f1": 0.89443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62968,
            "recall": 0.76528,
            "fmeasure": 0.68514
        },
        "rouge2": {
            "precision": 0.44695,
            "recall": 0.55043,
            "fmeasure": 0.48816
        },
        "rougeL": {
            "precision": 0.60885,
            "recall": 0.74444,
            "fmeasure": 0.66431
        },
        "rougeLsum": {
            "precision": 0.60885,
            "recall": 0.74444,
            "fmeasure": 0.66431
        },
        "bleu": 39.32437,
        "nist": 3.907064787740101,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.5333333333333333,
            "3": 0.9393939393939394
        },
        "nubia": {
            "semantic_relation": 3.66403,
            "contradiction": 16.10205,
            "irrelevancy": 49.5219,
            "logical_agreement": 34.37606,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.60462,
            "nubia_score": 0.58338
        },
        "meteor": 0.3998947879761964,
        "bleurt": 0.08695,
        "bertscore": {
            "precision": 0.8858,
            "recall": 0.93016,
            "f1": 0.90678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.729,
            "recall": 0.76336,
            "fmeasure": 0.74158
        },
        "rouge2": {
            "precision": 0.56712,
            "recall": 0.58071,
            "fmeasure": 0.56985
        },
        "rougeL": {
            "precision": 0.64238,
            "recall": 0.65299,
            "fmeasure": 0.64446
        },
        "rougeLsum": {
            "precision": 0.64238,
            "recall": 0.65299,
            "fmeasure": 0.64446
        },
        "bleu": 51.98161,
        "nist": 5.312431468668421,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.7,
            "3": 0.7808219178082192
        },
        "nubia": {
            "semantic_relation": 4.25186,
            "contradiction": 8.74292,
            "irrelevancy": 27.51652,
            "logical_agreement": 63.74057,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.59827,
            "nubia_score": 0.78463
        },
        "meteor": 0.42491406099615026,
        "bleurt": 0.25978,
        "bertscore": {
            "precision": 0.91612,
            "recall": 0.92845,
            "f1": 0.92074
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "bleu": 42.95749,
        "nist": 2.6330370023236713,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "meteor": 0.42350497485471644,
        "bleurt": 0.45492,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77105,
            "recall": 0.78598,
            "fmeasure": 0.77541
        },
        "rouge2": {
            "precision": 0.58957,
            "recall": 0.60325,
            "fmeasure": 0.59397
        },
        "rougeL": {
            "precision": 0.66225,
            "recall": 0.69097,
            "fmeasure": 0.67122
        },
        "rougeLsum": {
            "precision": 0.66225,
            "recall": 0.69097,
            "fmeasure": 0.67122
        },
        "bleu": 46.97043,
        "nist": 5.37813364833286,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.38095238095238093,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.27699,
            "contradiction": 0.79321,
            "irrelevancy": 54.03518,
            "logical_agreement": 45.17161,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.74482,
            "nubia_score": 0.74371
        },
        "meteor": 0.4458910526937887,
        "bleurt": 0.1963,
        "bertscore": {
            "precision": 0.92836,
            "recall": 0.93237,
            "f1": 0.92822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "bleu": 100.0,
        "nist": 4.01117167855772,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "meteor": 1.0,
        "bleurt": 0.77386,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59142,
            "recall": 0.56112,
            "fmeasure": 0.55988
        },
        "rouge2": {
            "precision": 0.29667,
            "recall": 0.28989,
            "fmeasure": 0.28404
        },
        "rougeL": {
            "precision": 0.48771,
            "recall": 0.4725,
            "fmeasure": 0.46564
        },
        "rougeLsum": {
            "precision": 0.48771,
            "recall": 0.4725,
            "fmeasure": 0.46564
        },
        "bleu": 22.29575,
        "nist": 4.066225490238644,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.45454545454545453,
            "3": 0.6571428571428571
        },
        "nubia": {
            "semantic_relation": 3.10633,
            "contradiction": 56.72456,
            "irrelevancy": 41.3387,
            "logical_agreement": 1.93674,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.66084,
            "nubia_score": 0.40688
        },
        "meteor": 0.28272428499734464,
        "bleurt": -0.11384,
        "bertscore": {
            "precision": 0.88788,
            "recall": 0.89125,
            "f1": 0.88843
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59696,
            "recall": 0.54588,
            "fmeasure": 0.5645
        },
        "rouge2": {
            "precision": 0.28358,
            "recall": 0.26264,
            "fmeasure": 0.27047
        },
        "rougeL": {
            "precision": 0.47248,
            "recall": 0.42708,
            "fmeasure": 0.44498
        },
        "rougeLsum": {
            "precision": 0.47248,
            "recall": 0.42708,
            "fmeasure": 0.44498
        },
        "bleu": 27.87052,
        "nist": 4.203946866545377,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.48101,
            "contradiction": 6.07424,
            "irrelevancy": 38.06673,
            "logical_agreement": 55.85903,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.24851,
            "nubia_score": 0.52526
        },
        "meteor": 0.29641470935098874,
        "bleurt": 0.01942,
        "bertscore": {
            "precision": 0.89498,
            "recall": 0.87673,
            "f1": 0.88505
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.71818,
            "fmeasure": 0.67589
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.42963,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.32576,
            "fmeasure": 0.32712
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.32576,
            "fmeasure": 0.32712
        },
        "bleu": 17.99653,
        "nist": 2.6289216478541677,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 3.87893,
            "contradiction": 0.19335,
            "irrelevancy": 0.94142,
            "logical_agreement": 98.86523,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.49306,
            "nubia_score": 0.53498
        },
        "meteor": 0.35865981448775286,
        "bleurt": -0.17005,
        "bertscore": {
            "precision": 0.92433,
            "recall": 0.93697,
            "f1": 0.92924
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55302,
            "recall": 0.53643,
            "fmeasure": 0.52874
        },
        "rouge2": {
            "precision": 0.29446,
            "recall": 0.29882,
            "fmeasure": 0.28746
        },
        "rougeL": {
            "precision": 0.46703,
            "recall": 0.44872,
            "fmeasure": 0.44273
        },
        "rougeLsum": {
            "precision": 0.46703,
            "recall": 0.44872,
            "fmeasure": 0.44273
        },
        "bleu": 16.55159,
        "nist": 2.889397640591555,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nubia": {
            "semantic_relation": 3.18261,
            "contradiction": 14.6998,
            "irrelevancy": 57.59845,
            "logical_agreement": 27.70175,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.41266,
            "nubia_score": 0.48428
        },
        "meteor": 0.23640114791532293,
        "bleurt": -0.09811,
        "bertscore": {
            "precision": 0.86364,
            "recall": 0.84252,
            "f1": 0.85033
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68328,
            "recall": 0.70981,
            "fmeasure": 0.68994
        },
        "rouge2": {
            "precision": 0.44148,
            "recall": 0.4574,
            "fmeasure": 0.44437
        },
        "rougeL": {
            "precision": 0.55171,
            "recall": 0.5522,
            "fmeasure": 0.54676
        },
        "rougeLsum": {
            "precision": 0.55171,
            "recall": 0.5522,
            "fmeasure": 0.54676
        },
        "bleu": 40.00623,
        "nist": 4.981303280046183,
        "local_recall": {
            "1": 0.17073170731707318,
            "2": 0.24,
            "3": 0.8840579710144928
        },
        "nubia": {
            "semantic_relation": 3.65651,
            "contradiction": 1.12067,
            "irrelevancy": 48.41768,
            "logical_agreement": 50.46165,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.65407,
            "nubia_score": 0.59921
        },
        "meteor": 0.3857548883223934,
        "bleurt": 0.03668,
        "bertscore": {
            "precision": 0.89701,
            "recall": 0.91439,
            "f1": 0.90393
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.38249,
            "fmeasure": 0.43266
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.13765,
            "fmeasure": 0.14968
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.25714,
            "fmeasure": 0.27834
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.25714,
            "fmeasure": 0.27834
        },
        "bleu": 14.9808,
        "nist": 1.7769191373151334,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.09090909090909091,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.87566,
            "contradiction": 43.38729,
            "irrelevancy": 10.37903,
            "logical_agreement": 46.23368,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.16042,
            "nubia_score": 0.57881
        },
        "meteor": 0.22917344538207254,
        "bleurt": 0.04089,
        "bertscore": {
            "precision": 0.89522,
            "recall": 0.88182,
            "f1": 0.87533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78241,
            "recall": 0.7905,
            "fmeasure": 0.77255
        },
        "rouge2": {
            "precision": 0.44296,
            "recall": 0.46569,
            "fmeasure": 0.44516
        },
        "rougeL": {
            "precision": 0.65741,
            "recall": 0.64754,
            "fmeasure": 0.64104
        },
        "rougeLsum": {
            "precision": 0.65741,
            "recall": 0.64754,
            "fmeasure": 0.64104
        },
        "bleu": 33.68682,
        "nist": 4.055539174305715,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.85
        },
        "nubia": {
            "semantic_relation": 4.89369,
            "contradiction": 0.86591,
            "irrelevancy": 16.51084,
            "logical_agreement": 82.62325,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.44352,
            "nubia_score": 0.96191
        },
        "meteor": 0.41929099023232325,
        "bleurt": 0.37853,
        "bertscore": {
            "precision": 0.94401,
            "recall": 0.94266,
            "f1": 0.94311
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59958,
            "recall": 0.64819,
            "fmeasure": 0.62028
        },
        "rouge2": {
            "precision": 0.30918,
            "recall": 0.32713,
            "fmeasure": 0.31653
        },
        "rougeL": {
            "precision": 0.37917,
            "recall": 0.40949,
            "fmeasure": 0.39211
        },
        "rougeLsum": {
            "precision": 0.37917,
            "recall": 0.40949,
            "fmeasure": 0.39211
        },
        "bleu": 24.35063,
        "nist": 3.5070937907638586,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.47619047619047616,
            "3": 0.631578947368421
        },
        "nubia": {
            "semantic_relation": 3.2639,
            "contradiction": 40.31855,
            "irrelevancy": 47.62749,
            "logical_agreement": 12.05396,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.90471,
            "nubia_score": 0.4882
        },
        "meteor": 0.3250109029226313,
        "bleurt": -0.16644,
        "bertscore": {
            "precision": 0.87499,
            "recall": 0.87965,
            "f1": 0.87723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61795,
            "recall": 0.51394,
            "fmeasure": 0.53911
        },
        "rouge2": {
            "precision": 0.39815,
            "recall": 0.32621,
            "fmeasure": 0.34528
        },
        "rougeL": {
            "precision": 0.61795,
            "recall": 0.51394,
            "fmeasure": 0.53911
        },
        "rougeLsum": {
            "precision": 0.61795,
            "recall": 0.51394,
            "fmeasure": 0.53911
        },
        "bleu": 32.43825,
        "nist": 2.868892216853879,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.7
        },
        "nubia": {
            "semantic_relation": 3.43772,
            "contradiction": 17.54929,
            "irrelevancy": 49.70836,
            "logical_agreement": 32.74235,
            "grammar_ref": 5.06451,
            "grammar_hyp": 5.04003,
            "nubia_score": 0.56665
        },
        "meteor": 0.2867167942928227,
        "bleurt": -0.09755,
        "bertscore": {
            "precision": 0.91476,
            "recall": 0.9062,
            "f1": 0.90875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "mT5_large/totto_test",
        "N": 79,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77346,
            "recall": 0.7524,
            "fmeasure": 0.75444
        },
        "rouge2": {
            "precision": 0.5793,
            "recall": 0.56249,
            "fmeasure": 0.56481
        },
        "rougeL": {
            "precision": 0.67504,
            "recall": 0.65909,
            "fmeasure": 0.65982
        },
        "rougeLsum": {
            "precision": 0.67504,
            "recall": 0.65909,
            "fmeasure": 0.65982
        },
        "bleu": 52.66378,
        "nist": 7.618837125426634,
        "local_recall": {
            "1": 0.16194331983805668,
            "2": 0.48188405797101447,
            "3": 0.8100113765642776
        },
        "nubia": {
            "semantic_relation": 4.17985,
            "contradiction": 7.90803,
            "irrelevancy": 28.99446,
            "logical_agreement": 63.09751,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.359,
            "nubia_score": 0.74136
        },
        "meteor": 0.40742273270223966,
        "bleurt": 0.30042,
        "bertscore": {
            "precision": 0.93501,
            "recall": 0.93182,
            "f1": 0.93155
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68904,
            "recall": 0.73785,
            "fmeasure": 0.68934
        },
        "rouge2": {
            "precision": 0.43633,
            "recall": 0.47662,
            "fmeasure": 0.44246
        },
        "rougeL": {
            "precision": 0.5989,
            "recall": 0.64629,
            "fmeasure": 0.59793
        },
        "rougeLsum": {
            "precision": 0.5989,
            "recall": 0.64629,
            "fmeasure": 0.59793
        },
        "bleu": 37.22181,
        "nist": 4.688463919223499,
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.39285714285714285,
            "3": 0.7971014492753623
        },
        "nubia": {
            "semantic_relation": 3.78652,
            "contradiction": 7.58281,
            "irrelevancy": 67.39456,
            "logical_agreement": 25.02263,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.6646,
            "nubia_score": 0.59399
        },
        "meteor": 0.3442892389860697,
        "bleurt": 0.18952,
        "bertscore": {
            "precision": 0.91587,
            "recall": 0.91573,
            "f1": 0.91121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.70032,
            "fmeasure": 0.71972
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.34444,
            "fmeasure": 0.35185
        },
        "rougeL": {
            "precision": 0.64103,
            "recall": 0.60737,
            "fmeasure": 0.62246
        },
        "rougeLsum": {
            "precision": 0.64103,
            "recall": 0.60737,
            "fmeasure": 0.62246
        },
        "bleu": 40.29883,
        "nist": 3.8207143475103598,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.50852,
            "contradiction": 0.41597,
            "irrelevancy": 12.07279,
            "logical_agreement": 87.51124,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.66411,
            "nubia_score": 0.78692
        },
        "meteor": 0.35058323818152326,
        "bleurt": 0.22318,
        "bertscore": {
            "precision": 0.92608,
            "recall": 0.91154,
            "f1": 0.91875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87093,
            "recall": 0.83009,
            "fmeasure": 0.83031
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.69351,
            "fmeasure": 0.68314
        },
        "rougeL": {
            "precision": 0.87093,
            "recall": 0.83009,
            "fmeasure": 0.83031
        },
        "rougeLsum": {
            "precision": 0.87093,
            "recall": 0.83009,
            "fmeasure": 0.83031
        },
        "bleu": 65.36979,
        "nist": 4.00607913919024,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.06367,
            "contradiction": 0.87477,
            "irrelevancy": 58.19511,
            "logical_agreement": 40.93011,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.61744,
            "nubia_score": 0.66556
        },
        "meteor": 0.48531981642046995,
        "bleurt": 0.18252,
        "bertscore": {
            "precision": 0.94731,
            "recall": 0.96086,
            "f1": 0.95344
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66735,
            "recall": 0.63439,
            "fmeasure": 0.62396
        },
        "rouge2": {
            "precision": 0.44932,
            "recall": 0.38346,
            "fmeasure": 0.40459
        },
        "rougeL": {
            "precision": 0.60183,
            "recall": 0.54574,
            "fmeasure": 0.55464
        },
        "rougeLsum": {
            "precision": 0.60183,
            "recall": 0.54574,
            "fmeasure": 0.55464
        },
        "bleu": 44.03701,
        "nist": 4.620434791358396,
        "local_recall": {
            "1": 0.0,
            "2": 0.6136363636363636,
            "3": 0.631578947368421
        },
        "nubia": {
            "semantic_relation": 3.58655,
            "contradiction": 6.65987,
            "irrelevancy": 27.18454,
            "logical_agreement": 66.15559,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.55355,
            "nubia_score": 0.46996
        },
        "meteor": 0.3532097239429702,
        "bleurt": -0.09251,
        "bertscore": {
            "precision": 0.87936,
            "recall": 0.89432,
            "f1": 0.88418
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.77576,
            "fmeasure": 0.58554
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.61111,
            "fmeasure": 0.44821
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.77576,
            "fmeasure": 0.58554
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.77576,
            "fmeasure": 0.58554
        },
        "bleu": 12.58635,
        "nist": 1.2760153200355449,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.30982,
            "contradiction": 14.08193,
            "irrelevancy": 84.72486,
            "logical_agreement": 1.19322,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.16712,
            "nubia_score": 0.43051
        },
        "meteor": 0.32092939549219957,
        "bleurt": -0.33927,
        "bertscore": {
            "precision": 0.79534,
            "recall": 0.91857,
            "f1": 0.85172
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75952,
            "recall": 0.7955,
            "fmeasure": 0.77551
        },
        "rouge2": {
            "precision": 0.59428,
            "recall": 0.61665,
            "fmeasure": 0.60371
        },
        "rougeL": {
            "precision": 0.75952,
            "recall": 0.7955,
            "fmeasure": 0.77551
        },
        "rougeLsum": {
            "precision": 0.75952,
            "recall": 0.7955,
            "fmeasure": 0.77551
        },
        "bleu": 57.25359,
        "nist": 4.577492880341934,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.7,
            "3": 0.84
        },
        "nubia": {
            "semantic_relation": 4.14651,
            "contradiction": 23.28926,
            "irrelevancy": 45.22341,
            "logical_agreement": 31.48733,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.45465,
            "nubia_score": 0.74686
        },
        "meteor": 0.49065042439538753,
        "bleurt": 0.35785,
        "bertscore": {
            "precision": 0.93541,
            "recall": 0.95538,
            "f1": 0.94522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.61111,
            "fmeasure": 0.52943
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.08283,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.17647,
            "recall": 0.22917,
            "fmeasure": 0.19854
        },
        "rougeLsum": {
            "precision": 0.17647,
            "recall": 0.22917,
            "fmeasure": 0.19854
        },
        "bleu": 6.07459,
        "nist": 1.7483971951349195,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6363636363636364
        },
        "nubia": {
            "semantic_relation": 3.93141,
            "contradiction": 0.23868,
            "irrelevancy": 13.22644,
            "logical_agreement": 86.53489,
            "grammar_ref": 5.53377,
            "grammar_hyp": 5.44163,
            "nubia_score": 0.64545
        },
        "meteor": 0.22325459953336868,
        "bleurt": -0.04292,
        "bertscore": {
            "precision": 0.82821,
            "recall": 0.82752,
            "f1": 0.82786
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "mT5_large/totto_test",
        "N": 114,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72636,
            "recall": 0.7269,
            "fmeasure": 0.71372
        },
        "rouge2": {
            "precision": 0.4933,
            "recall": 0.49454,
            "fmeasure": 0.48449
        },
        "rougeL": {
            "precision": 0.61162,
            "recall": 0.61727,
            "fmeasure": 0.60331
        },
        "rougeLsum": {
            "precision": 0.61162,
            "recall": 0.61727,
            "fmeasure": 0.60331
        },
        "bleu": 42.32246,
        "nist": 7.348979764037855,
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.5344827586206896,
            "3": 0.7661647475642162
        },
        "nubia": {
            "semantic_relation": 4.18464,
            "contradiction": 7.11761,
            "irrelevancy": 35.84291,
            "logical_agreement": 57.03949,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.7523,
            "nubia_score": 0.71423
        },
        "meteor": 0.3797728906991243,
        "bleurt": 0.23531,
        "bertscore": {
            "precision": 0.92329,
            "recall": 0.91942,
            "f1": 0.92003
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69034,
            "recall": 0.78791,
            "fmeasure": 0.73547
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.52259,
            "fmeasure": 0.49609
        },
        "rougeL": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "rougeLsum": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "bleu": 42.04482,
        "nist": 3.158657317355216,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7619047619047619
        },
        "nubia": {
            "semantic_relation": 4.79827,
            "contradiction": 0.24572,
            "irrelevancy": 16.15701,
            "logical_agreement": 83.59726,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.36664,
            "nubia_score": 0.90873
        },
        "meteor": 0.4273735056799845,
        "bleurt": 0.58525,
        "bertscore": {
            "precision": 0.91692,
            "recall": 0.92529,
            "f1": 0.92109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78667,
            "recall": 0.65216,
            "fmeasure": 0.70769
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.50427,
            "fmeasure": 0.54815
        },
        "rougeL": {
            "precision": 0.74667,
            "recall": 0.61548,
            "fmeasure": 0.669
        },
        "rougeLsum": {
            "precision": 0.74667,
            "recall": 0.61548,
            "fmeasure": 0.669
        },
        "bleu": 42.50283,
        "nist": 1.9596850246296758,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 2.49849,
            "contradiction": 99.60813,
            "irrelevancy": 0.31581,
            "logical_agreement": 0.07606,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.40262,
            "nubia_score": 0.22398
        },
        "meteor": 0.37245834643337605,
        "bleurt": 0.07787,
        "bertscore": {
            "precision": 0.95141,
            "recall": 0.9076,
            "f1": 0.92899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84722,
            "recall": 0.76847,
            "fmeasure": 0.80409
        },
        "rouge2": {
            "precision": 0.64987,
            "recall": 0.59014,
            "fmeasure": 0.61649
        },
        "rougeL": {
            "precision": 0.72263,
            "recall": 0.67282,
            "fmeasure": 0.69474
        },
        "rougeLsum": {
            "precision": 0.72263,
            "recall": 0.67282,
            "fmeasure": 0.69474
        },
        "bleu": 47.28483,
        "nist": 4.205412415563656,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.42857142857142855,
            "3": 0.7837837837837838
        },
        "nubia": {
            "semantic_relation": 4.32339,
            "contradiction": 0.39301,
            "irrelevancy": 12.8109,
            "logical_agreement": 86.79609,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.97674,
            "nubia_score": 0.74413
        },
        "meteor": 0.41410935475972116,
        "bleurt": 0.09134,
        "bertscore": {
            "precision": 0.9275,
            "recall": 0.91864,
            "f1": 0.92171
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.65567,
            "fmeasure": 0.6112
        },
        "rouge2": {
            "precision": 0.38295,
            "recall": 0.46218,
            "fmeasure": 0.39665
        },
        "rougeL": {
            "precision": 0.56127,
            "recall": 0.63978,
            "fmeasure": 0.57147
        },
        "rougeLsum": {
            "precision": 0.56127,
            "recall": 0.63978,
            "fmeasure": 0.57147
        },
        "bleu": 43.84107,
        "nist": 4.056323313574186,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.6571428571428571,
            "3": 0.375
        },
        "nubia": {
            "semantic_relation": 3.74381,
            "contradiction": 1.5728,
            "irrelevancy": 64.27664,
            "logical_agreement": 34.15056,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.66671,
            "nubia_score": 0.61503
        },
        "meteor": 0.34081700451288477,
        "bleurt": -0.02744,
        "bertscore": {
            "precision": 0.87368,
            "recall": 0.87594,
            "f1": 0.8706
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68116,
            "recall": 0.77109,
            "fmeasure": 0.72294
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.48333,
            "fmeasure": 0.44286
        },
        "rougeL": {
            "precision": 0.37681,
            "recall": 0.42607,
            "fmeasure": 0.39971
        },
        "rougeLsum": {
            "precision": 0.37681,
            "recall": 0.42607,
            "fmeasure": 0.39971
        },
        "bleu": 32.26402,
        "nist": 3.1968581191793035,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.51573,
            "contradiction": 0.36277,
            "irrelevancy": 3.09138,
            "logical_agreement": 96.54585,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.10846,
            "nubia_score": 0.91742
        },
        "meteor": 0.3889011037710154,
        "bleurt": 0.18237,
        "bertscore": {
            "precision": 0.91685,
            "recall": 0.93496,
            "f1": 0.92582
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87445,
            "recall": 0.8898,
            "fmeasure": 0.87866
        },
        "rouge2": {
            "precision": 0.70512,
            "recall": 0.71076,
            "fmeasure": 0.70553
        },
        "rougeL": {
            "precision": 0.70163,
            "recall": 0.71077,
            "fmeasure": 0.70334
        },
        "rougeLsum": {
            "precision": 0.70163,
            "recall": 0.71077,
            "fmeasure": 0.70334
        },
        "bleu": 57.49632,
        "nist": 6.024860710730234,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.5,
            "3": 0.9375
        },
        "nubia": {
            "semantic_relation": 4.35808,
            "contradiction": 8.68016,
            "irrelevancy": 16.32046,
            "logical_agreement": 74.99938,
            "grammar_ref": 4.87577,
            "grammar_hyp": 4.94108,
            "nubia_score": 0.75741
        },
        "meteor": 0.49288487309784124,
        "bleurt": 0.4187,
        "bertscore": {
            "precision": 0.95121,
            "recall": 0.96247,
            "f1": 0.95678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96875,
            "recall": 0.94118,
            "fmeasure": 0.95455
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.875,
            "fmeasure": 0.8871
        },
        "rougeL": {
            "precision": 0.90625,
            "recall": 0.89828,
            "fmeasure": 0.90215
        },
        "rougeLsum": {
            "precision": 0.90625,
            "recall": 0.89828,
            "fmeasure": 0.90215
        },
        "bleu": 84.40074,
        "nist": 4.886986709636569,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9629629629629629
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.28656,
            "irrelevancy": 0.54285,
            "logical_agreement": 99.17059,
            "grammar_ref": 5.04945,
            "grammar_hyp": 5.07659,
            "nubia_score": 0.99112
        },
        "meteor": 0.5591842651549158,
        "bleurt": 0.79362,
        "bertscore": {
            "precision": 0.98209,
            "recall": 0.98332,
            "f1": 0.98201
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "bleu": 100.0,
        "nist": 2.8936441277848375,
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "meteor": 0.9652173913043478,
        "bleurt": 0.55466,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91987,
            "recall": 0.73217,
            "fmeasure": 0.80182
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.59628,
            "fmeasure": 0.65
        },
        "rougeL": {
            "precision": 0.86432,
            "recall": 0.68654,
            "fmeasure": 0.75014
        },
        "rougeLsum": {
            "precision": 0.86432,
            "recall": 0.68654,
            "fmeasure": 0.75014
        },
        "bleu": 50.14277,
        "nist": 3.134538694769742,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.72
        },
        "nubia": {
            "semantic_relation": 4.32715,
            "contradiction": 0.20117,
            "irrelevancy": 0.47794,
            "logical_agreement": 99.32089,
            "grammar_ref": 4.65278,
            "grammar_hyp": 5.47766,
            "nubia_score": 0.69731
        },
        "meteor": 0.39644995155867024,
        "bleurt": 0.35407,
        "bertscore": {
            "precision": 0.97204,
            "recall": 0.93487,
            "f1": 0.95117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.375,
            "recall": 0.27381,
            "fmeasure": 0.31283
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.125,
            "recall": 0.09127,
            "fmeasure": 0.10428
        },
        "rougeLsum": {
            "precision": 0.125,
            "recall": 0.09127,
            "fmeasure": 0.10428
        },
        "bleu": 5.02435,
        "nist": 0.6258145836939114,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nubia": {
            "semantic_relation": 3.29223,
            "contradiction": 1.83146,
            "irrelevancy": 28.45687,
            "logical_agreement": 69.71167,
            "grammar_ref": 5.77141,
            "grammar_hyp": 7.06747,
            "nubia_score": 0.28996
        },
        "meteor": 0.11475409836065575,
        "bleurt": -0.21406,
        "bertscore": {
            "precision": 0.87061,
            "recall": 0.85471,
            "f1": 0.86259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67293,
            "recall": 0.76305,
            "fmeasure": 0.70455
        },
        "rouge2": {
            "precision": 0.36681,
            "recall": 0.4453,
            "fmeasure": 0.3959
        },
        "rougeL": {
            "precision": 0.54887,
            "recall": 0.62546,
            "fmeasure": 0.57601
        },
        "rougeLsum": {
            "precision": 0.54887,
            "recall": 0.62546,
            "fmeasure": 0.57601
        },
        "bleu": 32.07313,
        "nist": 3.5109343462282183,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6521739130434783
        },
        "nubia": {
            "semantic_relation": 4.10204,
            "contradiction": 0.21334,
            "irrelevancy": 68.7215,
            "logical_agreement": 31.06515,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.09711,
            "nubia_score": 0.68841
        },
        "meteor": 0.3892811937730581,
        "bleurt": 0.08325,
        "bertscore": {
            "precision": 0.90465,
            "recall": 0.91587,
            "f1": 0.90993
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rouge2": {
            "precision": 0.71014,
            "recall": 0.87427,
            "fmeasure": 0.78358
        },
        "rougeL": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "rougeLsum": {
            "precision": 0.81944,
            "recall": 1.0,
            "fmeasure": 0.90063
        },
        "bleu": 64.85614,
        "nist": 4.004474719441233,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9444444444444444
        },
        "nubia": {
            "semantic_relation": 4.0712,
            "contradiction": 6.06271,
            "irrelevancy": 92.56812,
            "logical_agreement": 1.36917,
            "grammar_ref": 3.98302,
            "grammar_hyp": 3.85099,
            "nubia_score": 0.70029
        },
        "meteor": 0.57649049673364,
        "bleurt": 0.33377,
        "bertscore": {
            "precision": 0.94651,
            "recall": 0.98918,
            "f1": 0.96738
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80808,
            "recall": 0.82042,
            "fmeasure": 0.80847
        },
        "rouge2": {
            "precision": 0.55635,
            "recall": 0.55444,
            "fmeasure": 0.5523
        },
        "rougeL": {
            "precision": 0.56457,
            "recall": 0.59938,
            "fmeasure": 0.57815
        },
        "rougeLsum": {
            "precision": 0.56457,
            "recall": 0.59938,
            "fmeasure": 0.57815
        },
        "bleu": 49.91545,
        "nist": 4.803359317537858,
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.8214285714285714
        },
        "nubia": {
            "semantic_relation": 4.10825,
            "contradiction": 0.354,
            "irrelevancy": 26.03289,
            "logical_agreement": 73.6131,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.3603,
            "nubia_score": 0.61836
        },
        "meteor": 0.3972056476490171,
        "bleurt": 0.18462,
        "bertscore": {
            "precision": 0.938,
            "recall": 0.93853,
            "f1": 0.9375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.25,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "bleu": 23.9093,
        "nist": 1.8665302907901862,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4666666666666667
        },
        "nubia": {
            "semantic_relation": 3.55774,
            "contradiction": 1.47615,
            "irrelevancy": 55.4624,
            "logical_agreement": 43.06145,
            "grammar_ref": 3.58521,
            "grammar_hyp": 4.36794,
            "nubia_score": 0.49011
        },
        "meteor": 0.2642139877225908,
        "bleurt": 0.03672,
        "bertscore": {
            "precision": 0.92848,
            "recall": 0.85571,
            "f1": 0.89061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90456,
            "recall": 0.71832,
            "fmeasure": 0.78902
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.56273,
            "fmeasure": 0.60949
        },
        "rougeL": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "rougeLsum": {
            "precision": 0.75641,
            "recall": 0.6326,
            "fmeasure": 0.68032
        },
        "bleu": 51.59163,
        "nist": 3.705673658197534,
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.34872,
            "contradiction": 0.41237,
            "irrelevancy": 0.58279,
            "logical_agreement": 99.00484,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.82322,
            "nubia_score": 0.79553
        },
        "meteor": 0.39681345172517646,
        "bleurt": 0.4433,
        "bertscore": {
            "precision": 0.96065,
            "recall": 0.93264,
            "f1": 0.94576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "rouge2": {
            "precision": 0.71389,
            "recall": 0.76914,
            "fmeasure": 0.74019
        },
        "rougeL": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "rougeLsum": {
            "precision": 0.83516,
            "recall": 0.89899,
            "fmeasure": 0.86558
        },
        "bleu": 76.50922,
        "nist": 4.988961634091554,
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 0.20334,
            "irrelevancy": 1.38884,
            "logical_agreement": 98.40782,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.55377,
            "nubia_score": 0.99237
        },
        "meteor": 0.5553026687084012,
        "bleurt": 0.74589,
        "bertscore": {
            "precision": 0.97037,
            "recall": 0.97563,
            "f1": 0.97299
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.50789957099271,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0,
        "bleurt": 0.89367,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82734,
            "recall": 0.75167,
            "fmeasure": 0.78124
        },
        "rouge2": {
            "precision": 0.64694,
            "recall": 0.58545,
            "fmeasure": 0.60902
        },
        "rougeL": {
            "precision": 0.74782,
            "recall": 0.68267,
            "fmeasure": 0.70797
        },
        "rougeLsum": {
            "precision": 0.74782,
            "recall": 0.68267,
            "fmeasure": 0.70797
        },
        "bleu": 56.97595,
        "nist": 4.882769866778613,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2222222222222222,
            "3": 0.8043478260869565
        },
        "nubia": {
            "semantic_relation": 4.67167,
            "contradiction": 0.40457,
            "irrelevancy": 0.60996,
            "logical_agreement": 98.98547,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.76769,
            "nubia_score": 0.89517
        },
        "meteor": 0.43839569232312847,
        "bleurt": 0.43319,
        "bertscore": {
            "precision": 0.96216,
            "recall": 0.94277,
            "f1": 0.95011
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "mT5_large/totto_test",
        "N": 26,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69464,
            "recall": 0.71052,
            "fmeasure": 0.68909
        },
        "rouge2": {
            "precision": 0.46142,
            "recall": 0.45716,
            "fmeasure": 0.44985
        },
        "rougeL": {
            "precision": 0.6157,
            "recall": 0.62693,
            "fmeasure": 0.60866
        },
        "rougeLsum": {
            "precision": 0.6157,
            "recall": 0.62693,
            "fmeasure": 0.60866
        },
        "bleu": 40.78098,
        "nist": 5.852142256025401,
        "local_recall": {
            "1": 0.25287356321839083,
            "2": 0.4946236559139785,
            "3": 0.7339055793991416
        },
        "nubia": {
            "semantic_relation": 3.77541,
            "contradiction": 16.4766,
            "irrelevancy": 43.36654,
            "logical_agreement": 40.15686,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.49291,
            "nubia_score": 0.61812
        },
        "meteor": 0.3602429700385499,
        "bleurt": 0.13026,
        "bertscore": {
            "precision": 0.90945,
            "recall": 0.90981,
            "f1": 0.90759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "mT5_large/totto_test",
        "N": 10,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79697,
            "recall": 0.76075,
            "fmeasure": 0.77287
        },
        "rouge2": {
            "precision": 0.59196,
            "recall": 0.57585,
            "fmeasure": 0.57922
        },
        "rougeL": {
            "precision": 0.68097,
            "recall": 0.65157,
            "fmeasure": 0.66015
        },
        "rougeLsum": {
            "precision": 0.68097,
            "recall": 0.65157,
            "fmeasure": 0.66015
        },
        "bleu": 47.30129,
        "nist": 5.523348835699905,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.4166666666666667,
            "3": 0.8290598290598291
        },
        "nubia": {
            "semantic_relation": 4.28472,
            "contradiction": 24.77337,
            "irrelevancy": 16.90853,
            "logical_agreement": 58.3181,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.45793,
            "nubia_score": 0.72663
        },
        "meteor": 0.4199960537300925,
        "bleurt": 0.38823,
        "bertscore": {
            "precision": 0.94525,
            "recall": 0.94151,
            "f1": 0.94321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.9375,
            "fmeasure": 0.75
        },
        "bleu": 57.60844,
        "nist": 2.4457289637024866,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 3.78386,
            "contradiction": 0.35437,
            "irrelevancy": 99.34266,
            "logical_agreement": 0.30297,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.23779,
            "nubia_score": 0.49785
        },
        "meteor": 0.5108007395276796,
        "bleurt": -0.90817,
        "bertscore": {
            "precision": 0.86546,
            "recall": 0.96651,
            "f1": 0.9132
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.8549,
            "fmeasure": 0.82906
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.52315,
            "fmeasure": 0.50109
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.68111,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.68111,
            "fmeasure": 0.65497
        },
        "bleu": 43.52449,
        "nist": 4.484405704245724,
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.70622,
            "contradiction": 0.16844,
            "irrelevancy": 1.25695,
            "logical_agreement": 98.5746,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.95147,
            "nubia_score": 0.91217
        },
        "meteor": 0.4382523952190582,
        "bleurt": 0.40376,
        "bertscore": {
            "precision": 0.93203,
            "recall": 0.93625,
            "f1": 0.93413
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "bleu": 90.3602,
        "nist": 4.514053391810574,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "nubia": {
            "semantic_relation": 3.74862,
            "contradiction": 97.6993,
            "irrelevancy": 1.77644,
            "logical_agreement": 0.52426,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.18253,
            "nubia_score": 0.52622
        },
        "meteor": 0.572472684946071,
        "bleurt": 0.72398,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.98839,
            "f1": 0.98631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.490498678107601,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "meteor": 1.0,
        "bleurt": 0.92254,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.52754,
            "fmeasure": 0.46045
        },
        "rouge2": {
            "precision": 0.19565,
            "recall": 0.24351,
            "fmeasure": 0.21441
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.52754,
            "fmeasure": 0.46045
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.52754,
            "fmeasure": 0.46045
        },
        "bleu": 12.14257,
        "nist": 2.39236531086916,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5833333333333334
        },
        "nubia": {
            "semantic_relation": 3.75001,
            "contradiction": 24.85977,
            "irrelevancy": 5.51592,
            "logical_agreement": 69.6243,
            "grammar_ref": 5.51157,
            "grammar_hyp": 3.83883,
            "nubia_score": 0.65969
        },
        "meteor": 0.25121885928581567,
        "bleurt": -0.07585,
        "bertscore": {
            "precision": 0.89329,
            "recall": 0.83372,
            "f1": 0.86248
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "bleu": 38.14156,
        "nist": 3.4595216280661427,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "meteor": 0.3918734238227112,
        "bleurt": 0.44858,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67722,
            "recall": 0.80019,
            "fmeasure": 0.72181
        },
        "rouge2": {
            "precision": 0.54514,
            "recall": 0.60962,
            "fmeasure": 0.56782
        },
        "rougeL": {
            "precision": 0.67722,
            "recall": 0.80019,
            "fmeasure": 0.72181
        },
        "rougeLsum": {
            "precision": 0.67722,
            "recall": 0.80019,
            "fmeasure": 0.72181
        },
        "bleu": 46.20605,
        "nist": 3.8685119099377974,
        "local_recall": {
            "1": 0.1875,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "nubia": {
            "semantic_relation": 4.58111,
            "contradiction": 0.36599,
            "irrelevancy": 33.61973,
            "logical_agreement": 66.01427,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.90414,
            "nubia_score": 0.91247
        },
        "meteor": 0.4711737917152653,
        "bleurt": 0.48075,
        "bertscore": {
            "precision": 0.90982,
            "recall": 0.95187,
            "f1": 0.9277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47851,
            "recall": 0.73564,
            "fmeasure": 0.57016
        },
        "rouge2": {
            "precision": 0.21453,
            "recall": 0.37521,
            "fmeasure": 0.27064
        },
        "rougeL": {
            "precision": 0.44235,
            "recall": 0.68374,
            "fmeasure": 0.52872
        },
        "rougeLsum": {
            "precision": 0.44235,
            "recall": 0.68374,
            "fmeasure": 0.52872
        },
        "bleu": 16.70914,
        "nist": 2.6335651571862573,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.25,
            "3": 0.7241379310344828
        },
        "nubia": {
            "semantic_relation": 3.55994,
            "contradiction": 33.01976,
            "irrelevancy": 33.78128,
            "logical_agreement": 33.19896,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.38653,
            "nubia_score": 0.50657
        },
        "meteor": 0.32024229476412286,
        "bleurt": -0.00838,
        "bertscore": {
            "precision": 0.83881,
            "recall": 0.91414,
            "f1": 0.8746
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.9375,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.73333,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8125,
            "fmeasure": 0.76471
        },
        "bleu": 47.31668,
        "nist": 3.290123040313548,
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 4.19317,
            "contradiction": 0.3026,
            "irrelevancy": 38.23995,
            "logical_agreement": 61.45745,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.50276,
            "nubia_score": 0.72329
        },
        "meteor": 0.4950277098031189,
        "bleurt": 0.64609,
        "bertscore": {
            "precision": 0.93206,
            "recall": 0.97949,
            "f1": 0.94931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67437,
            "recall": 0.76383,
            "fmeasure": 0.70308
        },
        "rouge2": {
            "precision": 0.31594,
            "recall": 0.42718,
            "fmeasure": 0.35269
        },
        "rougeL": {
            "precision": 0.54867,
            "recall": 0.63577,
            "fmeasure": 0.57767
        },
        "rougeLsum": {
            "precision": 0.54867,
            "recall": 0.63577,
            "fmeasure": 0.57767
        },
        "bleu": 35.07265,
        "nist": 4.453053950209586,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6666666666666666,
            "3": 0.8695652173913043
        },
        "nubia": {
            "semantic_relation": 3.829,
            "contradiction": 3.30805,
            "irrelevancy": 46.61203,
            "logical_agreement": 50.07992,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.16542,
            "nubia_score": 0.65913
        },
        "meteor": 0.3762840903176708,
        "bleurt": 0.14312,
        "bertscore": {
            "precision": 0.89855,
            "recall": 0.93301,
            "f1": 0.90793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74383,
            "recall": 0.71421,
            "fmeasure": 0.72222
        },
        "rouge2": {
            "precision": 0.48416,
            "recall": 0.5082,
            "fmeasure": 0.49416
        },
        "rougeL": {
            "precision": 0.58951,
            "recall": 0.61063,
            "fmeasure": 0.5975
        },
        "rougeLsum": {
            "precision": 0.58951,
            "recall": 0.61063,
            "fmeasure": 0.5975
        },
        "bleu": 37.73497,
        "nist": 4.281779109382526,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2,
            "3": 0.8484848484848485
        },
        "nubia": {
            "semantic_relation": 3.79096,
            "contradiction": 45.93668,
            "irrelevancy": 45.4514,
            "logical_agreement": 8.61192,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.51584,
            "nubia_score": 0.63833
        },
        "meteor": 0.37740422283779995,
        "bleurt": 0.07337,
        "bertscore": {
            "precision": 0.89617,
            "recall": 0.9148,
            "f1": 0.90358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "bleu": 46.59538,
        "nist": 3.015080064196097,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2281,
            "irrelevancy": 1.43239,
            "logical_agreement": 98.33951,
            "grammar_ref": 6.26263,
            "grammar_hyp": 6.04483,
            "nubia_score": 1.0
        },
        "meteor": 0.4526726052498426,
        "bleurt": 0.76059,
        "bertscore": {
            "precision": 0.973,
            "recall": 0.96618,
            "f1": 0.96777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.78571,
            "recall": 0.61111,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "bleu": 62.22142,
        "nist": 3.368551600409571,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.97227,
            "contradiction": 1.50172,
            "irrelevancy": 4.39492,
            "logical_agreement": 94.10337,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.60097,
            "nubia_score": 0.50716
        },
        "meteor": 0.3993500396692958,
        "bleurt": 0.38877,
        "bertscore": {
            "precision": 0.95507,
            "recall": 0.90862,
            "f1": 0.93127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68338,
            "recall": 0.6808,
            "fmeasure": 0.68018
        },
        "rouge2": {
            "precision": 0.37099,
            "recall": 0.35434,
            "fmeasure": 0.3613
        },
        "rougeL": {
            "precision": 0.60401,
            "recall": 0.60039,
            "fmeasure": 0.60055
        },
        "rougeLsum": {
            "precision": 0.60401,
            "recall": 0.60039,
            "fmeasure": 0.60055
        },
        "bleu": 23.33258,
        "nist": 3.971701722099069,
        "local_recall": {
            "1": 0.375,
            "2": 0.6086956521739131,
            "3": 0.5882352941176471
        },
        "nubia": {
            "semantic_relation": 4.47783,
            "contradiction": 0.31464,
            "irrelevancy": 20.86459,
            "logical_agreement": 78.82077,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.82346,
            "nubia_score": 0.78832
        },
        "meteor": 0.351198450641705,
        "bleurt": 0.46441,
        "bertscore": {
            "precision": 0.9344,
            "recall": 0.94314,
            "f1": 0.93869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.6530437207411035,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.9828,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "bleu": 48.32698,
        "nist": 3.0508096603987953,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.83309,
            "contradiction": 0.66535,
            "irrelevancy": 0.62268,
            "logical_agreement": 98.71197,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.82173,
            "nubia_score": 0.75668
        },
        "meteor": 0.44652308792916917,
        "bleurt": 0.15755,
        "bertscore": {
            "precision": 0.95343,
            "recall": 0.95343,
            "f1": 0.95343
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78431,
            "recall": 0.775,
            "fmeasure": 0.7775
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.68187,
            "fmeasure": 0.68264
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.65833,
            "fmeasure": 0.66066
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.65833,
            "fmeasure": 0.66066
        },
        "bleu": 78.03835,
        "nist": 4.476761605186087,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.6892,
            "contradiction": 0.10409,
            "irrelevancy": 1.02055,
            "logical_agreement": 98.87535,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.12329,
            "nubia_score": 0.94132
        },
        "meteor": 0.47638005745125284,
        "bleurt": 0.45456,
        "bertscore": {
            "precision": 0.95054,
            "recall": 0.92702,
            "f1": 0.93013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.3764992953429935,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0,
        "bleurt": 0.91462,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75694,
            "recall": 0.51891,
            "fmeasure": 0.61223
        },
        "rouge2": {
            "precision": 0.4256,
            "recall": 0.24466,
            "fmeasure": 0.30853
        },
        "rougeL": {
            "precision": 0.67593,
            "recall": 0.4402,
            "fmeasure": 0.5288
        },
        "rougeLsum": {
            "precision": 0.67593,
            "recall": 0.4402,
            "fmeasure": 0.5288
        },
        "bleu": 37.25177,
        "nist": 2.877268190691991,
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "nubia": {
            "semantic_relation": 4.39832,
            "contradiction": 0.43277,
            "irrelevancy": 1.02096,
            "logical_agreement": 98.54628,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.4012,
            "nubia_score": 0.73723
        },
        "meteor": 0.3347602959254823,
        "bleurt": 0.36431,
        "bertscore": {
            "precision": 0.94108,
            "recall": 0.87275,
            "f1": 0.90363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95238,
            "recall": 0.65954,
            "fmeasure": 0.77658
        },
        "rouge2": {
            "precision": 0.4359,
            "recall": 0.29464,
            "fmeasure": 0.35024
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.54011,
            "fmeasure": 0.63799
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.54011,
            "fmeasure": 0.63799
        },
        "bleu": 32.4395,
        "nist": 3.0350442723742685,
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.97385,
            "contradiction": 0.16568,
            "irrelevancy": 0.42875,
            "logical_agreement": 99.40557,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.66848,
            "nubia_score": 0.97308
        },
        "meteor": 0.3924521459052849,
        "bleurt": 0.57347,
        "bertscore": {
            "precision": 0.96921,
            "recall": 0.93053,
            "f1": 0.94066
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74603,
            "recall": 0.8114,
            "fmeasure": 0.77724
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.63938,
            "fmeasure": 0.60999
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.77807,
            "fmeasure": 0.74472
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.77807,
            "fmeasure": 0.74472
        },
        "bleu": 42.63551,
        "nist": 3.7463185490199438,
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.02251,
            "contradiction": 0.45253,
            "irrelevancy": 96.24144,
            "logical_agreement": 3.30603,
            "grammar_ref": 5.26752,
            "grammar_hyp": 4.35462,
            "nubia_score": 0.73498
        },
        "meteor": 0.439061442466606,
        "bleurt": 0.25971,
        "bertscore": {
            "precision": 0.93289,
            "recall": 0.949,
            "f1": 0.94088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72446,
            "recall": 0.53748,
            "fmeasure": 0.60154
        },
        "rouge2": {
            "precision": 0.50926,
            "recall": 0.35493,
            "fmeasure": 0.40542
        },
        "rougeL": {
            "precision": 0.66097,
            "recall": 0.49597,
            "fmeasure": 0.55334
        },
        "rougeLsum": {
            "precision": 0.66097,
            "recall": 0.49597,
            "fmeasure": 0.55334
        },
        "bleu": 39.22135,
        "nist": 3.033385626888787,
        "local_recall": {
            "1": 0.0,
            "2": 0.4166666666666667,
            "3": 0.625
        },
        "nubia": {
            "semantic_relation": 3.92577,
            "contradiction": 10.37629,
            "irrelevancy": 2.22378,
            "logical_agreement": 87.39993,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.8679,
            "nubia_score": 0.63546
        },
        "meteor": 0.35322517067728165,
        "bleurt": 0.19683,
        "bertscore": {
            "precision": 0.90209,
            "recall": 0.88065,
            "f1": 0.89118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80926,
            "recall": 0.62866,
            "fmeasure": 0.70338
        },
        "rouge2": {
            "precision": 0.56614,
            "recall": 0.4072,
            "fmeasure": 0.47116
        },
        "rougeL": {
            "precision": 0.72778,
            "recall": 0.55657,
            "fmeasure": 0.62671
        },
        "rougeLsum": {
            "precision": 0.72778,
            "recall": 0.55657,
            "fmeasure": 0.62671
        },
        "bleu": 42.24163,
        "nist": 3.6771533986529956,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.56
        },
        "nubia": {
            "semantic_relation": 4.1686,
            "contradiction": 1.03615,
            "irrelevancy": 25.31515,
            "logical_agreement": 73.6487,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.99058,
            "nubia_score": 0.81484
        },
        "meteor": 0.3708150859252452,
        "bleurt": 0.3861,
        "bertscore": {
            "precision": 0.9413,
            "recall": 0.90385,
            "f1": 0.92086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.57143,
            "fmeasure": 0.47059
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.16667,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.57143,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.57143,
            "fmeasure": 0.47059
        },
        "bleu": 6.27466,
        "nist": 1.7950054972753235,
        "local_recall": {
            "1": 0.125,
            "2": 0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.20676,
            "contradiction": 0.16973,
            "irrelevancy": 87.45648,
            "logical_agreement": 12.37379,
            "grammar_ref": 4.92688,
            "grammar_hyp": 4.27626,
            "nubia_score": 0.80233
        },
        "meteor": 0.26737272006641205,
        "bleurt": 0.40361,
        "bertscore": {
            "precision": 0.87758,
            "recall": 0.91196,
            "f1": 0.89163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73781,
            "recall": 0.71288,
            "fmeasure": 0.72009
        },
        "rouge2": {
            "precision": 0.53742,
            "recall": 0.53342,
            "fmeasure": 0.53306
        },
        "rougeL": {
            "precision": 0.56888,
            "recall": 0.57043,
            "fmeasure": 0.56778
        },
        "rougeLsum": {
            "precision": 0.56888,
            "recall": 0.57043,
            "fmeasure": 0.56778
        },
        "bleu": 45.2493,
        "nist": 4.010121266376647,
        "local_recall": {
            "1": 0.0,
            "2": 0.07692307692307693,
            "3": 0.8048780487804879
        },
        "nubia": {
            "semantic_relation": 4.14088,
            "contradiction": 0.42711,
            "irrelevancy": 32.5572,
            "logical_agreement": 67.0157,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.28012,
            "nubia_score": 0.73961
        },
        "meteor": 0.38229722176727376,
        "bleurt": 0.13727,
        "bertscore": {
            "precision": 0.94005,
            "recall": 0.92432,
            "f1": 0.93092
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64259,
            "recall": 0.54767,
            "fmeasure": 0.58682
        },
        "rouge2": {
            "precision": 0.35213,
            "recall": 0.30864,
            "fmeasure": 0.32774
        },
        "rougeL": {
            "precision": 0.63148,
            "recall": 0.52762,
            "fmeasure": 0.57125
        },
        "rougeLsum": {
            "precision": 0.63148,
            "recall": 0.52762,
            "fmeasure": 0.57125
        },
        "bleu": 28.66003,
        "nist": 3.6353651800111537,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.91581,
            "contradiction": 1.30712,
            "irrelevancy": 6.74708,
            "logical_agreement": 91.9458,
            "grammar_ref": 4.73268,
            "grammar_hyp": 5.22421,
            "nubia_score": 0.63055
        },
        "meteor": 0.37485065474497675,
        "bleurt": 0.13572,
        "bertscore": {
            "precision": 0.91394,
            "recall": 0.89667,
            "f1": 0.90479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77593,
            "recall": 0.72023,
            "fmeasure": 0.74014
        },
        "rouge2": {
            "precision": 0.48889,
            "recall": 0.457,
            "fmeasure": 0.46794
        },
        "rougeL": {
            "precision": 0.58009,
            "recall": 0.54618,
            "fmeasure": 0.55809
        },
        "rougeLsum": {
            "precision": 0.58009,
            "recall": 0.54618,
            "fmeasure": 0.55809
        },
        "bleu": 31.07271,
        "nist": 3.4650776867459285,
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.23529411764705882,
            "3": 0.8055555555555556
        },
        "nubia": {
            "semantic_relation": 4.17188,
            "contradiction": 0.32066,
            "irrelevancy": 5.373,
            "logical_agreement": 94.30634,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.66387,
            "nubia_score": 0.70511
        },
        "meteor": 0.36087841033706997,
        "bleurt": 0.25215,
        "bertscore": {
            "precision": 0.94401,
            "recall": 0.91349,
            "f1": 0.92833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.9,
            "fmeasure": 0.84837
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.78148,
            "fmeasure": 0.7402
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.9,
            "fmeasure": 0.84837
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.9,
            "fmeasure": 0.84837
        },
        "bleu": 75.61629,
        "nist": 3.6565686494002625,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.46612,
            "contradiction": 7.74209,
            "irrelevancy": 50.51434,
            "logical_agreement": 41.74357,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.23333,
            "nubia_score": 0.83722
        },
        "meteor": 0.5521280160036551,
        "bleurt": 0.4999,
        "bertscore": {
            "precision": 0.97264,
            "recall": 0.97506,
            "f1": 0.97385
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73485,
            "recall": 0.66263,
            "fmeasure": 0.69509
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.3297,
            "fmeasure": 0.35238
        },
        "rougeL": {
            "precision": 0.53977,
            "recall": 0.49579,
            "fmeasure": 0.51594
        },
        "rougeLsum": {
            "precision": 0.53977,
            "recall": 0.49579,
            "fmeasure": 0.51594
        },
        "bleu": 14.42011,
        "nist": 3.5873285276111404,
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.64
        },
        "nubia": {
            "semantic_relation": 3.91618,
            "contradiction": 48.93418,
            "irrelevancy": 1.05343,
            "logical_agreement": 50.01239,
            "grammar_ref": 4.18803,
            "grammar_hyp": 3.58629,
            "nubia_score": 0.75848
        },
        "meteor": 0.2978942722188248,
        "bleurt": 0.21922,
        "bertscore": {
            "precision": 0.90757,
            "recall": 0.86907,
            "f1": 0.88499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63391,
            "recall": 0.72397,
            "fmeasure": 0.66821
        },
        "rouge2": {
            "precision": 0.46979,
            "recall": 0.54254,
            "fmeasure": 0.4995
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.69979,
            "fmeasure": 0.63117
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.69979,
            "fmeasure": 0.63117
        },
        "bleu": 38.89529,
        "nist": 3.7984115378369863,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5,
            "3": 0.95
        },
        "nubia": {
            "semantic_relation": 3.98384,
            "contradiction": 30.74933,
            "irrelevancy": 8.66306,
            "logical_agreement": 60.58761,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.69926,
            "nubia_score": 0.61247
        },
        "meteor": 0.32074867151860226,
        "bleurt": 0.1681,
        "bertscore": {
            "precision": 0.90481,
            "recall": 0.91525,
            "f1": 0.90682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.70064,
            "recall": 0.69608,
            "fmeasure": 0.69388
        },
        "rouge2": {
            "precision": 0.48843,
            "recall": 0.49861,
            "fmeasure": 0.49035
        },
        "rougeL": {
            "precision": 0.675,
            "recall": 0.67647,
            "fmeasure": 0.67166
        },
        "rougeLsum": {
            "precision": 0.675,
            "recall": 0.67647,
            "fmeasure": 0.67166
        },
        "bleu": 59.33696,
        "nist": 4.4326416491875005,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.40615,
            "contradiction": 59.84716,
            "irrelevancy": 5.25262,
            "logical_agreement": 34.90022,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.03757,
            "nubia_score": 0.54132
        },
        "meteor": 0.40160020818898434,
        "bleurt": 0.4129,
        "bertscore": {
            "precision": 0.94828,
            "recall": 0.93937,
            "f1": 0.9437
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.1699250014423126,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99428,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "bleu": 73.48889,
        "nist": 3.5579098675041347,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "meteor": 0.9384615384615386,
        "bleurt": 0.54425,
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.26786,
            "fmeasure": 0.32051
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.23611,
            "fmeasure": 0.27619
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.23611,
            "fmeasure": 0.27619
        },
        "bleu": 12.87263,
        "nist": 0.9256182547129214,
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857
        },
        "nubia": {
            "semantic_relation": 3.60008,
            "contradiction": 15.21661,
            "irrelevancy": 10.65032,
            "logical_agreement": 74.13307,
            "grammar_ref": 4.73918,
            "grammar_hyp": 5.76757,
            "nubia_score": 0.44048
        },
        "meteor": 0.2570974710736757,
        "bleurt": 0.00375,
        "bertscore": {
            "precision": 0.86524,
            "recall": 0.84242,
            "f1": 0.85367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.65302,
            "fmeasure": 0.74196
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.38681,
            "fmeasure": 0.44167
        },
        "rougeL": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "rougeLsum": {
            "precision": 0.7963,
            "recall": 0.60311,
            "fmeasure": 0.68298
        },
        "bleu": 33.92072,
        "nist": 2.27669746579841,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.84412,
            "contradiction": 0.57963,
            "irrelevancy": 0.83691,
            "logical_agreement": 98.58346,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.92275,
            "nubia_score": 0.93636
        },
        "meteor": 0.41664419714148093,
        "bleurt": 0.36837,
        "bertscore": {
            "precision": 0.96929,
            "recall": 0.94456,
            "f1": 0.95676
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59649,
            "recall": 0.48485,
            "fmeasure": 0.53469
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.23741,
            "fmeasure": 0.2635
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.22398,
            "fmeasure": 0.24197
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.22398,
            "fmeasure": 0.24197
        },
        "bleu": 12.19901,
        "nist": 2.5249135692353746,
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.42105263157894735
        },
        "nubia": {
            "semantic_relation": 3.94838,
            "contradiction": 0.31306,
            "irrelevancy": 65.95001,
            "logical_agreement": 33.73693,
            "grammar_ref": 4.34096,
            "grammar_hyp": 4.55393,
            "nubia_score": 0.61406
        },
        "meteor": 0.25374973297321235,
        "bleurt": 0.00573,
        "bertscore": {
            "precision": 0.90097,
            "recall": 0.86131,
            "f1": 0.8807
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.48701,
            "fmeasure": 0.53571
        },
        "rougeL": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "rougeLsum": {
            "precision": 0.86364,
            "recall": 0.70833,
            "fmeasure": 0.77592
        },
        "bleu": 44.71019,
        "nist": 3.545758942044469,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.9
        },
        "nubia": {
            "semantic_relation": 4.61426,
            "contradiction": 0.44628,
            "irrelevancy": 0.61579,
            "logical_agreement": 98.93794,
            "grammar_ref": 5.25223,
            "grammar_hyp": 6.03672,
            "nubia_score": 0.78598
        },
        "meteor": 0.5225641582077987,
        "bleurt": 0.61144,
        "bertscore": {
            "precision": 0.98285,
            "recall": 0.98285,
            "f1": 0.98285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "mT5_large/totto_test",
        "N": 39,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7931,
            "recall": 0.67862,
            "fmeasure": 0.72064
        },
        "rouge2": {
            "precision": 0.53511,
            "recall": 0.46526,
            "fmeasure": 0.4897
        },
        "rougeL": {
            "precision": 0.64023,
            "recall": 0.55607,
            "fmeasure": 0.58524
        },
        "rougeLsum": {
            "precision": 0.64023,
            "recall": 0.55607,
            "fmeasure": 0.58524
        },
        "bleu": 46.39827,
        "nist": 6.77473778951224,
        "local_recall": {
            "1": 0.12030075187969924,
            "2": 0.6772486772486772,
            "3": 0.6997518610421837
        },
        "nubia": {
            "semantic_relation": 4.18014,
            "contradiction": 11.99873,
            "irrelevancy": 25.31926,
            "logical_agreement": 62.68202,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.34083,
            "nubia_score": 0.72285
        },
        "meteor": 0.3761312379136065,
        "bleurt": 0.30416,
        "bertscore": {
            "precision": 0.93257,
            "recall": 0.91598,
            "f1": 0.92324
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.36228,
            "fmeasure": 0.44691
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.16374,
            "fmeasure": 0.2046
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.25877,
            "fmeasure": 0.31922
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.25877,
            "fmeasure": 0.31922
        },
        "bleu": 11.93348,
        "nist": 0.7798067306994304,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3125
        },
        "nubia": {
            "semantic_relation": 3.79741,
            "contradiction": 0.57574,
            "irrelevancy": 15.45154,
            "logical_agreement": 83.97272,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.55202,
            "nubia_score": 0.56293
        },
        "meteor": 0.2068450245120029,
        "bleurt": -0.23482,
        "bertscore": {
            "precision": 0.86995,
            "recall": 0.80059,
            "f1": 0.83383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.80471,
            "fmeasure": 0.65598
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.80471,
            "fmeasure": 0.65598
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.80471,
            "fmeasure": 0.65598
        },
        "bleu": 21.02369,
        "nist": 2.0604444995361937,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.79442,
            "contradiction": 32.60267,
            "irrelevancy": 62.679,
            "logical_agreement": 4.71833,
            "grammar_ref": 6.0554,
            "grammar_hyp": 6.20575,
            "nubia_score": 0.43342
        },
        "meteor": 0.3515162119888525,
        "bleurt": -0.46449,
        "bertscore": {
            "precision": 0.86318,
            "recall": 0.9204,
            "f1": 0.89087
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.48016,
            "recall": 0.72859,
            "fmeasure": 0.57687
        },
        "rouge2": {
            "precision": 0.30135,
            "recall": 0.50743,
            "fmeasure": 0.37687
        },
        "rougeL": {
            "precision": 0.42659,
            "recall": 0.64005,
            "fmeasure": 0.51017
        },
        "rougeLsum": {
            "precision": 0.42659,
            "recall": 0.64005,
            "fmeasure": 0.51017
        },
        "bleu": 24.44049,
        "nist": 2.716530713679404,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.7333333333333333,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 3.55828,
            "contradiction": 1.13009,
            "irrelevancy": 80.42124,
            "logical_agreement": 18.44867,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.17667,
            "nubia_score": 0.56915
        },
        "meteor": 0.34491410191091554,
        "bleurt": -0.01185,
        "bertscore": {
            "precision": 0.87667,
            "recall": 0.91533,
            "f1": 0.89558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.45614,
            "recall": 0.6337,
            "fmeasure": 0.5303
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.36752,
            "fmeasure": 0.30394
        },
        "rougeL": {
            "precision": 0.45614,
            "recall": 0.6337,
            "fmeasure": 0.5303
        },
        "rougeLsum": {
            "precision": 0.45614,
            "recall": 0.6337,
            "fmeasure": 0.5303
        },
        "bleu": 17.69498,
        "nist": 1.9890341860521208,
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 2.99697,
            "contradiction": 1.63111,
            "irrelevancy": 97.56136,
            "logical_agreement": 0.80752,
            "grammar_ref": 5.35534,
            "grammar_hyp": 3.27155,
            "nubia_score": 0.56392
        },
        "meteor": 0.2867321299997588,
        "bleurt": -0.35337,
        "bertscore": {
            "precision": 0.82238,
            "recall": 0.85889,
            "f1": 0.84024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.3125,
            "recall": 0.30637,
            "fmeasure": 0.30934
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.08889,
            "fmeasure": 0.07556
        },
        "rougeL": {
            "precision": 0.22917,
            "recall": 0.25758,
            "fmeasure": 0.24074
        },
        "rougeLsum": {
            "precision": 0.22917,
            "recall": 0.25758,
            "fmeasure": 0.24074
        },
        "bleu": 7.96818,
        "nist": 2.5082820222083844,
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 3.72599,
            "contradiction": 0.14804,
            "irrelevancy": 99.37131,
            "logical_agreement": 0.48065,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.48007,
            "nubia_score": 0.61295
        },
        "meteor": 0.17225420080650777,
        "bleurt": -0.21875,
        "bertscore": {
            "precision": 0.80705,
            "recall": 0.8358,
            "f1": 0.81466
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77508,
            "recall": 0.63899,
            "fmeasure": 0.69885
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.44993,
            "fmeasure": 0.50323
        },
        "rougeL": {
            "precision": 0.74545,
            "recall": 0.5961,
            "fmeasure": 0.6593
        },
        "rougeLsum": {
            "precision": 0.74545,
            "recall": 0.5961,
            "fmeasure": 0.6593
        },
        "bleu": 44.46268,
        "nist": 2.766395825926024,
        "local_recall": {
            "1": 0.125,
            "2": 0.3333333333333333,
            "3": 0.7333333333333333
        },
        "nubia": {
            "semantic_relation": 3.91022,
            "contradiction": 1.3099,
            "irrelevancy": 33.73823,
            "logical_agreement": 64.95187,
            "grammar_ref": 4.66623,
            "grammar_hyp": 5.10785,
            "nubia_score": 0.6299
        },
        "meteor": 0.36928385835707267,
        "bleurt": 0.1101,
        "bertscore": {
            "precision": 0.9337,
            "recall": 0.90028,
            "f1": 0.91059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "mT5_large/totto_test",
        "N": 8,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79986,
            "recall": 0.64077,
            "fmeasure": 0.69452
        },
        "rouge2": {
            "precision": 0.63265,
            "recall": 0.50048,
            "fmeasure": 0.54446
        },
        "rougeL": {
            "precision": 0.75507,
            "recall": 0.6045,
            "fmeasure": 0.65604
        },
        "rougeLsum": {
            "precision": 0.75507,
            "recall": 0.6045,
            "fmeasure": 0.65604
        },
        "bleu": 43.08087,
        "nist": 3.9611887022471106,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.6486486486486487,
            "3": 0.6438356164383562
        },
        "nubia": {
            "semantic_relation": 3.45926,
            "contradiction": 34.50093,
            "irrelevancy": 28.40322,
            "logical_agreement": 37.09584,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.13609,
            "nubia_score": 0.49787
        },
        "meteor": 0.34527520185182087,
        "bleurt": 0.00243,
        "bertscore": {
            "precision": 0.91881,
            "recall": 0.88624,
            "f1": 0.90004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.55099,
            "fmeasure": 0.57692
        },
        "rouge2": {
            "precision": 0.40351,
            "recall": 0.36667,
            "fmeasure": 0.38015
        },
        "rougeL": {
            "precision": 0.575,
            "recall": 0.49836,
            "fmeasure": 0.52564
        },
        "rougeLsum": {
            "precision": 0.575,
            "recall": 0.49836,
            "fmeasure": 0.52564
        },
        "bleu": 42.94875,
        "nist": 3.9729219920997867,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 3.587,
            "contradiction": 0.13379,
            "irrelevancy": 48.41449,
            "logical_agreement": 51.45171,
            "grammar_ref": 4.36031,
            "grammar_hyp": 5.00308,
            "nubia_score": 0.5465
        },
        "meteor": 0.3476792302637932,
        "bleurt": -0.005,
        "bertscore": {
            "precision": 0.8839,
            "recall": 0.85003,
            "f1": 0.86419
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.375,
            "recall": 0.45238,
            "fmeasure": 0.40952
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.23776,
            "fmeasure": 0.21703
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.45238,
            "fmeasure": 0.40952
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.45238,
            "fmeasure": 0.40952
        },
        "bleu": 14.866,
        "nist": 2.3020178631926274,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 3.91496,
            "contradiction": 0.27186,
            "irrelevancy": 40.74345,
            "logical_agreement": 58.98469,
            "grammar_ref": 5.74657,
            "grammar_hyp": 3.89182,
            "nubia_score": 0.84171
        },
        "meteor": 0.2799029712855335,
        "bleurt": 0.13989,
        "bertscore": {
            "precision": 0.87952,
            "recall": 0.89458,
            "f1": 0.88699
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "bleu": 76.11606,
        "nist": 4.090634124990776,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67405,
            "recall": 0.66699,
            "fmeasure": 0.66896
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.45188,
            "fmeasure": 0.45396
        },
        "rougeL": {
            "precision": 0.55667,
            "recall": 0.57602,
            "fmeasure": 0.56419
        },
        "rougeLsum": {
            "precision": 0.55667,
            "recall": 0.57602,
            "fmeasure": 0.56419
        },
        "bleu": 48.45554,
        "nist": 4.867796525703052,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0,
            "3": 0.6923076923076923
        },
        "nubia": {
            "semantic_relation": 3.60505,
            "contradiction": 50.07054,
            "irrelevancy": 4.80691,
            "logical_agreement": 45.12256,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.58795,
            "nubia_score": 0.60677
        },
        "meteor": 0.34906039839967395,
        "bleurt": 0.21351,
        "bertscore": {
            "precision": 0.90411,
            "recall": 0.89958,
            "f1": 0.89869
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55044,
            "recall": 0.65694,
            "fmeasure": 0.59683
        },
        "rouge2": {
            "precision": 0.29545,
            "recall": 0.30529,
            "fmeasure": 0.29782
        },
        "rougeL": {
            "precision": 0.50877,
            "recall": 0.56574,
            "fmeasure": 0.53016
        },
        "rougeLsum": {
            "precision": 0.50877,
            "recall": 0.56574,
            "fmeasure": 0.53016
        },
        "bleu": 51.39036,
        "nist": 4.2083789093810475,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.42857142857142855,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 3.33592,
            "contradiction": 0.74855,
            "irrelevancy": 50.1781,
            "logical_agreement": 49.07334,
            "grammar_ref": 4.56769,
            "grammar_hyp": 3.97669,
            "nubia_score": 0.54734
        },
        "meteor": 0.39648822770768766,
        "bleurt": 0.21331,
        "bertscore": {
            "precision": 0.88985,
            "recall": 0.91543,
            "f1": 0.89428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.86247,
            "fmeasure": 0.84638
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.72778,
            "fmeasure": 0.71084
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.81119,
            "fmeasure": 0.79304
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.81119,
            "fmeasure": 0.79304
        },
        "bleu": 71.70327,
        "nist": 4.4864713825562985,
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.86197,
            "contradiction": 0.61314,
            "irrelevancy": 53.44523,
            "logical_agreement": 45.94163,
            "grammar_ref": 4.43463,
            "grammar_hyp": 5.04288,
            "nubia_score": 0.85248
        },
        "meteor": 0.5292398399849825,
        "bleurt": 0.14816,
        "bertscore": {
            "precision": 0.93595,
            "recall": 0.96793,
            "f1": 0.95167
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "nist": 4.251192788981044,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0,
        "bleurt": 0.64779,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.86667,
            "fmeasure": 0.83871
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.64286,
            "fmeasure": 0.62069
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.86667,
            "fmeasure": 0.83871
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.86667,
            "fmeasure": 0.83871
        },
        "bleu": 50.0815,
        "nist": 3.4269374984369985,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.88685,
            "contradiction": 0.81027,
            "irrelevancy": 14.16491,
            "logical_agreement": 85.02482,
            "grammar_ref": 4.08392,
            "grammar_hyp": 4.06014,
            "nubia_score": 0.93971
        },
        "meteor": 0.5182108531187031,
        "bleurt": 0.71476,
        "bertscore": {
            "precision": 0.9657,
            "recall": 0.97098,
            "f1": 0.96833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "mT5_large/totto_test",
        "N": 36,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7523,
            "recall": 0.69468,
            "fmeasure": 0.70885
        },
        "rouge2": {
            "precision": 0.48748,
            "recall": 0.44417,
            "fmeasure": 0.45639
        },
        "rougeL": {
            "precision": 0.64475,
            "recall": 0.59772,
            "fmeasure": 0.60774
        },
        "rougeLsum": {
            "precision": 0.64475,
            "recall": 0.59772,
            "fmeasure": 0.60774
        },
        "bleu": 43.80183,
        "nist": 6.738448782750541,
        "local_recall": {
            "1": 0.27350427350427353,
            "2": 0.4632352941176471,
            "3": 0.7487437185929648
        },
        "nubia": {
            "semantic_relation": 4.14787,
            "contradiction": 14.69192,
            "irrelevancy": 28.707,
            "logical_agreement": 56.60108,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.89478,
            "nubia_score": 0.70736
        },
        "meteor": 0.36849842216552053,
        "bleurt": 0.20963,
        "bertscore": {
            "precision": 0.92471,
            "recall": 0.91621,
            "f1": 0.91906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.33333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.11111,
            "fmeasure": 0.13333
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.11111,
            "fmeasure": 0.13333
        },
        "bleu": 3.94138,
        "nist": 0.4202766511294509,
        "local_recall": {
            "1": 0,
            "2": 0.2727272727272727
        },
        "nubia": {
            "semantic_relation": 3.57779,
            "contradiction": 2.2569,
            "irrelevancy": 73.91565,
            "logical_agreement": 23.82744,
            "grammar_ref": 4.80739,
            "grammar_hyp": 6.50515,
            "nubia_score": 0.3492
        },
        "meteor": 0.14678899082568805,
        "bleurt": -0.36502,
        "bertscore": {
            "precision": 0.82174,
            "recall": 0.73942,
            "f1": 0.77841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.95833,
            "fmeasure": 0.85784
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.74603,
            "fmeasure": 0.65397
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.95833,
            "fmeasure": 0.85784
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.95833,
            "fmeasure": 0.85784
        },
        "bleu": 37.09723,
        "nist": 3.6618762288329108,
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.36993,
            "contradiction": 0.12433,
            "irrelevancy": 99.75757,
            "logical_agreement": 0.1181,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.40674,
            "nubia_score": 0.98335
        },
        "meteor": 0.48417858019804877,
        "bleurt": 0.30205,
        "bertscore": {
            "precision": 0.94009,
            "recall": 0.97227,
            "f1": 0.9513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "bleu": 100.0,
        "nist": 3.898626692302749,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.90186,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.67677,
            "fmeasure": 0.76161
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 0.75591,
            "fmeasure": 0.84444
        },
        "bleu": 79.93249,
        "nist": 5.074202687561549,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.64656,
            "contradiction": 0.65741,
            "irrelevancy": 0.75432,
            "logical_agreement": 98.58827,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.01119,
            "nubia_score": 0.85081
        },
        "meteor": 0.5293855573293579,
        "bleurt": 0.52498,
        "bertscore": {
            "precision": 0.97669,
            "recall": 0.96698,
            "f1": 0.97082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80553,
            "recall": 0.8092,
            "fmeasure": 0.79925
        },
        "rouge2": {
            "precision": 0.56052,
            "recall": 0.5612,
            "fmeasure": 0.55387
        },
        "rougeL": {
            "precision": 0.70638,
            "recall": 0.70436,
            "fmeasure": 0.69863
        },
        "rougeLsum": {
            "precision": 0.70638,
            "recall": 0.70436,
            "fmeasure": 0.69863
        },
        "bleu": 50.28842,
        "nist": 4.882267476247834,
        "local_recall": {
            "1": 0.7,
            "2": 0.3333333333333333,
            "3": 0.868421052631579
        },
        "nubia": {
            "semantic_relation": 4.26317,
            "contradiction": 0.73562,
            "irrelevancy": 48.63029,
            "logical_agreement": 50.63409,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.66217,
            "nubia_score": 0.72036
        },
        "meteor": 0.4483522971597695,
        "bleurt": -0.05548,
        "bertscore": {
            "precision": 0.92835,
            "recall": 0.92507,
            "f1": 0.92669
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62388,
            "recall": 0.62706,
            "fmeasure": 0.61352
        },
        "rouge2": {
            "precision": 0.28759,
            "recall": 0.30243,
            "fmeasure": 0.2917
        },
        "rougeL": {
            "precision": 0.506,
            "recall": 0.47873,
            "fmeasure": 0.48085
        },
        "rougeLsum": {
            "precision": 0.506,
            "recall": 0.47873,
            "fmeasure": 0.48085
        },
        "bleu": 31.06798,
        "nist": 4.043367183475934,
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.42105263157894735,
            "3": 0.7037037037037037
        },
        "nubia": {
            "semantic_relation": 3.75852,
            "contradiction": 36.43875,
            "irrelevancy": 30.95508,
            "logical_agreement": 32.60617,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.252,
            "nubia_score": 0.54501
        },
        "meteor": 0.34443535545198634,
        "bleurt": 0.02679,
        "bertscore": {
            "precision": 0.88748,
            "recall": 0.87946,
            "f1": 0.87696
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "bleu": 69.04427,
        "nist": 4.306797170061882,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        },
        "meteor": 0.5500501807094148,
        "bleurt": 0.47554,
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77708,
            "recall": 0.92308,
            "fmeasure": 0.84325
        },
        "rouge2": {
            "precision": 0.53704,
            "recall": 0.64286,
            "fmeasure": 0.58469
        },
        "rougeL": {
            "precision": 0.68333,
            "recall": 0.80769,
            "fmeasure": 0.7398
        },
        "rougeLsum": {
            "precision": 0.68333,
            "recall": 0.80769,
            "fmeasure": 0.7398
        },
        "bleu": 40.46319,
        "nist": 4.005185609264805,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.8947368421052632
        },
        "nubia": {
            "semantic_relation": 4.61445,
            "contradiction": 0.38297,
            "irrelevancy": 33.68537,
            "logical_agreement": 65.93166,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.17441,
            "nubia_score": 0.85343
        },
        "meteor": 0.47502147636535524,
        "bleurt": 0.36919,
        "bertscore": {
            "precision": 0.9413,
            "recall": 0.96423,
            "f1": 0.95262
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64583,
            "recall": 0.53938,
            "fmeasure": 0.56307
        },
        "rouge2": {
            "precision": 0.39098,
            "recall": 0.30684,
            "fmeasure": 0.32723
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.48168,
            "fmeasure": 0.48341
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.48168,
            "fmeasure": 0.48341
        },
        "bleu": 19.58241,
        "nist": 2.4148333810645006,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nubia": {
            "semantic_relation": 3.67619,
            "contradiction": 0.30324,
            "irrelevancy": 49.07331,
            "logical_agreement": 50.62345,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.93507,
            "nubia_score": 0.66909
        },
        "meteor": 0.27364721032582734,
        "bleurt": -0.07274,
        "bertscore": {
            "precision": 0.88585,
            "recall": 0.87548,
            "f1": 0.8799
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.76667,
            "fmeasure": 0.76667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.73333,
            "fmeasure": 0.73333
        },
        "bleu": 61.97294,
        "nist": 3.588926052556107,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9523809523809523
        },
        "nubia": {
            "semantic_relation": 4.39487,
            "contradiction": 23.68316,
            "irrelevancy": 11.35583,
            "logical_agreement": 64.961,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.97923,
            "nubia_score": 0.69563
        },
        "meteor": 0.43021987420112057,
        "bleurt": 0.60932,
        "bertscore": {
            "precision": 0.95433,
            "recall": 0.94379,
            "f1": 0.94891
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68855,
            "recall": 0.64615,
            "fmeasure": 0.65779
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.29699,
            "fmeasure": 0.31012
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.52521,
            "fmeasure": 0.55101
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.52521,
            "fmeasure": 0.55101
        },
        "bleu": 19.29355,
        "nist": 3.5035652685894547,
        "local_recall": {
            "1": 0.3,
            "2": 0.0,
            "3": 0.6551724137931034
        },
        "nubia": {
            "semantic_relation": 4.42129,
            "contradiction": 27.75742,
            "irrelevancy": 18.49264,
            "logical_agreement": 53.74994,
            "grammar_ref": 5.969,
            "grammar_hyp": 6.09662,
            "nubia_score": 0.67735
        },
        "meteor": 0.34075945235606836,
        "bleurt": -0.04711,
        "bertscore": {
            "precision": 0.9246,
            "recall": 0.91235,
            "f1": 0.91781
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81202,
            "recall": 0.87051,
            "fmeasure": 0.83587
        },
        "rouge2": {
            "precision": 0.64369,
            "recall": 0.6748,
            "fmeasure": 0.65593
        },
        "rougeL": {
            "precision": 0.67016,
            "recall": 0.77979,
            "fmeasure": 0.70676
        },
        "rougeLsum": {
            "precision": 0.67016,
            "recall": 0.77979,
            "fmeasure": 0.70676
        },
        "bleu": 54.87328,
        "nist": 4.877505341676066,
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.8695652173913043
        },
        "nubia": {
            "semantic_relation": 4.48808,
            "contradiction": 16.6052,
            "irrelevancy": 25.97988,
            "logical_agreement": 57.41492,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.37253,
            "nubia_score": 0.86801
        },
        "meteor": 0.4841346736526056,
        "bleurt": 0.51766,
        "bertscore": {
            "precision": 0.9229,
            "recall": 0.94922,
            "f1": 0.93505
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62745,
            "recall": 0.61836,
            "fmeasure": 0.61667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.26768,
            "fmeasure": 0.29323
        },
        "rougeL": {
            "precision": 0.39216,
            "recall": 0.33445,
            "fmeasure": 0.35556
        },
        "rougeLsum": {
            "precision": 0.39216,
            "recall": 0.33445,
            "fmeasure": 0.35556
        },
        "bleu": 36.61511,
        "nist": 3.1008847210940513,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 2.85789,
            "contradiction": 1.28562,
            "irrelevancy": 46.30683,
            "logical_agreement": 52.40755,
            "grammar_ref": 4.61776,
            "grammar_hyp": 3.83022,
            "nubia_score": 0.4427
        },
        "meteor": 0.2737864067828953,
        "bleurt": -0.53134,
        "bertscore": {
            "precision": 0.82816,
            "recall": 0.81508,
            "f1": 0.82157
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.40278,
            "recall": 0.80556,
            "fmeasure": 0.53704
        },
        "rouge2": {
            "precision": 0.26087,
            "recall": 0.54545,
            "fmeasure": 0.35294
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.75,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.75,
            "fmeasure": 0.5
        },
        "bleu": 16.69249,
        "nist": 1.7659027521135249,
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.45443,
            "contradiction": 0.26702,
            "irrelevancy": 99.56394,
            "logical_agreement": 0.16904,
            "grammar_ref": 5.08958,
            "grammar_hyp": 2.78601,
            "nubia_score": 0.57045
        },
        "meteor": 0.40646077115819323,
        "bleurt": 0.13535,
        "bertscore": {
            "precision": 0.79303,
            "recall": 0.90249,
            "f1": 0.84423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.76944,
            "fmeasure": 0.77218
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4958,
            "fmeasure": 0.49692
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.55556,
            "fmeasure": 0.50851
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.55556,
            "fmeasure": 0.50851
        },
        "bleu": 43.52399,
        "nist": 3.8975314299616963,
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.9567,
            "contradiction": 65.79937,
            "irrelevancy": 31.92832,
            "logical_agreement": 2.27231,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.17605,
            "nubia_score": 0.66761
        },
        "meteor": 0.408002171999523,
        "bleurt": -0.19772,
        "bertscore": {
            "precision": 0.89351,
            "recall": 0.89442,
            "f1": 0.89288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.423065265165703,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0,
        "bleurt": 0.94038,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59144,
            "recall": 0.59049,
            "fmeasure": 0.5745
        },
        "rouge2": {
            "precision": 0.27227,
            "recall": 0.27505,
            "fmeasure": 0.26576
        },
        "rougeL": {
            "precision": 0.45775,
            "recall": 0.49393,
            "fmeasure": 0.46266
        },
        "rougeLsum": {
            "precision": 0.45775,
            "recall": 0.49393,
            "fmeasure": 0.46266
        },
        "bleu": 16.83895,
        "nist": 3.278572498054894,
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.5789473684210527
        },
        "nubia": {
            "semantic_relation": 4.14431,
            "contradiction": 4.51017,
            "irrelevancy": 26.96875,
            "logical_agreement": 68.52108,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.53387,
            "nubia_score": 0.64543
        },
        "meteor": 0.2692142921814408,
        "bleurt": 0.32096,
        "bertscore": {
            "precision": 0.88611,
            "recall": 0.87767,
            "f1": 0.88043
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "bleu": 30.67489,
        "nist": 0.6179519972810469,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.15284,
            "contradiction": 0.35397,
            "irrelevancy": 0.51105,
            "logical_agreement": 99.13498,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.8924,
            "nubia_score": 0.88513
        },
        "meteor": 0.4466946348571188,
        "bleurt": 0.26056,
        "bertscore": {
            "precision": 0.97564,
            "recall": 0.89184,
            "f1": 0.93186
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76599,
            "recall": 0.81397,
            "fmeasure": 0.77928
        },
        "rouge2": {
            "precision": 0.58889,
            "recall": 0.55556,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.69192,
            "recall": 0.69276,
            "fmeasure": 0.68732
        },
        "rougeLsum": {
            "precision": 0.69192,
            "recall": 0.69276,
            "fmeasure": 0.68732
        },
        "bleu": 49.26303,
        "nist": 3.5517657535543576,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "nubia": {
            "semantic_relation": 4.37669,
            "contradiction": 25.63823,
            "irrelevancy": 1.91357,
            "logical_agreement": 72.44821,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.0912,
            "nubia_score": 0.7935
        },
        "meteor": 0.4058383908022263,
        "bleurt": 0.55791,
        "bertscore": {
            "precision": 0.93876,
            "recall": 0.95688,
            "f1": 0.94658
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.45707,
            "fmeasure": 0.55625
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.25328,
            "fmeasure": 0.31145
        },
        "rougeL": {
            "precision": 0.64444,
            "recall": 0.41414,
            "fmeasure": 0.50404
        },
        "rougeLsum": {
            "precision": 0.64444,
            "recall": 0.41414,
            "fmeasure": 0.50404
        },
        "bleu": 21.77674,
        "nist": 1.3567461676553008,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "nubia": {
            "semantic_relation": 3.2503,
            "contradiction": 93.47009,
            "irrelevancy": 5.62017,
            "logical_agreement": 0.90975,
            "grammar_ref": 3.8277,
            "grammar_hyp": 4.192,
            "nubia_score": 0.35238
        },
        "meteor": 0.25321897753377653,
        "bleurt": 0.01113,
        "bertscore": {
            "precision": 0.88077,
            "recall": 0.82429,
            "f1": 0.85098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.72222,
            "fmeasure": 0.53755
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.54762,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.72222,
            "fmeasure": 0.53755
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.72222,
            "fmeasure": 0.53755
        },
        "bleu": 25.34744,
        "nist": 1.5259373822461564,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 2.69868,
            "contradiction": 81.73798,
            "irrelevancy": 17.33843,
            "logical_agreement": 0.92359,
            "grammar_ref": 5.1757,
            "grammar_hyp": 4.42225,
            "nubia_score": 0.29492
        },
        "meteor": 0.404713382634031,
        "bleurt": -0.42822,
        "bertscore": {
            "precision": 0.83696,
            "recall": 0.93876,
            "f1": 0.88494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52083,
            "recall": 0.49192,
            "fmeasure": 0.50198
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.26623,
            "fmeasure": 0.274
        },
        "rougeL": {
            "precision": 0.52083,
            "recall": 0.49192,
            "fmeasure": 0.50198
        },
        "rougeLsum": {
            "precision": 0.52083,
            "recall": 0.49192,
            "fmeasure": 0.50198
        },
        "bleu": 18.49071,
        "nist": 1.9242056308096391,
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.5384615384615384
        },
        "nubia": {
            "semantic_relation": 3.01965,
            "contradiction": 52.0027,
            "irrelevancy": 47.51976,
            "logical_agreement": 0.47754,
            "grammar_ref": 4.44297,
            "grammar_hyp": 5.70672,
            "nubia_score": 0.19393
        },
        "meteor": 0.24934962835704422,
        "bleurt": -0.25512,
        "bertscore": {
            "precision": 0.82587,
            "recall": 0.87157,
            "f1": 0.84811
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.39583,
            "recall": 0.38716,
            "fmeasure": 0.38632
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.0812,
            "fmeasure": 0.09219
        },
        "rougeL": {
            "precision": 0.27083,
            "recall": 0.26294,
            "fmeasure": 0.26325
        },
        "rougeLsum": {
            "precision": 0.27083,
            "recall": 0.26294,
            "fmeasure": 0.26325
        },
        "bleu": 7.43982,
        "nist": 1.4600232863467668,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.74192,
            "contradiction": 0.06245,
            "irrelevancy": 99.55467,
            "logical_agreement": 0.38288,
            "grammar_ref": 4.57081,
            "grammar_hyp": 4.76754,
            "nubia_score": 0.54094
        },
        "meteor": 0.23957323369763844,
        "bleurt": 0.0462,
        "bertscore": {
            "precision": 0.85854,
            "recall": 0.84567,
            "f1": 0.84174
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52244,
            "recall": 0.61806,
            "fmeasure": 0.55245
        },
        "rouge2": {
            "precision": 0.31061,
            "recall": 0.4212,
            "fmeasure": 0.35015
        },
        "rougeL": {
            "precision": 0.52244,
            "recall": 0.61806,
            "fmeasure": 0.55245
        },
        "rougeLsum": {
            "precision": 0.52244,
            "recall": 0.61806,
            "fmeasure": 0.55245
        },
        "bleu": 19.95791,
        "nist": 2.3725960273881026,
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.4
        },
        "nubia": {
            "semantic_relation": 3.7443,
            "contradiction": 6.12058,
            "irrelevancy": 63.32259,
            "logical_agreement": 30.55683,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.34572,
            "nubia_score": 0.5312
        },
        "meteor": 0.2813352142034814,
        "bleurt": 0.0983,
        "bertscore": {
            "precision": 0.87909,
            "recall": 0.88727,
            "f1": 0.88154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.6452,
            "fmeasure": 0.76541
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.46158,
            "fmeasure": 0.55769
        },
        "rougeL": {
            "precision": 0.90873,
            "recall": 0.6202,
            "fmeasure": 0.73599
        },
        "rougeLsum": {
            "precision": 0.90873,
            "recall": 0.6202,
            "fmeasure": 0.73599
        },
        "bleu": 43.4365,
        "nist": 1.7084668741367708,
        "local_recall": {
            "1": 0.1,
            "2": 0.5384615384615384,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 3.85551,
            "contradiction": 5.51698,
            "irrelevancy": 3.04851,
            "logical_agreement": 91.43451,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.84096,
            "nubia_score": 0.60283
        },
        "meteor": 0.3539971265879193,
        "bleurt": -0.00669,
        "bertscore": {
            "precision": 0.97981,
            "recall": 0.88793,
            "f1": 0.93152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66956,
            "recall": 0.63508,
            "fmeasure": 0.6375
        },
        "rouge2": {
            "precision": 0.4671,
            "recall": 0.42638,
            "fmeasure": 0.43225
        },
        "rougeL": {
            "precision": 0.66466,
            "recall": 0.60869,
            "fmeasure": 0.62174
        },
        "rougeLsum": {
            "precision": 0.66466,
            "recall": 0.60869,
            "fmeasure": 0.62174
        },
        "bleu": 37.7636,
        "nist": 3.860221321932611,
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.6,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.65461,
            "contradiction": 26.33931,
            "irrelevancy": 43.74997,
            "logical_agreement": 29.91072,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.46002,
            "nubia_score": 0.59163
        },
        "meteor": 0.3999762311317977,
        "bleurt": 0.19526,
        "bertscore": {
            "precision": 0.91669,
            "recall": 0.92268,
            "f1": 0.91928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85159,
            "recall": 0.81803,
            "fmeasure": 0.82905
        },
        "rouge2": {
            "precision": 0.68866,
            "recall": 0.66603,
            "fmeasure": 0.67208
        },
        "rougeL": {
            "precision": 0.85159,
            "recall": 0.81803,
            "fmeasure": 0.82905
        },
        "rougeLsum": {
            "precision": 0.85159,
            "recall": 0.81803,
            "fmeasure": 0.82905
        },
        "bleu": 53.70289,
        "nist": 4.540359438300825,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.803921568627451
        },
        "nubia": {
            "semantic_relation": 4.02796,
            "contradiction": 46.52228,
            "irrelevancy": 10.32762,
            "logical_agreement": 43.1501,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.08309,
            "nubia_score": 0.68022
        },
        "meteor": 0.4314254039846384,
        "bleurt": 0.58151,
        "bertscore": {
            "precision": 0.96117,
            "recall": 0.95829,
            "f1": 0.95948
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "bleu": 53.10725,
        "nist": 2.7109047337507373,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74936,
            "recall": 0.98039,
            "fmeasure": 0.84087
        },
        "rouge2": {
            "precision": 0.58991,
            "recall": 0.65256,
            "fmeasure": 0.60541
        },
        "rougeL": {
            "precision": 0.55705,
            "recall": 0.66789,
            "fmeasure": 0.60278
        },
        "rougeLsum": {
            "precision": 0.55705,
            "recall": 0.66789,
            "fmeasure": 0.60278
        },
        "bleu": 61.98876,
        "nist": 4.080038431617112,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9523809523809523
        },
        "nubia": {
            "semantic_relation": 4.20003,
            "contradiction": 0.3167,
            "irrelevancy": 50.96522,
            "logical_agreement": 48.71808,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.58684,
            "nubia_score": 0.76547
        },
        "meteor": 0.5299586737889468,
        "bleurt": 0.00168,
        "bertscore": {
            "precision": 0.92421,
            "recall": 0.94972,
            "f1": 0.9367
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.71753,
            "fmeasure": 0.75842
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.5348,
            "fmeasure": 0.56416
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.46914,
            "fmeasure": 0.49386
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.46914,
            "fmeasure": 0.49386
        },
        "bleu": 49.70449,
        "nist": 3.043847001009208,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.15026,
            "contradiction": 2.00263,
            "irrelevancy": 1.16976,
            "logical_agreement": 96.82761,
            "grammar_ref": 5.07625,
            "grammar_hyp": 4.97892,
            "nubia_score": 0.68155
        },
        "meteor": 0.3890565353180701,
        "bleurt": -0.03387,
        "bertscore": {
            "precision": 0.90067,
            "recall": 0.88165,
            "f1": 0.89106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.482634504257068,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2983,
            "irrelevancy": 0.53829,
            "logical_agreement": 99.16341,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.33734,
            "nubia_score": 0.99191
        },
        "meteor": 1.0,
        "bleurt": 0.76845,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8381,
            "recall": 0.79133,
            "fmeasure": 0.80999
        },
        "rouge2": {
            "precision": 0.64062,
            "recall": 0.59694,
            "fmeasure": 0.61484
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.64592,
            "fmeasure": 0.66378
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.64592,
            "fmeasure": 0.66378
        },
        "bleu": 49.81069,
        "nist": 4.431013914646322,
        "local_recall": {
            "1": 0.0,
            "2": 0.6875,
            "3": 0.8695652173913043
        },
        "nubia": {
            "semantic_relation": 4.08175,
            "contradiction": 4.01095,
            "irrelevancy": 62.4035,
            "logical_agreement": 33.58555,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.39236,
            "nubia_score": 0.5919
        },
        "meteor": 0.4432542417526886,
        "bleurt": 0.29091,
        "bertscore": {
            "precision": 0.94025,
            "recall": 0.94706,
            "f1": 0.94276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79074,
            "recall": 0.81381,
            "fmeasure": 0.79493
        },
        "rouge2": {
            "precision": 0.5496,
            "recall": 0.59281,
            "fmeasure": 0.56501
        },
        "rougeL": {
            "precision": 0.68704,
            "recall": 0.72135,
            "fmeasure": 0.69704
        },
        "rougeLsum": {
            "precision": 0.68704,
            "recall": 0.72135,
            "fmeasure": 0.69704
        },
        "bleu": 49.12821,
        "nist": 4.396770158228661,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8387096774193549
        },
        "nubia": {
            "semantic_relation": 4.13255,
            "contradiction": 0.96864,
            "irrelevancy": 62.56644,
            "logical_agreement": 36.46492,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.98425,
            "nubia_score": 0.71359
        },
        "meteor": 0.4273676392364122,
        "bleurt": 0.11264,
        "bertscore": {
            "precision": 0.94108,
            "recall": 0.93043,
            "f1": 0.93538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 4.098214829261011,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "meteor": 1.0,
        "bleurt": 0.94053,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.51176,
            "recall": 0.64713,
            "fmeasure": 0.56292
        },
        "rouge2": {
            "precision": 0.29203,
            "recall": 0.39978,
            "fmeasure": 0.33164
        },
        "rougeL": {
            "precision": 0.35033,
            "recall": 0.54025,
            "fmeasure": 0.42164
        },
        "rougeLsum": {
            "precision": 0.35033,
            "recall": 0.54025,
            "fmeasure": 0.42164
        },
        "bleu": 20.52917,
        "nist": 3.5044366669418276,
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.8,
            "3": 0.5652173913043478
        },
        "nubia": {
            "semantic_relation": 4.25786,
            "contradiction": 38.32896,
            "irrelevancy": 60.83601,
            "logical_agreement": 0.83503,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.47455,
            "nubia_score": 0.80685
        },
        "meteor": 0.33152000794950515,
        "bleurt": 0.32407,
        "bertscore": {
            "precision": 0.87604,
            "recall": 0.93045,
            "f1": 0.89687
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77475,
            "recall": 0.8343,
            "fmeasure": 0.79651
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.78056,
            "fmeasure": 0.73975
        },
        "rougeL": {
            "precision": 0.78232,
            "recall": 0.81568,
            "fmeasure": 0.78529
        },
        "rougeLsum": {
            "precision": 0.78232,
            "recall": 0.81568,
            "fmeasure": 0.78529
        },
        "bleu": 72.28518,
        "nist": 4.81799111524161,
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.8611111111111112
        },
        "nubia": {
            "semantic_relation": 4.48354,
            "contradiction": 1.39355,
            "irrelevancy": 45.61407,
            "logical_agreement": 52.99238,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.28098,
            "nubia_score": 0.86158
        },
        "meteor": 0.49387879573094884,
        "bleurt": 0.56637,
        "bertscore": {
            "precision": 0.95611,
            "recall": 0.96725,
            "f1": 0.95945
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "rouge2": {
            "precision": 0.97701,
            "recall": 0.89449,
            "fmeasure": 0.93388
        },
        "rougeL": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "rougeLsum": {
            "precision": 0.98889,
            "recall": 0.90814,
            "fmeasure": 0.94675
        },
        "bleu": 78.64943,
        "nist": 5.268669230620285,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 3.80951,
            "contradiction": 0.12886,
            "irrelevancy": 0.64448,
            "logical_agreement": 99.22665,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.37595,
            "nubia_score": 0.70765
        },
        "meteor": 0.526069341726537,
        "bleurt": 0.59688,
        "bertscore": {
            "precision": 0.99566,
            "recall": 0.97043,
            "f1": 0.98288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.48039,
            "recall": 0.61206,
            "fmeasure": 0.53825
        },
        "rouge2": {
            "precision": 0.31313,
            "recall": 0.40205,
            "fmeasure": 0.35204
        },
        "rougeL": {
            "precision": 0.2549,
            "recall": 0.53371,
            "fmeasure": 0.33624
        },
        "rougeLsum": {
            "precision": 0.2549,
            "recall": 0.53371,
            "fmeasure": 0.33624
        },
        "bleu": 26.3832,
        "nist": 2.662756900543786,
        "local_recall": {
            "1": 0.0,
            "2": 0.4166666666666667,
            "3": 0.9
        },
        "nubia": {
            "semantic_relation": 3.38168,
            "contradiction": 98.10045,
            "irrelevancy": 0.91427,
            "logical_agreement": 0.98528,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.42584,
            "nubia_score": 0.46187
        },
        "meteor": 0.34662318824791205,
        "bleurt": -0.19279,
        "bertscore": {
            "precision": 0.898,
            "recall": 0.8905,
            "f1": 0.89345
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.89744,
            "fmeasure": 0.77333
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "bleu": 64.75445,
        "nist": 3.0675674754291196,
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.56025,
            "contradiction": 2.65267,
            "irrelevancy": 34.945,
            "logical_agreement": 62.40233,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.62501,
            "nubia_score": 0.71789
        },
        "meteor": 0.5257043737612862,
        "bleurt": 0.45321,
        "bertscore": {
            "precision": 0.93222,
            "recall": 0.99573,
            "f1": 0.94784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.3447,
            "fmeasure": 0.3848
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.06926,
            "fmeasure": 0.0767
        },
        "rougeL": {
            "precision": 0.29167,
            "recall": 0.23485,
            "fmeasure": 0.2549
        },
        "rougeLsum": {
            "precision": 0.29167,
            "recall": 0.23485,
            "fmeasure": 0.2549
        },
        "bleu": 13.50863,
        "nist": 1.4819384029437794,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5
        },
        "nubia": {
            "semantic_relation": 3.17966,
            "contradiction": 1.54098,
            "irrelevancy": 97.01236,
            "logical_agreement": 1.44666,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.1448,
            "nubia_score": 0.33208
        },
        "meteor": 0.28184340940062236,
        "bleurt": -0.64769,
        "bertscore": {
            "precision": 0.87394,
            "recall": 0.87766,
            "f1": 0.8758
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8869,
            "recall": 0.87454,
            "fmeasure": 0.8788
        },
        "rouge2": {
            "precision": 0.7028,
            "recall": 0.70085,
            "fmeasure": 0.70012
        },
        "rougeL": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "rougeLsum": {
            "precision": 0.84524,
            "recall": 0.837,
            "fmeasure": 0.83932
        },
        "bleu": 57.37425,
        "nist": 4.186185062975116,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "nubia": {
            "semantic_relation": 4.56147,
            "contradiction": 0.17796,
            "irrelevancy": 49.33775,
            "logical_agreement": 50.48429,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.72623,
            "nubia_score": 0.84833
        },
        "meteor": 0.5268872887718299,
        "bleurt": 0.53956,
        "bertscore": {
            "precision": 0.96016,
            "recall": 0.96948,
            "f1": 0.9648
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75926,
            "recall": 0.7272,
            "fmeasure": 0.73914
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.39773,
            "fmeasure": 0.40249
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.67349,
            "fmeasure": 0.68479
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.67349,
            "fmeasure": 0.68479
        },
        "bleu": 27.04092,
        "nist": 3.3283321299485475,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8125
        },
        "nubia": {
            "semantic_relation": 4.23285,
            "contradiction": 0.92353,
            "irrelevancy": 12.96708,
            "logical_agreement": 86.10939,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.61861,
            "nubia_score": 0.68404
        },
        "meteor": 0.39276344640287947,
        "bleurt": 0.37295,
        "bertscore": {
            "precision": 0.91729,
            "recall": 0.94369,
            "f1": 0.92959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72619,
            "recall": 0.61917,
            "fmeasure": 0.62962
        },
        "rouge2": {
            "precision": 0.48077,
            "recall": 0.43122,
            "fmeasure": 0.42656
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.56622,
            "fmeasure": 0.55875
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.56622,
            "fmeasure": 0.55875
        },
        "bleu": 24.82167,
        "nist": 2.086883786942068,
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.48
        },
        "nubia": {
            "semantic_relation": 4.12345,
            "contradiction": 0.31832,
            "irrelevancy": 58.42387,
            "logical_agreement": 41.25781,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.56669,
            "nubia_score": 0.73648
        },
        "meteor": 0.2997877698336439,
        "bleurt": 0.03068,
        "bertscore": {
            "precision": 0.93006,
            "recall": 0.8863,
            "f1": 0.9068
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67949,
            "recall": 0.57911,
            "fmeasure": 0.60816
        },
        "rouge2": {
            "precision": 0.44596,
            "recall": 0.38907,
            "fmeasure": 0.39864
        },
        "rougeL": {
            "precision": 0.67949,
            "recall": 0.57911,
            "fmeasure": 0.60816
        },
        "rougeLsum": {
            "precision": 0.67949,
            "recall": 0.57911,
            "fmeasure": 0.60816
        },
        "bleu": 29.82845,
        "nist": 2.9106027658040117,
        "local_recall": {
            "1": 0.0,
            "2": 0.65,
            "3": 0.5263157894736842
        },
        "nubia": {
            "semantic_relation": 3.52286,
            "contradiction": 3.21924,
            "irrelevancy": 29.57015,
            "logical_agreement": 67.21062,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.65953,
            "nubia_score": 0.51746
        },
        "meteor": 0.3665805787457368,
        "bleurt": -0.14976,
        "bertscore": {
            "precision": 0.8969,
            "recall": 0.86719,
            "f1": 0.88106
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66336,
            "recall": 0.66667,
            "fmeasure": 0.66151
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.44774,
            "fmeasure": 0.43744
        },
        "rougeL": {
            "precision": 0.62632,
            "recall": 0.63765,
            "fmeasure": 0.62802
        },
        "rougeLsum": {
            "precision": 0.62632,
            "recall": 0.63765,
            "fmeasure": 0.62802
        },
        "bleu": 29.50381,
        "nist": 3.5311509468004187,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6111111111111112
        },
        "nubia": {
            "semantic_relation": 3.76441,
            "contradiction": 4.02496,
            "irrelevancy": 64.88144,
            "logical_agreement": 31.0936,
            "grammar_ref": 4.46773,
            "grammar_hyp": 3.8935,
            "nubia_score": 0.66282
        },
        "meteor": 0.31329613120821287,
        "bleurt": 0.115,
        "bertscore": {
            "precision": 0.89404,
            "recall": 0.89093,
            "f1": 0.8924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.63333,
            "fmeasure": 0.69413
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.31313,
            "fmeasure": 0.34056
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54286,
            "fmeasure": 0.59497
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54286,
            "fmeasure": 0.59497
        },
        "bleu": 27.80379,
        "nist": 2.890988706863137,
        "local_recall": {
            "1": 0.4,
            "2": 0.36363636363636365,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 3.87063,
            "contradiction": 2.25814,
            "irrelevancy": 34.43834,
            "logical_agreement": 63.30352,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.43002,
            "nubia_score": 0.50203
        },
        "meteor": 0.32384383865920374,
        "bleurt": 0.43241,
        "bertscore": {
            "precision": 0.94722,
            "recall": 0.90939,
            "f1": 0.92619
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.76974,
            "fmeasure": 0.78929
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.56667,
            "fmeasure": 0.58182
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.65132,
            "fmeasure": 0.66786
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.65132,
            "fmeasure": 0.66786
        },
        "bleu": 47.97544,
        "nist": 3.271930867500414,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8125
        },
        "nubia": {
            "semantic_relation": 4.90005,
            "contradiction": 0.42864,
            "irrelevancy": 1.30851,
            "logical_agreement": 98.26285,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.52947,
            "nubia_score": 0.94373
        },
        "meteor": 0.41398775027808776,
        "bleurt": 0.21692,
        "bertscore": {
            "precision": 0.93694,
            "recall": 0.90515,
            "f1": 0.92077
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.71429,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.46154,
            "fmeasure": 0.46154
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.42857,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.42857,
            "fmeasure": 0.42857
        },
        "bleu": 19.76544,
        "nist": 2.6394044288192338,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nubia": {
            "semantic_relation": 4.19311,
            "contradiction": 0.10178,
            "irrelevancy": 99.77639,
            "logical_agreement": 0.12182,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.71314,
            "nubia_score": 0.60911
        },
        "meteor": 0.40330752308799916,
        "bleurt": 0.08325,
        "bertscore": {
            "precision": 0.88698,
            "recall": 0.91019,
            "f1": 0.89843
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57407,
            "recall": 0.58689,
            "fmeasure": 0.53311
        },
        "rouge2": {
            "precision": 0.21591,
            "recall": 0.28838,
            "fmeasure": 0.22851
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.49074,
            "fmeasure": 0.41093
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.49074,
            "fmeasure": 0.41093
        },
        "bleu": 8.1844,
        "nist": 2.6175018445871023,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.96623,
            "contradiction": 0.35101,
            "irrelevancy": 64.82566,
            "logical_agreement": 34.82333,
            "grammar_ref": 5.09196,
            "grammar_hyp": 5.44368,
            "nubia_score": 0.59358
        },
        "meteor": 0.34006070581379694,
        "bleurt": -0.14081,
        "bertscore": {
            "precision": 0.8663,
            "recall": 0.91412,
            "f1": 0.88802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89474,
            "recall": 0.76153,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.55267,
            "fmeasure": 0.60427
        },
        "rougeL": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "rougeLsum": {
            "precision": 0.82456,
            "recall": 0.69104,
            "fmeasure": 0.75184
        },
        "bleu": 46.0002,
        "nist": 3.0398761319201837,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7647058823529411
        },
        "nubia": {
            "semantic_relation": 4.34275,
            "contradiction": 0.11339,
            "irrelevancy": 1.47731,
            "logical_agreement": 98.40931,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.85893,
            "nubia_score": 0.92287
        },
        "meteor": 0.41086177530149887,
        "bleurt": 0.43261,
        "bertscore": {
            "precision": 0.95573,
            "recall": 0.93158,
            "f1": 0.9435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.24324,
            "recall": 0.78462,
            "fmeasure": 0.37021
        },
        "rouge2": {
            "precision": 0.06944,
            "recall": 0.23611,
            "fmeasure": 0.10694
        },
        "rougeL": {
            "precision": 0.14865,
            "recall": 0.48077,
            "fmeasure": 0.22638
        },
        "rougeLsum": {
            "precision": 0.14865,
            "recall": 0.48077,
            "fmeasure": 0.22638
        },
        "bleu": 4.9651,
        "nist": 1.1190743430737042,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 3.15735,
            "contradiction": 0.45887,
            "irrelevancy": 99.10928,
            "logical_agreement": 0.43185,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.30408,
            "nubia_score": 0.07389
        },
        "meteor": 0.30375340828819497,
        "bleurt": -0.81376,
        "bertscore": {
            "precision": 0.77349,
            "recall": 0.9121,
            "f1": 0.83508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.61667,
            "fmeasure": 0.61022
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.2963,
            "fmeasure": 0.30303
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.52222,
            "fmeasure": 0.51075
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.52222,
            "fmeasure": 0.51075
        },
        "bleu": 24.79798,
        "nist": 3.098724959969779,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "nubia": {
            "semantic_relation": 3.32183,
            "contradiction": 89.08962,
            "irrelevancy": 9.11109,
            "logical_agreement": 1.79929,
            "grammar_ref": 5.46955,
            "grammar_hyp": 5.00801,
            "nubia_score": 0.44771
        },
        "meteor": 0.28558803627448653,
        "bleurt": -0.15346,
        "bertscore": {
            "precision": 0.87072,
            "recall": 0.86579,
            "f1": 0.86825
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62963,
            "recall": 0.69281,
            "fmeasure": 0.65916
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40152,
            "fmeasure": 0.36147
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.61438,
            "fmeasure": 0.55873
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.61438,
            "fmeasure": 0.55873
        },
        "bleu": 24.69207,
        "nist": 3.2744048052730457,
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 4.20881,
            "contradiction": 0.58838,
            "irrelevancy": 47.95816,
            "logical_agreement": 51.45346,
            "grammar_ref": 4.69116,
            "grammar_hyp": 4.12201,
            "nubia_score": 0.77297
        },
        "meteor": 0.3599462668362322,
        "bleurt": 0.0647,
        "bertscore": {
            "precision": 0.89396,
            "recall": 0.89718,
            "f1": 0.8921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81111,
            "recall": 0.68571,
            "fmeasure": 0.73123
        },
        "rouge2": {
            "precision": 0.72619,
            "recall": 0.6429,
            "fmeasure": 0.67306
        },
        "rougeL": {
            "precision": 0.81111,
            "recall": 0.68571,
            "fmeasure": 0.73123
        },
        "rougeLsum": {
            "precision": 0.81111,
            "recall": 0.68571,
            "fmeasure": 0.73123
        },
        "bleu": 55.90433,
        "nist": 2.4795871074096953,
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.6538461538461539
        },
        "nubia": {
            "semantic_relation": 3.99582,
            "contradiction": 24.05025,
            "irrelevancy": 24.77975,
            "logical_agreement": 51.16999,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.7514,
            "nubia_score": 0.62232
        },
        "meteor": 0.37476917984582947,
        "bleurt": 0.35045,
        "bertscore": {
            "precision": 0.95709,
            "recall": 0.92456,
            "f1": 0.93905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.62393,
            "fmeasure": 0.65657
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.22222,
            "fmeasure": 0.23333
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.54416,
            "fmeasure": 0.60943
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.54416,
            "fmeasure": 0.60943
        },
        "bleu": 21.47795,
        "nist": 2.0510199537568283,
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.36801,
            "contradiction": 0.15792,
            "irrelevancy": 0.75974,
            "logical_agreement": 99.08234,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.99885,
            "nubia_score": 0.80406
        },
        "meteor": 0.3195991120367437,
        "bleurt": 0.33098,
        "bertscore": {
            "precision": 0.91857,
            "recall": 0.88735,
            "f1": 0.90269
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "bleu": 76.74162,
        "nist": 3.8535769082186824,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "meteor": 0.5426177315437225,
        "bleurt": 0.39021,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.63492,
            "fmeasure": 0.71484
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.47564,
            "fmeasure": 0.53943
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.63492,
            "fmeasure": 0.71484
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.63492,
            "fmeasure": 0.71484
        },
        "bleu": 46.23498,
        "nist": 2.1933874260024186,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 3.87219,
            "contradiction": 0.43601,
            "irrelevancy": 0.61147,
            "logical_agreement": 98.95252,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.97312,
            "nubia_score": 0.65758
        },
        "meteor": 0.45092249565407133,
        "bleurt": 0.12541,
        "bertscore": {
            "precision": 0.93419,
            "recall": 0.92574,
            "f1": 0.92994
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.50961,
            "fmeasure": 0.65278
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.37037,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.47588,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.47588,
            "fmeasure": 0.59259
        },
        "bleu": 55.4897,
        "nist": 2.8320780831181662,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.42857142857142855
        },
        "nubia": {
            "semantic_relation": 3.89898,
            "contradiction": 0.22977,
            "irrelevancy": 33.59978,
            "logical_agreement": 66.17045,
            "grammar_ref": 4.42639,
            "grammar_hyp": 5.07351,
            "nubia_score": 0.56166
        },
        "meteor": 0.29742819820738936,
        "bleurt": 0.04391,
        "bertscore": {
            "precision": 0.95234,
            "recall": 0.8754,
            "f1": 0.91225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88462,
            "recall": 0.88462,
            "fmeasure": 0.88462
        },
        "rouge2": {
            "precision": 0.76,
            "recall": 0.76,
            "fmeasure": 0.76
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.65385,
            "fmeasure": 0.65385
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.65385,
            "fmeasure": 0.65385
        },
        "bleu": 70.01293,
        "nist": 4.496487400105039,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9166666666666666
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1791,
            "irrelevancy": 0.44061,
            "logical_agreement": 99.38029,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.51369,
            "nubia_score": 0.99974
        },
        "meteor": 0.5318654868481969,
        "bleurt": 0.45802,
        "bertscore": {
            "precision": 0.96029,
            "recall": 0.96287,
            "f1": 0.96109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79514,
            "recall": 0.70751,
            "fmeasure": 0.74493
        },
        "rouge2": {
            "precision": 0.46093,
            "recall": 0.42885,
            "fmeasure": 0.44265
        },
        "rougeL": {
            "precision": 0.69097,
            "recall": 0.61819,
            "fmeasure": 0.6496
        },
        "rougeLsum": {
            "precision": 0.69097,
            "recall": 0.61819,
            "fmeasure": 0.6496
        },
        "bleu": 47.53946,
        "nist": 4.1665245899825125,
        "local_recall": {
            "1": 0.5,
            "2": 0.6,
            "3": 0.7111111111111111
        },
        "nubia": {
            "semantic_relation": 3.96471,
            "contradiction": 16.65309,
            "irrelevancy": 23.14592,
            "logical_agreement": 60.20098,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.32143,
            "nubia_score": 0.58082
        },
        "meteor": 0.37613788616270827,
        "bleurt": 0.21485,
        "bertscore": {
            "precision": 0.93632,
            "recall": 0.89159,
            "f1": 0.91286
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.35354,
            "fmeasure": 0.43665
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.32576,
            "fmeasure": 0.40156
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.32576,
            "fmeasure": 0.40156
        },
        "bleu": 8.42356,
        "nist": 0.7403441135981234,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4
        },
        "nubia": {
            "semantic_relation": 3.42224,
            "contradiction": 1.37502,
            "irrelevancy": 47.54107,
            "logical_agreement": 51.08391,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.88761,
            "nubia_score": 0.43545
        },
        "meteor": 0.2037203424242953,
        "bleurt": -0.37116,
        "bertscore": {
            "precision": 0.87221,
            "recall": 0.8197,
            "f1": 0.84205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.63377,
            "fmeasure": 0.6692
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.24028,
            "fmeasure": 0.25057
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.34056,
            "fmeasure": 0.36765
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.34056,
            "fmeasure": 0.36765
        },
        "bleu": 13.22051,
        "nist": 2.4683430516121208,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 2.80775,
            "contradiction": 1.91945,
            "irrelevancy": 39.89199,
            "logical_agreement": 58.18856,
            "grammar_ref": 3.5564,
            "grammar_hyp": 2.66229,
            "nubia_score": 0.50863
        },
        "meteor": 0.31923075992497985,
        "bleurt": -0.111,
        "bertscore": {
            "precision": 0.892,
            "recall": 0.88685,
            "f1": 0.88941
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "bleu": 12.54931,
        "nist": 1.6609640474436813,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "nubia": {
            "semantic_relation": 4.59766,
            "contradiction": 0.24242,
            "irrelevancy": 90.95441,
            "logical_agreement": 8.80317,
            "grammar_ref": 3.99081,
            "grammar_hyp": 2.90139,
            "nubia_score": 1.0
        },
        "meteor": 0.29568923502227945,
        "bleurt": 0.30052,
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.89984,
            "f1": 0.8893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "rouge2": {
            "precision": 0.36905,
            "recall": 0.45899,
            "fmeasure": 0.40384
        },
        "rougeL": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "rougeLsum": {
            "precision": 0.56818,
            "recall": 0.65231,
            "fmeasure": 0.59936
        },
        "bleu": 34.94654,
        "nist": 2.742541030440724,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "nubia": {
            "semantic_relation": 4.63321,
            "contradiction": 0.10963,
            "irrelevancy": 50.16334,
            "logical_agreement": 49.72703,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.22642,
            "nubia_score": 0.89091
        },
        "meteor": 0.39781289839908923,
        "bleurt": 0.43327,
        "bertscore": {
            "precision": 0.92765,
            "recall": 0.9398,
            "f1": 0.9332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.64444,
            "fmeasure": 0.7033
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.35979,
            "fmeasure": 0.40351
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.56667,
            "fmeasure": 0.62027
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.56667,
            "fmeasure": 0.62027
        },
        "bleu": 48.76837,
        "nist": 3.266206484406486,
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 1.0,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 4.10553,
            "contradiction": 0.90873,
            "irrelevancy": 35.45007,
            "logical_agreement": 63.6412,
            "grammar_ref": 4.75278,
            "grammar_hyp": 6.14105,
            "nubia_score": 0.50396
        },
        "meteor": 0.3927516521122784,
        "bleurt": 0.12222,
        "bertscore": {
            "precision": 0.95324,
            "recall": 0.89244,
            "f1": 0.92184
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.97619,
            "fmeasure": 0.95556
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "bleu": 81.53551,
        "nist": 4.503310677983855,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16036,
            "irrelevancy": 2.58913,
            "logical_agreement": 97.25051,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.06363,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.83419,
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99927,
            "f1": 0.99595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65278,
            "recall": 0.71627,
            "fmeasure": 0.68241
        },
        "rouge2": {
            "precision": 0.42029,
            "recall": 0.48333,
            "fmeasure": 0.44961
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.36508,
            "fmeasure": 0.34815
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.36508,
            "fmeasure": 0.34815
        },
        "bleu": 26.51812,
        "nist": 3.1631610693363132,
        "local_recall": {
            "1": 0.125,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.02471,
            "contradiction": 1.69728,
            "irrelevancy": 75.92892,
            "logical_agreement": 22.37379,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.00493,
            "nubia_score": 0.6476
        },
        "meteor": 0.3972482511573958,
        "bleurt": -0.29824,
        "bertscore": {
            "precision": 0.87271,
            "recall": 0.88117,
            "f1": 0.87145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.89286,
            "recall": 0.92857,
            "fmeasure": 0.91005
        },
        "rouge2": {
            "precision": 0.69231,
            "recall": 0.72436,
            "fmeasure": 0.70769
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.78022,
            "fmeasure": 0.76455
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.78022,
            "fmeasure": 0.76455
        },
        "bleu": 76.35913,
        "nist": 3.890798410123824,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 4.75857,
            "contradiction": 0.05702,
            "irrelevancy": 99.71257,
            "logical_agreement": 0.2304,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.28987,
            "nubia_score": 0.98567
        },
        "meteor": 0.4953563741443045,
        "bleurt": 0.46974,
        "bertscore": {
            "precision": 0.94553,
            "recall": 0.9637,
            "f1": 0.95453
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.94737,
            "fmeasure": 0.87805
        },
        "bleu": 64.44281,
        "nist": 3.5287855477614216,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9333333333333333
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.3456,
            "irrelevancy": 0.69108,
            "logical_agreement": 98.96331,
            "grammar_ref": 3.47563,
            "grammar_hyp": 2.87876,
            "nubia_score": 1.0
        },
        "meteor": 0.601757720024524,
        "bleurt": 0.8218,
        "bertscore": {
            "precision": 0.98199,
            "recall": 0.99063,
            "f1": 0.98629
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79762,
            "recall": 0.78301,
            "fmeasure": 0.78284
        },
        "rouge2": {
            "precision": 0.61058,
            "recall": 0.58364,
            "fmeasure": 0.58989
        },
        "rougeL": {
            "precision": 0.79762,
            "recall": 0.78301,
            "fmeasure": 0.78284
        },
        "rougeLsum": {
            "precision": 0.79762,
            "recall": 0.78301,
            "fmeasure": 0.78284
        },
        "bleu": 60.29502,
        "nist": 3.1371065340384043,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "nubia": {
            "semantic_relation": 3.84555,
            "contradiction": 1.61688,
            "irrelevancy": 0.99128,
            "logical_agreement": 97.39184,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.23809,
            "nubia_score": 0.62682
        },
        "meteor": 0.4817440868204493,
        "bleurt": 0.2801,
        "bertscore": {
            "precision": 0.97018,
            "recall": 0.96778,
            "f1": 0.96898
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "mT5_large/totto_test",
        "N": 5,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.67136,
            "recall": 0.80974,
            "fmeasure": 0.72221
        },
        "rouge2": {
            "precision": 0.49365,
            "recall": 0.58356,
            "fmeasure": 0.52669
        },
        "rougeL": {
            "precision": 0.56578,
            "recall": 0.65866,
            "fmeasure": 0.60041
        },
        "rougeLsum": {
            "precision": 0.56578,
            "recall": 0.65866,
            "fmeasure": 0.60041
        },
        "bleu": 53.73527,
        "nist": 5.100171300709431,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.7843137254901961,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.97681,
            "contradiction": 22.19254,
            "irrelevancy": 47.83183,
            "logical_agreement": 29.97563,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.01389,
            "nubia_score": 0.71161
        },
        "meteor": 0.4437651987124188,
        "bleurt": 0.2289,
        "bertscore": {
            "precision": 0.91809,
            "recall": 0.93207,
            "f1": 0.9243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5254,
            "recall": 0.62424,
            "fmeasure": 0.55706
        },
        "rouge2": {
            "precision": 0.25549,
            "recall": 0.29148,
            "fmeasure": 0.2652
        },
        "rougeL": {
            "precision": 0.44286,
            "recall": 0.50227,
            "fmeasure": 0.46026
        },
        "rougeLsum": {
            "precision": 0.44286,
            "recall": 0.50227,
            "fmeasure": 0.46026
        },
        "bleu": 11.81093,
        "nist": 2.643615316856224,
        "local_recall": {
            "1": 0.25,
            "2": 0.1111111111111111,
            "3": 0.5882352941176471
        },
        "nubia": {
            "semantic_relation": 3.4752,
            "contradiction": 45.81666,
            "irrelevancy": 52.30787,
            "logical_agreement": 1.87548,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.29734,
            "nubia_score": 0.50237
        },
        "meteor": 0.28983030232173396,
        "bleurt": 0.00851,
        "bertscore": {
            "precision": 0.88514,
            "recall": 0.90839,
            "f1": 0.89395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.46154
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.18182,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.41667,
            "fmeasure": 0.38462
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.41667,
            "fmeasure": 0.38462
        },
        "bleu": 10.5215,
        "nist": 1.4761610297087115,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.79326,
            "contradiction": 0.29322,
            "irrelevancy": 99.45709,
            "logical_agreement": 0.2497,
            "grammar_ref": 5.64121,
            "grammar_hyp": 5.49866,
            "nubia_score": 0.55599
        },
        "meteor": 0.3059054193199602,
        "bleurt": -0.4282,
        "bertscore": {
            "precision": 0.82676,
            "recall": 0.86744,
            "f1": 0.84649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.95833,
            "recall": 0.78704,
            "fmeasure": 0.86078
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.47727,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.68519,
            "fmeasure": 0.74902
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.68519,
            "fmeasure": 0.74902
        },
        "bleu": 51.31108,
        "nist": 2.5957991985036752,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.40959,
            "contradiction": 4.40287,
            "irrelevancy": 3.29014,
            "logical_agreement": 92.307,
            "grammar_ref": 4.01628,
            "grammar_hyp": 4.54335,
            "nubia_score": 0.75761
        },
        "meteor": 0.4707750203543871,
        "bleurt": 0.60221,
        "bertscore": {
            "precision": 0.98708,
            "recall": 0.96348,
            "f1": 0.97514
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "mT5_large/totto_test",
        "N": 6,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83413,
            "recall": 0.78414,
            "fmeasure": 0.80056
        },
        "rouge2": {
            "precision": 0.64618,
            "recall": 0.59023,
            "fmeasure": 0.61151
        },
        "rougeL": {
            "precision": 0.76403,
            "recall": 0.7218,
            "fmeasure": 0.736
        },
        "rougeLsum": {
            "precision": 0.76403,
            "recall": 0.7218,
            "fmeasure": 0.736
        },
        "bleu": 46.45833,
        "nist": 4.652776948024384,
        "local_recall": {
            "1": 0.3,
            "2": 0.45,
            "3": 0.7741935483870968
        },
        "nubia": {
            "semantic_relation": 4.44962,
            "contradiction": 3.03976,
            "irrelevancy": 14.14415,
            "logical_agreement": 82.81609,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.66366,
            "nubia_score": 0.78765
        },
        "meteor": 0.4343931179754862,
        "bleurt": 0.30811,
        "bertscore": {
            "precision": 0.94253,
            "recall": 0.92477,
            "f1": 0.93238
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.69841,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 86.68779,
        "nist": 3.0476314089081704,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.22675,
            "contradiction": 0.58601,
            "irrelevancy": 0.55339,
            "logical_agreement": 98.8606,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.5844,
            "nubia_score": 0.77636
        },
        "meteor": 0.5570133484098374,
        "bleurt": 0.30208,
        "bertscore": {
            "precision": 0.99092,
            "recall": 0.97079,
            "f1": 0.98075
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2037,
            "fmeasure": 0.1913
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "bleu": 8.13085,
        "nist": 1.7609861280393986,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 3.55137,
            "contradiction": 2.8639,
            "irrelevancy": 96.0266,
            "logical_agreement": 1.1095,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.15651,
            "nubia_score": 0.57012
        },
        "meteor": 0.25360827784083245,
        "bleurt": -0.16593,
        "bertscore": {
            "precision": 0.8866,
            "recall": 0.86039,
            "f1": 0.8733
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.58333,
            "fmeasure": 0.42222
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.17143,
            "fmeasure": 0.11806
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.35417,
            "fmeasure": 0.26111
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.35417,
            "fmeasure": 0.26111
        },
        "bleu": 10.82598,
        "nist": 1.292694301094038,
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "nubia": {
            "semantic_relation": 2.79385,
            "contradiction": 32.92816,
            "irrelevancy": 65.59363,
            "logical_agreement": 1.47822,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.67279,
            "nubia_score": 0.30162
        },
        "meteor": 0.19512195121951217,
        "bleurt": -0.83856,
        "bertscore": {
            "precision": 0.71588,
            "recall": 0.82901,
            "f1": 0.7683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "nist": 2.4156844010247407,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "meteor": 1.0,
        "bleurt": 0.6432,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 50.0,
        "nist": 2.456435556800404,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.1828,
            "irrelevancy": 0.64042,
            "logical_agreement": 98.17678,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.57266,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432,
        "bleurt": 0.83889,
        "bertscore": {
            "precision": 0.97618,
            "recall": 0.98533,
            "f1": 0.98073
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.55633,
            "fmeasure": 0.61712
        },
        "rouge2": {
            "precision": 0.54386,
            "recall": 0.43333,
            "fmeasure": 0.48017
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.40773,
            "fmeasure": 0.44775
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.40773,
            "fmeasure": 0.44775
        },
        "bleu": 44.70253,
        "nist": 2.7778419491965685,
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.6111111111111112
        },
        "nubia": {
            "semantic_relation": 4.28826,
            "contradiction": 24.73165,
            "irrelevancy": 29.63524,
            "logical_agreement": 45.63311,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.75054,
            "nubia_score": 0.75638
        },
        "meteor": 0.3795455527017471,
        "bleurt": -0.03224,
        "bertscore": {
            "precision": 0.932,
            "recall": 0.91809,
            "f1": 0.92499
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.35,
            "recall": 0.5,
            "fmeasure": 0.41176
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.22527,
            "fmeasure": 0.18561
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.41905,
            "fmeasure": 0.34958
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.41905,
            "fmeasure": 0.34958
        },
        "bleu": 6.79832,
        "nist": 1.975528752215161,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 3.35114,
            "contradiction": 63.43231,
            "irrelevancy": 35.98484,
            "logical_agreement": 0.58285,
            "grammar_ref": 3.90604,
            "grammar_hyp": 3.21755,
            "nubia_score": 0.6116
        },
        "meteor": 0.2864543596707069,
        "bleurt": 0.00777,
        "bertscore": {
            "precision": 0.80678,
            "recall": 0.88698,
            "f1": 0.84498
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.52807,
            "fmeasure": 0.58699
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.39286,
            "fmeasure": 0.4381
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.43717,
            "fmeasure": 0.47889
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.43717,
            "fmeasure": 0.47889
        },
        "bleu": 40.64626,
        "nist": 3.1033441431925057,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.8
        },
        "nubia": {
            "semantic_relation": 2.89006,
            "contradiction": 30.92374,
            "irrelevancy": 68.78603,
            "logical_agreement": 0.29022,
            "grammar_ref": 3.66593,
            "grammar_hyp": 4.23534,
            "nubia_score": 0.29608
        },
        "meteor": 0.3865487057654271,
        "bleurt": -0.88636,
        "bertscore": {
            "precision": 0.83583,
            "recall": 0.8417,
            "f1": 0.83876
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.69565,
            "recall": 0.59259,
            "fmeasure": 0.64
        },
        "rougeLsum": {
            "precision": 0.69565,
            "recall": 0.59259,
            "fmeasure": 0.64
        },
        "bleu": 23.75992,
        "nist": 2.2463483543990534,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 3.1664,
            "contradiction": 4.1046,
            "irrelevancy": 23.19128,
            "logical_agreement": 72.70411,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.61955,
            "nubia_score": 0.32791
        },
        "meteor": 0.29419633032185105,
        "bleurt": -0.23325,
        "bertscore": {
            "precision": 0.91924,
            "recall": 0.884,
            "f1": 0.90128
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78409,
            "fmeasure": 0.81988
        },
        "rouge2": {
            "precision": 0.74242,
            "recall": 0.65,
            "fmeasure": 0.6862
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.70644,
            "fmeasure": 0.73395
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.70644,
            "fmeasure": 0.73395
        },
        "bleu": 48.52176,
        "nist": 4.11612579602964,
        "local_recall": {
            "1": 0.5,
            "2": 0.7142857142857143,
            "3": 0.7894736842105263
        },
        "nubia": {
            "semantic_relation": 4.76583,
            "contradiction": 0.14868,
            "irrelevancy": 17.08209,
            "logical_agreement": 82.76922,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.6398,
            "nubia_score": 0.77209
        },
        "meteor": 0.4317910231432469,
        "bleurt": 0.30528,
        "bertscore": {
            "precision": 0.94569,
            "recall": 0.91535,
            "f1": 0.93025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55229,
            "recall": 0.55686,
            "fmeasure": 0.54704
        },
        "rouge2": {
            "precision": 0.34077,
            "recall": 0.33333,
            "fmeasure": 0.33123
        },
        "rougeL": {
            "precision": 0.45621,
            "recall": 0.45338,
            "fmeasure": 0.44828
        },
        "rougeLsum": {
            "precision": 0.45621,
            "recall": 0.45338,
            "fmeasure": 0.44828
        },
        "bleu": 39.94147,
        "nist": 4.0505404506227,
        "local_recall": {
            "1": 0.47058823529411764,
            "2": 0.2857142857142857,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.88076,
            "contradiction": 28.30714,
            "irrelevancy": 54.32445,
            "logical_agreement": 17.36841,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.33788,
            "nubia_score": 0.72693
        },
        "meteor": 0.333864272339849,
        "bleurt": -0.16485,
        "bertscore": {
            "precision": 0.87878,
            "recall": 0.90237,
            "f1": 0.89041
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.88235,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.5625,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.76471,
            "fmeasure": 0.74286
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.76471,
            "fmeasure": 0.74286
        },
        "bleu": 33.86855,
        "nist": 3.7142719787868845,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "nubia": {
            "semantic_relation": 4.36237,
            "contradiction": 0.84342,
            "irrelevancy": 12.27265,
            "logical_agreement": 86.88394,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.47205,
            "nubia_score": 0.64514
        },
        "meteor": 0.5084738171056818,
        "bleurt": 0.48615,
        "bertscore": {
            "precision": 0.96507,
            "recall": 0.97167,
            "f1": 0.96836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69378,
            "recall": 0.76312,
            "fmeasure": 0.71452
        },
        "rouge2": {
            "precision": 0.47064,
            "recall": 0.52468,
            "fmeasure": 0.48858
        },
        "rougeL": {
            "precision": 0.51786,
            "recall": 0.56681,
            "fmeasure": 0.534
        },
        "rougeLsum": {
            "precision": 0.51786,
            "recall": 0.56681,
            "fmeasure": 0.534
        },
        "bleu": 36.84462,
        "nist": 4.04305980553404,
        "local_recall": {
            "1": 0.3,
            "2": 0.7777777777777778,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.11879,
            "contradiction": 1.63083,
            "irrelevancy": 75.79871,
            "logical_agreement": 22.57046,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.20444,
            "nubia_score": 0.71451
        },
        "meteor": 0.39186415979974687,
        "bleurt": 0.04394,
        "bertscore": {
            "precision": 0.91181,
            "recall": 0.92562,
            "f1": 0.91441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "bleu": 42.13953,
        "nist": 1.353289509199005,
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "meteor": 0.2969362339094229,
        "bleurt": 0.02674,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77273,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.65079,
            "fmeasure": 0.73874
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "bleu": 66.49438,
        "nist": 4.1338259274987,
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.41068,
            "contradiction": 0.25383,
            "irrelevancy": 33.28628,
            "logical_agreement": 66.45989,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.26591,
            "nubia_score": 0.87103
        },
        "meteor": 0.45532127755528956,
        "bleurt": 0.05712,
        "bertscore": {
            "precision": 0.97205,
            "recall": 0.93675,
            "f1": 0.95407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88004,
            "recall": 0.82353,
            "fmeasure": 0.84817
        },
        "rouge2": {
            "precision": 0.7938,
            "recall": 0.75,
            "fmeasure": 0.76862
        },
        "rougeL": {
            "precision": 0.88004,
            "recall": 0.82353,
            "fmeasure": 0.84817
        },
        "rougeLsum": {
            "precision": 0.88004,
            "recall": 0.82353,
            "fmeasure": 0.84817
        },
        "bleu": 71.08582,
        "nist": 4.7497414216680305,
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.782608695652174
        },
        "nubia": {
            "semantic_relation": 4.35055,
            "contradiction": 0.23369,
            "irrelevancy": 32.98417,
            "logical_agreement": 66.78214,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.00938,
            "nubia_score": 0.83668
        },
        "meteor": 0.4979506885459726,
        "bleurt": 0.39875,
        "bertscore": {
            "precision": 0.97191,
            "recall": 0.94837,
            "f1": 0.95984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.92593,
            "fmeasure": 0.75185
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77576
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77576
        },
        "bleu": 22.17387,
        "nist": 2.4641043000863823,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.09649,
            "contradiction": 0.82026,
            "irrelevancy": 97.67954,
            "logical_agreement": 1.5002,
            "grammar_ref": 3.90726,
            "grammar_hyp": 3.45954,
            "nubia_score": 0.75354
        },
        "meteor": 0.5649401496178331,
        "bleurt": -0.01085,
        "bertscore": {
            "precision": 0.87526,
            "recall": 0.94809,
            "f1": 0.89285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.44363,
            "fmeasure": 0.49242
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.09647,
            "fmeasure": 0.11121
        },
        "rougeL": {
            "precision": 0.46875,
            "recall": 0.36397,
            "fmeasure": 0.40682
        },
        "rougeLsum": {
            "precision": 0.46875,
            "recall": 0.36397,
            "fmeasure": 0.40682
        },
        "bleu": 8.19531,
        "nist": 2.0548397091348716,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 4.07669,
            "contradiction": 0.6098,
            "irrelevancy": 0.96213,
            "logical_agreement": 98.42807,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.60737,
            "nubia_score": 0.7149
        },
        "meteor": 0.21171456333163696,
        "bleurt": 0.25357,
        "bertscore": {
            "precision": 0.89269,
            "recall": 0.87588,
            "f1": 0.87302
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "mT5_large/totto_test",
        "N": 898,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74499,
            "recall": 0.72606,
            "fmeasure": 0.72026
        },
        "rouge2": {
            "precision": 0.54972,
            "recall": 0.53693,
            "fmeasure": 0.53168
        },
        "rougeL": {
            "precision": 0.7021,
            "recall": 0.68865,
            "fmeasure": 0.68129
        },
        "rougeLsum": {
            "precision": 0.7021,
            "recall": 0.68865,
            "fmeasure": 0.68129
        },
        "bleu": 50.06068,
        "nist": 8.813281502050295,
        "local_recall": {
            "1": 0.24660814046288906,
            "2": 0.5550817341862118,
            "3": 0.7527279452561494
        },
        "nubia": {
            "semantic_relation": 4.08493,
            "contradiction": 10.58214,
            "irrelevancy": 32.15075,
            "logical_agreement": 57.26711,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.06866,
            "nubia_score": 0.70223
        },
        "meteor": 0.40690278465160296,
        "bleurt": 0.32057,
        "bertscore": {
            "precision": 0.93133,
            "recall": 0.92669,
            "f1": 0.92749
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84848,
            "recall": 0.59598,
            "fmeasure": 0.62477
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.23788,
            "fmeasure": 0.30853
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.42236,
            "fmeasure": 0.48133
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.42236,
            "fmeasure": 0.48133
        },
        "bleu": 19.91659,
        "nist": 0.8523422501423792,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "nubia": {
            "semantic_relation": 3.46422,
            "contradiction": 9.30825,
            "irrelevancy": 30.02026,
            "logical_agreement": 60.67149,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.61962,
            "nubia_score": 0.44231
        },
        "meteor": 0.22071064197679782,
        "bleurt": -0.17253,
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.85129,
            "f1": 0.88501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.23214,
            "fmeasure": 0.32071
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.11396,
            "fmeasure": 0.15882
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.23214,
            "fmeasure": 0.32071
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.23214,
            "fmeasure": 0.32071
        },
        "bleu": 16.89984,
        "nist": 0.1959183883776573,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4444444444444444
        },
        "nubia": {
            "semantic_relation": 3.0924,
            "contradiction": 1.8796,
            "irrelevancy": 56.6472,
            "logical_agreement": 41.47321,
            "grammar_ref": 3.10421,
            "grammar_hyp": 3.71805,
            "nubia_score": 0.37937
        },
        "meteor": 0.16157016091176066,
        "bleurt": -0.19237,
        "bertscore": {
            "precision": 0.83632,
            "recall": 0.79154,
            "f1": 0.80878
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.25333,
            "recall": 0.65556,
            "fmeasure": 0.35909
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.2381,
            "fmeasure": 0.12111
        },
        "rougeL": {
            "precision": 0.21333,
            "recall": 0.55,
            "fmeasure": 0.30202
        },
        "rougeLsum": {
            "precision": 0.21333,
            "recall": 0.55,
            "fmeasure": 0.30202
        },
        "bleu": 4.85897,
        "nist": 1.2756029978758245,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 3.70068,
            "contradiction": 0.23836,
            "irrelevancy": 98.88745,
            "logical_agreement": 0.8742,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.11433,
            "nubia_score": 0.34711
        },
        "meteor": 0.2508846138919531,
        "bleurt": -0.43565,
        "bertscore": {
            "precision": 0.81618,
            "recall": 0.9038,
            "f1": 0.8313
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21481,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "bleu": 43.47209,
        "nist": 1.6209105484829365,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 4.15845,
            "contradiction": 14.7927,
            "irrelevancy": 6.53478,
            "logical_agreement": 78.67251,
            "grammar_ref": 7.45181,
            "grammar_hyp": 7.96474,
            "nubia_score": 0.66915
        },
        "meteor": 0.38938120775882434,
        "bleurt": -0.01618,
        "bertscore": {
            "precision": 0.91329,
            "recall": 0.90413,
            "f1": 0.90375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.47222,
            "fmeasure": 0.42319
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.20875,
            "fmeasure": 0.18496
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.47222,
            "fmeasure": 0.42319
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.47222,
            "fmeasure": 0.42319
        },
        "bleu": 7.76856,
        "nist": 1.3471155155881471,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.64718,
            "contradiction": 0.36639,
            "irrelevancy": 81.22038,
            "logical_agreement": 18.41323,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.34987,
            "nubia_score": 0.52431
        },
        "meteor": 0.24849077473656858,
        "bleurt": -0.15322,
        "bertscore": {
            "precision": 0.84197,
            "recall": 0.87082,
            "f1": 0.85615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "bleu": 10.60031,
        "nist": 1.5,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 4.7181,
            "contradiction": 0.18101,
            "irrelevancy": 42.50259,
            "logical_agreement": 57.31642,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.91475,
            "nubia_score": 1.0
        },
        "meteor": 0.44519131687853003,
        "bleurt": 0.68944,
        "bertscore": {
            "precision": 0.88921,
            "recall": 0.94805,
            "f1": 0.91769
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47826,
            "recall": 0.56316,
            "fmeasure": 0.51717
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.29678,
            "fmeasure": 0.27134
        },
        "rougeL": {
            "precision": 0.28261,
            "recall": 0.33289,
            "fmeasure": 0.30565
        },
        "rougeLsum": {
            "precision": 0.28261,
            "recall": 0.33289,
            "fmeasure": 0.30565
        },
        "bleu": 12.76975,
        "nist": 2.635714803711303,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 3.63074,
            "contradiction": 0.29317,
            "irrelevancy": 97.48831,
            "logical_agreement": 2.21852,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.63522,
            "nubia_score": 0.5377
        },
        "meteor": 0.3126696074799186,
        "bleurt": -0.05832,
        "bertscore": {
            "precision": 0.86501,
            "recall": 0.89016,
            "f1": 0.87741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47937,
            "recall": 0.43426,
            "fmeasure": 0.42525
        },
        "rouge2": {
            "precision": 0.16781,
            "recall": 0.16356,
            "fmeasure": 0.15269
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.30444,
            "fmeasure": 0.29362
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.30444,
            "fmeasure": 0.29362
        },
        "bleu": 15.73377,
        "nist": 2.665326368045481,
        "local_recall": {
            "1": 0.15,
            "2": 0.2222222222222222,
            "3": 0.41379310344827586
        },
        "nubia": {
            "semantic_relation": 3.62827,
            "contradiction": 25.53345,
            "irrelevancy": 45.13465,
            "logical_agreement": 29.33189,
            "grammar_ref": 5.44243,
            "grammar_hyp": 5.33034,
            "nubia_score": 0.46934
        },
        "meteor": 0.20683884267890948,
        "bleurt": -0.20894,
        "bertscore": {
            "precision": 0.85662,
            "recall": 0.83511,
            "f1": 0.83615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.54762,
            "fmeasure": 0.50605
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.21703,
            "fmeasure": 0.20115
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.34048,
            "fmeasure": 0.31552
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.34048,
            "fmeasure": 0.31552
        },
        "bleu": 29.75928,
        "nist": 2.977308497872955,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.5454545454545454
        },
        "nubia": {
            "semantic_relation": 3.88892,
            "contradiction": 88.42485,
            "irrelevancy": 9.2669,
            "logical_agreement": 2.30825,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.53498,
            "nubia_score": 0.61347
        },
        "meteor": 0.34594460202174,
        "bleurt": 0.1265,
        "bertscore": {
            "precision": 0.86594,
            "recall": 0.90818,
            "f1": 0.88656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.7037,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "bleu": 59.8806,
        "nist": 3.987204478988863,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22121,
            "irrelevancy": 0.41207,
            "logical_agreement": 99.36672,
            "grammar_ref": 4.16465,
            "grammar_hyp": 4.16956,
            "nubia_score": 0.9949
        },
        "meteor": 0.4809926254597002,
        "bleurt": 0.68527,
        "bertscore": {
            "precision": 0.97856,
            "recall": 0.97206,
            "f1": 0.9753
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.48,
            "fmeasure": 0.57973
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.09127,
            "fmeasure": 0.11128
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.30545,
            "fmeasure": 0.36892
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.30545,
            "fmeasure": 0.36892
        },
        "bleu": 5.9814,
        "nist": 1.4510458684899747,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "nubia": {
            "semantic_relation": 3.30381,
            "contradiction": 30.19941,
            "irrelevancy": 69.44864,
            "logical_agreement": 0.35195,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.34335,
            "nubia_score": 0.39098
        },
        "meteor": 0.206562549322654,
        "bleurt": -0.46979,
        "bertscore": {
            "precision": 0.8527,
            "recall": 0.78265,
            "f1": 0.81618
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.85119,
            "fmeasure": 0.86218
        },
        "rouge2": {
            "precision": 0.78485,
            "recall": 0.76263,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.85119,
            "fmeasure": 0.86218
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.85119,
            "fmeasure": 0.86218
        },
        "bleu": 67.90669,
        "nist": 3.6284207351126496,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.73102,
            "contradiction": 43.62479,
            "irrelevancy": 4.69505,
            "logical_agreement": 51.68017,
            "grammar_ref": 4.94813,
            "grammar_hyp": 4.81589,
            "nubia_score": 0.87228
        },
        "meteor": 0.5201885203480598,
        "bleurt": 0.65241,
        "bertscore": {
            "precision": 0.97609,
            "recall": 0.97753,
            "f1": 0.97681
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.67402,
            "fmeasure": 0.75019
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.32639,
            "fmeasure": 0.36596
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.30637,
            "fmeasure": 0.341
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.30637,
            "fmeasure": 0.341
        },
        "bleu": 15.64124,
        "nist": 2.1679831421664315,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6875
        },
        "nubia": {
            "semantic_relation": 3.40589,
            "contradiction": 3.43369,
            "irrelevancy": 0.87536,
            "logical_agreement": 95.69094,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.20539,
            "nubia_score": 0.46432
        },
        "meteor": 0.3071497776056554,
        "bleurt": 0.12266,
        "bertscore": {
            "precision": 0.92984,
            "recall": 0.88158,
            "f1": 0.90507
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "bleu": 59.46036,
        "nist": 2.625,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.78492,
            "irrelevancy": 0.54406,
            "logical_agreement": 98.67101,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.3113,
            "nubia_score": 1.0
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.90115,
        "bertscore": {
            "precision": 0.97522,
            "recall": 0.97522,
            "f1": 0.97522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81746,
            "recall": 0.81,
            "fmeasure": 0.81283
        },
        "rouge2": {
            "precision": 0.65,
            "recall": 0.65072,
            "fmeasure": 0.65018
        },
        "rougeL": {
            "precision": 0.69841,
            "recall": 0.70072,
            "fmeasure": 0.69937
        },
        "rougeLsum": {
            "precision": 0.69841,
            "recall": 0.70072,
            "fmeasure": 0.69937
        },
        "bleu": 52.0492,
        "nist": 3.8920936045161176,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.84
        },
        "nubia": {
            "semantic_relation": 4.18751,
            "contradiction": 19.35462,
            "irrelevancy": 20.90913,
            "logical_agreement": 59.73625,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.32586,
            "nubia_score": 0.74794
        },
        "meteor": 0.47080280225666526,
        "bleurt": 0.56604,
        "bertscore": {
            "precision": 0.94807,
            "recall": 0.96024,
            "f1": 0.95407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.62963,
            "fmeasure": 0.60943
        },
        "rouge2": {
            "precision": 0.32381,
            "recall": 0.37619,
            "fmeasure": 0.34709
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.54444,
            "fmeasure": 0.5101
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.54444,
            "fmeasure": 0.5101
        },
        "bleu": 29.08187,
        "nist": 3.0123955406795058,
        "local_recall": {
            "1": 0.2,
            "2": 0.4,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.20033,
            "contradiction": 37.91926,
            "irrelevancy": 8.1338,
            "logical_agreement": 53.94695,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.48723,
            "nubia_score": 0.64898
        },
        "meteor": 0.3320748753591156,
        "bleurt": -0.18534,
        "bertscore": {
            "precision": 0.87976,
            "recall": 0.89203,
            "f1": 0.8842
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68251
        },
        "rouge2": {
            "precision": 0.51296,
            "recall": 0.56296,
            "fmeasure": 0.52963
        },
        "rougeL": {
            "precision": 0.57424,
            "recall": 0.65,
            "fmeasure": 0.60098
        },
        "rougeLsum": {
            "precision": 0.57424,
            "recall": 0.65,
            "fmeasure": 0.60098
        },
        "bleu": 53.38557,
        "nist": 3.2928089595271097,
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.09204,
            "contradiction": 0.28522,
            "irrelevancy": 48.59858,
            "logical_agreement": 51.11619,
            "grammar_ref": 5.47595,
            "grammar_hyp": 4.87563,
            "nubia_score": 0.76027
        },
        "meteor": 0.42522227113747574,
        "bleurt": 0.2105,
        "bertscore": {
            "precision": 0.91546,
            "recall": 0.92837,
            "f1": 0.92181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78889,
            "recall": 0.71111,
            "fmeasure": 0.73818
        },
        "rouge2": {
            "precision": 0.53457,
            "recall": 0.51743,
            "fmeasure": 0.52037
        },
        "rougeL": {
            "precision": 0.63704,
            "recall": 0.63704,
            "fmeasure": 0.63348
        },
        "rougeLsum": {
            "precision": 0.63704,
            "recall": 0.63704,
            "fmeasure": 0.63348
        },
        "bleu": 44.80449,
        "nist": 4.2537389206799645,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.23069,
            "contradiction": 2.1306,
            "irrelevancy": 49.96675,
            "logical_agreement": 47.90265,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.03847,
            "nubia_score": 0.73753
        },
        "meteor": 0.3139481865287973,
        "bleurt": 0.1448,
        "bertscore": {
            "precision": 0.91472,
            "recall": 0.88693,
            "f1": 0.8975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "mT5_large/totto_test",
        "N": 4,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69345,
            "recall": 0.63123,
            "fmeasure": 0.66027
        },
        "rouge2": {
            "precision": 0.47941,
            "recall": 0.44402,
            "fmeasure": 0.46075
        },
        "rougeL": {
            "precision": 0.55027,
            "recall": 0.51087,
            "fmeasure": 0.52933
        },
        "rougeLsum": {
            "precision": 0.55027,
            "recall": 0.51087,
            "fmeasure": 0.52933
        },
        "bleu": 29.69384,
        "nist": 3.8944146281882306,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5454545454545454,
            "3": 0.5135135135135135
        },
        "nubia": {
            "semantic_relation": 3.30745,
            "contradiction": 39.26039,
            "irrelevancy": 6.0844,
            "logical_agreement": 54.65521,
            "grammar_ref": 4.12218,
            "grammar_hyp": 4.27767,
            "nubia_score": 0.48637
        },
        "meteor": 0.3186722818735593,
        "bleurt": 0.13481,
        "bertscore": {
            "precision": 0.90856,
            "recall": 0.88791,
            "f1": 0.89782
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92068,
            "recall": 0.88003,
            "fmeasure": 0.89933
        },
        "rouge2": {
            "precision": 0.7625,
            "recall": 0.77492,
            "fmeasure": 0.76445
        },
        "rougeL": {
            "precision": 0.7344,
            "recall": 0.79864,
            "fmeasure": 0.75993
        },
        "rougeLsum": {
            "precision": 0.7344,
            "recall": 0.79864,
            "fmeasure": 0.75993
        },
        "bleu": 68.34546,
        "nist": 4.855515519261943,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6363636363636364,
            "3": 0.9444444444444444
        },
        "nubia": {
            "semantic_relation": 4.72565,
            "contradiction": 0.36471,
            "irrelevancy": 17.071,
            "logical_agreement": 82.56429,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.81956,
            "nubia_score": 0.926
        },
        "meteor": 0.5572384071480025,
        "bleurt": 0.46709,
        "bertscore": {
            "precision": 0.98296,
            "recall": 0.97862,
            "f1": 0.98078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.46252,
            "fmeasure": 0.48323
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.4,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.46252,
            "fmeasure": 0.48323
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.46252,
            "fmeasure": 0.48323
        },
        "bleu": 9.66927,
        "nist": 1.971343932131538,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.88493,
            "contradiction": 0.42114,
            "irrelevancy": 89.68333,
            "logical_agreement": 9.89554,
            "grammar_ref": 3.90557,
            "grammar_hyp": 4.05539,
            "nubia_score": 0.64468
        },
        "meteor": 0.2744159560105366,
        "bleurt": 0.0065,
        "bertscore": {
            "precision": 0.85677,
            "recall": 0.85737,
            "f1": 0.85175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "bleu": 29.42096,
        "nist": 2.749392935937563,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.44897,
            "contradiction": 0.23046,
            "irrelevancy": 99.4262,
            "logical_agreement": 0.34334,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.55703,
            "nubia_score": 0.843
        },
        "meteor": 0.4294445532848442,
        "bleurt": 0.432,
        "bertscore": {
            "precision": 0.91844,
            "recall": 0.94556,
            "f1": 0.9318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.46199,
            "fmeasure": 0.55303
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.25817,
            "fmeasure": 0.31514
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.43421,
            "fmeasure": 0.52273
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.43421,
            "fmeasure": 0.52273
        },
        "bleu": 18.81377,
        "nist": 1.358000211646314,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "nubia": {
            "semantic_relation": 3.86032,
            "contradiction": 0.21346,
            "irrelevancy": 0.89633,
            "logical_agreement": 98.89021,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.68784,
            "nubia_score": 0.59727
        },
        "meteor": 0.30987707503134093,
        "bleurt": 0.22065,
        "bertscore": {
            "precision": 0.93811,
            "recall": 0.83187,
            "f1": 0.88015
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.53333,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.60606,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.60606,
            "fmeasure": 0.66667
        },
        "bleu": 45.54463,
        "nist": 2.9493005133155115,
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.47949,
            "contradiction": 0.42398,
            "irrelevancy": 0.52163,
            "logical_agreement": 99.05438,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.3074,
            "nubia_score": 0.79327
        },
        "meteor": 0.42517641817391244,
        "bleurt": 0.25129,
        "bertscore": {
            "precision": 0.9441,
            "recall": 0.9335,
            "f1": 0.93877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.76912,
            "fmeasure": 0.79985
        },
        "rouge2": {
            "precision": 0.68421,
            "recall": 0.63968,
            "fmeasure": 0.66111
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.6555,
            "fmeasure": 0.67643
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.6555,
            "fmeasure": 0.67643
        },
        "bleu": 65.17633,
        "nist": 4.736498331392873,
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.7857142857142857
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18183,
            "irrelevancy": 0.74294,
            "logical_agreement": 99.07524,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.75693,
            "nubia_score": 0.98469
        },
        "meteor": 0.5244869361126784,
        "bleurt": 0.56565,
        "bertscore": {
            "precision": 0.96846,
            "recall": 0.95761,
            "f1": 0.963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68889,
            "recall": 0.66214,
            "fmeasure": 0.67262
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.29167,
            "fmeasure": 0.29915
        },
        "rougeL": {
            "precision": 0.62222,
            "recall": 0.59729,
            "fmeasure": 0.60714
        },
        "rougeLsum": {
            "precision": 0.62222,
            "recall": 0.59729,
            "fmeasure": 0.60714
        },
        "bleu": 15.31025,
        "nist": 3.2362978660071007,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 3.43382,
            "contradiction": 2.33413,
            "irrelevancy": 97.1298,
            "logical_agreement": 0.53608,
            "grammar_ref": 5.01319,
            "grammar_hyp": 5.45176,
            "nubia_score": 0.3974
        },
        "meteor": 0.25959414761358673,
        "bleurt": -0.31927,
        "bertscore": {
            "precision": 0.90724,
            "recall": 0.88258,
            "f1": 0.88966
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.52941,
            "fmeasure": 0.58065
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "bleu": 12.03953,
        "nist": 2.053843041075097,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "nubia": {
            "semantic_relation": 3.61318,
            "contradiction": 16.36839,
            "irrelevancy": 46.32834,
            "logical_agreement": 37.30327,
            "grammar_ref": 4.71038,
            "grammar_hyp": 5.05114,
            "nubia_score": 0.4516
        },
        "meteor": 0.26124754154767094,
        "bleurt": -0.02168,
        "bertscore": {
            "precision": 0.90109,
            "recall": 0.88653,
            "f1": 0.89375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.69231,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.5,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.69231,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.69231,
            "fmeasure": 0.72
        },
        "bleu": 37.25742,
        "nist": 3.0550460351184014,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.17583,
            "contradiction": 75.55822,
            "irrelevancy": 16.38423,
            "logical_agreement": 8.05755,
            "grammar_ref": 4.23153,
            "grammar_hyp": 4.08441,
            "nubia_score": 0.70052
        },
        "meteor": 0.4406489293262741,
        "bleurt": 0.48019,
        "bertscore": {
            "precision": 0.92485,
            "recall": 0.91375,
            "f1": 0.91927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.84615,
            "recall": 1.0,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 87.02398,
        "nist": 4.131424769581419,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.62082,
            "contradiction": 0.14107,
            "irrelevancy": 33.53918,
            "logical_agreement": 66.31975,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.81494,
            "nubia_score": 0.87596
        },
        "meteor": 0.5722389475370169,
        "bleurt": 0.601,
        "bertscore": {
            "precision": 0.96627,
            "recall": 0.96903,
            "f1": 0.96468
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59821,
            "recall": 0.59768,
            "fmeasure": 0.591
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.44979,
            "fmeasure": 0.43563
        },
        "rougeL": {
            "precision": 0.53571,
            "recall": 0.52259,
            "fmeasure": 0.5228
        },
        "rougeLsum": {
            "precision": 0.53571,
            "recall": 0.52259,
            "fmeasure": 0.5228
        },
        "bleu": 32.00286,
        "nist": 2.696918739764221,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.62938,
            "contradiction": 0.99258,
            "irrelevancy": 0.85966,
            "logical_agreement": 98.14776,
            "grammar_ref": 5.01983,
            "grammar_hyp": 5.11339,
            "nubia_score": 0.82234
        },
        "meteor": 0.36816063050077574,
        "bleurt": 0.46637,
        "bertscore": {
            "precision": 0.95361,
            "recall": 0.93523,
            "f1": 0.94411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.8,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.4,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.4,
            "fmeasure": 0.26667
        },
        "bleu": 7.14182,
        "nist": 0.9232008931146986,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.1457,
            "contradiction": 0.1,
            "irrelevancy": 99.7505,
            "logical_agreement": 0.1495,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.16604,
            "nubia_score": 1.0
        },
        "meteor": 0.3473636678142766,
        "bleurt": 0.37583,
        "bertscore": {
            "precision": 0.87333,
            "recall": 0.94828,
            "f1": 0.90926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.33855,
            "fmeasure": 0.46187
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.04419,
            "fmeasure": 0.06127
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.14348,
            "fmeasure": 0.18786
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.14348,
            "fmeasure": 0.18786
        },
        "bleu": 6.56679,
        "nist": 0.8545675230621658,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.45454545454545453,
            "3": 0.2222222222222222
        },
        "nubia": {
            "semantic_relation": 2.49326,
            "contradiction": 11.8616,
            "irrelevancy": 39.65296,
            "logical_agreement": 48.48544,
            "grammar_ref": 3.96534,
            "grammar_hyp": 4.04188,
            "nubia_score": 0.214
        },
        "meteor": 0.21413755934244527,
        "bleurt": -0.69152,
        "bertscore": {
            "precision": 0.89413,
            "recall": 0.827,
            "f1": 0.85926
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "mT5_large/totto_test",
        "N": 136,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77027,
            "recall": 0.74205,
            "fmeasure": 0.74703
        },
        "rouge2": {
            "precision": 0.54726,
            "recall": 0.52715,
            "fmeasure": 0.5314
        },
        "rougeL": {
            "precision": 0.67617,
            "recall": 0.65137,
            "fmeasure": 0.65608
        },
        "rougeLsum": {
            "precision": 0.67617,
            "recall": 0.65137,
            "fmeasure": 0.65608
        },
        "bleu": 52.28075,
        "nist": 7.83824444420506,
        "local_recall": {
            "1": 0.2701298701298701,
            "2": 0.43506493506493504,
            "3": 0.7920446615491975
        },
        "nubia": {
            "semantic_relation": 4.22924,
            "contradiction": 5.52118,
            "irrelevancy": 24.40633,
            "logical_agreement": 70.07249,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.54958,
            "nubia_score": 0.74749
        },
        "meteor": 0.4099172838474119,
        "bleurt": 0.38311,
        "bertscore": {
            "precision": 0.93543,
            "recall": 0.92885,
            "f1": 0.93068
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.56667,
            "fmeasure": 0.56667
        },
        "rougeL": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "rougeLsum": {
            "precision": 0.77419,
            "recall": 0.77419,
            "fmeasure": 0.77419
        },
        "bleu": 44.87502,
        "nist": 3.8370475980386485,
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 2.49992,
            "contradiction": 84.83945,
            "irrelevancy": 12.11439,
            "logical_agreement": 3.04617,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.6764,
            "nubia_score": 0.27803
        },
        "meteor": 0.3864569947061297,
        "bleurt": -0.10033,
        "bertscore": {
            "precision": 0.97877,
            "recall": 0.97655,
            "f1": 0.97766
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.51754,
            "fmeasure": 0.5358
        },
        "rouge2": {
            "precision": 0.21569,
            "recall": 0.20078,
            "fmeasure": 0.20794
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.46579,
            "fmeasure": 0.48222
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.46579,
            "fmeasure": 0.48222
        },
        "bleu": 16.69107,
        "nist": 2.5249790384034756,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.75448,
            "contradiction": 0.14744,
            "irrelevancy": 99.38746,
            "logical_agreement": 0.4651,
            "grammar_ref": 4.62058,
            "grammar_hyp": 5.02487,
            "nubia_score": 0.53058
        },
        "meteor": 0.2811002242758874,
        "bleurt": -0.18422,
        "bertscore": {
            "precision": 0.81253,
            "recall": 0.78171,
            "f1": 0.79682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "bleu": 19.43406,
        "nist": 2.4929182263680483,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6363636363636364
        },
        "nubia": {
            "semantic_relation": 4.25211,
            "contradiction": 0.57776,
            "irrelevancy": 0.52541,
            "logical_agreement": 98.89683,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.57554,
            "nubia_score": 0.83281
        },
        "meteor": 0.38388402914845343,
        "bleurt": 0.5593,
        "bertscore": {
            "precision": 0.96843,
            "recall": 0.92985,
            "f1": 0.94875
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "bleu": 58.33511,
        "nist": 3.0088906840841796,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "meteor": 0.4630505936482093,
        "bleurt": 0.7528,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.89899,
            "fmeasure": 0.90537
        },
        "rouge2": {
            "precision": 0.7013,
            "recall": 0.69722,
            "fmeasure": 0.69524
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83232,
            "fmeasure": 0.82895
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83232,
            "fmeasure": 0.82895
        },
        "bleu": 57.69398,
        "nist": 3.756985550547935,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9411764705882353
        },
        "nubia": {
            "semantic_relation": 4.98748,
            "contradiction": 0.58137,
            "irrelevancy": 6.10091,
            "logical_agreement": 93.31772,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.73759,
            "nubia_score": 0.95921
        },
        "meteor": 0.48371334997123483,
        "bleurt": 0.76698,
        "bertscore": {
            "precision": 0.98344,
            "recall": 0.97535,
            "f1": 0.97799
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54762,
            "recall": 0.43355,
            "fmeasure": 0.48387
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.12255,
            "fmeasure": 0.1364
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.34641,
            "fmeasure": 0.38306
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.34641,
            "fmeasure": 0.38306
        },
        "bleu": 7.47632,
        "nist": 1.7411221376869714,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.35294117647058826
        },
        "nubia": {
            "semantic_relation": 3.63865,
            "contradiction": 0.41344,
            "irrelevancy": 92.96934,
            "logical_agreement": 6.61721,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.78062,
            "nubia_score": 0.4915
        },
        "meteor": 0.23119269706969292,
        "bleurt": 0.05247,
        "bertscore": {
            "precision": 0.88623,
            "recall": 0.86019,
            "f1": 0.87302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.625,
            "recall": 0.68452,
            "fmeasure": 0.65278
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.47619,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.68452,
            "fmeasure": 0.65278
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.68452,
            "fmeasure": 0.65278
        },
        "bleu": 13.8881,
        "nist": 2.0555103499921668,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.61319,
            "contradiction": 0.10798,
            "irrelevancy": 16.19274,
            "logical_agreement": 83.69928,
            "grammar_ref": 6.37596,
            "grammar_hyp": 5.31967,
            "nubia_score": 0.75394
        },
        "meteor": 0.4453721972021769,
        "bleurt": -0.25696,
        "bertscore": {
            "precision": 0.91347,
            "recall": 0.90102,
            "f1": 0.90721
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.72381,
            "fmeasure": 0.71724
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.27381,
            "fmeasure": 0.2674
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.41905,
            "fmeasure": 0.4092
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.41905,
            "fmeasure": 0.4092
        },
        "bleu": 9.85792,
        "nist": 3.1709763790269765,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 4.08832,
            "contradiction": 0.39364,
            "irrelevancy": 51.75428,
            "logical_agreement": 47.85208,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.42573,
            "nubia_score": 0.84223
        },
        "meteor": 0.3252229975055346,
        "bleurt": 0.06653,
        "bertscore": {
            "precision": 0.90872,
            "recall": 0.87545,
            "f1": 0.89178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.67917,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "bleu": 57.58522,
        "nist": 2.955116912262305,
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 2.89108,
            "contradiction": 0.54,
            "irrelevancy": 98.75045,
            "logical_agreement": 0.70956,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.79961,
            "nubia_score": 0.34265
        },
        "meteor": 0.5139078546685881,
        "bleurt": -0.33255,
        "bertscore": {
            "precision": 0.89616,
            "recall": 0.94973,
            "f1": 0.92216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.3219280948873626,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97683,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.53072,
            "fmeasure": 0.571
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.29722,
            "fmeasure": 0.32512
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.5085,
            "fmeasure": 0.54802
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.5085,
            "fmeasure": 0.54802
        },
        "bleu": 17.96072,
        "nist": 2.9453385319682246,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 2.60689,
            "contradiction": 0.20303,
            "irrelevancy": 97.4244,
            "logical_agreement": 2.37257,
            "grammar_ref": 4.68072,
            "grammar_hyp": 3.78867,
            "nubia_score": 0.35976
        },
        "meteor": 0.24432528689647684,
        "bleurt": -0.1962,
        "bertscore": {
            "precision": 0.86715,
            "recall": 0.80559,
            "f1": 0.83494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.71515,
            "fmeasure": 0.72381
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.85606,
            "fmeasure": 0.86693
        },
        "bleu": 70.71068,
        "nist": 3.4003450955050463,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.91147,
            "contradiction": 0.80604,
            "irrelevancy": 0.73693,
            "logical_agreement": 98.45703,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.43508,
            "nubia_score": 0.92052
        },
        "meteor": 0.5306045115147152,
        "bleurt": 0.64695,
        "bertscore": {
            "precision": 0.98873,
            "recall": 0.98873,
            "f1": 0.98873
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.36276,
            "fmeasure": 0.49323
        },
        "rouge2": {
            "precision": 0.35476,
            "recall": 0.15328,
            "fmeasure": 0.21137
        },
        "rougeL": {
            "precision": 0.72159,
            "recall": 0.28779,
            "fmeasure": 0.40367
        },
        "rougeLsum": {
            "precision": 0.72159,
            "recall": 0.28779,
            "fmeasure": 0.40367
        },
        "bleu": 7.03759,
        "nist": 0.13266114623970662,
        "local_recall": {
            "1": 0.0,
            "2": 0.11764705882352941,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.53207,
            "contradiction": 0.3991,
            "irrelevancy": 2.19185,
            "logical_agreement": 97.40905,
            "grammar_ref": 3.63495,
            "grammar_hyp": 5.37145,
            "nubia_score": 0.37764
        },
        "meteor": 0.21114692225593082,
        "bleurt": -0.26879,
        "bertscore": {
            "precision": 0.91025,
            "recall": 0.82908,
            "f1": 0.86737
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68056,
            "recall": 0.54571,
            "fmeasure": 0.59287
        },
        "rouge2": {
            "precision": 0.43824,
            "recall": 0.32346,
            "fmeasure": 0.36318
        },
        "rougeL": {
            "precision": 0.57465,
            "recall": 0.44663,
            "fmeasure": 0.49159
        },
        "rougeLsum": {
            "precision": 0.57465,
            "recall": 0.44663,
            "fmeasure": 0.49159
        },
        "bleu": 33.02459,
        "nist": 3.5066176820728514,
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.71798,
            "contradiction": 0.15701,
            "irrelevancy": 70.78254,
            "logical_agreement": 29.06045,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.56115,
            "nubia_score": 0.60557
        },
        "meteor": 0.29831012797953604,
        "bleurt": -0.18203,
        "bertscore": {
            "precision": 0.91826,
            "recall": 0.88382,
            "f1": 0.8977
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.40741,
            "fmeasure": 0.39153
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.64133,
            "fmeasure": 0.62222
        },
        "bleu": 31.70233,
        "nist": 1.920911643007432,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.45599,
            "contradiction": 0.07569,
            "irrelevancy": 5.00353,
            "logical_agreement": 94.92078,
            "grammar_ref": 3.44041,
            "grammar_hyp": 4.34642,
            "nubia_score": 0.80331
        },
        "meteor": 0.49721225160341215,
        "bleurt": 0.3902,
        "bertscore": {
            "precision": 0.94738,
            "recall": 0.95744,
            "f1": 0.95238
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51453,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "bleu": 49.35579,
        "nist": 4.502060569538222,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nubia": {
            "semantic_relation": 4.76119,
            "contradiction": 0.26908,
            "irrelevancy": 33.53051,
            "logical_agreement": 66.20041,
            "grammar_ref": 4.41465,
            "grammar_hyp": 4.7223,
            "nubia_score": 0.88644
        },
        "meteor": 0.4452980347402408,
        "bleurt": 0.29739,
        "bertscore": {
            "precision": 0.95538,
            "recall": 0.92773,
            "f1": 0.94135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.15,
            "recall": 0.2,
            "fmeasure": 0.17143
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.07143,
            "fmeasure": 0.06061
        },
        "rougeL": {
            "precision": 0.1,
            "recall": 0.13333,
            "fmeasure": 0.11429
        },
        "rougeLsum": {
            "precision": 0.1,
            "recall": 0.13333,
            "fmeasure": 0.11429
        },
        "bleu": 4.3194,
        "nist": 0.7619047619047619,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nubia": {
            "semantic_relation": 2.54676,
            "contradiction": 0.23115,
            "irrelevancy": 99.35725,
            "logical_agreement": 0.4116,
            "grammar_ref": 5.48676,
            "grammar_hyp": 5.26415,
            "nubia_score": 0.3099
        },
        "meteor": 0.10975885904381236,
        "bleurt": -0.56148,
        "bertscore": {
            "precision": 0.74679,
            "recall": 0.77097,
            "f1": 0.75727
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.64087,
            "fmeasure": 0.66244
        },
        "rouge2": {
            "precision": 0.55159,
            "recall": 0.52164,
            "fmeasure": 0.5259
        },
        "rougeL": {
            "precision": 0.68333,
            "recall": 0.65125,
            "fmeasure": 0.65637
        },
        "rougeLsum": {
            "precision": 0.68333,
            "recall": 0.65125,
            "fmeasure": 0.65637
        },
        "bleu": 49.98751,
        "nist": 3.9149175616711163,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.8181818181818182,
            "3": 0.7272727272727273
        },
        "nubia": {
            "semantic_relation": 4.20519,
            "contradiction": 22.34358,
            "irrelevancy": 35.11354,
            "logical_agreement": 42.54287,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.80316,
            "nubia_score": 0.63606
        },
        "meteor": 0.35355353914787224,
        "bleurt": -0.04993,
        "bertscore": {
            "precision": 0.93542,
            "recall": 0.92472,
            "f1": 0.92116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.57895,
            "recall": 0.69259,
            "fmeasure": 0.62957
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.33613,
            "fmeasure": 0.30357
        },
        "rougeL": {
            "precision": 0.45614,
            "recall": 0.51111,
            "fmeasure": 0.48119
        },
        "rougeLsum": {
            "precision": 0.45614,
            "recall": 0.51111,
            "fmeasure": 0.48119
        },
        "bleu": 29.35974,
        "nist": 2.66624656704561,
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.6923076923076923
        },
        "nubia": {
            "semantic_relation": 4.28813,
            "contradiction": 0.4911,
            "irrelevancy": 58.01708,
            "logical_agreement": 41.49182,
            "grammar_ref": 4.4151,
            "grammar_hyp": 5.21248,
            "nubia_score": 0.62664
        },
        "meteor": 0.3298337096796177,
        "bleurt": -0.10025,
        "bertscore": {
            "precision": 0.91904,
            "recall": 0.91693,
            "f1": 0.91756
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.46875,
            "fmeasure": 0.43793
        },
        "rouge2": {
            "precision": 0.09375,
            "recall": 0.11026,
            "fmeasure": 0.10122
        },
        "rougeL": {
            "precision": 0.38235,
            "recall": 0.43304,
            "fmeasure": 0.40567
        },
        "rougeLsum": {
            "precision": 0.38235,
            "recall": 0.43304,
            "fmeasure": 0.40567
        },
        "bleu": 10.97576,
        "nist": 1.7151456207095728,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "nubia": {
            "semantic_relation": 3.63537,
            "contradiction": 82.85389,
            "irrelevancy": 7.22237,
            "logical_agreement": 9.92374,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.0961,
            "nubia_score": 0.66621
        },
        "meteor": 0.29593876638335775,
        "bleurt": 0.3882,
        "bertscore": {
            "precision": 0.85067,
            "recall": 0.87199,
            "f1": 0.8612
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.4,
            "recall": 0.66667,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.25,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.66667,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.66667,
            "fmeasure": 0.5
        },
        "bleu": 19.92341,
        "nist": 2.1306120659840215,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "nubia": {
            "semantic_relation": 3.62533,
            "contradiction": 6.22533,
            "irrelevancy": 89.82493,
            "logical_agreement": 3.94973,
            "grammar_ref": 5.49813,
            "grammar_hyp": 4.46208,
            "nubia_score": 0.49623
        },
        "meteor": 0.2598163306004562,
        "bleurt": 0.33118,
        "bertscore": {
            "precision": 0.88305,
            "recall": 0.91947,
            "f1": 0.90089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9,
            "recall": 0.69231,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.34921,
            "fmeasure": 0.41684
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.5094,
            "fmeasure": 0.60058
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.5094,
            "fmeasure": 0.60058
        },
        "bleu": 21.35218,
        "nist": 2.930776602466769,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 4.9426,
            "contradiction": 0.34255,
            "irrelevancy": 0.61616,
            "logical_agreement": 99.0413,
            "grammar_ref": 4.20051,
            "grammar_hyp": 5.36142,
            "nubia_score": 0.86853
        },
        "meteor": 0.33946054009743665,
        "bleurt": 0.45089,
        "bertscore": {
            "precision": 0.92786,
            "recall": 0.92547,
            "f1": 0.92666
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 68.94026,
        "nist": 3.0881978509745025,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268,
        "bleurt": 0.64449,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97491
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.854285871987245,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94692,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "bleu": 39.28147,
        "nist": 3.1439774686768684,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 2.68766,
            "contradiction": 26.50481,
            "irrelevancy": 71.49975,
            "logical_agreement": 1.99544,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.72658,
            "nubia_score": 0.46158
        },
        "meteor": 0.49043387317825937,
        "bleurt": 0.07163,
        "bertscore": {
            "precision": 0.91675,
            "recall": 0.92378,
            "f1": 0.92025
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.85613,
            "fmeasure": 0.83405
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.75,
            "fmeasure": 0.64336
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.83761,
            "fmeasure": 0.81385
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.83761,
            "fmeasure": 0.81385
        },
        "bleu": 61.69955,
        "nist": 4.066769838533933,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 3.77193,
            "contradiction": 19.82126,
            "irrelevancy": 75.8945,
            "logical_agreement": 4.28424,
            "grammar_ref": 5.3293,
            "grammar_hyp": 5.15754,
            "nubia_score": 0.52483
        },
        "meteor": 0.504146712391219,
        "bleurt": -0.08283,
        "bertscore": {
            "precision": 0.95208,
            "recall": 0.97168,
            "f1": 0.96178
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.95238,
            "fmeasure": 0.93514
        },
        "rouge2": {
            "precision": 0.78431,
            "recall": 0.81111,
            "fmeasure": 0.79392
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.75794,
            "fmeasure": 0.7823
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.75794,
            "fmeasure": 0.7823
        },
        "bleu": 67.60821,
        "nist": 4.893823938801171,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.15012,
            "contradiction": 0.14811,
            "irrelevancy": 64.18905,
            "logical_agreement": 35.66284,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.84435,
            "nubia_score": 0.79143
        },
        "meteor": 0.524493388596595,
        "bleurt": 0.38998,
        "bertscore": {
            "precision": 0.98712,
            "recall": 0.96534,
            "f1": 0.97354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.69188,
            "fmeasure": 0.73827
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.58013,
            "fmeasure": 0.6419
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.69188,
            "fmeasure": 0.73827
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.69188,
            "fmeasure": 0.73827
        },
        "bleu": 58.63954,
        "nist": 3.6133991758995396,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nubia": {
            "semantic_relation": 4.0419,
            "contradiction": 25.17142,
            "irrelevancy": 68.20729,
            "logical_agreement": 6.62129,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.55505,
            "nubia_score": 0.65409
        },
        "meteor": 0.43767688012631095,
        "bleurt": 0.08378,
        "bertscore": {
            "precision": 0.96337,
            "recall": 0.92431,
            "f1": 0.92777
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.7107,
            "fmeasure": 0.81042
        },
        "rouge2": {
            "precision": 0.70588,
            "recall": 0.52364,
            "fmeasure": 0.60073
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.62709,
            "fmeasure": 0.71508
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.62709,
            "fmeasure": 0.71508
        },
        "bleu": 33.49882,
        "nist": 1.9468876135763638,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.908,
            "contradiction": 0.21385,
            "irrelevancy": 0.47726,
            "logical_agreement": 99.3089,
            "grammar_ref": 3.26294,
            "grammar_hyp": 2.98443,
            "nubia_score": 0.99567
        },
        "meteor": 0.38683478053236436,
        "bleurt": 0.45941,
        "bertscore": {
            "precision": 0.94944,
            "recall": 0.89812,
            "f1": 0.92307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "bleu": 41.10546,
        "nist": 2.32249814589546,
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "meteor": 0.8569614896318238,
        "bleurt": 0.65075,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.69841,
            "fmeasure": 0.45079
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.37778,
            "fmeasure": 0.21832
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.69841,
            "fmeasure": 0.45079
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.69841,
            "fmeasure": 0.45079
        },
        "bleu": 11.18305,
        "nist": 1.2337410628742702,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 2.35587,
            "contradiction": 3.33844,
            "irrelevancy": 96.4321,
            "logical_agreement": 0.22946,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.96977,
            "nubia_score": 0.19086
        },
        "meteor": 0.2618695595037368,
        "bleurt": -1.04963,
        "bertscore": {
            "precision": 0.79924,
            "recall": 0.8931,
            "f1": 0.84357
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79798,
            "recall": 0.5625,
            "fmeasure": 0.659
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.30012,
            "fmeasure": 0.35423
        },
        "rougeL": {
            "precision": 0.79798,
            "recall": 0.5625,
            "fmeasure": 0.659
        },
        "rougeLsum": {
            "precision": 0.79798,
            "recall": 0.5625,
            "fmeasure": 0.659
        },
        "bleu": 13.95551,
        "nist": 2.3929715609428834,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.34612,
            "contradiction": 1.4355,
            "irrelevancy": 1.86759,
            "logical_agreement": 96.69691,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.41844,
            "nubia_score": 0.83416
        },
        "meteor": 0.3557262148639024,
        "bleurt": 0.43976,
        "bertscore": {
            "precision": 0.91564,
            "recall": 0.89439,
            "f1": 0.90488
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.8465578035643277,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "meteor": 1.0,
        "bleurt": 0.87565,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.56173,
            "fmeasure": 0.68372
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.38785,
            "fmeasure": 0.46394
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "bleu": 23.09472,
        "nist": 1.259375898165659,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.85327,
            "contradiction": 0.17167,
            "irrelevancy": 33.45547,
            "logical_agreement": 66.37286,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.58191,
            "nubia_score": 0.72381
        },
        "meteor": 0.32038272111982113,
        "bleurt": 0.18008,
        "bertscore": {
            "precision": 0.96471,
            "recall": 0.89731,
            "f1": 0.92814
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.6,
            "recall": 0.70346,
            "fmeasure": 0.64755
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.51429,
            "fmeasure": 0.40191
        },
        "rougeL": {
            "precision": 0.45333,
            "recall": 0.67937,
            "fmeasure": 0.54058
        },
        "rougeLsum": {
            "precision": 0.45333,
            "recall": 0.67937,
            "fmeasure": 0.54058
        },
        "bleu": 18.55668,
        "nist": 2.4895636680482602,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.71261,
            "contradiction": 0.62951,
            "irrelevancy": 95.47223,
            "logical_agreement": 3.89826,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.14531,
            "nubia_score": 0.71414
        },
        "meteor": 0.40228309302712995,
        "bleurt": -0.02252,
        "bertscore": {
            "precision": 0.8512,
            "recall": 0.93065,
            "f1": 0.87639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.47059
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.125,
            "fmeasure": 0.13333
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.47059
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44444,
            "fmeasure": 0.47059
        },
        "bleu": 8.59132,
        "nist": 1.2807523693493112,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 4.55151,
            "contradiction": 0.24676,
            "irrelevancy": 0.66932,
            "logical_agreement": 99.08392,
            "grammar_ref": 4.6877,
            "grammar_hyp": 5.68232,
            "nubia_score": 0.7523
        },
        "meteor": 0.26765461360568654,
        "bleurt": 0.45074,
        "bertscore": {
            "precision": 0.86551,
            "recall": 0.78119,
            "f1": 0.82119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.79259,
            "fmeasure": 0.74127
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "bleu": 67.03421,
        "nist": 3.317042327913041,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.58306,
            "contradiction": 0.32034,
            "irrelevancy": 2.0668,
            "logical_agreement": 97.61285,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.39911,
            "nubia_score": 0.80652
        },
        "meteor": 0.5101312448597993,
        "bleurt": 0.70956,
        "bertscore": {
            "precision": 0.96861,
            "recall": 0.97259,
            "f1": 0.97059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.46667,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.14286,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.26667,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.26667,
            "fmeasure": 0.33333
        },
        "bleu": 6.7284,
        "nist": 1.518575346287537,
        "local_recall": {
            "1": 0.0,
            "2": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 3.49578,
            "contradiction": 11.33758,
            "irrelevancy": 43.49428,
            "logical_agreement": 45.16815,
            "grammar_ref": 5.62728,
            "grammar_hyp": 6.12287,
            "nubia_score": 0.3693
        },
        "meteor": 0.2899518349921722,
        "bleurt": -0.45025,
        "bertscore": {
            "precision": 0.90485,
            "recall": 0.88122,
            "f1": 0.89288
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.80556,
            "fmeasure": 0.65152
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.46061,
            "fmeasure": 0.35238
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "bleu": 13.49277,
        "nist": 2.4750342424108394,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.41602,
            "contradiction": 4.30121,
            "irrelevancy": 64.9026,
            "logical_agreement": 30.79619,
            "grammar_ref": 5.75818,
            "grammar_hyp": 4.90912,
            "nubia_score": 0.79964
        },
        "meteor": 0.42919650333815856,
        "bleurt": 0.09151,
        "bertscore": {
            "precision": 0.85921,
            "recall": 0.91534,
            "f1": 0.87223
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55,
            "recall": 0.62037,
            "fmeasure": 0.55486
        },
        "rouge2": {
            "precision": 0.24561,
            "recall": 0.42029,
            "fmeasure": 0.29277
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.65741,
            "fmeasure": 0.47335
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.65741,
            "fmeasure": 0.47335
        },
        "bleu": 40.28998,
        "nist": 3.414199825900226,
        "local_recall": {
            "1": 0.8,
            "2": 0.2222222222222222,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 3.79217,
            "contradiction": 0.09367,
            "irrelevancy": 90.51177,
            "logical_agreement": 9.39456,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.4527,
            "nubia_score": 0.59896
        },
        "meteor": 0.3477697778009141,
        "bleurt": -0.03634,
        "bertscore": {
            "precision": 0.88533,
            "recall": 0.86866,
            "f1": 0.86927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.87179,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.80556,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.82051,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.82051,
            "fmeasure": 0.85714
        },
        "bleu": 100.0,
        "nist": 0.8492125634412494,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.10842,
            "contradiction": 0.14426,
            "irrelevancy": 0.4271,
            "logical_agreement": 99.42863,
            "grammar_ref": 4.62626,
            "grammar_hyp": 5.09643,
            "nubia_score": 0.67307
        },
        "meteor": 1.0,
        "bleurt": 0.33679,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.9463,
            "recall": 0.95,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.90046,
            "recall": 0.90509,
            "fmeasure": 0.90196
        },
        "rougeL": {
            "precision": 0.9463,
            "recall": 0.95,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9463,
            "recall": 0.95,
            "fmeasure": 0.94737
        },
        "bleu": 100.0,
        "nist": 5.517095336095972,
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.42189,
            "irrelevancy": 0.50293,
            "logical_agreement": 99.07518,
            "grammar_ref": 4.85767,
            "grammar_hyp": 4.88867,
            "nubia_score": 0.98318
        },
        "meteor": 1.0,
        "bleurt": 0.86652,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69913,
            "recall": 0.833,
            "fmeasure": 0.75983
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.6468,
            "fmeasure": 0.58427
        },
        "rougeL": {
            "precision": 0.69913,
            "recall": 0.833,
            "fmeasure": 0.75983
        },
        "rougeLsum": {
            "precision": 0.69913,
            "recall": 0.833,
            "fmeasure": 0.75983
        },
        "bleu": 45.23612,
        "nist": 3.545940114546514,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "nubia": {
            "semantic_relation": 4.30582,
            "contradiction": 15.28607,
            "irrelevancy": 24.52595,
            "logical_agreement": 60.18797,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.80953,
            "nubia_score": 0.74866
        },
        "meteor": 0.4047603923429866,
        "bleurt": 0.37887,
        "bertscore": {
            "precision": 0.92087,
            "recall": 0.93997,
            "f1": 0.92862
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.30556,
            "recall": 0.26869,
            "fmeasure": 0.28449
        },
        "rougeLsum": {
            "precision": 0.30556,
            "recall": 0.26869,
            "fmeasure": 0.28449
        },
        "bleu": 8.03228,
        "nist": 2.3194686589272067,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.29429,
            "contradiction": 0.52901,
            "irrelevancy": 98.42825,
            "logical_agreement": 1.04274,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.80459,
            "nubia_score": 0.41007
        },
        "meteor": 0.2255639097744361,
        "bleurt": -0.38423,
        "bertscore": {
            "precision": 0.78642,
            "recall": 0.76963,
            "f1": 0.77456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75439,
            "recall": 0.82114,
            "fmeasure": 0.75843
        },
        "rouge2": {
            "precision": 0.54444,
            "recall": 0.60921,
            "fmeasure": 0.55068
        },
        "rougeL": {
            "precision": 0.63876,
            "recall": 0.75082,
            "fmeasure": 0.65245
        },
        "rougeLsum": {
            "precision": 0.63876,
            "recall": 0.75082,
            "fmeasure": 0.65245
        },
        "bleu": 40.01602,
        "nist": 3.6525749934450578,
        "local_recall": {
            "1": 0.75,
            "2": 0.5,
            "3": 0.9333333333333333
        },
        "nubia": {
            "semantic_relation": 3.98597,
            "contradiction": 1.48099,
            "irrelevancy": 48.45288,
            "logical_agreement": 50.06612,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.51428,
            "nubia_score": 0.58157
        },
        "meteor": 0.447917839982815,
        "bleurt": 0.15998,
        "bertscore": {
            "precision": 0.89662,
            "recall": 0.96662,
            "f1": 0.92332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75198,
            "recall": 0.60522,
            "fmeasure": 0.66088
        },
        "rouge2": {
            "precision": 0.48737,
            "recall": 0.40065,
            "fmeasure": 0.43294
        },
        "rougeL": {
            "precision": 0.6131,
            "recall": 0.51936,
            "fmeasure": 0.555
        },
        "rougeLsum": {
            "precision": 0.6131,
            "recall": 0.51936,
            "fmeasure": 0.555
        },
        "bleu": 14.76275,
        "nist": 2.9640664211283183,
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.5789473684210527
        },
        "nubia": {
            "semantic_relation": 4.05748,
            "contradiction": 21.15533,
            "irrelevancy": 17.43296,
            "logical_agreement": 61.41171,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.35958,
            "nubia_score": 0.63849
        },
        "meteor": 0.3020958905699467,
        "bleurt": -0.16036,
        "bertscore": {
            "precision": 0.90451,
            "recall": 0.85917,
            "f1": 0.87874
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.93333,
            "recall": 1.0,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.85185,
            "recall": 0.94444,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94118
        },
        "bleu": 58.77284,
        "nist": 3.276287077976025,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.86235,
            "contradiction": 0.89405,
            "irrelevancy": 60.76008,
            "logical_agreement": 38.34587,
            "grammar_ref": 6.57473,
            "grammar_hyp": 5.18446,
            "nubia_score": 0.99266
        },
        "meteor": 0.5054764086193895,
        "bleurt": 0.4663,
        "bertscore": {
            "precision": 0.99179,
            "recall": 0.95164,
            "f1": 0.9713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74697,
            "recall": 0.71347,
            "fmeasure": 0.72277
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.41429,
            "fmeasure": 0.41423
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.51498,
            "fmeasure": 0.52531
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.51498,
            "fmeasure": 0.52531
        },
        "bleu": 30.1773,
        "nist": 3.098689418832649,
        "local_recall": {
            "1": 0.5,
            "2": 0.14285714285714285,
            "3": 0.7368421052631579
        },
        "nubia": {
            "semantic_relation": 4.43702,
            "contradiction": 0.38567,
            "irrelevancy": 6.13479,
            "logical_agreement": 93.47954,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.59678,
            "nubia_score": 0.82202
        },
        "meteor": 0.3963445767543614,
        "bleurt": 0.34474,
        "bertscore": {
            "precision": 0.93481,
            "recall": 0.92236,
            "f1": 0.92604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.89356,
            "fmeasure": 0.88937
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.55609,
            "fmeasure": 0.55062
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.80672,
            "fmeasure": 0.80172
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.80672,
            "fmeasure": 0.80172
        },
        "bleu": 52.18739,
        "nist": 3.9131113378579667,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.9285714285714286
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2935,
            "irrelevancy": 0.41515,
            "logical_agreement": 99.29135,
            "grammar_ref": 5.90677,
            "grammar_hyp": 5.87001,
            "nubia_score": 0.94602
        },
        "meteor": 0.46827837129790095,
        "bleurt": 0.65866,
        "bertscore": {
            "precision": 0.97993,
            "recall": 0.98922,
            "f1": 0.98456
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.74611,
        "msttr-100_nopunct": 0.78533,
        "total_length": 1807,
        "mean_pred_length": 28.682539682539684,
        "std_pred_length": 9.062088124105845,
        "median_pred_length": 27.0,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.47703375760929717,
        "vocab_size-1": 862,
        "unique-1": 695,
        "entropy-1": 8.416891409582309,
        "distinct-2": 0.9111238532110092,
        "vocab_size-2": 1589,
        "unique-2": 1517,
        "entropy-2": 10.512554435416176,
        "cond_entropy-2": 1.9560697224837291,
        "distinct-3": 0.9815585960737656,
        "vocab_size-3": 1650,
        "unique-3": 1642,
        "entropy-3": 10.64909192108952,
        "cond_entropy-3": 0.14314348390650342,
        "total_length-nopunct": 1595,
        "mean_pred_length-nopunct": 25.317460317460316,
        "std_pred_length-nopunct": 7.688014578107094,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.534796238244514,
        "vocab_size-1-nopunct": 853,
        "unique-1-nopunct": 693,
        "entropy-1-nopunct": 8.666921754713195,
        "distinct-2-nopunct": 0.9464751958224543,
        "vocab_size-2-nopunct": 1450,
        "unique-2-nopunct": 1400,
        "entropy-2-nopunct": 10.448885052866776,
        "cond_entropy-2-nopunct": 1.843050130215959,
        "distinct-3-nopunct": 0.998638529611981,
        "vocab_size-3-nopunct": 1467,
        "unique-3-nopunct": 1465,
        "entropy-3-nopunct": 10.517895739780387,
        "cond_entropy-3-nopunct": 0.07468521266652015,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.87748,
            "recall": 0.91655,
            "fmeasure": 0.8939
        },
        "rouge2": {
            "precision": 0.78164,
            "recall": 0.81414,
            "fmeasure": 0.79476
        },
        "rougeL": {
            "precision": 0.86966,
            "recall": 0.91036,
            "fmeasure": 0.88679
        },
        "rougeLsum": {
            "precision": 0.86966,
            "recall": 0.91036,
            "fmeasure": 0.88679
        },
        "bleu": 85.15728,
        "nist": 11.380531237792248,
        "local_recall": {
            "1": 0.03183673469387755,
            "2": 0.22404371584699453,
            "3": 0.45614035087719296,
            "4": 0.6871165644171779,
            "5": 0.7784431137724551,
            "6": 0.8440860215053764,
            "7": 0.927710843373494,
            "8": 0.986046511627907,
            "9": 0.9655172413793104,
            "10": 0.9814814814814815
        },
        "nubia": {
            "semantic_relation": 4.30349,
            "contradiction": 1.21796,
            "irrelevancy": 42.84568,
            "logical_agreement": 55.93636,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.50446,
            "nubia_score": 0.6307
        },
        "meteor": 0.5630547605601864,
        "bleurt": 0.22683,
        "bertscore": {
            "precision": 0.96588,
            "recall": 0.98047,
            "f1": 0.97096
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.50739,
            "fmeasure": 0.52762
        },
        "rouge2": {
            "precision": 0.28333,
            "recall": 0.25952,
            "fmeasure": 0.26944
        },
        "rougeL": {
            "precision": 0.39683,
            "recall": 0.35742,
            "fmeasure": 0.37397
        },
        "rougeLsum": {
            "precision": 0.39683,
            "recall": 0.35742,
            "fmeasure": 0.37397
        },
        "bleu": 12.05561,
        "nist": 2.748435577656519,
        "local_recall": {
            "1": 0.375,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "nubia": {
            "semantic_relation": 4.21575,
            "contradiction": 1.24389,
            "irrelevancy": 51.92902,
            "logical_agreement": 46.82709,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.92654,
            "nubia_score": 0.60496
        },
        "meteor": 0.3107737502632116,
        "bleurt": 0.21972,
        "bertscore": {
            "precision": 0.87724,
            "recall": 0.8713,
            "f1": 0.87291
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.30556,
            "recall": 0.26869,
            "fmeasure": 0.28449
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.09697,
            "fmeasure": 0.0938
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.26515,
            "fmeasure": 0.25725
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.26515,
            "fmeasure": 0.25725
        },
        "bleu": 6.10241,
        "nist": 0.9446671111884889,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.3
        },
        "nubia": {
            "semantic_relation": 2.76834,
            "contradiction": 2.56836,
            "irrelevancy": 85.34946,
            "logical_agreement": 12.08218,
            "grammar_ref": 5.20931,
            "grammar_hyp": 5.85544,
            "nubia_score": 0.23713
        },
        "meteor": 0.12009625851054263,
        "bleurt": -0.67356,
        "bertscore": {
            "precision": 0.74824,
            "recall": 0.74943,
            "f1": 0.74496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.62143,
            "fmeasure": 0.65476
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2967,
            "fmeasure": 0.31385
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.62143,
            "fmeasure": 0.65476
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.62143,
            "fmeasure": 0.65476
        },
        "bleu": 45.2274,
        "nist": 3.871951691541422,
        "local_recall": {
            "1": 0.4,
            "2": 0.7272727272727273
        },
        "nubia": {
            "semantic_relation": 4.48939,
            "contradiction": 0.15767,
            "irrelevancy": 88.47917,
            "logical_agreement": 11.36316,
            "grammar_ref": 5.03823,
            "grammar_hyp": 5.26163,
            "nubia_score": 0.76675
        },
        "meteor": 0.4141804763245871,
        "bleurt": 0.51036,
        "bertscore": {
            "precision": 0.9263,
            "recall": 0.91426,
            "f1": 0.92024
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.42857,
            "fmeasure": 0.35294
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "bleu": 21.4016,
        "nist": 1.5331975822557058,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 2.95435,
            "contradiction": 11.50637,
            "irrelevancy": 87.75297,
            "logical_agreement": 0.74066,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.72795,
            "nubia_score": 0.31847
        },
        "meteor": 0.2972166785916692,
        "bleurt": -0.24768,
        "bertscore": {
            "precision": 0.8401,
            "recall": 0.88374,
            "f1": 0.84977
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2,
            "fmeasure": 0.25
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "bleu": 28.6419,
        "nist": 1.3934338964335204,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.30154,
            "irrelevancy": 0.49604,
            "logical_agreement": 99.20242,
            "grammar_ref": 5.72796,
            "grammar_hyp": 7.07513,
            "nubia_score": 0.79132
        },
        "meteor": 0.4307001776843669,
        "bleurt": 0.82527,
        "bertscore": {
            "precision": 0.97397,
            "recall": 0.93815,
            "f1": 0.95573
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.72345,
        "msttr-100_nopunct": 0.76808,
        "total_length": 2990,
        "mean_pred_length": 17.183908045977013,
        "std_pred_length": 7.330504264588735,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 43,
        "distinct-1": 0.4377926421404682,
        "vocab_size-1": 1309,
        "unique-1": 1019,
        "entropy-1": 8.583522077543034,
        "distinct-2": 0.8707386363636364,
        "vocab_size-2": 2452,
        "unique-2": 2325,
        "entropy-2": 11.019498426665981,
        "cond_entropy-2": 2.1508152419673623,
        "distinct-3": 0.9697199091597275,
        "vocab_size-3": 2562,
        "unique-3": 2531,
        "entropy-3": 11.269934750629176,
        "cond_entropy-3": 0.2708615370222313,
        "total_length-nopunct": 2616,
        "mean_pred_length-nopunct": 15.03448275862069,
        "std_pred_length-nopunct": 6.296228164566262,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.49655963302752293,
        "vocab_size-1-nopunct": 1299,
        "unique-1-nopunct": 1018,
        "entropy-1-nopunct": 8.913369968232965,
        "distinct-2-nopunct": 0.8886158886158886,
        "vocab_size-2-nopunct": 2170,
        "unique-2-nopunct": 2070,
        "entropy-2-nopunct": 10.8786578051414,
        "cond_entropy-2-nopunct": 2.1025192755941458,
        "distinct-3-nopunct": 0.9845679012345679,
        "vocab_size-3-nopunct": 2233,
        "unique-3-nopunct": 2209,
        "entropy-3-nopunct": 11.112247159282727,
        "cond_entropy-3-nopunct": 0.25623405951596284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.87829,
            "recall": 0.83493,
            "fmeasure": 0.84554
        },
        "rouge2": {
            "precision": 0.74423,
            "recall": 0.71194,
            "fmeasure": 0.7165
        },
        "rougeL": {
            "precision": 0.84374,
            "recall": 0.80885,
            "fmeasure": 0.81517
        },
        "rougeLsum": {
            "precision": 0.84374,
            "recall": 0.80885,
            "fmeasure": 0.81517
        },
        "bleu": 72.6252,
        "nist": 10.646446017770925,
        "local_recall": {
            "1": 0.04249737670514166,
            "2": 0.16831683168316833,
            "3": 0.42857142857142855,
            "4": 0.5846774193548387,
            "5": 0.6904024767801857,
            "6": 0.7955223880597015,
            "7": 0.8987341772151899
        },
        "nubia": {
            "semantic_relation": 4.40944,
            "contradiction": 4.05175,
            "irrelevancy": 16.2569,
            "logical_agreement": 79.69135,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.02998,
            "nubia_score": 0.72068
        },
        "meteor": 0.4914280760654701,
        "bleurt": 0.28382,
        "bertscore": {
            "precision": 0.95974,
            "recall": 0.95351,
            "f1": 0.9544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.27273,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "bleu": 31.4556,
        "nist": 2.0067815186346585,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.75725,
            "contradiction": 1.66237,
            "irrelevancy": 89.32813,
            "logical_agreement": 9.00951,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.64818,
            "nubia_score": 0.54273
        },
        "meteor": 0.3094759133961572,
        "bleurt": -0.33575,
        "bertscore": {
            "precision": 0.87928,
            "recall": 0.88074,
            "f1": 0.87752
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.48254,
            "fmeasure": 0.53011
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.27018,
            "fmeasure": 0.29841
        },
        "rougeL": {
            "precision": 0.39216,
            "recall": 0.32222,
            "fmeasure": 0.35372
        },
        "rougeLsum": {
            "precision": 0.39216,
            "recall": 0.32222,
            "fmeasure": 0.35372
        },
        "bleu": 27.19327,
        "nist": 3.625238334145811,
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.0,
            "3": 0.7
        },
        "nubia": {
            "semantic_relation": 3.60115,
            "contradiction": 6.22248,
            "irrelevancy": 68.44098,
            "logical_agreement": 25.33654,
            "grammar_ref": 5.50536,
            "grammar_hyp": 5.11548,
            "nubia_score": 0.53398
        },
        "meteor": 0.32717415873019895,
        "bleurt": -0.18963,
        "bertscore": {
            "precision": 0.88788,
            "recall": 0.86711,
            "f1": 0.87673
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.77091,
        "total_length": 1248,
        "mean_pred_length": 21.517241379310345,
        "std_pred_length": 8.950517957099283,
        "median_pred_length": 20.5,
        "min_pred_length": 9,
        "max_pred_length": 52,
        "distinct-1": 0.5128205128205128,
        "vocab_size-1": 640,
        "unique-1": 521,
        "entropy-1": 8.10916520897887,
        "distinct-2": 0.9252100840336135,
        "vocab_size-2": 1101,
        "unique-2": 1053,
        "entropy-2": 10.020511597869616,
        "cond_entropy-2": 1.7249781087002614,
        "distinct-3": 0.9840989399293286,
        "vocab_size-3": 1114,
        "unique-3": 1104,
        "entropy-3": 10.103121537877518,
        "cond_entropy-3": 0.09266434557198601,
        "total_length-nopunct": 1120,
        "mean_pred_length-nopunct": 19.310344827586206,
        "std_pred_length-nopunct": 8.124477482512493,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5642857142857143,
        "vocab_size-1-nopunct": 632,
        "unique-1-nopunct": 519,
        "entropy-1-nopunct": 8.291383993222414,
        "distinct-2-nopunct": 0.9425612052730696,
        "vocab_size-2-nopunct": 1001,
        "unique-2-nopunct": 960,
        "entropy-2-nopunct": 9.91148689702255,
        "cond_entropy-2-nopunct": 1.708875234573337,
        "distinct-3-nopunct": 0.9940239043824701,
        "vocab_size-3-nopunct": 998,
        "unique-3-nopunct": 992,
        "entropy-3-nopunct": 9.959591362715882,
        "cond_entropy-3-nopunct": 0.056254572186285795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.86345,
            "recall": 0.81715,
            "fmeasure": 0.83522
        },
        "rouge2": {
            "precision": 0.74776,
            "recall": 0.70693,
            "fmeasure": 0.7222
        },
        "rougeL": {
            "precision": 0.84708,
            "recall": 0.80628,
            "fmeasure": 0.82153
        },
        "rougeLsum": {
            "precision": 0.84708,
            "recall": 0.80628,
            "fmeasure": 0.82153
        },
        "bleu": 72.61643,
        "nist": 9.766333373362023,
        "local_recall": {
            "1": 0.044548651817116064,
            "2": 0.19014084507042253,
            "3": 0.4025974025974026,
            "4": 0.5576923076923077,
            "5": 0.6927374301675978,
            "6": 0.8458781362007168,
            "7": 0.8967136150234741
        },
        "nubia": {
            "semantic_relation": 4.41976,
            "contradiction": 4.53908,
            "irrelevancy": 16.27759,
            "logical_agreement": 79.18333,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.77229,
            "nubia_score": 0.74968
        },
        "meteor": 0.4810868237658687,
        "bleurt": 0.25111,
        "bertscore": {
            "precision": 0.95802,
            "recall": 0.95234,
            "f1": 0.95366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86957,
            "recall": 0.74074,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "bleu": 45.8736,
        "nist": 3.233101956544771,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nubia": {
            "semantic_relation": 4.16847,
            "contradiction": 0.12934,
            "irrelevancy": 3.90988,
            "logical_agreement": 95.96078,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.08326,
            "nubia_score": 0.73512
        },
        "meteor": 0.41030282160569487,
        "bleurt": 0.14383,
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.91449,
            "f1": 0.9194
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 502,
        "mean_pred_length": 22.818181818181817,
        "std_pred_length": 10.007435252380027,
        "median_pred_length": 21.5,
        "min_pred_length": 10,
        "max_pred_length": 44,
        "distinct-1": 0.5856573705179283,
        "vocab_size-1": 294,
        "unique-1": 243,
        "entropy-1": 7.367387678980402,
        "distinct-2": 0.9375,
        "vocab_size-2": 450,
        "unique-2": 431,
        "entropy-2": 8.748475803905826,
        "cond_entropy-2": 1.2444678212452203,
        "distinct-3": 0.9934497816593887,
        "vocab_size-3": 455,
        "unique-3": 452,
        "entropy-3": 8.826103351415743,
        "cond_entropy-3": 0.08523699165285255,
        "total_length-nopunct": 446,
        "mean_pred_length-nopunct": 20.272727272727273,
        "std_pred_length-nopunct": 8.634928110359366,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6457399103139013,
        "vocab_size-1-nopunct": 288,
        "unique-1-nopunct": 243,
        "entropy-1-nopunct": 7.4923127281636,
        "distinct-2-nopunct": 0.9386792452830188,
        "vocab_size-2-nopunct": 398,
        "unique-2-nopunct": 383,
        "entropy-2-nopunct": 8.567450879050737,
        "cond_entropy-2-nopunct": 1.1322229510709056,
        "distinct-3-nopunct": 0.9975124378109452,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 400,
        "entropy-3-nopunct": 8.64607656680077,
        "cond_entropy-3-nopunct": 0.08492004262893196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84247,
            "recall": 0.81807,
            "fmeasure": 0.82044
        },
        "rouge2": {
            "precision": 0.7008,
            "recall": 0.68575,
            "fmeasure": 0.68555
        },
        "rougeL": {
            "precision": 0.81446,
            "recall": 0.8025,
            "fmeasure": 0.80041
        },
        "rougeLsum": {
            "precision": 0.81446,
            "recall": 0.8025,
            "fmeasure": 0.80041
        },
        "bleu": 72.60576,
        "nist": 8.621725646057156,
        "local_recall": {
            "1": 0.03666666666666667,
            "2": 0.1694915254237288,
            "3": 0.5,
            "4": 0.5306122448979592,
            "5": 0.6621621621621622,
            "6": 0.7777777777777778,
            "7": 0.9107142857142857
        },
        "nubia": {
            "semantic_relation": 4.41114,
            "contradiction": 2.35792,
            "irrelevancy": 16.88443,
            "logical_agreement": 80.75765,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.78141,
            "nubia_score": 0.74091
        },
        "meteor": 0.48020305463236257,
        "bleurt": 0.30974,
        "bertscore": {
            "precision": 0.96227,
            "recall": 0.95515,
            "f1": 0.95686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.47872969366552,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0,
        "bleurt": 0.9148,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 88.23314,
        "nist": 4.725958657424895,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "nubia": {
            "semantic_relation": 4.59491,
            "contradiction": 0.51227,
            "irrelevancy": 10.44657,
            "logical_agreement": 89.04116,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.00862,
            "nubia_score": 0.9067
        },
        "meteor": 0.5463176402057991,
        "bleurt": 0.56181,
        "bertscore": {
            "precision": 0.99215,
            "recall": 0.94723,
            "f1": 0.96862
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.86364,
            "fmeasure": 0.86364
        },
        "rouge2": {
            "precision": 0.51429,
            "recall": 0.51429,
            "fmeasure": 0.51429
        },
        "rougeL": {
            "precision": 0.70606,
            "recall": 0.70606,
            "fmeasure": 0.70606
        },
        "rougeLsum": {
            "precision": 0.70606,
            "recall": 0.70606,
            "fmeasure": 0.70606
        },
        "bleu": 59.05414,
        "nist": 4.728696407659346,
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8846153846153846
        },
        "nubia": {
            "semantic_relation": 4.86758,
            "contradiction": 0.19525,
            "irrelevancy": 48.06448,
            "logical_agreement": 51.74027,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.70786,
            "nubia_score": 0.97154
        },
        "meteor": 0.4962574568661923,
        "bleurt": 0.65104,
        "bertscore": {
            "precision": 0.95495,
            "recall": 0.96137,
            "f1": 0.95815
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.899494936611665,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 52,
        "unique-1": 45,
        "entropy-1": 5.627642470572459,
        "distinct-2": 0.9824561403508771,
        "vocab_size-2": 56,
        "unique-2": 55,
        "entropy-2": 5.797802294866491,
        "cond_entropy-2": 0.10143801504745138,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.04096547496423607,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 8.956685895029603,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.599541531706474,
        "distinct-2-nopunct": 0.9807692307692307,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.661978179679557,
        "cond_entropy-2-nopunct": 0.053695389231817145,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.044913547495271544,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.8331,
            "recall": 0.80055,
            "fmeasure": 0.81115
        },
        "rouge2": {
            "precision": 0.59894,
            "recall": 0.57633,
            "fmeasure": 0.58275
        },
        "rougeL": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "rougeLsum": {
            "precision": 0.7331,
            "recall": 0.71073,
            "fmeasure": 0.71653
        },
        "bleu": 62.07006,
        "nist": 6.053896167593934,
        "local_recall": {
            "1": 0.02564102564102564,
            "2": 0.3333333333333333,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.8571428571428571,
            "7": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.77243,
            "contradiction": 0.25676,
            "irrelevancy": 17.25748,
            "logical_agreement": 82.48575,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.93574,
            "nubia_score": 0.84182
        },
        "meteor": 0.4995612734248125,
        "bleurt": 0.43745,
        "bertscore": {
            "precision": 0.94924,
            "recall": 0.95155,
            "f1": 0.9493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "bleu": 20.16495,
        "nist": 1.7990385038524417,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "meteor": 0.861811391223156,
        "bleurt": 0.49066,
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.88889,
            "fmeasure": 0.8
        },
        "bleu": 32.64971,
        "nist": 2.659005565642719,
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.4082,
            "irrelevancy": 0.76883,
            "logical_agreement": 98.82297,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.37368,
            "nubia_score": 0.96322
        },
        "meteor": 0.9051319272478866,
        "bleurt": 0.74939,
        "bertscore": {
            "precision": 0.94619,
            "recall": 0.97387,
            "f1": 0.95983
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59764,
            "recall": 0.60976,
            "fmeasure": 0.60342
        },
        "rouge2": {
            "precision": 0.275,
            "recall": 0.28241,
            "fmeasure": 0.27851
        },
        "rougeL": {
            "precision": 0.48485,
            "recall": 0.51667,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.48485,
            "recall": 0.51667,
            "fmeasure": 0.5
        },
        "bleu": 15.22005,
        "nist": 3.070486482934914,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.59742,
            "contradiction": 41.09627,
            "irrelevancy": 50.38542,
            "logical_agreement": 8.51831,
            "grammar_ref": 5.12311,
            "grammar_hyp": 5.0421,
            "nubia_score": 0.43904
        },
        "meteor": 0.2981458594544677,
        "bleurt": 0.05196,
        "bertscore": {
            "precision": 0.85432,
            "recall": 0.84484,
            "f1": 0.8459
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "bleu": 51.15078,
        "nist": 2.425622163887878,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.03933,
            "contradiction": 14.76512,
            "irrelevancy": 1.30136,
            "logical_agreement": 83.93352,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.12865,
            "nubia_score": 0.54196
        },
        "meteor": 0.42750933026297866,
        "bleurt": 0.50807,
        "bertscore": {
            "precision": 0.99151,
            "recall": 0.95959,
            "f1": 0.97529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.275,
            "fmeasure": 0.37931
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.13158,
            "fmeasure": 0.18519
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.225,
            "fmeasure": 0.31034
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.225,
            "fmeasure": 0.31034
        },
        "bleu": 6.94773,
        "nist": 0.27955318352106245,
        "local_recall": {
            "1": 0.5,
            "2": 0.3125
        },
        "nubia": {
            "semantic_relation": 3.43237,
            "contradiction": 0.33988,
            "irrelevancy": 0.53274,
            "logical_agreement": 99.12738,
            "grammar_ref": 4.55046,
            "grammar_hyp": 5.76496,
            "nubia_score": 0.38481
        },
        "meteor": 0.16734015292606902,
        "bleurt": -0.16252,
        "bertscore": {
            "precision": 0.8594,
            "recall": 0.79343,
            "f1": 0.8251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.37691,
            "fmeasure": 0.44904
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.30637,
            "fmeasure": 0.36596
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.37691,
            "fmeasure": 0.44904
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.37691,
            "fmeasure": 0.44904
        },
        "bleu": 30.65455,
        "nist": 1.0154296900221278,
        "local_recall": {
            "1": 0.0,
            "2": 0.1111111111111111,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.04939,
            "contradiction": 62.34779,
            "irrelevancy": 26.75495,
            "logical_agreement": 10.89726,
            "grammar_ref": 5.24053,
            "grammar_hyp": 6.1466,
            "nubia_score": 0.22626
        },
        "meteor": 0.24108178413547315,
        "bleurt": -0.81373,
        "bertscore": {
            "precision": 0.90874,
            "recall": 0.89691,
            "f1": 0.90279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.45833,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.57937,
            "fmeasure": 0.53472
        },
        "bleu": 41.11336,
        "nist": 2.1795698619043824,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 3.54171,
            "contradiction": 0.14209,
            "irrelevancy": 77.4757,
            "logical_agreement": 22.38221,
            "grammar_ref": 4.8549,
            "grammar_hyp": 5.74514,
            "nubia_score": 0.46846
        },
        "meteor": 0.4144683820350649,
        "bleurt": 0.31537,
        "bertscore": {
            "precision": 0.90942,
            "recall": 0.94271,
            "f1": 0.92577
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.53846,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.46154,
            "fmeasure": 0.5
        },
        "bleu": 8.80435,
        "nist": 1.3552949027436123,
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "nubia": {
            "semantic_relation": 4.40295,
            "contradiction": 0.08266,
            "irrelevancy": 1.28061,
            "logical_agreement": 98.63673,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.77488,
            "nubia_score": 0.98382
        },
        "meteor": 0.31762924434162076,
        "bleurt": 0.37655,
        "bertscore": {
            "precision": 0.92088,
            "recall": 0.91879,
            "f1": 0.91984
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.3,
            "recall": 0.54701,
            "fmeasure": 0.38454
        },
        "rouge2": {
            "precision": 0.13158,
            "recall": 0.25,
            "fmeasure": 0.17085
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.54701,
            "fmeasure": 0.38454
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.54701,
            "fmeasure": 0.38454
        },
        "bleu": 12.21711,
        "nist": 1.4896686822707874,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 2.76375,
            "contradiction": 0.67389,
            "irrelevancy": 93.02849,
            "logical_agreement": 6.29762,
            "grammar_ref": 4.60771,
            "grammar_hyp": 5.01003,
            "nubia_score": 0.18183
        },
        "meteor": 0.26691346213904915,
        "bleurt": -0.13631,
        "bertscore": {
            "precision": 0.79206,
            "recall": 0.83774,
            "f1": 0.81145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "bleu": 29.81247,
        "nist": 2.841001848468879,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.88337,
            "contradiction": 1.04405,
            "irrelevancy": 0.68355,
            "logical_agreement": 98.27239,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.63969,
            "nubia_score": 0.90265
        },
        "meteor": 0.4917847911537735,
        "bleurt": 0.645,
        "bertscore": {
            "precision": 0.95588,
            "recall": 0.93651,
            "f1": 0.9461
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 2.8483609718589222,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "meteor": 1.0,
        "bleurt": 0.96931,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.85833,
            "fmeasure": 0.72741
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85568
        },
        "bleu": 55.60337,
        "nist": 3.196979798573185,
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "nubia": {
            "semantic_relation": 4.17998,
            "contradiction": 0.61916,
            "irrelevancy": 93.24068,
            "logical_agreement": 6.14017,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.84954,
            "nubia_score": 0.77863
        },
        "meteor": 0.5206924026304247,
        "bleurt": 0.40102,
        "bertscore": {
            "precision": 0.9344,
            "recall": 0.97921,
            "f1": 0.95628
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.46875,
            "fmeasure": 0.40714
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "bleu": 31.61488,
        "nist": 2.333361941695811,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143
        },
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 0.26553,
            "irrelevancy": 84.0294,
            "logical_agreement": 15.70508,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.19382,
            "nubia_score": 0.77504
        },
        "meteor": 0.4361381544346885,
        "bleurt": 0.18823,
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.91528,
            "f1": 0.89678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.92857,
            "fmeasure": 0.61579
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.63333,
            "fmeasure": 0.39869
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.70238,
            "fmeasure": 0.46316
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.70238,
            "fmeasure": 0.46316
        },
        "bleu": 12.03922,
        "nist": 1.4829529272603437,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 4.27351,
            "contradiction": 0.15236,
            "irrelevancy": 97.84954,
            "logical_agreement": 1.9981,
            "grammar_ref": 7.77345,
            "grammar_hyp": 4.60265,
            "nubia_score": 1.0
        },
        "meteor": 0.38512988974641926,
        "bleurt": 0.10483,
        "bertscore": {
            "precision": 0.81912,
            "recall": 0.9186,
            "f1": 0.86601
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.75333,
        "total_length": 747,
        "mean_pred_length": 24.9,
        "std_pred_length": 10.918943782863495,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 51,
        "distinct-1": 0.5220883534136547,
        "vocab_size-1": 390,
        "unique-1": 308,
        "entropy-1": 7.7091953367124075,
        "distinct-2": 0.900976290097629,
        "vocab_size-2": 646,
        "unique-2": 599,
        "entropy-2": 9.256535545809376,
        "cond_entropy-2": 1.4112860774998401,
        "distinct-3": 0.9679767103347889,
        "vocab_size-3": 665,
        "unique-3": 648,
        "entropy-3": 9.354625622863642,
        "cond_entropy-3": 0.10519169697658999,
        "total_length-nopunct": 660,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 9.003702941938204,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.5787878787878787,
        "vocab_size-1-nopunct": 382,
        "unique-1-nopunct": 308,
        "entropy-1-nopunct": 7.833186330929464,
        "distinct-2-nopunct": 0.919047619047619,
        "vocab_size-2-nopunct": 579,
        "unique-2-nopunct": 543,
        "entropy-2-nopunct": 9.114082319207748,
        "cond_entropy-2-nopunct": 1.3374899985903295,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 590,
        "unique-3-nopunct": 580,
        "entropy-3-nopunct": 9.195485357162564,
        "cond_entropy-3-nopunct": 0.08899265624708647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.76815,
            "recall": 0.76329,
            "fmeasure": 0.75406
        },
        "rouge2": {
            "precision": 0.59592,
            "recall": 0.58911,
            "fmeasure": 0.58126
        },
        "rougeL": {
            "precision": 0.73465,
            "recall": 0.73194,
            "fmeasure": 0.71905
        },
        "rougeLsum": {
            "precision": 0.73465,
            "recall": 0.73194,
            "fmeasure": 0.71905
        },
        "bleu": 57.65315,
        "nist": 8.13767036162024,
        "local_recall": {
            "1": 0.05429864253393665,
            "2": 0.16049382716049382,
            "3": 0.423728813559322,
            "4": 0.5217391304347826,
            "5": 0.6521739130434783,
            "6": 0.7727272727272727,
            "7": 0.8995433789954338
        },
        "nubia": {
            "semantic_relation": 4.25667,
            "contradiction": 2.05288,
            "irrelevancy": 22.76321,
            "logical_agreement": 75.18391,
            "grammar_ref": 4.65355,
            "grammar_hyp": 4.94045,
            "nubia_score": 0.67069
        },
        "meteor": 0.43852577871911463,
        "bleurt": 0.12635,
        "bertscore": {
            "precision": 0.94106,
            "recall": 0.94162,
            "f1": 0.93785
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.765,
        "msttr-100_nopunct": 0.75,
        "total_length": 204,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 9.797958971132712,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.6862745098039216,
        "vocab_size-1": 140,
        "unique-1": 117,
        "entropy-1": 6.670055181281402,
        "distinct-2": 0.9282051282051282,
        "vocab_size-2": 181,
        "unique-2": 175,
        "entropy-2": 7.412888534463012,
        "cond_entropy-2": 0.6183070659146062,
        "distinct-3": 0.978494623655914,
        "vocab_size-3": 182,
        "unique-3": 180,
        "entropy-3": 7.488030988504138,
        "cond_entropy-3": 0.08455092723243543,
        "total_length-nopunct": 176,
        "mean_pred_length-nopunct": 19.555555555555557,
        "std_pred_length-nopunct": 7.747560348782362,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.7556818181818182,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.693136042270156,
        "distinct-2-nopunct": 0.9520958083832335,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.242078637058441,
        "cond_entropy-2-nopunct": 0.5842519372272642,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.303780748177119,
        "cond_entropy-3-nopunct": 0.06976939528788147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.82288,
            "recall": 0.76223,
            "fmeasure": 0.77686
        },
        "rouge2": {
            "precision": 0.66796,
            "recall": 0.60418,
            "fmeasure": 0.61414
        },
        "rougeL": {
            "precision": 0.76896,
            "recall": 0.70334,
            "fmeasure": 0.72129
        },
        "rougeLsum": {
            "precision": 0.76896,
            "recall": 0.70334,
            "fmeasure": 0.72129
        },
        "bleu": 57.06659,
        "nist": 6.882732034449978,
        "local_recall": {
            "1": 0.07407407407407407,
            "2": 0.18181818181818182,
            "3": 0.0,
            "4": 0.9,
            "5": 0.5,
            "6": 0.66,
            "7": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.1489,
            "contradiction": 6.22671,
            "irrelevancy": 22.76997,
            "logical_agreement": 71.00331,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.20342,
            "nubia_score": 0.58332
        },
        "meteor": 0.4202170273413408,
        "bleurt": 0.03491,
        "bertscore": {
            "precision": 0.93636,
            "recall": 0.92079,
            "f1": 0.92655
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.73471,
        "msttr-100_nopunct": 0.77533,
        "total_length": 1722,
        "mean_pred_length": 27.333333333333332,
        "std_pred_length": 8.19601141864768,
        "median_pred_length": 26.0,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.4547038327526132,
        "vocab_size-1": 783,
        "unique-1": 606,
        "entropy-1": 8.290391998391643,
        "distinct-2": 0.8921036769138035,
        "vocab_size-2": 1480,
        "unique-2": 1398,
        "entropy-2": 10.365127204286285,
        "cond_entropy-2": 1.9267070574538572,
        "distinct-3": 0.9680451127819549,
        "vocab_size-3": 1545,
        "unique-3": 1530,
        "entropy-3": 10.519053679636448,
        "cond_entropy-3": 0.16511141952294395,
        "total_length-nopunct": 1518,
        "mean_pred_length-nopunct": 24.095238095238095,
        "std_pred_length-nopunct": 7.124102362201163,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.5085638998682477,
        "vocab_size-1-nopunct": 772,
        "unique-1-nopunct": 603,
        "entropy-1-nopunct": 8.512586083915737,
        "distinct-2-nopunct": 0.9312714776632303,
        "vocab_size-2-nopunct": 1355,
        "unique-2-nopunct": 1289,
        "entropy-2-nopunct": 10.338367243667092,
        "cond_entropy-2-nopunct": 1.894153448880371,
        "distinct-3-nopunct": 0.9949712643678161,
        "vocab_size-3-nopunct": 1385,
        "unique-3-nopunct": 1378,
        "entropy-3-nopunct": 10.432886024584368,
        "cond_entropy-3-nopunct": 0.09884817583774091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.80381,
            "recall": 0.79503,
            "fmeasure": 0.79487
        },
        "rouge2": {
            "precision": 0.66361,
            "recall": 0.6603,
            "fmeasure": 0.6574
        },
        "rougeL": {
            "precision": 0.77884,
            "recall": 0.76899,
            "fmeasure": 0.76872
        },
        "rougeLsum": {
            "precision": 0.77884,
            "recall": 0.76899,
            "fmeasure": 0.76872
        },
        "bleu": 63.87294,
        "nist": 9.198013755866048,
        "local_recall": {
            "1": 0.052073288331726135,
            "2": 0.18012422360248448,
            "3": 0.48936170212765956,
            "4": 0.5671641791044776,
            "5": 0.6705882352941176,
            "6": 0.7556675062972292,
            "7": 0.8867924528301887
        },
        "nubia": {
            "semantic_relation": 4.27071,
            "contradiction": 5.05235,
            "irrelevancy": 20.89782,
            "logical_agreement": 74.04982,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.77963,
            "nubia_score": 0.67775
        },
        "meteor": 0.4568703630761791,
        "bleurt": 0.15943,
        "bertscore": {
            "precision": 0.93958,
            "recall": 0.94684,
            "f1": 0.94108
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.29825,
            "recall": 0.3635,
            "fmeasure": 0.32639
        },
        "rouge2": {
            "precision": 0.05556,
            "recall": 0.07639,
            "fmeasure": 0.06405
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.31222,
            "fmeasure": 0.28472
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.31222,
            "fmeasure": 0.28472
        },
        "bleu": 6.10856,
        "nist": 1.6758113988473455,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nubia": {
            "semantic_relation": 1.79871,
            "contradiction": 17.53804,
            "irrelevancy": 78.0347,
            "logical_agreement": 4.42725,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.23235,
            "nubia_score": 0.23408
        },
        "meteor": 0.1578647274797024,
        "bleurt": -0.53989,
        "bertscore": {
            "precision": 0.68701,
            "recall": 0.67856,
            "f1": 0.68276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.81746,
            "recall": 0.75694,
            "fmeasure": 0.78059
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.45298,
            "fmeasure": 0.45206
        },
        "rougeL": {
            "precision": 0.72751,
            "recall": 0.68908,
            "fmeasure": 0.70331
        },
        "rougeLsum": {
            "precision": 0.72751,
            "recall": 0.68908,
            "fmeasure": 0.70331
        },
        "bleu": 52.43152,
        "nist": 4.102545171504303,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.15886,
            "contradiction": 14.8961,
            "irrelevancy": 19.5571,
            "logical_agreement": 65.54681,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.53052,
            "nubia_score": 0.67754
        },
        "meteor": 0.4523305676269658,
        "bleurt": 0.20939,
        "bertscore": {
            "precision": 0.93434,
            "recall": 0.92432,
            "f1": 0.92731
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.47727,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.26667,
            "fmeasure": 0.28758
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.47727,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.47727,
            "fmeasure": 0.51316
        },
        "bleu": 18.60045,
        "nist": 2.049328728578919,
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.16861,
            "contradiction": 83.74273,
            "irrelevancy": 11.88739,
            "logical_agreement": 4.36987,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.33627,
            "nubia_score": 0.2852
        },
        "meteor": 0.3082803660278626,
        "bleurt": 0.37042,
        "bertscore": {
            "precision": 0.91832,
            "recall": 0.90045,
            "f1": 0.9093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "mT5_large/totto_test",
        "N": 110,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76305,
            "recall": 0.7179,
            "fmeasure": 0.72553
        },
        "rouge2": {
            "precision": 0.5288,
            "recall": 0.49569,
            "fmeasure": 0.50226
        },
        "rougeL": {
            "precision": 0.66528,
            "recall": 0.62374,
            "fmeasure": 0.63195
        },
        "rougeLsum": {
            "precision": 0.66528,
            "recall": 0.62374,
            "fmeasure": 0.63195
        },
        "bleu": 46.42653,
        "nist": 7.676939244945852,
        "local_recall": {
            "1": 0.20634920634920634,
            "2": 0.5384615384615384,
            "3": 0.7839622641509434
        },
        "nubia": {
            "semantic_relation": 4.19149,
            "contradiction": 6.91604,
            "irrelevancy": 24.31679,
            "logical_agreement": 68.76717,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.83543,
            "nubia_score": 0.72677
        },
        "meteor": 0.39213037249056737,
        "bleurt": 0.26972,
        "bertscore": {
            "precision": 0.93083,
            "recall": 0.92132,
            "f1": 0.92398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "bleu": 49.33885,
        "nist": 4.126570492796873,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.49839,
            "contradiction": 5.6293,
            "irrelevancy": 59.34361,
            "logical_agreement": 35.02709,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.57982,
            "nubia_score": 0.7428
        },
        "meteor": 0.4357852299085562,
        "bleurt": 0.09319,
        "bertscore": {
            "precision": 0.91173,
            "recall": 0.9582,
            "f1": 0.92725
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.71429,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.46154,
            "fmeasure": 0.46154
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.64286,
            "fmeasure": 0.64286
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.64286,
            "fmeasure": 0.64286
        },
        "bleu": 22.62944,
        "nist": 2.7356741033626357,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.5
        },
        "nubia": {
            "semantic_relation": 3.91211,
            "contradiction": 0.16867,
            "irrelevancy": 99.74128,
            "logical_agreement": 0.09005,
            "grammar_ref": 4.76643,
            "grammar_hyp": 4.52783,
            "nubia_score": 0.69029
        },
        "meteor": 0.3828078000939029,
        "bleurt": 0.34543,
        "bertscore": {
            "precision": 0.92401,
            "recall": 0.93124,
            "f1": 0.92761
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "bleu": 76.11606,
        "nist": 3.6961650890339652,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.74566,
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.62319,
            "recall": 0.74579,
            "fmeasure": 0.67751
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.42484,
            "fmeasure": 0.38203
        },
        "rougeL": {
            "precision": 0.26087,
            "recall": 0.31313,
            "fmeasure": 0.28401
        },
        "rougeLsum": {
            "precision": 0.26087,
            "recall": 0.31313,
            "fmeasure": 0.28401
        },
        "bleu": 29.68262,
        "nist": 3.5277622566595546,
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.625
        },
        "nubia": {
            "semantic_relation": 3.07353,
            "contradiction": 9.20376,
            "irrelevancy": 89.66283,
            "logical_agreement": 1.13341,
            "grammar_ref": 4.78465,
            "grammar_hyp": 5.39098,
            "nubia_score": 0.35675
        },
        "meteor": 0.3855080853816047,
        "bleurt": -0.37076,
        "bertscore": {
            "precision": 0.9022,
            "recall": 0.90081,
            "f1": 0.90151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.82955,
            "fmeasure": 0.80978
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.67273,
            "fmeasure": 0.65368
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.82955,
            "fmeasure": 0.80978
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.82955,
            "fmeasure": 0.80978
        },
        "bleu": 67.03421,
        "nist": 3.2435193400657925,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.9
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36736,
            "irrelevancy": 0.46622,
            "logical_agreement": 99.16643,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.42931,
            "nubia_score": 0.9935
        },
        "meteor": 0.9824520287095357,
        "bleurt": 0.76418,
        "bertscore": {
            "precision": 0.98184,
            "recall": 0.98834,
            "f1": 0.98508
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.65954,
            "fmeasure": 0.69524
        },
        "rouge2": {
            "precision": 0.31373,
            "recall": 0.27381,
            "fmeasure": 0.29133
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.50446,
            "fmeasure": 0.50952
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.50446,
            "fmeasure": 0.50952
        },
        "bleu": 34.52142,
        "nist": 4.095482765373453,
        "local_recall": {
            "1": 0.5,
            "2": 0.6,
            "3": 0.75
        },
        "nubia": {
            "semantic_relation": 4.36014,
            "contradiction": 7.00576,
            "irrelevancy": 46.32448,
            "logical_agreement": 46.66976,
            "grammar_ref": 3.28677,
            "grammar_hyp": 3.40055,
            "nubia_score": 0.83452
        },
        "meteor": 0.31497504307814983,
        "bleurt": 0.37501,
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.93112,
            "f1": 0.92822
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.1699250014423126,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.95702,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.25,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.29412,
            "fmeasure": 0.34483
        },
        "bleu": 19.07733,
        "nist": 1.0738270250535529,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 2.3931,
            "contradiction": 44.11333,
            "irrelevancy": 54.89031,
            "logical_agreement": 0.99636,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.21765,
            "nubia_score": 0.18356
        },
        "meteor": 0.19198335664587465,
        "bleurt": -0.17539,
        "bertscore": {
            "precision": 0.86153,
            "recall": 0.77393,
            "f1": 0.81539
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.85,
            "fmeasure": 0.80952
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95455,
            "fmeasure": 0.91304
        },
        "bleu": 77.79319,
        "nist": 3.1103359996409683,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9545454545454546
        },
        "nubia": {
            "semantic_relation": 4.39526,
            "contradiction": 0.35576,
            "irrelevancy": 94.77989,
            "logical_agreement": 4.86435,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.45423,
            "nubia_score": 0.89179
        },
        "meteor": 0.5664771340463897,
        "bleurt": 0.51078,
        "bertscore": {
            "precision": 0.93381,
            "recall": 0.9737,
            "f1": 0.95333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84747,
            "recall": 0.72347,
            "fmeasure": 0.76896
        },
        "rouge2": {
            "precision": 0.66327,
            "recall": 0.59074,
            "fmeasure": 0.61584
        },
        "rougeL": {
            "precision": 0.84747,
            "recall": 0.72347,
            "fmeasure": 0.76896
        },
        "rougeLsum": {
            "precision": 0.84747,
            "recall": 0.72347,
            "fmeasure": 0.76896
        },
        "bleu": 45.85622,
        "nist": 2.7059894001951816,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6296296296296297
        },
        "nubia": {
            "semantic_relation": 3.78334,
            "contradiction": 60.5979,
            "irrelevancy": 17.65657,
            "logical_agreement": 21.74553,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.37297,
            "nubia_score": 0.59822
        },
        "meteor": 0.45404434571941343,
        "bleurt": 0.43854,
        "bertscore": {
            "precision": 0.9643,
            "recall": 0.92026,
            "f1": 0.94057
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.25,
            "fmeasure": 0.2381
        },
        "rougeL": {
            "precision": 0.45833,
            "recall": 0.5,
            "fmeasure": 0.47826
        },
        "rougeLsum": {
            "precision": 0.45833,
            "recall": 0.5,
            "fmeasure": 0.47826
        },
        "bleu": 24.71244,
        "nist": 2.4497205132643014,
        "local_recall": {
            "1": 0.5,
            "2": 0.42857142857142855
        },
        "nubia": {
            "semantic_relation": 3.25217,
            "contradiction": 0.07696,
            "irrelevancy": 99.50875,
            "logical_agreement": 0.41429,
            "grammar_ref": 4.25346,
            "grammar_hyp": 3.96868,
            "nubia_score": 0.53738
        },
        "meteor": 0.3047677960441017,
        "bleurt": -0.18113,
        "bertscore": {
            "precision": 0.87151,
            "recall": 0.88222,
            "f1": 0.87683
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.68376,
            "recall": 0.52424,
            "fmeasure": 0.59236
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.34085,
            "fmeasure": 0.39024
        },
        "rougeL": {
            "precision": 0.56838,
            "recall": 0.44091,
            "fmeasure": 0.49559
        },
        "rougeLsum": {
            "precision": 0.56838,
            "recall": 0.44091,
            "fmeasure": 0.49559
        },
        "bleu": 21.20063,
        "nist": 3.025323366069783,
        "local_recall": {
            "1": 0.2,
            "2": 0.3684210526315789,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.2467,
            "contradiction": 6.33956,
            "irrelevancy": 61.94036,
            "logical_agreement": 31.72008,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.73724,
            "nubia_score": 0.57468
        },
        "meteor": 0.2886850916895051,
        "bleurt": -0.08151,
        "bertscore": {
            "precision": 0.90376,
            "recall": 0.87675,
            "f1": 0.88975
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.41071,
            "fmeasure": 0.45055
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.72222,
            "fmeasure": 0.78333
        },
        "bleu": 33.12203,
        "nist": 2.8610927314735184,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.56442,
            "contradiction": 2.44907,
            "irrelevancy": 2.37459,
            "logical_agreement": 95.17634,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.50772,
            "nubia_score": 0.67533
        },
        "meteor": 0.3707878006073302,
        "bleurt": 0.35902,
        "bertscore": {
            "precision": 0.95923,
            "recall": 0.93678,
            "f1": 0.94787
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.713,
        "msttr-100_nopunct": 0.76,
        "total_length": 3021,
        "mean_pred_length": 18.198795180722893,
        "std_pred_length": 7.457687777196458,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 46,
        "distinct-1": 0.4448857994041708,
        "vocab_size-1": 1344,
        "unique-1": 1061,
        "entropy-1": 8.587306216975827,
        "distinct-2": 0.8665499124343258,
        "vocab_size-2": 2474,
        "unique-2": 2336,
        "entropy-2": 11.031238229187215,
        "cond_entropy-2": 2.1826287493306946,
        "distinct-3": 0.9672740795834883,
        "vocab_size-3": 2601,
        "unique-3": 2552,
        "entropy-3": 11.304276243054861,
        "cond_entropy-3": 0.2910276416014213,
        "total_length-nopunct": 2636,
        "mean_pred_length-nopunct": 15.879518072289157,
        "std_pred_length-nopunct": 6.432967780623564,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 39,
        "distinct-1-nopunct": 0.5064491654021245,
        "vocab_size-1-nopunct": 1335,
        "unique-1-nopunct": 1061,
        "entropy-1-nopunct": 8.91865229989524,
        "distinct-2-nopunct": 0.8817813765182186,
        "vocab_size-2-nopunct": 2178,
        "unique-2-nopunct": 2069,
        "entropy-2-nopunct": 10.868342696983952,
        "cond_entropy-2-nopunct": 2.0839210445198084,
        "distinct-3-nopunct": 0.9796006944444444,
        "vocab_size-3-nopunct": 2257,
        "unique-3-nopunct": 2221,
        "entropy-3-nopunct": 11.124441499914981,
        "cond_entropy-3-nopunct": 0.2786549005842847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90404,
            "recall": 0.92463,
            "fmeasure": 0.91058
        },
        "rouge2": {
            "precision": 0.80695,
            "recall": 0.84069,
            "fmeasure": 0.81832
        },
        "rougeL": {
            "precision": 0.89014,
            "recall": 0.91403,
            "fmeasure": 0.8982
        },
        "rougeLsum": {
            "precision": 0.89014,
            "recall": 0.91403,
            "fmeasure": 0.8982
        },
        "bleu": 88.35133,
        "nist": 12.236935802855777,
        "local_recall": {
            "1": 0.032035485460818136,
            "2": 0.16308243727598568,
            "3": 0.3879003558718861,
            "4": 0.5879828326180258,
            "5": 0.7096774193548387,
            "6": 0.8674242424242424,
            "7": 0.9190140845070423,
            "8": 0.9356913183279743,
            "9": 0.9570707070707071,
            "10": 0.9884488448844885
        },
        "nubia": {
            "semantic_relation": 4.46662,
            "contradiction": 2.3386,
            "irrelevancy": 30.72396,
            "logical_agreement": 66.93744,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.77971,
            "nubia_score": 0.73065
        },
        "meteor": 0.5659206386055404,
        "bleurt": 0.37567,
        "bertscore": {
            "precision": 0.97507,
            "recall": 0.98257,
            "f1": 0.97642
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "bleu": 80.03203,
        "nist": 3.665478841615569,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.09029,
            "irrelevancy": 0.64534,
            "logical_agreement": 98.26437,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.93719,
            "nubia_score": 0.99638
        },
        "meteor": 0.5412422363150462,
        "bleurt": 0.85769,
        "bertscore": {
            "precision": 0.98984,
            "recall": 0.98984,
            "f1": 0.98984
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.71846,
        "msttr-100_nopunct": 0.75727,
        "total_length": 1347,
        "mean_pred_length": 23.224137931034484,
        "std_pred_length": 8.622430858638968,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 47,
        "distinct-1": 0.49072011878247956,
        "vocab_size-1": 661,
        "unique-1": 534,
        "entropy-1": 8.095754582134875,
        "distinct-2": 0.8983708301008534,
        "vocab_size-2": 1158,
        "unique-2": 1105,
        "entropy-2": 10.021914005964367,
        "cond_entropy-2": 1.7529258172833078,
        "distinct-3": 0.9707554833468724,
        "vocab_size-3": 1195,
        "unique-3": 1182,
        "entropy-3": 10.16734833635116,
        "cond_entropy-3": 0.16004611548766703,
        "total_length-nopunct": 1183,
        "mean_pred_length-nopunct": 20.396551724137932,
        "std_pred_length-nopunct": 7.583875033463215,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.5511411665257819,
        "vocab_size-1-nopunct": 652,
        "unique-1-nopunct": 532,
        "entropy-1-nopunct": 8.31798878341598,
        "distinct-2-nopunct": 0.9315555555555556,
        "vocab_size-2-nopunct": 1048,
        "unique-2-nopunct": 1003,
        "entropy-2-nopunct": 9.961605032474866,
        "cond_entropy-2-nopunct": 1.7312911320328437,
        "distinct-3-nopunct": 0.9925023430178069,
        "vocab_size-3-nopunct": 1059,
        "unique-3-nopunct": 1051,
        "entropy-3-nopunct": 10.044349146860052,
        "cond_entropy-3-nopunct": 0.09127086856551314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90662,
            "recall": 0.92454,
            "fmeasure": 0.91315
        },
        "rouge2": {
            "precision": 0.82256,
            "recall": 0.84213,
            "fmeasure": 0.82996
        },
        "rougeL": {
            "precision": 0.89974,
            "recall": 0.91914,
            "fmeasure": 0.90694
        },
        "rougeLsum": {
            "precision": 0.89974,
            "recall": 0.91914,
            "fmeasure": 0.90694
        },
        "bleu": 86.72943,
        "nist": 11.18196373203761,
        "local_recall": {
            "1": 0.035106382978723406,
            "2": 0.18604651162790697,
            "3": 0.4105960264900662,
            "4": 0.5545454545454546,
            "5": 0.7851851851851852,
            "6": 0.8557692307692307,
            "7": 0.9122807017543859,
            "8": 0.9591836734693877,
            "9": 0.954248366013072,
            "10": 0.9906103286384976
        },
        "nubia": {
            "semantic_relation": 4.41468,
            "contradiction": 2.62574,
            "irrelevancy": 33.27658,
            "logical_agreement": 64.09768,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.65501,
            "nubia_score": 0.71089
        },
        "meteor": 0.5501156869033517,
        "bleurt": 0.30235,
        "bertscore": {
            "precision": 0.96881,
            "recall": 0.97995,
            "f1": 0.97263
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.70429,
        "msttr-100_nopunct": 0.75333,
        "total_length": 737,
        "mean_pred_length": 23.03125,
        "std_pred_length": 9.709802955647453,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 44,
        "distinct-1": 0.5400271370420624,
        "vocab_size-1": 398,
        "unique-1": 320,
        "entropy-1": 7.65716741715648,
        "distinct-2": 0.9106382978723404,
        "vocab_size-2": 642,
        "unique-2": 607,
        "entropy-2": 9.2409616856088,
        "cond_entropy-2": 1.4339356989428464,
        "distinct-3": 0.9762258543833581,
        "vocab_size-3": 657,
        "unique-3": 647,
        "entropy-3": 9.3387275162979,
        "cond_entropy-3": 0.10676518934229232,
        "total_length-nopunct": 640,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 8.154753215150045,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6109375,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.859882917914788,
        "distinct-2-nopunct": 0.9276315789473685,
        "vocab_size-2-nopunct": 564,
        "unique-2-nopunct": 540,
        "entropy-2-nopunct": 9.067080067755715,
        "cond_entropy-2-nopunct": 1.2657753088240409,
        "distinct-3-nopunct": 0.9878472222222222,
        "vocab_size-3-nopunct": 569,
        "unique-3-nopunct": 563,
        "entropy-3-nopunct": 9.144308877306674,
        "cond_entropy-3-nopunct": 0.08553977875573794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.93096,
            "recall": 0.93606,
            "fmeasure": 0.92989
        },
        "rouge2": {
            "precision": 0.8501,
            "recall": 0.85918,
            "fmeasure": 0.8509
        },
        "rougeL": {
            "precision": 0.91075,
            "recall": 0.91645,
            "fmeasure": 0.90971
        },
        "rougeLsum": {
            "precision": 0.91075,
            "recall": 0.91645,
            "fmeasure": 0.90971
        },
        "bleu": 92.08795,
        "nist": 10.7231454702874,
        "local_recall": {
            "1": 0.03285420944558522,
            "2": 0.2523364485981308,
            "3": 0.38028169014084506,
            "4": 0.703125,
            "5": 0.8,
            "6": 0.8676470588235294,
            "7": 0.9090909090909091,
            "8": 1.0,
            "9": 0.9642857142857143,
            "10": 0.9919354838709677
        },
        "nubia": {
            "semantic_relation": 4.48419,
            "contradiction": 1.78408,
            "irrelevancy": 35.01092,
            "logical_agreement": 63.205,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.56731,
            "nubia_score": 0.70975
        },
        "meteor": 0.5703173208448271,
        "bleurt": 0.31878,
        "bertscore": {
            "precision": 0.97621,
            "recall": 0.98453,
            "f1": 0.97895
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.55147,
            "fmeasure": 0.52437
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.19583,
            "fmeasure": 0.18561
        },
        "rougeL": {
            "precision": 0.37037,
            "recall": 0.40931,
            "fmeasure": 0.3888
        },
        "rougeLsum": {
            "precision": 0.37037,
            "recall": 0.40931,
            "fmeasure": 0.3888
        },
        "bleu": 16.32064,
        "nist": 2.4935595418255816,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5384615384615384
        },
        "nubia": {
            "semantic_relation": 3.65586,
            "contradiction": 0.13933,
            "irrelevancy": 13.62358,
            "logical_agreement": 86.23708,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.67509,
            "nubia_score": 0.70349
        },
        "meteor": 0.27228204751173823,
        "bleurt": 0.13081,
        "bertscore": {
            "precision": 0.88984,
            "recall": 0.87098,
            "f1": 0.88031
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.72751,
            "fmeasure": 0.77977
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.42836,
            "fmeasure": 0.48184
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.51704,
            "fmeasure": 0.62309
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.51704,
            "fmeasure": 0.62309
        },
        "bleu": 46.82569,
        "nist": 2.6480557839832715,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nubia": {
            "semantic_relation": 3.40876,
            "contradiction": 0.32234,
            "irrelevancy": 0.80338,
            "logical_agreement": 98.87429,
            "grammar_ref": 3.09217,
            "grammar_hyp": 2.63045,
            "nubia_score": 0.7359
        },
        "meteor": 0.3600287039374883,
        "bleurt": -0.00821,
        "bertscore": {
            "precision": 0.9387,
            "recall": 0.89931,
            "f1": 0.91858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.63333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.37037,
            "fmeasure": 0.39216
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.63333,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.63333,
            "fmeasure": 0.66667
        },
        "bleu": 42.26839,
        "nist": 2.96863417591989,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nubia": {
            "semantic_relation": 4.73018,
            "contradiction": 5.68019,
            "irrelevancy": 6.64574,
            "logical_agreement": 87.67407,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.67439,
            "nubia_score": 0.75138
        },
        "meteor": 0.4752438471562426,
        "bleurt": 0.04008,
        "bertscore": {
            "precision": 0.96877,
            "recall": 0.95671,
            "f1": 0.9627
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 20.0,
        "std_pred_length": 9.077444574328174,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.73,
        "vocab_size-1": 73,
        "unique-1": 59,
        "entropy-1": 5.92120956470983,
        "distinct-2": 0.9894736842105263,
        "vocab_size-2": 94,
        "unique-2": 93,
        "entropy-2": 6.548802976752,
        "cond_entropy-2": 0.5295767870076403,
        "distinct-3": 1.0,
        "vocab_size-3": 90,
        "unique-3": 90,
        "entropy-3": 6.491853096329662,
        "cond_entropy-3": -0.05578028977905097,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.883465457416738,
        "distinct-2-nopunct": 0.9882352941176471,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.385861524373001,
        "cond_entropy-2-nopunct": 0.5381835751275978,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.06246284125033935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.93545,
            "recall": 0.9371,
            "fmeasure": 0.93584
        },
        "rouge2": {
            "precision": 0.88817,
            "recall": 0.88873,
            "fmeasure": 0.88797
        },
        "rougeL": {
            "precision": 0.93378,
            "recall": 0.93877,
            "fmeasure": 0.93568
        },
        "rougeLsum": {
            "precision": 0.93378,
            "recall": 0.93877,
            "fmeasure": 0.93568
        },
        "bleu": 83.79083,
        "nist": 7.644519726182525,
        "local_recall": {
            "1": 0.06944444444444445,
            "2": 0.19047619047619047,
            "3": 0.375,
            "4": 0.8,
            "5": 0.7142857142857143,
            "6": 0.9230769230769231,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 1.0
        },
        "nubia": {
            "semantic_relation": 4.55457,
            "contradiction": 0.22546,
            "irrelevancy": 37.98992,
            "logical_agreement": 61.78462,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.25645,
            "nubia_score": 0.68448
        },
        "meteor": 0.6392249564979924,
        "bleurt": 0.38182,
        "bertscore": {
            "precision": 0.98292,
            "recall": 0.99373,
            "f1": 0.9866
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.74833,
        "msttr-100_nopunct": 0.76833,
        "total_length": 680,
        "mean_pred_length": 24.285714285714285,
        "std_pred_length": 8.526668847366658,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 41,
        "distinct-1": 0.5691176470588235,
        "vocab_size-1": 387,
        "unique-1": 321,
        "entropy-1": 7.74294466470912,
        "distinct-2": 0.9325153374233128,
        "vocab_size-2": 608,
        "unique-2": 576,
        "entropy-2": 9.191474588260121,
        "cond_entropy-2": 1.309369737850209,
        "distinct-3": 0.9871794871794872,
        "vocab_size-3": 616,
        "unique-3": 608,
        "entropy-3": 9.259761193221157,
        "cond_entropy-3": 0.06893259830581948,
        "total_length-nopunct": 606,
        "mean_pred_length-nopunct": 21.642857142857142,
        "std_pred_length-nopunct": 7.334917886940744,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.6270627062706271,
        "vocab_size-1-nopunct": 380,
        "unique-1-nopunct": 321,
        "entropy-1-nopunct": 7.862844718160273,
        "distinct-2-nopunct": 0.9446366782006921,
        "vocab_size-2-nopunct": 546,
        "unique-2-nopunct": 523,
        "entropy-2-nopunct": 9.04382803974848,
        "cond_entropy-2-nopunct": 1.2334216769962505,
        "distinct-3-nopunct": 0.9945454545454545,
        "vocab_size-3-nopunct": 547,
        "unique-3-nopunct": 544,
        "entropy-3-nopunct": 9.09237871750285,
        "cond_entropy-3-nopunct": 0.05158837593101118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.92099,
            "recall": 0.8939,
            "fmeasure": 0.90383
        },
        "rouge2": {
            "precision": 0.83592,
            "recall": 0.81583,
            "fmeasure": 0.82017
        },
        "rougeL": {
            "precision": 0.90841,
            "recall": 0.89495,
            "fmeasure": 0.89662
        },
        "rougeLsum": {
            "precision": 0.90841,
            "recall": 0.89495,
            "fmeasure": 0.89662
        },
        "bleu": 86.07623,
        "nist": 10.216892709620684,
        "local_recall": {
            "1": 0.02697495183044316,
            "2": 0.14473684210526316,
            "3": 0.34210526315789475,
            "4": 0.5967741935483871,
            "5": 0.7096774193548387,
            "6": 0.873015873015873,
            "7": 0.9135802469135802,
            "8": 0.9838709677419355,
            "9": 0.9545454545454546,
            "10": 0.9767441860465116
        },
        "nubia": {
            "semantic_relation": 4.35408,
            "contradiction": 2.1672,
            "irrelevancy": 31.026,
            "logical_agreement": 66.8068,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.85696,
            "nubia_score": 0.6806
        },
        "meteor": 0.5411565783278101,
        "bleurt": 0.24509,
        "bertscore": {
            "precision": 0.97821,
            "recall": 0.9771,
            "f1": 0.97477
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.83974,
            "recall": 0.96047,
            "fmeasure": 0.89566
        },
        "rouge2": {
            "precision": 0.77564,
            "recall": 0.89899,
            "fmeasure": 0.83232
        },
        "rougeL": {
            "precision": 0.83974,
            "recall": 0.96047,
            "fmeasure": 0.89566
        },
        "rougeLsum": {
            "precision": 0.83974,
            "recall": 0.96047,
            "fmeasure": 0.89566
        },
        "bleu": 65.15835,
        "nist": 4.0604341916811695,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.9545454545454546
        },
        "nubia": {
            "semantic_relation": 4.32311,
            "contradiction": 6.03223,
            "irrelevancy": 73.19109,
            "logical_agreement": 20.77669,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.58238,
            "nubia_score": 0.65738
        },
        "meteor": 0.5451161102779325,
        "bleurt": -0.01724,
        "bertscore": {
            "precision": 0.90401,
            "recall": 0.97972,
            "f1": 0.93892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.98718,
            "recall": 0.90523,
            "fmeasure": 0.94206
        },
        "rouge2": {
            "precision": 0.92,
            "recall": 0.83142,
            "fmeasure": 0.87016
        },
        "rougeL": {
            "precision": 0.94872,
            "recall": 0.85752,
            "fmeasure": 0.89762
        },
        "rougeLsum": {
            "precision": 0.94872,
            "recall": 0.85752,
            "fmeasure": 0.89762
        },
        "bleu": 85.75747,
        "nist": 5.213174196220299,
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.9107,
            "contradiction": 0.86046,
            "irrelevancy": 0.98865,
            "logical_agreement": 98.15089,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.39218,
            "nubia_score": 0.95116
        },
        "meteor": 0.5249057565360988,
        "bleurt": 0.65426,
        "bertscore": {
            "precision": 0.98511,
            "recall": 0.97513,
            "f1": 0.97714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92361,
            "recall": 0.82051,
            "fmeasure": 0.86316
        },
        "rouge2": {
            "precision": 0.78384,
            "recall": 0.69291,
            "fmeasure": 0.72947
        },
        "rougeL": {
            "precision": 0.7662,
            "recall": 0.64848,
            "fmeasure": 0.6965
        },
        "rougeLsum": {
            "precision": 0.7662,
            "recall": 0.64848,
            "fmeasure": 0.6965
        },
        "bleu": 63.74294,
        "nist": 4.719162628023933,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8222222222222222
        },
        "nubia": {
            "semantic_relation": 4.03127,
            "contradiction": 0.51761,
            "irrelevancy": 20.32273,
            "logical_agreement": 79.15966,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.63499,
            "nubia_score": 0.6828
        },
        "meteor": 0.45463105562755696,
        "bleurt": 0.207,
        "bertscore": {
            "precision": 0.96084,
            "recall": 0.92611,
            "f1": 0.94094
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.71717,
            "fmeasure": 0.74444
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.425,
            "fmeasure": 0.43056
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.62626,
            "fmeasure": 0.64444
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.62626,
            "fmeasure": 0.64444
        },
        "bleu": 65.8037,
        "nist": 3.7314446766051224,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 3.32594,
            "contradiction": 98.93022,
            "irrelevancy": 0.69515,
            "logical_agreement": 0.37463,
            "grammar_ref": 5.60099,
            "grammar_hyp": 4.9577,
            "nubia_score": 0.40377
        },
        "meteor": 0.4800707485133138,
        "bleurt": 0.32404,
        "bertscore": {
            "precision": 0.9708,
            "recall": 0.9708,
            "f1": 0.9708
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 180,
        "mean_pred_length": 25.714285714285715,
        "std_pred_length": 5.993193418115152,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 38,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 130,
        "unique-1": 116,
        "entropy-1": 6.602786291540735,
        "distinct-2": 0.9595375722543352,
        "vocab_size-2": 166,
        "unique-2": 163,
        "entropy-2": 7.328474886731522,
        "cond_entropy-2": 0.6402751133036191,
        "distinct-3": 1.0,
        "vocab_size-3": 166,
        "unique-3": 166,
        "entropy-3": 7.375039431346908,
        "cond_entropy-3": 0.03899269754514165,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 22.857142857142858,
        "std_pred_length-nopunct": 4.485805276602166,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.76875,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.569288192465052,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.1504301434991655,
        "cond_entropy-2-nopunct": 0.6155764563737194,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 146,
        "entropy-3-nopunct": 7.18982455888002,
        "cond_entropy-3-nopunct": 0.04452252424627159,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.89641,
            "recall": 0.93669,
            "fmeasure": 0.91388
        },
        "rouge2": {
            "precision": 0.81775,
            "recall": 0.8653,
            "fmeasure": 0.83804
        },
        "rougeL": {
            "precision": 0.88041,
            "recall": 0.93239,
            "fmeasure": 0.90426
        },
        "rougeLsum": {
            "precision": 0.88041,
            "recall": 0.93239,
            "fmeasure": 0.90426
        },
        "bleu": 83.50653,
        "nist": 8.285121333469883,
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.13636363636363635,
            "3": 0.6666666666666666,
            "4": 0.9166666666666666,
            "5": 0.9375,
            "6": 1.0,
            "7": 0.8666666666666667,
            "8": 0.96,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "nubia": {
            "semantic_relation": 4.41095,
            "contradiction": 1.87568,
            "irrelevancy": 46.69438,
            "logical_agreement": 51.42994,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.63765,
            "nubia_score": 0.66442
        },
        "meteor": 0.5738409868165011,
        "bleurt": 0.28823,
        "bertscore": {
            "precision": 0.97662,
            "recall": 0.98319,
            "f1": 0.97774
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.60985,
            "fmeasure": 0.43087
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.38182,
            "fmeasure": 0.26237
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.60985,
            "fmeasure": 0.43087
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.60985,
            "fmeasure": 0.43087
        },
        "bleu": 11.85666,
        "nist": 1.1109759945164182,
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nubia": {
            "semantic_relation": 4.46721,
            "contradiction": 0.1966,
            "irrelevancy": 57.75132,
            "logical_agreement": 42.05208,
            "grammar_ref": 5.10481,
            "grammar_hyp": 3.63832,
            "nubia_score": 0.56018
        },
        "meteor": 0.27795583073328367,
        "bleurt": 0.04681,
        "bertscore": {
            "precision": 0.81651,
            "recall": 0.88649,
            "f1": 0.85006
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.875,
            "recall": 0.54444,
            "fmeasure": 0.66957
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.39827,
            "fmeasure": 0.49735
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "bleu": 21.7929,
        "nist": 0.998658318138759,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5555555555555556
        },
        "nubia": {
            "semantic_relation": 3.83037,
            "contradiction": 0.33214,
            "irrelevancy": 0.80058,
            "logical_agreement": 98.86728,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.87991,
            "nubia_score": 0.65307
        },
        "meteor": 0.2985045194114117,
        "bleurt": 0.05518,
        "bertscore": {
            "precision": 0.91326,
            "recall": 0.82764,
            "f1": 0.86606
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "bleu": 85.22457,
        "nist": 4.373609831586596,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "meteor": 0.5747920211718521,
        "bleurt": 0.78906,
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.4213,
            "fmeasure": 0.37193
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "bleu": 27.62935,
        "nist": 3.038485661251777,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "nubia": {
            "semantic_relation": 4.34536,
            "contradiction": 0.38822,
            "irrelevancy": 93.49285,
            "logical_agreement": 6.11894,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.77914,
            "nubia_score": 0.56712
        },
        "meteor": 0.42856343508545097,
        "bleurt": 0.22323,
        "bertscore": {
            "precision": 0.90112,
            "recall": 0.91088,
            "f1": 0.90597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79365,
            "fmeasure": 0.76863
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.90815
        },
        "bleu": 65.8037,
        "nist": 3.0185957289397036,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91106,
            "contradiction": 0.27234,
            "irrelevancy": 35.38581,
            "logical_agreement": 64.34184,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.9396,
            "nubia_score": 0.96685
        },
        "meteor": 0.902035682675735,
        "bleurt": 0.6833,
        "bertscore": {
            "precision": 0.97989,
            "recall": 0.97368,
            "f1": 0.97222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "bleu": 8.91377,
        "nist": 1.2418318179195795,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nubia": {
            "semantic_relation": 2.77982,
            "contradiction": 0.27781,
            "irrelevancy": 96.86995,
            "logical_agreement": 2.85225,
            "grammar_ref": 4.79209,
            "grammar_hyp": 4.14194,
            "nubia_score": 0.37188
        },
        "meteor": 0.24478644006080186,
        "bleurt": -0.66816,
        "bertscore": {
            "precision": 0.77928,
            "recall": 0.76132,
            "f1": 0.7702
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.52963,
            "fmeasure": 0.62393
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.28105,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.52422
        },
        "bleu": 25.43314,
        "nist": 0.6720027070852478,
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.6
        },
        "nubia": {
            "semantic_relation": 3.97598,
            "contradiction": 0.24545,
            "irrelevancy": 3.51789,
            "logical_agreement": 96.23665,
            "grammar_ref": 3.74426,
            "grammar_hyp": 4.16414,
            "nubia_score": 0.7061
        },
        "meteor": 0.29905304748723316,
        "bleurt": 0.29567,
        "bertscore": {
            "precision": 0.95289,
            "recall": 0.89204,
            "f1": 0.92146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.15362,
            "fmeasure": 0.22756
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.11522,
            "fmeasure": 0.17067
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.11522,
            "fmeasure": 0.17067
        },
        "bleu": 1.54731,
        "nist": 0.03118684365344194,
        "local_recall": {
            "1": 0.0,
            "2": 0.21052631578947367
        },
        "nubia": {
            "semantic_relation": 3.33192,
            "contradiction": 57.63789,
            "irrelevancy": 9.90365,
            "logical_agreement": 32.45846,
            "grammar_ref": 4.294,
            "grammar_hyp": 6.2006,
            "nubia_score": 0.1688
        },
        "meteor": 0.1288702928870293,
        "bleurt": -0.31963,
        "bertscore": {
            "precision": 0.85021,
            "recall": 0.76048,
            "f1": 0.80285
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "bleu": 78.25423,
        "nist": 3.470039480297192,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29005,
            "irrelevancy": 30.51014,
            "logical_agreement": 69.1998,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.57507,
            "nubia_score": 0.96926
        },
        "meteor": 0.5777337135978416,
        "bleurt": 0.85835,
        "bertscore": {
            "precision": 0.9943,
            "recall": 0.9943,
            "f1": 0.9943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "bleu": 54.45179,
        "nist": 2.9991662387674958,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.29853,
            "contradiction": 10.83902,
            "irrelevancy": 85.02242,
            "logical_agreement": 4.13857,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.23792,
            "nubia_score": 0.56981
        },
        "meteor": 0.5777337135978416,
        "bleurt": 0.49208,
        "bertscore": {
            "precision": 0.97343,
            "recall": 0.97664,
            "f1": 0.97503
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.32353,
            "recall": 0.6875,
            "fmeasure": 0.44
        },
        "rouge2": {
            "precision": 0.15625,
            "recall": 0.35714,
            "fmeasure": 0.21739
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.625,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.625,
            "fmeasure": 0.4
        },
        "bleu": 13.17331,
        "nist": 1.3843650161171894,
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "nubia": {
            "semantic_relation": 3.14424,
            "contradiction": 3.40762,
            "irrelevancy": 94.28273,
            "logical_agreement": 2.30965,
            "grammar_ref": 5.57872,
            "grammar_hyp": 4.61472,
            "nubia_score": 0.2999
        },
        "meteor": 0.2920251208870112,
        "bleurt": -0.32033,
        "bertscore": {
            "precision": 0.74771,
            "recall": 0.88198,
            "f1": 0.80554
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.73333,
            "fmeasure": 0.65598
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.45118,
            "fmeasure": 0.39899
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.73333,
            "fmeasure": 0.65598
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.73333,
            "fmeasure": 0.65598
        },
        "bleu": 23.57832,
        "nist": 2.2431107543686966,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.625
        },
        "nubia": {
            "semantic_relation": 4.14424,
            "contradiction": 0.14189,
            "irrelevancy": 80.05845,
            "logical_agreement": 19.79965,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.52603,
            "nubia_score": 0.72684
        },
        "meteor": 0.40186560291839535,
        "bleurt": 0.10918,
        "bertscore": {
            "precision": 0.90043,
            "recall": 0.9305,
            "f1": 0.91522
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nist": 3.867976246918685,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0,
        "bleurt": 0.73788,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.82353,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.625,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.76471,
            "fmeasure": 0.68421
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.76471,
            "fmeasure": 0.68421
        },
        "bleu": 45.00147,
        "nist": 2.8471815715025,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "nubia": {
            "semantic_relation": 4.20571,
            "contradiction": 0.10896,
            "irrelevancy": 95.1645,
            "logical_agreement": 4.72654,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.63812,
            "nubia_score": 0.82147
        },
        "meteor": 0.4156716758442836,
        "bleurt": 0.4799,
        "bertscore": {
            "precision": 0.93883,
            "recall": 0.95649,
            "f1": 0.94758
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "mT5_large/totto_test",
        "N": 111,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77611,
            "recall": 0.758,
            "fmeasure": 0.75611
        },
        "rouge2": {
            "precision": 0.5714,
            "recall": 0.55672,
            "fmeasure": 0.55559
        },
        "rougeL": {
            "precision": 0.68996,
            "recall": 0.67142,
            "fmeasure": 0.67082
        },
        "rougeLsum": {
            "precision": 0.68996,
            "recall": 0.67142,
            "fmeasure": 0.67082
        },
        "bleu": 53.9308,
        "nist": 7.815221867517161,
        "local_recall": {
            "1": 0.18787878787878787,
            "2": 0.42962962962962964,
            "3": 0.8140462889066241
        },
        "nubia": {
            "semantic_relation": 4.24472,
            "contradiction": 6.60314,
            "irrelevancy": 22.79703,
            "logical_agreement": 70.59983,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.48361,
            "nubia_score": 0.7533
        },
        "meteor": 0.41771207667769106,
        "bleurt": 0.38844,
        "bertscore": {
            "precision": 0.93772,
            "recall": 0.9347,
            "f1": 0.93387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.65744,
            "fmeasure": 0.69324
        },
        "rouge2": {
            "precision": 0.45614,
            "recall": 0.40693,
            "fmeasure": 0.43008
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.56785,
            "fmeasure": 0.59874
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.56785,
            "fmeasure": 0.59874
        },
        "bleu": 17.91004,
        "nist": 2.1652450545594526,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nubia": {
            "semantic_relation": 4.78513,
            "contradiction": 6.97382,
            "irrelevancy": 3.15663,
            "logical_agreement": 89.86955,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.23488,
            "nubia_score": 0.94771
        },
        "meteor": 0.31853588816221373,
        "bleurt": 0.18419,
        "bertscore": {
            "precision": 0.92212,
            "recall": 0.91844,
            "f1": 0.92028
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87121,
            "recall": 0.66342,
            "fmeasure": 0.71898
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.53219,
            "fmeasure": 0.56218
        },
        "rougeL": {
            "precision": 0.87121,
            "recall": 0.66342,
            "fmeasure": 0.71898
        },
        "rougeLsum": {
            "precision": 0.87121,
            "recall": 0.66342,
            "fmeasure": 0.71898
        },
        "bleu": 42.18015,
        "nist": 1.5514586755481785,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "nubia": {
            "semantic_relation": 4.00134,
            "contradiction": 55.04692,
            "irrelevancy": 15.61083,
            "logical_agreement": 29.34226,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.20734,
            "nubia_score": 0.52779
        },
        "meteor": 0.3537185578952078,
        "bleurt": 0.33058,
        "bertscore": {
            "precision": 0.96311,
            "recall": 0.89772,
            "f1": 0.9271
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.41915,
            "fmeasure": 0.5509
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.19697,
            "fmeasure": 0.26509
        },
        "rougeL": {
            "precision": 0.53158,
            "recall": 0.28038,
            "fmeasure": 0.367
        },
        "rougeLsum": {
            "precision": 0.53158,
            "recall": 0.28038,
            "fmeasure": 0.367
        },
        "bleu": 5.30154,
        "nist": 0.34284912813768,
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "nubia": {
            "semantic_relation": 3.02969,
            "contradiction": 30.72659,
            "irrelevancy": 6.97714,
            "logical_agreement": 62.29627,
            "grammar_ref": 3.44707,
            "grammar_hyp": 4.13224,
            "nubia_score": 0.32159
        },
        "meteor": 0.19598910045464085,
        "bleurt": -0.12961,
        "bertscore": {
            "precision": 0.90566,
            "recall": 0.84722,
            "f1": 0.87317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.96667,
            "fmeasure": 0.92558
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.7967,
            "fmeasure": 0.76322
        },
        "rougeL": {
            "precision": 0.87302,
            "recall": 0.94815,
            "fmeasure": 0.90848
        },
        "rougeLsum": {
            "precision": 0.87302,
            "recall": 0.94815,
            "fmeasure": 0.90848
        },
        "bleu": 73.89984,
        "nist": 4.847640225047175,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nubia": {
            "semantic_relation": 4.64501,
            "contradiction": 0.81301,
            "irrelevancy": 97.11121,
            "logical_agreement": 2.07577,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.47807,
            "nubia_score": 0.8531
        },
        "meteor": 0.5465891818029109,
        "bleurt": 0.57483,
        "bertscore": {
            "precision": 0.98748,
            "recall": 0.99271,
            "f1": 0.99009
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "mT5_large/totto_test",
        "N": 3,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.87778,
            "recall": 0.87172,
            "fmeasure": 0.8746
        },
        "rouge2": {
            "precision": 0.78363,
            "recall": 0.78028,
            "fmeasure": 0.78187
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.82828,
            "fmeasure": 0.83069
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.82828,
            "fmeasure": 0.83069
        },
        "bleu": 69.4612,
        "nist": 4.5279618611158545,
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.8888888888888888
        },
        "nubia": {
            "semantic_relation": 4.50717,
            "contradiction": 0.36637,
            "irrelevancy": 33.38498,
            "logical_agreement": 66.24865,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.0703,
            "nubia_score": 0.84154
        },
        "meteor": 0.52349324363923,
        "bleurt": 0.66433,
        "bertscore": {
            "precision": 0.94948,
            "recall": 0.96683,
            "f1": 0.9579
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "mT5_large/totto_test",
        "N": 48,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.80493,
            "recall": 0.79825,
            "fmeasure": 0.79395
        },
        "rouge2": {
            "precision": 0.64033,
            "recall": 0.63765,
            "fmeasure": 0.63359
        },
        "rougeL": {
            "precision": 0.73932,
            "recall": 0.72415,
            "fmeasure": 0.72525
        },
        "rougeLsum": {
            "precision": 0.73932,
            "recall": 0.72415,
            "fmeasure": 0.72525
        },
        "bleu": 65.74115,
        "nist": 7.439329214643607,
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.5875,
            "3": 0.8323471400394478
        },
        "nubia": {
            "semantic_relation": 4.52126,
            "contradiction": 4.9615,
            "irrelevancy": 16.9802,
            "logical_agreement": 78.0583,
            "grammar_ref": 4.06325,
            "grammar_hyp": 3.95137,
            "nubia_score": 0.87683
        },
        "meteor": 0.46550428526058407,
        "bleurt": 0.59679,
        "bertscore": {
            "precision": 0.95412,
            "recall": 0.95002,
            "f1": 0.95039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "mT5_large/totto_test",
        "N": 123,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.76717,
            "recall": 0.7472,
            "fmeasure": 0.7453
        },
        "rouge2": {
            "precision": 0.53698,
            "recall": 0.52381,
            "fmeasure": 0.52263
        },
        "rougeL": {
            "precision": 0.66226,
            "recall": 0.64538,
            "fmeasure": 0.64308
        },
        "rougeLsum": {
            "precision": 0.66226,
            "recall": 0.64538,
            "fmeasure": 0.64308
        },
        "bleu": 50.73902,
        "nist": 7.496285675603985,
        "local_recall": {
            "1": 0.21201413427561838,
            "2": 0.39464882943143814,
            "3": 0.7659738260200154
        },
        "nubia": {
            "semantic_relation": 4.26519,
            "contradiction": 4.63254,
            "irrelevancy": 24.8474,
            "logical_agreement": 70.52006,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.69844,
            "nubia_score": 0.7592
        },
        "meteor": 0.4027353819390191,
        "bleurt": 0.37031,
        "bertscore": {
            "precision": 0.92997,
            "recall": 0.92486,
            "f1": 0.92551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "mT5_large/totto_test",
        "N": 29,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.88244,
            "recall": 0.86332,
            "fmeasure": 0.87002
        },
        "rouge2": {
            "precision": 0.75223,
            "recall": 0.73353,
            "fmeasure": 0.7406
        },
        "rougeL": {
            "precision": 0.83419,
            "recall": 0.81522,
            "fmeasure": 0.82208
        },
        "rougeLsum": {
            "precision": 0.83419,
            "recall": 0.81522,
            "fmeasure": 0.82208
        },
        "bleu": 74.15025,
        "nist": 7.4409438993801285,
        "local_recall": {
            "1": 0.175,
            "2": 0.47368421052631576,
            "3": 0.8994082840236687
        },
        "nubia": {
            "semantic_relation": 4.45579,
            "contradiction": 7.15386,
            "irrelevancy": 8.816,
            "logical_agreement": 84.03014,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.22484,
            "nubia_score": 0.84543
        },
        "meteor": 0.4846941471868639,
        "bleurt": 0.61999,
        "bertscore": {
            "precision": 0.96682,
            "recall": 0.96039,
            "f1": 0.96213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "mT5_large/totto_test",
        "N": 112,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74736,
            "recall": 0.72953,
            "fmeasure": 0.72677
        },
        "rouge2": {
            "precision": 0.5032,
            "recall": 0.4839,
            "fmeasure": 0.48677
        },
        "rougeL": {
            "precision": 0.63163,
            "recall": 0.62038,
            "fmeasure": 0.61652
        },
        "rougeLsum": {
            "precision": 0.63163,
            "recall": 0.62038,
            "fmeasure": 0.61652
        },
        "bleu": 44.5284,
        "nist": 7.343287454784519,
        "local_recall": {
            "1": 0.2314540059347181,
            "2": 0.4519230769230769,
            "3": 0.7839020122484689
        },
        "nubia": {
            "semantic_relation": 4.11912,
            "contradiction": 9.80513,
            "irrelevancy": 27.45836,
            "logical_agreement": 62.73651,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.70567,
            "nubia_score": 0.70997
        },
        "meteor": 0.38491796050629423,
        "bleurt": 0.23829,
        "bertscore": {
            "precision": 0.92068,
            "recall": 0.92023,
            "f1": 0.91892
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1850,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.74594,
            "recall": 0.73287,
            "fmeasure": 0.72625
        },
        "rouge2": {
            "precision": 0.54311,
            "recall": 0.53282,
            "fmeasure": 0.52834
        },
        "rougeL": {
            "precision": 0.67395,
            "recall": 0.66419,
            "fmeasure": 0.657
        },
        "rougeLsum": {
            "precision": 0.67395,
            "recall": 0.66419,
            "fmeasure": 0.657
        },
        "bleu": 51.06678,
        "nist": 9.471902607972641,
        "local_recall": {
            "1": 0.23401486988847583,
            "2": 0.49064528445971745,
            "3": 0.7823079481210509
        },
        "nubia": {
            "semantic_relation": 4.18268,
            "contradiction": 7.67914,
            "irrelevancy": 30.49936,
            "logical_agreement": 61.82149,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.68167,
            "nubia_score": 0.73174
        },
        "meteor": 0.40565289762016565,
        "bleurt": 0.32272,
        "bertscore": {
            "precision": 0.928,
            "recall": 0.92678,
            "f1": 0.92556
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "mT5_large/totto_test",
        "N": 91,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.79681,
            "recall": 0.74791,
            "fmeasure": 0.76068
        },
        "rouge2": {
            "precision": 0.60391,
            "recall": 0.5551,
            "fmeasure": 0.57032
        },
        "rougeL": {
            "precision": 0.71203,
            "recall": 0.66841,
            "fmeasure": 0.68022
        },
        "rougeLsum": {
            "precision": 0.71203,
            "recall": 0.66841,
            "fmeasure": 0.68022
        },
        "bleu": 54.40675,
        "nist": 7.624737175598426,
        "local_recall": {
            "1": 0.22072072072072071,
            "2": 0.4849624060150376,
            "3": 0.7783613445378151
        },
        "nubia": {
            "semantic_relation": 4.18132,
            "contradiction": 6.08069,
            "irrelevancy": 24.12393,
            "logical_agreement": 69.79537,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.38954,
            "nubia_score": 0.74561
        },
        "meteor": 0.4118494607407599,
        "bleurt": 0.32564,
        "bertscore": {
            "precision": 0.93696,
            "recall": 0.92308,
            "f1": 0.92875
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "mT5_large/totto_test",
        "N": 2221,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.77645,
            "recall": 0.75317,
            "fmeasure": 0.7543
        },
        "rouge2": {
            "precision": 0.54312,
            "recall": 0.52679,
            "fmeasure": 0.52713
        },
        "rougeL": {
            "precision": 0.66787,
            "recall": 0.65028,
            "fmeasure": 0.64981
        },
        "rougeLsum": {
            "precision": 0.66787,
            "recall": 0.65028,
            "fmeasure": 0.64981
        },
        "bleu": 48.0816,
        "nist": 10.199606259159776,
        "local_recall": {
            "1": 0.2156670403587444,
            "2": 0.4558310055865922,
            "3": 0.7971392587261605
        },
        "nubia": {
            "semantic_relation": 4.32303,
            "contradiction": 6.46892,
            "irrelevancy": 27.87606,
            "logical_agreement": 65.65502,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.79338,
            "nubia_score": 0.75794
        },
        "meteor": 0.40799405401148026,
        "bleurt": 0.31465,
        "bertscore": {
            "precision": 0.93323,
            "recall": 0.93082,
            "f1": 0.93042
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "mT5_large/totto_test",
        "N": 1369,
        "msttr-100": 0.72549,
        "msttr-100_nopunct": 0.77894,
        "total_length": 127813,
        "mean_pred_length": 16.599090909090908,
        "std_pred_length": 6.841711201195699,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 77,
        "distinct-1": 0.17117194651561266,
        "vocab_size-1": 21878,
        "unique-1": 15096,
        "entropy-1": 10.0864298628411,
        "distinct-2": 0.5457943769616944,
        "vocab_size-2": 65557,
        "unique-2": 54786,
        "entropy-2": 14.638098518091274,
        "cond_entropy-2": 4.16366619451092,
        "distinct-3": 0.7802567318726482,
        "vocab_size-3": 87711,
        "unique-3": 79862,
        "entropy-3": 15.939155252015796,
        "cond_entropy-3": 1.2714408266373882,
        "total_length-nopunct": 111182,
        "mean_pred_length-nopunct": 14.43922077922078,
        "std_pred_length-nopunct": 5.878405951928815,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.19660556564911585,
        "vocab_size-1-nopunct": 21859,
        "unique-1-nopunct": 15094,
        "entropy-1-nopunct": 10.651921079229073,
        "distinct-2-nopunct": 0.5903538779691154,
        "vocab_size-2-nopunct": 61091,
        "unique-2-nopunct": 52154,
        "entropy-2-nopunct": 14.640933057250537,
        "cond_entropy-2-nopunct": 4.156022744623075,
        "distinct-3-nopunct": 0.807093190787413,
        "vocab_size-3-nopunct": 77305,
        "unique-3-nopunct": 71261,
        "entropy-3-nopunct": 15.812070330118555,
        "cond_entropy-3-nopunct": 1.2433537296410553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75935,
            "recall": 0.73938,
            "fmeasure": 0.73877
        },
        "rouge2": {
            "precision": 0.52223,
            "recall": 0.50998,
            "fmeasure": 0.50869
        },
        "rougeL": {
            "precision": 0.63769,
            "recall": 0.6241,
            "fmeasure": 0.62177
        },
        "rougeLsum": {
            "precision": 0.63769,
            "recall": 0.6241,
            "fmeasure": 0.62177
        },
        "bleu": 47.23692,
        "nist": 9.851187936756293,
        "local_recall": {
            "1": 0.2211764705882353,
            "2": 0.44441729782555583,
            "3": 0.7831914508241261
        },
        "nubia": {
            "semantic_relation": 4.22516,
            "contradiction": 9.10033,
            "irrelevancy": 30.51365,
            "logical_agreement": 60.38602,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.46683,
            "nubia_score": 0.73606
        },
        "meteor": 0.40176981104479026,
        "bleurt": 0.27028,
        "bertscore": {
            "precision": 0.92882,
            "recall": 0.92617,
            "f1": 0.92584
        }
    },
    "totto_test": {
        "predictions_file": "mT5_large/totto_test",
        "N": 7700,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "rouge1": {
            "precision": 0.75413,
            "recall": 0.7349,
            "fmeasure": 0.73285
        },
        "rouge2": {
            "precision": 0.5278,
            "recall": 0.51507,
            "fmeasure": 0.51296
        },
        "rougeL": {
            "precision": 0.65383,
            "recall": 0.6402,
            "fmeasure": 0.63659
        },
        "rougeLsum": {
            "precision": 0.65383,
            "recall": 0.6402,
            "fmeasure": 0.63659
        },
        "bleu": 46.70964,
        "nist": 10.768428667235126,
        "local_recall": {
            "1": 0.22489764481738214,
            "2": 0.4669708822251195,
            "3": 0.7775349760128601
        },
        "nubia": {
            "semantic_relation": 4.18433,
            "contradiction": 8.69259,
            "irrelevancy": 30.35459,
            "logical_agreement": 60.95282,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.63706,
            "nubia_score": 0.72663
        },
        "meteor": 0.3964562700457436,
        "bleurt": 0.2811,
        "bertscore": {
            "precision": 0.92817,
            "recall": 0.9255,
            "f1": 0.92514
        }
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "mT5_large/totto_challenge_test_scramble",
        "N": 378
    },
    "wiki_auto_asset_turk_val": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_val",
        "N": 20000,
        "msttr-100": 0.26831,
        "msttr-100_nopunct": 0.25172,
        "total_length": 421280,
        "mean_pred_length": 21.064,
        "std_pred_length": 8.82518577708141,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 56,
        "distinct-1": 0.022001993923281428,
        "vocab_size-1": 9269,
        "unique-1": 0,
        "entropy-1": 9.844404228290918,
        "distinct-2": 0.07107505980861244,
        "vocab_size-2": 28521,
        "unique-2": 0,
        "entropy-2": 14.074242391109696,
        "cond_entropy-2": 3.9531348195422202,
        "distinct-3": 0.09182752832563995,
        "vocab_size-3": 35012,
        "unique-3": 0,
        "entropy-3": 14.929219483730758,
        "cond_entropy-3": 0.8748351977723162,
        "total_length-nopunct": 369760,
        "mean_pred_length-nopunct": 18.488,
        "std_pred_length-nopunct": 7.693234430329028,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.025018931198615316,
        "vocab_size-1-nopunct": 9251,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.299079956274767,
        "distinct-2-nopunct": 0.07461402104300091,
        "vocab_size-2-nopunct": 26097,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 14.078478688558489,
        "cond_entropy-2-nopunct": 3.9469797820191244,
        "distinct-3-nopunct": 0.0939531780688986,
        "vocab_size-3-nopunct": 30982,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.845383263504337,
        "cond_entropy-3-nopunct": 0.808883404911465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_val.json",
        "rouge1": {
            "precision": 0.74174,
            "recall": 0.7972,
            "fmeasure": 0.75655
        },
        "rouge2": {
            "precision": 0.56849,
            "recall": 0.60821,
            "fmeasure": 0.57783
        },
        "rougeL": {
            "precision": 0.69961,
            "recall": 0.751,
            "fmeasure": 0.71325
        },
        "rougeLsum": {
            "precision": 0.69961,
            "recall": 0.751,
            "fmeasure": 0.71325
        },
        "bleu": 48.44882,
        "nist": 10.005518777025165,
        "local_recall": {
            "1": 0.7858738710447722
        },
        "sari": 50.8424,
        "nubia": {
            "semantic_relation": 4.5271,
            "contradiction": 1.8891,
            "irrelevancy": 26.69348,
            "logical_agreement": 71.41742,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.70421,
            "nubia_score": 0.75207
        },
        "meteor": 0.43363627731874693,
        "bleurt": 0.39041,
        "bertscore": {
            "precision": 0.92653,
            "recall": 0.94161,
            "f1": 0.93342
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72641,
        "msttr-100_nopunct": 0.77159,
        "total_length": 7872,
        "mean_pred_length": 21.92757660167131,
        "std_pred_length": 9.145697344708735,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 47,
        "distinct-1": 0.36826727642276424,
        "vocab_size-1": 2899,
        "unique-1": 2127,
        "entropy-1": 9.246974371814963,
        "distinct-2": 0.8348196459470252,
        "vocab_size-2": 6272,
        "unique-2": 5809,
        "entropy-2": 12.278967879716744,
        "cond_entropy-2": 2.794687580953878,
        "distinct-3": 0.9636566955549343,
        "vocab_size-3": 6894,
        "unique-3": 6774,
        "entropy-3": 12.676595660248898,
        "cond_entropy-3": 0.41401468373945943,
        "total_length-nopunct": 6910,
        "mean_pred_length-nopunct": 19.24791086350975,
        "std_pred_length-nopunct": 7.931274425961432,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.41794500723589,
        "vocab_size-1-nopunct": 2888,
        "unique-1-nopunct": 2127,
        "entropy-1-nopunct": 9.62963196659567,
        "distinct-2-nopunct": 0.8630743397954511,
        "vocab_size-2-nopunct": 5654,
        "unique-2-nopunct": 5281,
        "entropy-2-nopunct": 12.213759639242365,
        "cond_entropy-2-nopunct": 2.7129905594099775,
        "distinct-3-nopunct": 0.9828811369509044,
        "vocab_size-3-nopunct": 6086,
        "unique-3-nopunct": 6005,
        "entropy-3-nopunct": 12.557750920798163,
        "cond_entropy-3-nopunct": 0.36560027478198537,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "rouge1": {
            "precision": 0.90381,
            "recall": 0.92223,
            "fmeasure": 0.90968
        },
        "rouge2": {
            "precision": 0.81248,
            "recall": 0.83712,
            "fmeasure": 0.82047
        },
        "rougeL": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "rougeLsum": {
            "precision": 0.89178,
            "recall": 0.91364,
            "fmeasure": 0.89915
        },
        "bleu": 87.35189,
        "nist": 13.426135311676614,
        "local_recall": {
            "1": 0.03270856302829842,
            "2": 0.18665768194070081,
            "3": 0.4108433734939759,
            "4": 0.6284403669724771,
            "5": 0.7556904400606981,
            "6": 0.8633802816901408,
            "7": 0.9180327868852459,
            "8": 0.962605548854041,
            "9": 0.9587301587301588,
            "10": 0.9868217054263566
        },
        "sari": 49.41358,
        "nubia": {
            "semantic_relation": 4.42253,
            "contradiction": 2.08708,
            "irrelevancy": 34.08185,
            "logical_agreement": 63.83107,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.70222,
            "nubia_score": 0.70222
        },
        "meteor": 0.5615520197272345,
        "bleurt": 0.32083,
        "bertscore": {
            "precision": 0.97293,
            "recall": 0.98169,
            "f1": 0.97511
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.72892,
        "msttr-100_nopunct": 0.77415,
        "total_length": 7473,
        "mean_pred_length": 20.81615598885794,
        "std_pred_length": 9.260673476905579,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 52,
        "distinct-1": 0.3579553057674294,
        "vocab_size-1": 2675,
        "unique-1": 1949,
        "entropy-1": 9.169092875128287,
        "distinct-2": 0.8344110205229126,
        "vocab_size-2": 5936,
        "unique-2": 5505,
        "entropy-2": 12.196322045700507,
        "cond_entropy-2": 2.775686154122889,
        "distinct-3": 0.9613619541080681,
        "vocab_size-3": 6494,
        "unique-3": 6386,
        "entropy-3": 12.578535338759838,
        "cond_entropy-3": 0.4024308993694754,
        "total_length-nopunct": 6591,
        "mean_pred_length-nopunct": 18.35933147632312,
        "std_pred_length-nopunct": 8.059086506490225,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.40388408435745715,
        "vocab_size-1-nopunct": 2662,
        "unique-1-nopunct": 1948,
        "entropy-1-nopunct": 9.522437969113502,
        "distinct-2-nopunct": 0.8629653401797176,
        "vocab_size-2-nopunct": 5378,
        "unique-2-nopunct": 5029,
        "entropy-2-nopunct": 12.141330080564511,
        "cond_entropy-2-nopunct": 2.7548271047488933,
        "distinct-3-nopunct": 0.9816107611101652,
        "vocab_size-3-nopunct": 5765,
        "unique-3-nopunct": 5685,
        "entropy-3-nopunct": 12.477857403520586,
        "cond_entropy-3-nopunct": 0.3587983845878242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "rouge1": {
            "precision": 0.84966,
            "recall": 0.81593,
            "fmeasure": 0.82379
        },
        "rouge2": {
            "precision": 0.71247,
            "recall": 0.68636,
            "fmeasure": 0.69017
        },
        "rougeL": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "rougeLsum": {
            "precision": 0.81918,
            "recall": 0.79116,
            "fmeasure": 0.79593
        },
        "bleu": 68.84591,
        "nist": 11.338523983358163,
        "local_recall": {
            "1": 0.04647707979626486,
            "2": 0.17752234993614305,
            "3": 0.437636761487965,
            "4": 0.5768621236133122,
            "5": 0.6728971962616822,
            "6": 0.7874396135265701,
            "7": 0.8953799159984727
        },
        "sari": 49.3597,
        "nubia": {
            "semantic_relation": 4.3706,
            "contradiction": 4.05805,
            "irrelevancy": 17.82847,
            "logical_agreement": 78.11348,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.92526,
            "nubia_score": 0.71246
        },
        "meteor": 0.47385603354829703,
        "bleurt": 0.24018,
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.95042,
            "f1": 0.94997
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.71338,
        "msttr-100_nopunct": 0.75877,
        "total_length": 6569,
        "mean_pred_length": 18.298050139275766,
        "std_pred_length": 9.345594441971532,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 64,
        "distinct-1": 0.3551529913228802,
        "vocab_size-1": 2333,
        "unique-1": 1677,
        "entropy-1": 9.014760719005292,
        "distinct-2": 0.825925925925926,
        "vocab_size-2": 5129,
        "unique-2": 4702,
        "entropy-2": 11.998292088717218,
        "cond_entropy-2": 2.696435102549583,
        "distinct-3": 0.9512903777132115,
        "vocab_size-3": 5566,
        "unique-3": 5434,
        "entropy-3": 12.338348367354458,
        "cond_entropy-3": 0.3612970078639179,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 8.025307964620573,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 49,
        "distinct-1-nopunct": 0.4034051424600417,
        "vocab_size-1-nopunct": 2322,
        "unique-1-nopunct": 1675,
        "entropy-1-nopunct": 9.387625264372602,
        "distinct-2-nopunct": 0.8589957383731702,
        "vocab_size-2-nopunct": 4636,
        "unique-2-nopunct": 4284,
        "entropy-2-nopunct": 11.963074257488541,
        "cond_entropy-2-nopunct": 2.7234390129682033,
        "distinct-3-nopunct": 0.9769749900754268,
        "vocab_size-3-nopunct": 4922,
        "unique-3-nopunct": 4828,
        "entropy-3-nopunct": 12.248008441664854,
        "cond_entropy-3-nopunct": 0.3082144156968157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "rouge1": {
            "precision": 0.5762,
            "recall": 0.55452,
            "fmeasure": 0.5456
        },
        "rouge2": {
            "precision": 0.33148,
            "recall": 0.3262,
            "fmeasure": 0.31387
        },
        "rougeL": {
            "precision": 0.51053,
            "recall": 0.50341,
            "fmeasure": 0.48786
        },
        "rougeLsum": {
            "precision": 0.51053,
            "recall": 0.50341,
            "fmeasure": 0.48786
        },
        "bleu": 28.21856,
        "nist": 6.915437886402388,
        "local_recall": {
            "1": 0.05178743961352657,
            "2": 0.12087912087912088,
            "3": 0.1899179366940211,
            "4": 0.24645892351274787,
            "5": 0.28419654714475434,
            "6": 0.3608374384236453,
            "7": 0.4041095890410959,
            "8": 0.5396825396825397,
            "9": 0.6827338129496403
        },
        "sari": 40.41128,
        "nubia": {
            "semantic_relation": 3.03156,
            "contradiction": 17.05547,
            "irrelevancy": 45.10571,
            "logical_agreement": 37.83881,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.39245,
            "nubia_score": 0.34121
        },
        "meteor": 0.28214281616291453,
        "bleurt": -0.38899,
        "bertscore": {
            "precision": 0.87561,
            "recall": 0.87792,
            "f1": 0.87201
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.71507,
        "msttr-100_nopunct": 0.75333,
        "total_length": 6923,
        "mean_pred_length": 19.284122562674096,
        "std_pred_length": 9.953235990438346,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 84,
        "distinct-1": 0.36559295103278927,
        "vocab_size-1": 2531,
        "unique-1": 1908,
        "entropy-1": 9.070897934308986,
        "distinct-2": 0.8104814137720902,
        "vocab_size-2": 5320,
        "unique-2": 4883,
        "entropy-2": 11.9735695687929,
        "cond_entropy-2": 2.6293493784709434,
        "distinct-3": 0.9408541498791297,
        "vocab_size-3": 5838,
        "unique-3": 5693,
        "entropy-3": 12.36466860664727,
        "cond_entropy-3": 0.4164105436961144,
        "total_length-nopunct": 6072,
        "mean_pred_length-nopunct": 16.91364902506964,
        "std_pred_length-nopunct": 8.686159566900864,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 73,
        "distinct-1-nopunct": 0.41436100131752307,
        "vocab_size-1-nopunct": 2516,
        "unique-1-nopunct": 1903,
        "entropy-1-nopunct": 9.434657629600915,
        "distinct-2-nopunct": 0.8442149483633817,
        "vocab_size-2-nopunct": 4823,
        "unique-2-nopunct": 4451,
        "entropy-2-nopunct": 11.974744215176512,
        "cond_entropy-2-nopunct": 2.685616111391715,
        "distinct-3-nopunct": 0.9703025775121404,
        "vocab_size-3-nopunct": 5195,
        "unique-3-nopunct": 5083,
        "entropy-3-nopunct": 12.31796345269056,
        "cond_entropy-3-nopunct": 0.3710980006650795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "rouge1": {
            "precision": 0.62691,
            "recall": 0.62647,
            "fmeasure": 0.60992
        },
        "rouge2": {
            "precision": 0.40914,
            "recall": 0.42495,
            "fmeasure": 0.39995
        },
        "rougeL": {
            "precision": 0.57209,
            "recall": 0.5824,
            "fmeasure": 0.55884
        },
        "rougeLsum": {
            "precision": 0.57209,
            "recall": 0.5824,
            "fmeasure": 0.55884
        },
        "bleu": 37.16153,
        "nist": 7.879918984835743,
        "local_recall": {
            "1": 0.0527536231884058,
            "2": 0.12156593406593406,
            "3": 0.2227432590855803,
            "4": 0.3101983002832861,
            "5": 0.38778220451527223,
            "6": 0.43842364532019706,
            "7": 0.5376712328767124,
            "8": 0.6259920634920635,
            "9": 0.746043165467626
        },
        "sari": 43.97185,
        "nubia": {
            "semantic_relation": 3.35082,
            "contradiction": 12.13059,
            "irrelevancy": 42.52419,
            "logical_agreement": 45.34522,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.60352,
            "nubia_score": 0.37994
        },
        "meteor": 0.31159218355116813,
        "bleurt": -0.4508,
        "bertscore": {
            "precision": 0.87787,
            "recall": 0.89718,
            "f1": 0.88245
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.71515,
        "msttr-100_nopunct": 0.76351,
        "total_length": 6607,
        "mean_pred_length": 18.403899721448468,
        "std_pred_length": 8.017118617078477,
        "median_pred_length": 17.0,
        "min_pred_length": 4,
        "max_pred_length": 42,
        "distinct-1": 0.384138035416982,
        "vocab_size-1": 2538,
        "unique-1": 1960,
        "entropy-1": 9.125764639598897,
        "distinct-2": 0.8290653008962868,
        "vocab_size-2": 5180,
        "unique-2": 4744,
        "entropy-2": 12.003500862701298,
        "cond_entropy-2": 2.58102654610952,
        "distinct-3": 0.9526235354049923,
        "vocab_size-3": 5610,
        "unique-3": 5494,
        "entropy-3": 12.33355909697215,
        "cond_entropy-3": 0.3533514410580992,
        "total_length-nopunct": 5776,
        "mean_pred_length-nopunct": 16.089136490250695,
        "std_pred_length-nopunct": 6.9384776798231345,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.4373268698060942,
        "vocab_size-1-nopunct": 2526,
        "unique-1-nopunct": 1957,
        "entropy-1-nopunct": 9.515956300138994,
        "distinct-2-nopunct": 0.8641314380653499,
        "vocab_size-2-nopunct": 4681,
        "unique-2-nopunct": 4320,
        "entropy-2-nopunct": 11.992930857679141,
        "cond_entropy-2-nopunct": 2.6230018588314716,
        "distinct-3-nopunct": 0.9810201660735468,
        "vocab_size-3-nopunct": 4962,
        "unique-3-nopunct": 4878,
        "entropy-3-nopunct": 12.26383418109969,
        "cond_entropy-3-nopunct": 0.2928437957189901,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "rouge1": {
            "precision": 0.56715,
            "recall": 0.55457,
            "fmeasure": 0.54259
        },
        "rouge2": {
            "precision": 0.33857,
            "recall": 0.33959,
            "fmeasure": 0.3243
        },
        "rougeL": {
            "precision": 0.51878,
            "recall": 0.51541,
            "fmeasure": 0.4994
        },
        "rougeLsum": {
            "precision": 0.51878,
            "recall": 0.51541,
            "fmeasure": 0.4994
        },
        "bleu": 29.81417,
        "nist": 7.0462396826145515,
        "local_recall": {
            "1": 0.04657004830917874,
            "2": 0.11881868131868131,
            "3": 0.19577960140679954,
            "4": 0.2747875354107649,
            "5": 0.34794156706507307,
            "6": 0.39408866995073893,
            "7": 0.4429223744292237,
            "8": 0.5287698412698413,
            "9": 0.6474820143884892
        },
        "sari": 42.91105,
        "nubia": {
            "semantic_relation": 3.06231,
            "contradiction": 15.35584,
            "irrelevancy": 42.71333,
            "logical_agreement": 41.93083,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.07081,
            "nubia_score": 0.30097
        },
        "meteor": 0.26570239367946735,
        "bleurt": -0.7377,
        "bertscore": {
            "precision": 0.84776,
            "recall": 0.87138,
            "f1": 0.85482
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.70687,
        "msttr-100_nopunct": 0.74914,
        "total_length": 6741,
        "mean_pred_length": 18.77715877437326,
        "std_pred_length": 9.460395779578517,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 88,
        "distinct-1": 0.3453493546951491,
        "vocab_size-1": 2328,
        "unique-1": 1648,
        "entropy-1": 8.975629054569588,
        "distinct-2": 0.802413036665622,
        "vocab_size-2": 5121,
        "unique-2": 4610,
        "entropy-2": 11.92202016429395,
        "cond_entropy-2": 2.6735491144905437,
        "distinct-3": 0.9365764569151586,
        "vocab_size-3": 5641,
        "unique-3": 5463,
        "entropy-3": 12.311453815310433,
        "cond_entropy-3": 0.41578480448166427,
        "total_length-nopunct": 5893,
        "mean_pred_length-nopunct": 16.415041782729805,
        "std_pred_length-nopunct": 7.959710310648998,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 61,
        "distinct-1-nopunct": 0.39317834719158323,
        "vocab_size-1-nopunct": 2317,
        "unique-1-nopunct": 1647,
        "entropy-1-nopunct": 9.346109308244788,
        "distinct-2-nopunct": 0.8415251174557282,
        "vocab_size-2-nopunct": 4657,
        "unique-2-nopunct": 4229,
        "entropy-2-nopunct": 11.94523506945978,
        "cond_entropy-2-nopunct": 2.7453299079629665,
        "distinct-3-nopunct": 0.9669565217391304,
        "vocab_size-3-nopunct": 5004,
        "unique-3-nopunct": 4863,
        "entropy-3-nopunct": 12.26542158632012,
        "cond_entropy-3-nopunct": 0.34445321926348277,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "rouge1": {
            "precision": 0.68176,
            "recall": 0.66778,
            "fmeasure": 0.65371
        },
        "rouge2": {
            "precision": 0.49092,
            "recall": 0.48315,
            "fmeasure": 0.46631
        },
        "rougeL": {
            "precision": 0.62758,
            "recall": 0.62694,
            "fmeasure": 0.60719
        },
        "rougeLsum": {
            "precision": 0.62758,
            "recall": 0.62694,
            "fmeasure": 0.60719
        },
        "bleu": 45.40404,
        "nist": 9.003538788520519,
        "local_recall": {
            "1": 0.051594202898550726,
            "2": 0.14285714285714285,
            "3": 0.23798358733880423,
            "4": 0.3286118980169972,
            "5": 0.4169986719787517,
            "6": 0.48645320197044334,
            "7": 0.6118721461187214,
            "8": 0.6755952380952381,
            "9": 0.7827338129496403
        },
        "sari": 42.37999,
        "nubia": {
            "semantic_relation": 3.53229,
            "contradiction": 9.23645,
            "irrelevancy": 42.5341,
            "logical_agreement": 48.22945,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.0939,
            "nubia_score": 0.45038
        },
        "meteor": 0.35099530269290974,
        "bleurt": -0.16812,
        "bertscore": {
            "precision": 0.90748,
            "recall": 0.9111,
            "f1": 0.90394
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.71865,
        "msttr-100_nopunct": 0.75308,
        "total_length": 7407,
        "mean_pred_length": 20.632311977715876,
        "std_pred_length": 9.65641864860646,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 70,
        "distinct-1": 0.3444039422168219,
        "vocab_size-1": 2551,
        "unique-1": 1805,
        "entropy-1": 9.084045433739604,
        "distinct-2": 0.8203745743473326,
        "vocab_size-2": 5782,
        "unique-2": 5277,
        "entropy-2": 12.158427286127742,
        "cond_entropy-2": 2.8252395351406077,
        "distinct-3": 0.9582897294064883,
        "vocab_size-3": 6410,
        "unique-3": 6265,
        "entropy-3": 12.565575247776028,
        "cond_entropy-3": 0.4215450271913769,
        "total_length-nopunct": 6556,
        "mean_pred_length-nopunct": 18.261838440111422,
        "std_pred_length-nopunct": 8.555469863585039,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 62,
        "distinct-1-nopunct": 0.3872788285539963,
        "vocab_size-1-nopunct": 2539,
        "unique-1-nopunct": 1803,
        "entropy-1-nopunct": 9.414575006915392,
        "distinct-2-nopunct": 0.8473454897531063,
        "vocab_size-2-nopunct": 5251,
        "unique-2-nopunct": 4822,
        "entropy-2-nopunct": 12.104198303060127,
        "cond_entropy-2-nopunct": 2.8157984719571925,
        "distinct-3-nopunct": 0.9792737238780405,
        "vocab_size-3-nopunct": 5717,
        "unique-3-nopunct": 5612,
        "entropy-3-nopunct": 12.467142552537798,
        "cond_entropy-3-nopunct": 0.38285611974712364,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "rouge1": {
            "precision": 0.59849,
            "recall": 0.57034,
            "fmeasure": 0.56666
        },
        "rouge2": {
            "precision": 0.35339,
            "recall": 0.34529,
            "fmeasure": 0.33684
        },
        "rougeL": {
            "precision": 0.5352,
            "recall": 0.51664,
            "fmeasure": 0.50939
        },
        "rougeLsum": {
            "precision": 0.5352,
            "recall": 0.51664,
            "fmeasure": 0.50939
        },
        "bleu": 30.68347,
        "nist": 7.012303760459233,
        "local_recall": {
            "1": 0.06727504244482173,
            "2": 0.14559386973180077,
            "3": 0.24945295404814005,
            "4": 0.2931854199683043,
            "5": 0.3603322949117342,
            "6": 0.5054347826086957,
            "7": 0.6380297823596792
        },
        "sari": 40.73002,
        "nubia": {
            "semantic_relation": 3.27122,
            "contradiction": 15.66082,
            "irrelevancy": 42.12821,
            "logical_agreement": 42.21097,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.17231,
            "nubia_score": 0.42194
        },
        "meteor": 0.28929191585726616,
        "bleurt": -0.26941,
        "bertscore": {
            "precision": 0.88007,
            "recall": 0.87658,
            "f1": 0.8753
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.72264,
        "msttr-100_nopunct": 0.76413,
        "total_length": 7245,
        "mean_pred_length": 20.181058495821727,
        "std_pred_length": 9.624891013060424,
        "median_pred_length": 18.0,
        "min_pred_length": 4,
        "max_pred_length": 60,
        "distinct-1": 0.36411318150448585,
        "vocab_size-1": 2638,
        "unique-1": 1956,
        "entropy-1": 9.1665808172702,
        "distinct-2": 0.8332849259366831,
        "vocab_size-2": 5738,
        "unique-2": 5287,
        "entropy-2": 12.169333727356097,
        "cond_entropy-2": 2.743348471990909,
        "distinct-3": 0.9620039834533476,
        "vocab_size-3": 6279,
        "unique-3": 6159,
        "entropy-3": 12.53874321580406,
        "cond_entropy-3": 0.38754280727805607,
        "total_length-nopunct": 6380,
        "mean_pred_length-nopunct": 17.771587743732592,
        "std_pred_length-nopunct": 8.30029535920864,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 54,
        "distinct-1-nopunct": 0.4114420062695925,
        "vocab_size-1-nopunct": 2625,
        "unique-1-nopunct": 1952,
        "entropy-1-nopunct": 9.525795754996468,
        "distinct-2-nopunct": 0.8624813153961136,
        "vocab_size-2-nopunct": 5193,
        "unique-2-nopunct": 4822,
        "entropy-2-nopunct": 12.113399884115305,
        "cond_entropy-2-nopunct": 2.722324523584724,
        "distinct-3-nopunct": 0.9811020840692335,
        "vocab_size-3-nopunct": 5555,
        "unique-3-nopunct": 5469,
        "entropy-3-nopunct": 12.42521003681981,
        "cond_entropy-3-nopunct": 0.3333278872079042,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "rouge1": {
            "precision": 0.64605,
            "recall": 0.60804,
            "fmeasure": 0.60819
        },
        "rouge2": {
            "precision": 0.43122,
            "recall": 0.40882,
            "fmeasure": 0.40642
        },
        "rougeL": {
            "precision": 0.60065,
            "recall": 0.56736,
            "fmeasure": 0.56637
        },
        "rougeLsum": {
            "precision": 0.60065,
            "recall": 0.56736,
            "fmeasure": 0.56637
        },
        "bleu": 38.1501,
        "nist": 7.81626701858116,
        "local_recall": {
            "1": 0.051570458404074704,
            "2": 0.14559386973180077,
            "3": 0.25601750547045954,
            "4": 0.36450079239302696,
            "5": 0.45275181723779856,
            "6": 0.5591787439613527,
            "7": 0.6823214967544865
        },
        "sari": 41.24138,
        "nubia": {
            "semantic_relation": 3.47132,
            "contradiction": 13.88119,
            "irrelevancy": 35.81226,
            "logical_agreement": 50.30655,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.64641,
            "nubia_score": 0.40999
        },
        "meteor": 0.31321393040341905,
        "bleurt": -0.45786,
        "bertscore": {
            "precision": 0.87977,
            "recall": 0.88633,
            "f1": 0.87988
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.73133,
        "msttr-100_nopunct": 0.77227,
        "total_length": 7574,
        "mean_pred_length": 21.0974930362117,
        "std_pred_length": 10.202079058381251,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 66,
        "distinct-1": 0.3819646157908635,
        "vocab_size-1": 2893,
        "unique-1": 2263,
        "entropy-1": 9.261874326410128,
        "distinct-2": 0.8327096327096327,
        "vocab_size-2": 6008,
        "unique-2": 5556,
        "entropy-2": 12.222078719227145,
        "cond_entropy-2": 2.7085330589180736,
        "distinct-3": 0.9568261376896149,
        "vocab_size-3": 6560,
        "unique-3": 6424,
        "entropy-3": 12.58252411466808,
        "cond_entropy-3": 0.3747832441461742,
        "total_length-nopunct": 6638,
        "mean_pred_length-nopunct": 18.49025069637883,
        "std_pred_length-nopunct": 8.789667883204682,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.4335643266043989,
        "vocab_size-1-nopunct": 2878,
        "unique-1-nopunct": 2259,
        "entropy-1-nopunct": 9.637270477298735,
        "distinct-2-nopunct": 0.8671763019589106,
        "vocab_size-2-nopunct": 5445,
        "unique-2-nopunct": 5082,
        "entropy-2-nopunct": 12.192052917182014,
        "cond_entropy-2-nopunct": 2.6796410717024193,
        "distinct-3-nopunct": 0.9798986486486486,
        "vocab_size-3-nopunct": 5801,
        "unique-3-nopunct": 5700,
        "entropy-3-nopunct": 12.48849068298295,
        "cond_entropy-3-nopunct": 0.3161263926673092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "rouge1": {
            "precision": 0.58379,
            "recall": 0.57329,
            "fmeasure": 0.5623
        },
        "rouge2": {
            "precision": 0.36243,
            "recall": 0.36465,
            "fmeasure": 0.35187
        },
        "rougeL": {
            "precision": 0.54607,
            "recall": 0.54158,
            "fmeasure": 0.5269
        },
        "rougeLsum": {
            "precision": 0.54607,
            "recall": 0.54158,
            "fmeasure": 0.5269
        },
        "bleu": 30.673,
        "nist": 6.809201467476336,
        "local_recall": {
            "1": 0.04456706281833616,
            "2": 0.140485312899106,
            "3": 0.24726477024070023,
            "4": 0.34072900158478603,
            "5": 0.3811007268951194,
            "6": 0.5138888888888888,
            "7": 0.6403207331042382
        },
        "sari": 43.65912,
        "nubia": {
            "semantic_relation": 3.34244,
            "contradiction": 15.63684,
            "irrelevancy": 40.13346,
            "logical_agreement": 44.22969,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.99138,
            "nubia_score": 0.36659
        },
        "meteor": 0.2805698994071363,
        "bleurt": -0.6927,
        "bertscore": {
            "precision": 0.85293,
            "recall": 0.8748,
            "f1": 0.86077
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "mT5_large/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.70808,
        "msttr-100_nopunct": 0.74,
        "total_length": 7815,
        "mean_pred_length": 21.768802228412255,
        "std_pred_length": 10.847359611585627,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 63,
        "distinct-1": 0.3307741522712732,
        "vocab_size-1": 2585,
        "unique-1": 1799,
        "entropy-1": 9.097150898889707,
        "distinct-2": 0.7962714592274678,
        "vocab_size-2": 5937,
        "unique-2": 5300,
        "entropy-2": 12.145664694167381,
        "cond_entropy-2": 2.817452661111638,
        "distinct-3": 0.9339157390446667,
        "vocab_size-3": 6628,
        "unique-3": 6358,
        "entropy-3": 12.568433923036073,
        "cond_entropy-3": 0.44268836764929725,
        "total_length-nopunct": 6883,
        "mean_pred_length-nopunct": 19.172701949860723,
        "std_pred_length-nopunct": 9.45231287065549,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 57,
        "distinct-1-nopunct": 0.3738195554264129,
        "vocab_size-1-nopunct": 2573,
        "unique-1-nopunct": 1797,
        "entropy-1-nopunct": 9.436695516448333,
        "distinct-2-nopunct": 0.831698344573881,
        "vocab_size-2-nopunct": 5426,
        "unique-2-nopunct": 4890,
        "entropy-2-nopunct": 12.147345905264292,
        "cond_entropy-2-nopunct": 2.8341527650198493,
        "distinct-3-nopunct": 0.9602595296025953,
        "vocab_size-3-nopunct": 5920,
        "unique-3-nopunct": 5706,
        "entropy-3-nopunct": 12.505588692588947,
        "cond_entropy-3-nopunct": 0.3797170088298616,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "rouge1": {
            "precision": 0.71263,
            "recall": 0.69759,
            "fmeasure": 0.68693
        },
        "rouge2": {
            "precision": 0.54315,
            "recall": 0.5351,
            "fmeasure": 0.52222
        },
        "rougeL": {
            "precision": 0.67294,
            "recall": 0.66057,
            "fmeasure": 0.64783
        },
        "rougeLsum": {
            "precision": 0.67294,
            "recall": 0.66057,
            "fmeasure": 0.64783
        },
        "bleu": 49.74438,
        "nist": 8.989786364906994,
        "local_recall": {
            "1": 0.05539049235993209,
            "2": 0.17113665389527458,
            "3": 0.33698030634573306,
            "4": 0.41679873217115687,
            "5": 0.5586708203530634,
            "6": 0.6388888888888888,
            "7": 0.7926689576174112
        },
        "sari": 42.81785,
        "nubia": {
            "semantic_relation": 3.79927,
            "contradiction": 10.07766,
            "irrelevancy": 31.98884,
            "logical_agreement": 57.9335,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.99179,
            "nubia_score": 0.52994
        },
        "meteor": 0.38162156336682734,
        "bleurt": -0.05401,
        "bertscore": {
            "precision": 0.91564,
            "recall": 0.91403,
            "f1": 0.91171
        }
    }
}
